{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13632383", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13632383", "key": "HADOOP-19736", "fields": {"summary": "ABFS: Support for new auth type: User-bound SAS", "description": "Adding support for new authentication type: user bound SAS", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18032721", "id": "18032721", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 opened a new pull request, #8051:\nURL: https://github.com/apache/hadoop/pull/8051\n\n   ### Description of PR\r\n   Adding support for new authentication type: user bound SAS\r\n   \r\n   ### How was this patch tested?\r\n   Test suite will be run for the patch\r\n   \r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-24T09:44:17.799+0000", "updated": "2025-10-24T09:44:17.799+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18032747", "id": "18032747", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#issuecomment-3442714485\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  34m 38s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 50s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 45s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 37s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   1m 23s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  26m 16s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 34s | [/patch-mvninstall-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-mvninstall-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/blanks-eol.txt) |  The patch has 3 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   0m 22s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 36 new + 4 unchanged - 0 fixed = 40 total (was 4)  |\r\n   | -1 :x: |  mvnsite  |   0m 37s | [/patch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 32s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 2 new + 1472 unchanged - 0 fixed = 1474 total (was 1472)  |\r\n   | -1 :x: |  javadoc  |   0m 30s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 2 new + 1413 unchanged - 0 fixed = 1415 total (was 1413)  |\r\n   | -1 :x: |  spotbugs  |   0m 34s | [/patch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  29m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 41s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 34s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 119m 57s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8051 |\r\n   | JIRA Issue | HADOOP-19736 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets markdownlint |\r\n   | uname | Linux 88abe69cd96c 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 05b52e40f1bc99edc039fc0d2ab5f83d1ceb0da9 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/testReport/ |\r\n   | Max. process+thread count | 779 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-24T11:45:38.208+0000", "updated": "2025-10-24T11:45:38.208+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18033415", "id": "18033415", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#issuecomment-3454395745\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   4m 52s |  |  Docker failed to build run-specific yetus/hadoop:tp-4947}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8051 |\r\n   | JIRA Issue | HADOOP-19736 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T03:40:16.476+0000", "updated": "2025-10-28T03:40:16.476+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18033416", "id": "18033416", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#issuecomment-3454455082\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   6m 57s |  |  Docker failed to build run-specific yetus/hadoop:tp-29291}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8051 |\r\n   | JIRA Issue | HADOOP-19736 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/3/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T04:12:50.949+0000", "updated": "2025-10-28T04:12:50.949+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18033442", "id": "18033442", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#issuecomment-3454654532\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   6m  5s |  |  Docker failed to build run-specific yetus/hadoop:tp-27223}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8051 |\r\n   | JIRA Issue | HADOOP-19736 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/4/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T05:32:29.452+0000", "updated": "2025-10-28T05:32:29.452+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18033802", "id": "18033802", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2472593921\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClientHandler.java:\n##########\n@@ -80,6 +80,25 @@ public AbfsClientHandler(final URL baseUrl,\n         abfsClientContext);\n   }\n \n+  public AbfsClientHandler(final URL baseUrl,\n\nReview Comment:\n   Java doc missing for the constructor\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/AbfsHttpConstants.java:\n##########\n@@ -187,7 +187,8 @@ public enum ApiVersion {\n     DEC_12_2019(\"2019-12-12\"),\n     APR_10_2021(\"2021-04-10\"),\n     AUG_03_2023(\"2023-08-03\"),\n-    NOV_04_2024(\"2024-11-04\");\n+    NOV_04_2024(\"2024-11-04\"),\n+    JULY_05_2025(\"2025-07-05\");\n\nReview Comment:\n   We should follow the same format: JUL_05_2025, what do you think?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -174,6 +174,17 @@ public AbfsDfsClient(final URL baseUrl,\n         encryptionContextProvider, abfsClientContext, AbfsServiceType.DFS);\n   }\n \n+  public AbfsDfsClient(final URL baseUrl,\n\nReview Comment:\n   Java doc missing\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -570,6 +570,11 @@ public void signRequest(final AbfsHttpOperation httpOperation, int bytesToSign)\n         // do nothing; the SAS token should already be appended to the query string\n         httpOperation.setMaskForSAS(); //mask sig/oid from url for logs\n         break;\n+      case UserboundSASWithOAuth:\n+        httpOperation.setRequestProperty(HttpHeaderConfigurations.AUTHORIZATION,\n+            client.getAccessToken());\n+        httpOperation.setMaskForSAS(); //mask sig/oid from url for logs\n\nReview Comment:\n   Typo: *sign\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/constants/TestConfigurationKeys.java:\n##########\n@@ -55,6 +55,9 @@ public final class TestConfigurationKeys {\n \n   public static final String FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID = \"fs.azure.test.app.service.principal.object.id\";\n \n+  public static final String FS_AZURE_END_USER_TENANT_ID = \"fs.azure.test.end.user.tenant.id\";\n\nReview Comment:\n   Rename the variable to FS_AZURE_TEST_END_USER_TENANT_ID \n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1741,7 +1741,15 @@ private void initializeClient(URI uri, String fileSystemName,\n     } else if (authType == AuthType.SAS) {\n       LOG.trace(\"Fetching SAS Token Provider\");\n       sasTokenProvider = abfsConfiguration.getSASTokenProvider();\n-    } else {\n+    } else if(authType == AuthType.UserboundSASWithOAuth){\n+      LOG.trace(\"Fetching SAS and OAuth Token Provider for user bound SAS\");\n+      AzureADAuthenticator.init(abfsConfiguration);\n+      tokenProvider = abfsConfiguration.getTokenProvider();\n+      ExtensionHelper.bind(tokenProvider, uri,\n+          abfsConfiguration.getRawConfiguration());\n+      sasTokenProvider = abfsConfiguration.getSASTokenProviderForUserBoundSAS();\n+    }\n\nReview Comment:\n   else can be started in the same line after }, same format we are using at other places as well.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -363,6 +363,21 @@ public AbfsClient(final URL baseUrl,\n     this.sasTokenProvider = sasTokenProvider;\n   }\n \n+  public AbfsClient(final URL baseUrl,\n\nReview Comment:\n   Java doc missing\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/constants/TestConfigurationKeys.java:\n##########\n@@ -55,6 +55,9 @@ public final class TestConfigurationKeys {\n \n   public static final String FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID = \"fs.azure.test.app.service.principal.object.id\";\n \n+  public static final String FS_AZURE_END_USER_TENANT_ID = \"fs.azure.test.end.user.tenant.id\";\n+  public static final String FS_AZURE_END_USER_OBJECT_ID = \"fs.azure.test.end.user.object.id\";\n\nReview Comment:\n   same as above\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/site/markdown/index.md:\n##########\n@@ -303,6 +303,7 @@ driven by them.\n 3. Deployed in-Azure with the Azure VMs providing OAuth 2.0 tokens to the application, \"Managed Instance\".\n 4. Using Shared Access Signature (SAS) tokens provided by a custom implementation of the SASTokenProvider interface.\n 5. By directly configuring a fixed Shared Access Signature (SAS) token in the account configuration settings files.\n+6. Using user-bound SAS auth type, which is requires OAuth 2.0 setup (point 2 above) and SAS setup (point 4 above)\n\nReview Comment:\n   Grammatical mistake: which requires or which is required?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AuthType.java:\n##########\n@@ -24,5 +24,6 @@ public enum AuthType {\n     SharedKey,\n     OAuth,\n     Custom,\n-    SAS\n+    SAS,\n+     UserboundSASWithOAuth\n\nReview Comment:\n   Format issue: There is an extra space before UserboundSASWithOAuth\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1741,7 +1741,15 @@ private void initializeClient(URI uri, String fileSystemName,\n     } else if (authType == AuthType.SAS) {\n       LOG.trace(\"Fetching SAS Token Provider\");\n       sasTokenProvider = abfsConfiguration.getSASTokenProvider();\n-    } else {\n+    } else if(authType == AuthType.UserboundSASWithOAuth){\n\nReview Comment:\n   Missing space between if and (\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1770,7 +1778,12 @@ private void initializeClient(URI uri, String fileSystemName,\n     }\n \n     LOG.trace(\"Initializing AbfsClient for {}\", baseUrl);\n-    if (tokenProvider != null) {\n+    if(tokenProvider != null && sasTokenProvider != null){\n\nReview Comment:\n   Space between if and (\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1770,7 +1778,12 @@ private void initializeClient(URI uri, String fileSystemName,\n     }\n \n     LOG.trace(\"Initializing AbfsClient for {}\", baseUrl);\n-    if (tokenProvider != null) {\n+    if(tokenProvider != null && sasTokenProvider != null){\n+      this.clientHandler = new AbfsClientHandler(baseUrl, creds, abfsConfiguration,\n+          tokenProvider, sasTokenProvider, encryptionContextProvider,\n+          populateAbfsClientContext());\n+    }\n+    else if (tokenProvider != null) {\n\nReview Comment:\n   same as above\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-29T11:36:52.517+0000", "updated": "2025-10-29T11:36:52.517+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034389", "id": "18034389", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481295321\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/utils/SASGenerator.java:\n##########\n@@ -41,7 +41,8 @@ public abstract class SASGenerator {\n   public enum AuthenticationVersion {\n     Nov18(\"2018-11-09\"),\n     Dec19(\"2019-12-12\"),\n-    Feb20(\"2020-02-10\");\n+    Feb20(\"2020-02-10\"),\n+    July5(\"2025-07-05\");\n\nReview Comment:\n   Same here should be JUL\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T12:43:06.479+0000", "updated": "2025-10-31T12:43:06.479+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034391", "id": "18034391", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481303390\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/utils/DelegationSASGenerator.java:\n##########\n@@ -36,20 +38,26 @@ public class DelegationSASGenerator extends SASGenerator {\n   private final String ske;\n   private final String sks = \"b\";\n   private final String skv;\n+  private final String skdutid;\n+  private final String sduoid;\n \n-  public DelegationSASGenerator(byte[] userDelegationKey, String skoid, String sktid, String skt, String ske, String skv) {\n+  public DelegationSASGenerator(byte[] userDelegationKey, String skoid, String sktid, String skt, String ske, String skv, String skdutid, String sduoid) {\n\nReview Comment:\n   add javadoc for what do all these params signify\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T12:45:50.560+0000", "updated": "2025-10-31T12:45:50.560+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034392", "id": "18034392", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481307275\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/utils/DelegationSASGenerator.java:\n##########\n@@ -117,6 +125,15 @@ public String getDelegationSAS(String accountName, String containerName, String\n     qb.addQuery(\"ske\", ske);\n     qb.addQuery(\"sks\", sks);\n     qb.addQuery(\"skv\", skv);\n+\n+    //skdutid and sduoid are required for user bound SAS only\n+    if(!Objects.equals(skdutid, EMPTY_STRING)){\n\nReview Comment:\n   spaces after if\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T12:47:31.632+0000", "updated": "2025-10-31T12:47:31.632+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034393", "id": "18034393", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481327412\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/utils/DelegationSASGenerator.java:\n##########\n@@ -197,6 +228,7 @@ private String computeSignatureForSAS(String sp, String st, String se, String sv\n \n     String stringToSign = sb.toString();\n     LOG.debug(\"Delegation SAS stringToSign: \" + stringToSign.replace(\"\\n\", \".\"));\n+    System.out.println(\"Delegation SAS stringToSign: \" + stringToSign.replace(\"\\n\", \".\"));\n\nReview Comment:\n   Remove this\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T12:55:56.570+0000", "updated": "2025-10-31T12:55:56.570+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034396", "id": "18034396", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481341233\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/extensions/MockUserBoundSASTokenProvider.java:\n##########\n@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.extensions;\n+\n+import java.io.IOException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n+import org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.InvalidUriException;\n+import org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsHttpHeader;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsJdkHttpOperation;\n+import org.apache.hadoop.fs.azurebfs.utils.Base64;\n+import org.apache.hadoop.fs.azurebfs.utils.DelegationSASGenerator;\n+import org.apache.hadoop.fs.azurebfs.utils.SASGenerator;\n+import org.apache.hadoop.security.AccessControlException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_CONNECTION_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_READ_TIMEOUT;\n+\n+/**\n+ * A mock user-bound SAS token provider implementation.\n+ */\n+\n+public class MockUserBoundSASTokenProvider implements SASTokenProvider {\n+\n+  private DelegationSASGenerator generator;\n+\n+  public static final String TEST_OWNER = \"325f1619-4205-432f-9fce-3fd594325ce5\";\n+  public static final String CORRELATION_ID = \"66ff4ffc-ff17-417e-a2a9-45db8c5b0b5c\";\n+  public static final String NO_AGENT_PATH = \"NoAgentPath\";\n+\n+  @Override\n+  public void initialize(Configuration configuration, String accountName) throws IOException {\n+    String appID = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_ID);\n+    String appSecret = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SECRET);\n+    String sktid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_TENANT_ID);\n+    String skoid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID);\n+    String skt = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().minus(SASGenerator.FIVE_MINUTES));\n+    String ske = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().plus(SASGenerator.ONE_DAY));\n+    String skv = SASGenerator.AuthenticationVersion.July5.toString();\n+\n+    String skdutid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_TENANT_ID);\n+    String sduoid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_OBJECT_ID);\n+\n+    byte[] key = getUserDelegationKey(accountName, appID, appSecret, sktid, skt, ske, skv, skdutid);\n+\n+    generator = new DelegationSASGenerator(key, skoid, sktid, skt, ske, skv, skdutid, sduoid);\n+  }\n+\n+  // Invokes the AAD v2.0 authentication endpoint with a client credentials grant to get an\n+  // access token.  See https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow.\n+  private String getAuthorizationHeader(String accountName, String appID, String appSecret, String sktid) throws IOException {\n\nReview Comment:\n   include params in javadoc as well\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:01:32.292+0000", "updated": "2025-10-31T13:01:32.292+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034397", "id": "18034397", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481342577\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/extensions/MockUserBoundSASTokenProvider.java:\n##########\n@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.extensions;\n+\n+import java.io.IOException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n+import org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.InvalidUriException;\n+import org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsHttpHeader;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsJdkHttpOperation;\n+import org.apache.hadoop.fs.azurebfs.utils.Base64;\n+import org.apache.hadoop.fs.azurebfs.utils.DelegationSASGenerator;\n+import org.apache.hadoop.fs.azurebfs.utils.SASGenerator;\n+import org.apache.hadoop.security.AccessControlException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_CONNECTION_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_READ_TIMEOUT;\n+\n+/**\n+ * A mock user-bound SAS token provider implementation.\n+ */\n+\n+public class MockUserBoundSASTokenProvider implements SASTokenProvider {\n+\n+  private DelegationSASGenerator generator;\n+\n+  public static final String TEST_OWNER = \"325f1619-4205-432f-9fce-3fd594325ce5\";\n+  public static final String CORRELATION_ID = \"66ff4ffc-ff17-417e-a2a9-45db8c5b0b5c\";\n+  public static final String NO_AGENT_PATH = \"NoAgentPath\";\n+\n+  @Override\n+  public void initialize(Configuration configuration, String accountName) throws IOException {\n+    String appID = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_ID);\n+    String appSecret = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SECRET);\n+    String sktid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_TENANT_ID);\n+    String skoid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID);\n+    String skt = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().minus(SASGenerator.FIVE_MINUTES));\n+    String ske = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().plus(SASGenerator.ONE_DAY));\n+    String skv = SASGenerator.AuthenticationVersion.July5.toString();\n+\n+    String skdutid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_TENANT_ID);\n+    String sduoid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_OBJECT_ID);\n+\n+    byte[] key = getUserDelegationKey(accountName, appID, appSecret, sktid, skt, ske, skv, skdutid);\n+\n+    generator = new DelegationSASGenerator(key, skoid, sktid, skt, ske, skv, skdutid, sduoid);\n+  }\n+\n+  // Invokes the AAD v2.0 authentication endpoint with a client credentials grant to get an\n+  // access token.  See https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow.\n+  private String getAuthorizationHeader(String accountName, String appID, String appSecret, String sktid) throws IOException {\n+    String authEndPoint = String.format(\"https://login.microsoftonline.com/%s/oauth2/v2.0/token\", sktid);\n\nReview Comment:\n   Add a constant for the string\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:02:02.390+0000", "updated": "2025-10-31T13:02:02.390+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034398", "id": "18034398", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481343344\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/extensions/MockUserBoundSASTokenProvider.java:\n##########\n@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.extensions;\n+\n+import java.io.IOException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n+import org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.InvalidUriException;\n+import org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsHttpHeader;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsJdkHttpOperation;\n+import org.apache.hadoop.fs.azurebfs.utils.Base64;\n+import org.apache.hadoop.fs.azurebfs.utils.DelegationSASGenerator;\n+import org.apache.hadoop.fs.azurebfs.utils.SASGenerator;\n+import org.apache.hadoop.security.AccessControlException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_CONNECTION_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_READ_TIMEOUT;\n+\n+/**\n+ * A mock user-bound SAS token provider implementation.\n+ */\n+\n+public class MockUserBoundSASTokenProvider implements SASTokenProvider {\n+\n+  private DelegationSASGenerator generator;\n+\n+  public static final String TEST_OWNER = \"325f1619-4205-432f-9fce-3fd594325ce5\";\n+  public static final String CORRELATION_ID = \"66ff4ffc-ff17-417e-a2a9-45db8c5b0b5c\";\n+  public static final String NO_AGENT_PATH = \"NoAgentPath\";\n+\n+  @Override\n+  public void initialize(Configuration configuration, String accountName) throws IOException {\n+    String appID = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_ID);\n+    String appSecret = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SECRET);\n+    String sktid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_TENANT_ID);\n+    String skoid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID);\n+    String skt = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().minus(SASGenerator.FIVE_MINUTES));\n+    String ske = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().plus(SASGenerator.ONE_DAY));\n+    String skv = SASGenerator.AuthenticationVersion.July5.toString();\n+\n+    String skdutid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_TENANT_ID);\n+    String sduoid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_OBJECT_ID);\n+\n+    byte[] key = getUserDelegationKey(accountName, appID, appSecret, sktid, skt, ske, skv, skdutid);\n+\n+    generator = new DelegationSASGenerator(key, skoid, sktid, skt, ske, skv, skdutid, sduoid);\n+  }\n+\n+  // Invokes the AAD v2.0 authentication endpoint with a client credentials grant to get an\n+  // access token.  See https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow.\n+  private String getAuthorizationHeader(String accountName, String appID, String appSecret, String sktid) throws IOException {\n+    String authEndPoint = String.format(\"https://login.microsoftonline.com/%s/oauth2/v2.0/token\", sktid);\n+    ClientCredsTokenProvider provider = new ClientCredsTokenProvider(authEndPoint, appID, appSecret);\n+    return \"Bearer \" + provider.getToken().getAccessToken();\n+  }\n+\n+  private byte[] getUserDelegationKey(String accountName, String appID, String appSecret,\n\nReview Comment:\n   javadoc\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:02:27.168+0000", "updated": "2025-10-31T13:02:27.168+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034399", "id": "18034399", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481344728\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/extensions/MockUserBoundSASTokenProvider.java:\n##########\n@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.extensions;\n+\n+import java.io.IOException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n+import org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.InvalidUriException;\n+import org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsHttpHeader;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsJdkHttpOperation;\n+import org.apache.hadoop.fs.azurebfs.utils.Base64;\n+import org.apache.hadoop.fs.azurebfs.utils.DelegationSASGenerator;\n+import org.apache.hadoop.fs.azurebfs.utils.SASGenerator;\n+import org.apache.hadoop.security.AccessControlException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_CONNECTION_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_READ_TIMEOUT;\n+\n+/**\n+ * A mock user-bound SAS token provider implementation.\n+ */\n+\n+public class MockUserBoundSASTokenProvider implements SASTokenProvider {\n+\n+  private DelegationSASGenerator generator;\n+\n+  public static final String TEST_OWNER = \"325f1619-4205-432f-9fce-3fd594325ce5\";\n+  public static final String CORRELATION_ID = \"66ff4ffc-ff17-417e-a2a9-45db8c5b0b5c\";\n+  public static final String NO_AGENT_PATH = \"NoAgentPath\";\n+\n+  @Override\n+  public void initialize(Configuration configuration, String accountName) throws IOException {\n+    String appID = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_ID);\n+    String appSecret = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SECRET);\n+    String sktid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_TENANT_ID);\n+    String skoid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID);\n+    String skt = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().minus(SASGenerator.FIVE_MINUTES));\n+    String ske = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().plus(SASGenerator.ONE_DAY));\n+    String skv = SASGenerator.AuthenticationVersion.July5.toString();\n+\n+    String skdutid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_TENANT_ID);\n+    String sduoid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_OBJECT_ID);\n+\n+    byte[] key = getUserDelegationKey(accountName, appID, appSecret, sktid, skt, ske, skv, skdutid);\n+\n+    generator = new DelegationSASGenerator(key, skoid, sktid, skt, ske, skv, skdutid, sduoid);\n+  }\n+\n+  // Invokes the AAD v2.0 authentication endpoint with a client credentials grant to get an\n+  // access token.  See https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow.\n+  private String getAuthorizationHeader(String accountName, String appID, String appSecret, String sktid) throws IOException {\n+    String authEndPoint = String.format(\"https://login.microsoftonline.com/%s/oauth2/v2.0/token\", sktid);\n+    ClientCredsTokenProvider provider = new ClientCredsTokenProvider(authEndPoint, appID, appSecret);\n+    return \"Bearer \" + provider.getToken().getAccessToken();\n+  }\n+\n+  private byte[] getUserDelegationKey(String accountName, String appID, String appSecret,\n+      String sktid, String skt, String ske, String skv, String skdutid) throws IOException {\n+\n+    String method = \"POST\";\n\nReview Comment:\n   we have constants for HTTP methods, can be used here\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:03:02.216+0000", "updated": "2025-10-31T13:03:02.216+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034400", "id": "18034400", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481347800\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/extensions/MockUserBoundSASTokenProvider.java:\n##########\n@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.extensions;\n+\n+import java.io.IOException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n+import org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.InvalidUriException;\n+import org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsHttpHeader;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsJdkHttpOperation;\n+import org.apache.hadoop.fs.azurebfs.utils.Base64;\n+import org.apache.hadoop.fs.azurebfs.utils.DelegationSASGenerator;\n+import org.apache.hadoop.fs.azurebfs.utils.SASGenerator;\n+import org.apache.hadoop.security.AccessControlException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_CONNECTION_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_READ_TIMEOUT;\n+\n+/**\n+ * A mock user-bound SAS token provider implementation.\n+ */\n+\n+public class MockUserBoundSASTokenProvider implements SASTokenProvider {\n+\n+  private DelegationSASGenerator generator;\n+\n+  public static final String TEST_OWNER = \"325f1619-4205-432f-9fce-3fd594325ce5\";\n+  public static final String CORRELATION_ID = \"66ff4ffc-ff17-417e-a2a9-45db8c5b0b5c\";\n+  public static final String NO_AGENT_PATH = \"NoAgentPath\";\n+\n+  @Override\n+  public void initialize(Configuration configuration, String accountName) throws IOException {\n+    String appID = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_ID);\n+    String appSecret = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SECRET);\n+    String sktid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_TENANT_ID);\n+    String skoid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID);\n+    String skt = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().minus(SASGenerator.FIVE_MINUTES));\n+    String ske = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().plus(SASGenerator.ONE_DAY));\n+    String skv = SASGenerator.AuthenticationVersion.July5.toString();\n+\n+    String skdutid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_TENANT_ID);\n+    String sduoid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_OBJECT_ID);\n+\n+    byte[] key = getUserDelegationKey(accountName, appID, appSecret, sktid, skt, ske, skv, skdutid);\n+\n+    generator = new DelegationSASGenerator(key, skoid, sktid, skt, ske, skv, skdutid, sduoid);\n+  }\n+\n+  // Invokes the AAD v2.0 authentication endpoint with a client credentials grant to get an\n+  // access token.  See https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow.\n+  private String getAuthorizationHeader(String accountName, String appID, String appSecret, String sktid) throws IOException {\n+    String authEndPoint = String.format(\"https://login.microsoftonline.com/%s/oauth2/v2.0/token\", sktid);\n+    ClientCredsTokenProvider provider = new ClientCredsTokenProvider(authEndPoint, appID, appSecret);\n+    return \"Bearer \" + provider.getToken().getAccessToken();\n+  }\n+\n+  private byte[] getUserDelegationKey(String accountName, String appID, String appSecret,\n+      String sktid, String skt, String ske, String skv, String skdutid) throws IOException {\n+\n+    String method = \"POST\";\n+    String account = accountName.substring(0, accountName.indexOf(AbfsHttpConstants.DOT));\n+\n+    final StringBuilder sb = new StringBuilder(128);\n+    sb.append(\"https://\");\n+    sb.append(account);\n+    sb.append(\".blob.core.windows.net/?restype=service&comp=userdelegationkey\");\n\nReview Comment:\n   Try to use constants as much as possible\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:04:21.351+0000", "updated": "2025-10-31T13:04:21.351+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632383/comment/18034401", "id": "18034401", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8051:\nURL: https://github.com/apache/hadoop/pull/8051#discussion_r2481350011\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/extensions/MockUserBoundSASTokenProvider.java:\n##########\n@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.extensions;\n+\n+import java.io.IOException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n+import org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.InvalidUriException;\n+import org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsHttpHeader;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsJdkHttpOperation;\n+import org.apache.hadoop.fs.azurebfs.utils.Base64;\n+import org.apache.hadoop.fs.azurebfs.utils.DelegationSASGenerator;\n+import org.apache.hadoop.fs.azurebfs.utils.SASGenerator;\n+import org.apache.hadoop.security.AccessControlException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_CONNECTION_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.DEFAULT_HTTP_READ_TIMEOUT;\n+\n+/**\n+ * A mock user-bound SAS token provider implementation.\n+ */\n+\n+public class MockUserBoundSASTokenProvider implements SASTokenProvider {\n+\n+  private DelegationSASGenerator generator;\n+\n+  public static final String TEST_OWNER = \"325f1619-4205-432f-9fce-3fd594325ce5\";\n+  public static final String CORRELATION_ID = \"66ff4ffc-ff17-417e-a2a9-45db8c5b0b5c\";\n+  public static final String NO_AGENT_PATH = \"NoAgentPath\";\n+\n+  @Override\n+  public void initialize(Configuration configuration, String accountName) throws IOException {\n+    String appID = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_ID);\n+    String appSecret = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SECRET);\n+    String sktid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_TENANT_ID);\n+    String skoid = configuration.get(TestConfigurationKeys.FS_AZURE_TEST_APP_SERVICE_PRINCIPAL_OBJECT_ID);\n+    String skt = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().minus(SASGenerator.FIVE_MINUTES));\n+    String ske = SASGenerator.ISO_8601_FORMATTER.format(Instant.now().plus(SASGenerator.ONE_DAY));\n+    String skv = SASGenerator.AuthenticationVersion.July5.toString();\n+\n+    String skdutid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_TENANT_ID);\n+    String sduoid = configuration.get(TestConfigurationKeys.FS_AZURE_END_USER_OBJECT_ID);\n+\n+    byte[] key = getUserDelegationKey(accountName, appID, appSecret, sktid, skt, ske, skv, skdutid);\n+\n+    generator = new DelegationSASGenerator(key, skoid, sktid, skt, ske, skv, skdutid, sduoid);\n+  }\n+\n+  // Invokes the AAD v2.0 authentication endpoint with a client credentials grant to get an\n+  // access token.  See https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow.\n+  private String getAuthorizationHeader(String accountName, String appID, String appSecret, String sktid) throws IOException {\n+    String authEndPoint = String.format(\"https://login.microsoftonline.com/%s/oauth2/v2.0/token\", sktid);\n+    ClientCredsTokenProvider provider = new ClientCredsTokenProvider(authEndPoint, appID, appSecret);\n+    return \"Bearer \" + provider.getToken().getAccessToken();\n+  }\n+\n+  private byte[] getUserDelegationKey(String accountName, String appID, String appSecret,\n+      String sktid, String skt, String ske, String skv, String skdutid) throws IOException {\n+\n+    String method = \"POST\";\n+    String account = accountName.substring(0, accountName.indexOf(AbfsHttpConstants.DOT));\n+\n+    final StringBuilder sb = new StringBuilder(128);\n+    sb.append(\"https://\");\n+    sb.append(account);\n+    sb.append(\".blob.core.windows.net/?restype=service&comp=userdelegationkey\");\n+\n+    URL url;\n+    try {\n+      url = new URL(sb.toString());\n+    } catch (MalformedURLException ex) {\n+      throw new InvalidUriException(sb.toString());\n+    }\n+\n+    List<AbfsHttpHeader> requestHeaders = new ArrayList<AbfsHttpHeader>();\n+    requestHeaders.add(new AbfsHttpHeader(HttpHeaderConfigurations.X_MS_VERSION, skv));\n+    requestHeaders.add(new AbfsHttpHeader(HttpHeaderConfigurations.CONTENT_TYPE, \"application/x-www-form-urlencoded\"));\n+    requestHeaders.add(new AbfsHttpHeader(HttpHeaderConfigurations.AUTHORIZATION, getAuthorizationHeader(account, appID, appSecret, sktid)));\n+\n+    final StringBuilder requestBody = new StringBuilder(512);\n+    requestBody.append(\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?><KeyInfo><Start>\");\n+    requestBody.append(skt);\n+    requestBody.append(\"</Start><Expiry>\");\n+    requestBody.append(ske);\n+    requestBody.append(\"</Expiry><DelegatedUserTid>\");\n+    requestBody.append(skdutid);\n+    requestBody.append(\"</DelegatedUserTid></KeyInfo>\");\n+\n+//    requestBody.append(\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?><KeyInfo><Start>\");\n\nReview Comment:\n   Remove comments\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:05:18.144+0000", "updated": "2025-10-31T13:05:18.144+0000"}], "maxResults": 16, "total": 16, "startAt": 0}, "updated": "2025-10-31T13:05:18.000+0000", "created": "2025-10-24T09:31:18.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13632361", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13632361", "key": "HADOOP-19735", "fields": {"summary": "ABFS: Adding request priority for prefetches", "description": "Adding low traffic request priority (behind a config flag) for prefetches to reduce load on server during throttling", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-10-24T05:00:42.000+0000", "created": "2025-10-24T04:46:13.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13632319", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13632319", "key": "HADOOP-19734", "fields": {"summary": "S3A: retry on MPU completion failure \"One or more of the specified parts could not be found\"", "description": "\r\nExperienced transient failure in test run of https://github.com/apache/hadoop/pull/7882 : all MPU complete posts failed because the request or parts were not found...the tests started succeeding 60-90s later *and* a \"hadoop s3guards uploads\" call listed the outstanding uploads of the failing tests.\r\n\r\nHypothesis: a transient failure meant the server receiving the POST calls to complete the uploads was mistakenly reporting no upload IDs.\r\n\r\nOutcome: all active write operations failed, without any retry attempts. This can lose data and fail jobs, even though the store may recover.\r\n\r\nProposed. The multipart uploads, especially block output stream, retry on this error; treat it as a connectivity issue. ", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13632319/comment/18032518", "id": "18032518", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "\r\n{code}\r\n[ERROR]   ITestS3AHugeMagicCommits.test_030_postCreationAssertions:192 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: JAEYPCZ4P3JYGMTD, Extended Request ID: O/135mw9Xd2aEuFUh0ICWYc8DLXSpBUWaVGkEgEFGf0xO8o+XlZXY0hI+mvennOGt+C/UI7mNrQ=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: JAEYPCZ4P3JYGMTD, Extended Request ID: O/135mw9Xd2aEuFUh0ICWYc8DLXSpBUWaVGkEgEFGf0xO8o+XlZXY0hI+mvennOGt+C/UI7mNrQ=) (SDK Attempt Count: 1)                                                                                                                                                                                   \r\n[ERROR]   ITestS3AHugeMagicCommits>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin in s3a://stevel-london/job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit                                                                                                                                                      \r\n[ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1)                                                                                                                     \r\n[ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src                                                                                                                  \r\n[ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src  \r\n[ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src      \r\n[ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src            \r\n[ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src          \r\n[ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/bytebuffer/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: K0K75V8AH7SVBHS3, Extended Request ID: kDosbp+Z2PLZn9tVtRF9QfOqh1MgLbIKYaYFn2JeIptXlBV4v1a/wFukoXnaF7fCp6zx3vR8feE0fScUJEw+WhNW9lzu9dBxssOA62UA2kg=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: K0K75V8AH7SVBHS3, Extended Request ID: kDosbp+Z2PLZn9tVtRF9QfOqh1MgLbIKYaYFn2JeIptXlBV4v1a/wFukoXnaF7fCp6zx3vR8feE0fScUJEw+WhNW9lzu9dBxssOA62UA2kg=) (SDK Attempt Count: 1)                                                                                                           \r\n[ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                   \r\n[ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                             \r\n[ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                                 \r\n[ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                                       \r\n[ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                                     \r\n[ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/disk/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 73T4YAYRWE63WAW5, Extended Request ID: 6ucEY2heh2NsxE8dBrlZp9AE4Tb+hbvnyxea1/yp5H85BEvkQdYsfNlRH5XZM1g4hHPDSoGMVtM=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 73T4YAYRWE63WAW5, Extended Request ID: 6ucEY2heh2NsxE8dBrlZp9AE4Tb+hbvnyxea1/yp5H85BEvkQdYsfNlRH5XZM1g4hHPDSoGMVtM=) (SDK Attempt Count: 1)                                                                                                                                                                                       \r\n[ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src                                                                                                                     \r\n[ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src     \r\n[ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src         \r\n[ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src               \r\n[ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src             \r\n[ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/disk/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: ZSY181YB49GQFR83, Extended Request ID: FrPEfsXO3Gbhxi3m4ZmyYSiyfscQ1QSm/1lKjRPLHEbLWH5vtGked+fHvZl281Dm6u013/5VP6pj42h4XISftk7p9uEIDGw31E7Ymcoviq4=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: ZSY181YB49GQFR83, Extended Request ID: FrPEfsXO3Gbhxi3m4ZmyYSiyfscQ1QSm/1lKjRPLHEbLWH5vtGked+fHvZl281Dm6u013/5VP6pj42h4XISftk7p9uEIDGw31E7Ymcoviq4=) (SDK Attempt Count: 1)                                                                                                                   \r\n[ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src                                                                                                                 \r\n[ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src \r\n[ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src     \r\n[ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src           \r\n[ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src         \r\n[ERROR]   ITestS3AHugeFilesStorageClass.test_010_CreateHugeFile:74->AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: APYCQNP1GY02DGDE, Extended Request ID: lE0hQJ67sSwCYSMmO7tDEAvEIOCcpwIbLdfqqrNTpWT0bHIaacaIEzZusajj79rnFQlWudxsMHBIUXdS9ELiKR0T923lcULZy4Essx1LoTs=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: APYCQNP1GY02DGDE, Extended Request ID: lE0hQJ67sSwCYSMmO7tDEAvEIOCcpwIbLdfqqrNTpWT0bHIaacaIEzZusajj79rnFQlWudxsMHBIUXdS9ELiKR0T923lcULZy4Essx1LoTs=) (SDK Attempt Count: 1)                                                                                        \r\n[ERROR]   ITestS3AHugeFilesStorageClass.test_030_postCreationAssertions:81->AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src                                                                             \r\n[ERROR]   ITestS3AHugeFilesStorageClass>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src     \r\n[ERROR]   ITestS3AHugeFilesStorageClass.test_100_renameHugeFile:108->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src                                   \r\n[INFO] \r\n[ERROR] Tests run: 124, Failures: 1, Errors: 30, Skipped: 13\r\n[INFO] \r\n{code}\r\n\r\nThis has to be some transient issue with my s3 london bucket, as if in progress upload parts were not being retained. Never seen this before; the expiry time is set to 24h\r\n\r\nWhen these uploads fail we do leave incomplete uploads in progress:\r\n{code}\r\nListing uploads under path \"\"\r\njob-00-fork-0005/test/testCommitOperations 141OKG11JHhWF1GOnunHUd9ZzBJ8cUG9z0LsW_4wUGgCXCvDMQM3kRi5IOCUV8FdCHtg_w8SlipfubRtzCQoT5yEpOLv.cWOiOwjEaBzUjnuJORppfXuKy1piHpLnu98\r\njob-00-fork-0005/test/testIfMatchTwoMultipartUploadsRaceConditionOneClosesFirst yBJpm3zh4DjNQIDtyWgEmWVCk5sehVz5Vzn3QGr_tQT2iOonRp5ErXsQy24yIvnzRxBCZqVapy5VepLeu2udZBT5EXLnKRA3bchvzjtKDlipywSzYlL2N_xLUDCT359I\r\njob-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads AnspJPHUoPJqg61t28OvLfAogi6G9ocyx1Dm6XY2C.a_H_onklM0Nr0LIXaPiYlQjZIiH0fTsQ1e2KhEjS9pGxvSKOXq_4YibiGZmFC6rBolmfACMqIRpoeaqYDgzYW4\r\njob-00-fork-0005/test/testMagicWriteRecovery/file.txt KpvoTuVh85Wzm9XuU1EuxbATjb6D.Zv8vEj3z2S6AvJBHCBssy4iphxNhTkLDs7ceEwak4IPtdXED1vRf3geXT7MRMJn8d6feafvHVEgzbD31odpzTLmOaPrU_mFQXGV\r\njob-00-fork-0005/test/testMagicWriteRecovery/file.txt CnrbWU3pzgEGvjRuDuaP43Xcv1eBF5aLknqYaZA1vwO3b1QUIu9QJSiZjuLMYKT9GKw1QXwqoKo4iuxTY1a18bARx4XMEiL98kZBv0TPMaAfXE.70Olh8Q2kTyDlUCSh\r\njob-00-fork-0005/test/testMagicWriteRecovery/file.txt dEVGPBRsuOAzL5pGA02ve9qJhAlNK8lb8khF6laKjo9U0j_aG1xLkHEfPLrmcrcsLxC3R755Yv_uKbzY_Vnoc.nXCprvutM1TZmLLN_7LHrQ0tY0IjYSS6hVzDVlHbvC\r\njob-00-fork-0006/test/restricted/testCommitEmptyFile/empty-commit.txt NOCjVJqycZhkalrvU26F5oIaJP51q055et2N6b74.2JVjiKL8KwrhOhdrtumOrZ2tZWNqaK4iKZ_iosqgehJOiPbWJwxvrfvA5V.dAUTLNqjtEf5tfWh0UXu.vahDy_S5SSgNLFXK.VB82i5MZtOcw--\r\njob-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin lsYNpdn_oiWLwEVvvM621hCvIwDVaL4y_bbwVpQouW1OBThA.P9cR8fZtxvBjGdMY41UH0dTjxGHtF3BXEY8WXqmcnO9QHs_Jy.os781pE3MGzqgzFyxmd0yN6LFcTbq\r\ntest/restricted/testCommitEmptyFile/empty-commit.txt T3W9V56Bv_FMhKpgcBgJ1H2wOBkPKk23T0JomesBzZyqiIAu3NiROibAgoZUhWSdoTKSJoOgcn3UWYGOvGBbsHteS_N_c1QoTEp0GE7PNlzDfs1GheJ5SOpUgaEY6MaYdNe0mn0gY48FDXpVB2nqiA--\r\ntest/restricted/testCommitEmptyFile/empty-commit.txt .cr4b3xkfze4N24Bj3PAm_ACIyIVuTU4DueDktU1abNu2LJWXH2HKnUu1oOjfnnQwnUXp4VmXBVbZ5aq8E8gVCxN.Oyb7hmGVtESmRjpqIXSW80JrB_0_dqXe.uAT.JH7kEWywAlb4NIqJ5Xz99tvA--\r\nTotal 10 uploads found.\r\n{code}\r\n\r\nMost interesting here is `testIfNoneMatchTwoConcurrentMultipartUploads`, because this initiates then completes an MPU, so as to create a zero byte file. It doesn't upload any parts. \r\n\r\nThe attempt to complete failed.\r\n{code}\r\n[ERROR] org.apache.hadoop.fs.s3a.impl.ITestS3APutIfMatchAndIfNoneMatch.testIfNoneMatchTwoConcurrentMultipartUploads -- Time elapsed: 2.783 s <<< ERROR!\r\norg.apache.hadoop.fs.s3a.AWSBadRequestException: Completing multipart upload on job-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1)\r\n        at org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:265)\r\n        at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:124)\r\n        at org.apache.hadoop.fs.s3a.Invoker.lambda$retry$4(Invoker.java:376)\r\n        at org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:468)\r\n        at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:372)\r\n        at org.apache.hadoop.fs.s3a.WriteOperationHelper.finalizeMultipartUpload(WriteOperationHelper.java:318)\r\n        at org.apache.hadoop.fs.s3a.WriteOperationHelper.completeMPUwithRetries(WriteOperationHelper.java:370)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.lambda$complete$3(S3ABlockOutputStream.java:1227)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.measureDurationOfInvocation(IOStatisticsBinding.java:493)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDurationOfInvocation(IOStatisticsBinding.java:464)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.complete(S3ABlockOutputStream.java:1225)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.access$1500(S3ABlockOutputStream.java:876)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.close(S3ABlockOutputStream.java:545)\r\n        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)\r\n        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\r\n        at org.apache.hadoop.fs.s3a.impl.ITestS3APutIfMatchAndIfNoneMatch.createFileWithFlags(ITestS3APutIfMatchAndIfNoneMatch.java:190)\r\n        at org.apache.hadoop.fs.s3a.impl.ITestS3APutIfMatchAndIfNoneMatch.testIfNoneMatchTwoConcurrentMultipartUploads(ITestS3APutIfMatchAndIfNoneMatch.java:380)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at java.util.ArrayList.forEach(ArrayList.java:1259)\r\n        at java.util.ArrayList.forEach(ArrayList.java:1259)\r\nCaused by: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1)\r\n        at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:113)\r\n        at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:61)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.utils.RetryableStageHelper.retryPolicyDisallowedRetryException(RetryableStageHelper.java:168)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:73)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:36)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n        at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:53)\r\n        at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:35)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.executeWithTimer(ApiCallTimeoutTrackingStage.java:82)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:62)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:43)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:50)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:32)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:37)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:26)\r\n        at software.amazon.awssdk.core.internal.http.AmazonSyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonSyncHttpClient.java:210)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.invoke(BaseSyncClientHandler.java:103)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.doExecute(BaseSyncClientHandler.java:173)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.lambda$execute$1(BaseSyncClientHandler.java:80)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.measureApiCallSuccess(BaseSyncClientHandler.java:182)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:74)\r\n        at software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:45)\r\n        at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:53)\r\n        at software.amazon.awssdk.services.s3.DefaultS3Client.completeMultipartUpload(DefaultS3Client.java:801)\r\n        at software.amazon.awssdk.services.s3.DelegatingS3Client.lambda$completeMultipartUpload$1(DelegatingS3Client.java:611)\r\n        at software.amazon.awssdk.services.s3.internal.crossregion.S3CrossRegionSyncClient.invokeOperation(S3CrossRegionSyncClient.java:67)\r\n        at software.amazon.awssdk.services.s3.DelegatingS3Client.completeMultipartUpload(DelegatingS3Client.java:611)\r\n        at org.apache.hadoop.fs.s3a.impl.S3AStoreImpl.completeMultipartUpload(S3AStoreImpl.java:906)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem$WriteOperationHelperCallbacksImpl.completeMultipartUpload(S3AFileSystem.java:1953)\r\n        at org.apache.hadoop.fs.s3a.WriteOperationHelper.lambda$finalizeMultipartUpload$1(WriteOperationHelper.java:324)\r\n        at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:122)\r\n        ... 18 more\r\n\r\n{code}\r\n\r\nYet the uploads list afterwards finds it\r\n{code}\r\njob-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads AnspJPHUoPJqg61t28OvLfAogi6G9ocyx1Dm6XY2C.a_H_onklM0Nr0LIXaPiYlQjZIiH0fTsQ1e2KhEjS9pGxvSKOXq_4YibiGZmFC6rBolmfACMqIRpoeaqYDgzYW4\r\n{code}\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-23T15:47:44.415+0000", "updated": "2025-10-23T15:47:44.415+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632319/comment/18032522", "id": "18032522", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "And stack on a write failure. \r\n{code}\r\n[ERROR] org.apache.hadoop.fs.s3a.scale.ITestS3AHugeFilesArrayBlocks.test_010_CreateHugeFile -- Time elapsed: 2.870 s <<< ERROR!\r\norg.apache.hadoop.fs.s3a.AWSBadRequestException: Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1)\r\n        at org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:265)\r\n        at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:124)\r\n        at org.apache.hadoop.fs.s3a.Invoker.lambda$retry$4(Invoker.java:376)\r\n        at org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:468)\r\n        at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:372)\r\n        at org.apache.hadoop.fs.s3a.WriteOperationHelper.finalizeMultipartUpload(WriteOperationHelper.java:318)\r\n        at org.apache.hadoop.fs.s3a.WriteOperationHelper.completeMPUwithRetries(WriteOperationHelper.java:370)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.lambda$complete$3(S3ABlockOutputStream.java:1227)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.measureDurationOfInvocation(IOStatisticsBinding.java:493)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDurationOfInvocation(IOStatisticsBinding.java:464)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.complete(S3ABlockOutputStream.java:1225)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.access$1500(S3ABlockOutputStream.java:876)\r\n        at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.close(S3ABlockOutputStream.java:545)\r\n        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)\r\n        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\r\n        at org.apache.hadoop.fs.s3a.scale.AbstractSTestS3AHugeFiles.test_010_CreateHugeFile(AbstractSTestS3AHugeFiles.java:276)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at java.util.ArrayList.forEach(ArrayList.java:1259)\r\n        at java.util.ArrayList.forEach(ArrayList.java:1259)\r\nCaused by: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1)\r\n        at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:113)\r\n        at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:61)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.utils.RetryableStageHelper.retryPolicyDisallowedRetryException(RetryableStageHelper.java:168)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:73)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:36)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n        at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:53)\r\n        at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:35)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.executeWithTimer(ApiCallTimeoutTrackingStage.java:82)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:62)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:43)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:50)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:32)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:37)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:26)\r\n        at software.amazon.awssdk.core.internal.http.AmazonSyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonSyncHttpClient.java:210)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.invoke(BaseSyncClientHandler.java:103)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.doExecute(BaseSyncClientHandler.java:173)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.lambda$execute$1(BaseSyncClientHandler.java:80)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.measureApiCallSuccess(BaseSyncClientHandler.java:182)\r\n        at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:74)\r\n        at software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:45)\r\n        at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:53)\r\n        at software.amazon.awssdk.services.s3.DefaultS3Client.completeMultipartUpload(DefaultS3Client.java:801)\r\n        at software.amazon.awssdk.services.s3.DelegatingS3Client.lambda$completeMultipartUpload$1(DelegatingS3Client.java:611)\r\n        at software.amazon.awssdk.services.s3.internal.crossregion.S3CrossRegionSyncClient.invokeOperation(S3CrossRegionSyncClient.java:67)\r\n        at software.amazon.awssdk.services.s3.DelegatingS3Client.completeMultipartUpload(DelegatingS3Client.java:611)\r\n        at org.apache.hadoop.fs.s3a.impl.S3AStoreImpl.completeMultipartUpload(S3AStoreImpl.java:906)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem$WriteOperationHelperCallbacksImpl.completeMultipartUpload(S3AFileSystem.java:1953)\r\n        at org.apache.hadoop.fs.s3a.WriteOperationHelper.lambda$finalizeMultipartUpload$1(WriteOperationHelper.java:324)\r\n        at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:122)\r\n        ... 17 more\r\n\r\n{code}\r\n\r\nwe'd have to map 400 + the error text to a \"MultipartUploadCompleteFailed\" exception and add a policy for it, leaving other 400s as unrecoverable.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-23T15:52:03.066+0000", "updated": "2025-10-23T15:52:03.066+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632319/comment/18032525", "id": "18032525", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "+ any tracking in block output stream should record when the POST to initiate the MPU was issued. That way if an error still surfaces but the output stream has been open for three days, we have a good cause \"stream open too long\"", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-23T15:57:00.573+0000", "updated": "2025-10-23T15:57:00.573+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632319/comment/18032772", "id": "18032772", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "\r\nthis is actually me making a mess of checksum config\r\n\r\nif the sdk checksum clalculation is set to \"always\" then the user MUST choose a checksum algorithm for s3 uploads (proposed: CRC32). \r\n\r\nI\"m going to leave checksum calculation off by default for performance and compatibility", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-24T13:48:33.158+0000", "updated": "2025-10-24T13:48:33.158+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "updated": "2025-10-24T13:48:33.000+0000", "created": "2025-10-23T15:42:38.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13632245", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13632245", "key": "HADOOP-19733", "fields": {"summary": "S3A: Credentials provider classes not found despite setting `fs.s3a.classloader.isolation` to `false`", "description": "HADOOP-18993 added the option `fs.s3a.classloader.isolation` to support, for example, a Spark job using an AWS credentials provider class that is bundled into the Spark job JAR. In testing this, the AWS credentials provider classes are still not found.\r\n\r\nI think the cause is:\r\n * `fs.s3a.classloader.isolation` is implemented by setting (or not setting) a classloader on the `Configuration`\r\n * However, code paths to load AWS credential provider call `S3AUtils.getInstanceFromReflection`, which uses the classloader that loaded the S3AUtils class. That's likely to be the built-in application classloader, which won't be able to load classes in a Spark job JAR.\r\n\r\nAnd the fix seems small:\r\n * Change `S3AUtils.getInstanceFromReflection` to load classes using the `Configuration`'s classloader. Luckily we already have the Configuration in this method.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032249", "id": "18032249", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "body": "I haven't contributed to Hadoop or other Apache projects before, but this approachable for a first contribution. I'll open a PR.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-22T20:36:34.829+0000", "updated": "2025-10-22T20:49:13.366+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032340", "id": "18032340", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brandonvin opened a new pull request, #8048:\nURL: https://github.com/apache/hadoop/pull/8048\n\n   \u2026lassloader\r\n   \r\n   \r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Follow-up to [HADOOP-18993](https://issues.apache.org/jira/browse/HADOOP-18993) and [HADOOP-19733](https://issues.apache.org/jira/browse/HADOOP-19733) before it.\r\n   \r\n   With `fs.s3a.classloader.isolation` set to `false` in a Spark application, it was still impossible to load a credentials provider class from the Spark application jar.\r\n   \r\n   `fs.s3a.classloader.isolation` works by saving a reference to the intended classloader in the `Configuration`.\r\n   \r\n   However, loading credentials providers goes through\r\n   `S3AUtils#getInstanceFromReflection`, which always used the classloader that loaded `S3AUtils`.\r\n   \r\n   With this patch, credentials providers will be loaded using the `Configuration`'s classloader.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Unit tests in `org.apache.hadoop.fs.s3a.ITestS3AFileSystemIsolatedClassloader`.\r\n   \r\n   Manual testing in a Spark application.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [x] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [x] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T04:13:15.711+0000", "updated": "2025-10-23T04:13:15.711+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032344", "id": "18032344", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brandonvin commented on code in PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#discussion_r2453905622\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS\n     }\n   }\n \n-  private Map<String, String> mapOf() {\n-    return new HashMap<>();\n-  }\n-\n-  private Map<String, String> mapOf(String key, String value) {\n-    HashMap<String, String> m = new HashMap<>();\n-    m.put(key, value);\n-    return m;\n-  }\n\nReview Comment:\n   Since I added test cases that set 2 key-value pairs, I switched to `Map.of` instead of extending these. Not sure if there was a reason to avoid `Map.of` here.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T04:43:50.648+0000", "updated": "2025-10-23T04:43:50.648+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032345", "id": "18032345", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#issuecomment-3435132657\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  24m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 51s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-aws.txt) |  hadoop-tools/hadoop-aws: The patch generated 31 new + 4 unchanged - 0 fixed = 35 total (was 4)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) |  hadoop-tools/hadoop-aws generated 2 new + 188 unchanged - 0 fixed = 190 total (was 188)  |\r\n   | +1 :green_heart: |  shadedclient  |  15m  9s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   1m 57s | [/patch-unit-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/patch-unit-hadoop-tools_hadoop-aws.txt) |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  63m 28s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-aws |\r\n   |  |  Nullcheck of conf at line 655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:[line 645] |\r\n   |  |  Non-virtual method call in org.apache.hadoop.fs.s3a.auth.SignerFactory.createSigner(String, String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:[line 125] |\r\n   | Failed junit tests | hadoop.fs.s3a.auth.TestSignerManager |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8048 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 573c49df2825 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 032c335082f24aef12ee3e002ae1cfd9c5f40507 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/testReport/ |\r\n   | Max. process+thread count | 610 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T05:17:39.742+0000", "updated": "2025-10-23T05:17:39.742+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032358", "id": "18032358", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#issuecomment-3435205771\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  25m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 50s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 10s | [/results-checkstyle-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-aws.txt) |  hadoop-tools/hadoop-aws: The patch generated 12 new + 4 unchanged - 0 fixed = 16 total (was 4)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) |  hadoop-tools/hadoop-aws generated 2 new + 188 unchanged - 0 fixed = 190 total (was 188)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m  2s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   2m  0s | [/patch-unit-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/patch-unit-hadoop-tools_hadoop-aws.txt) |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  63m 47s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-aws |\r\n   |  |  Nullcheck of conf at line 655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:[line 645] |\r\n   |  |  Non-virtual method call in org.apache.hadoop.fs.s3a.auth.SignerFactory.createSigner(String, String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:[line 125] |\r\n   | Failed junit tests | hadoop.fs.s3a.auth.TestSignerManager |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8048 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 55f7cbac0d20 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 249aef5213fa039d252e7f7ae03c060b6c87d94f |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/testReport/ |\r\n   | Max. process+thread count | 616 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T05:46:12.703+0000", "updated": "2025-10-23T05:46:12.703+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032474", "id": "18032474", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#discussion_r2455036391\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -37,10 +46,33 @@\n  */\n public class ITestS3AFileSystemIsolatedClassloader extends AbstractS3ATestBase {\n \n+  private static String customClassName = \"custom.class.name\";\n+\n+  private static class CustomCredentialsProvider implements AwsCredentialsProvider {\n+\n+      public CustomCredentialsProvider() {\n+      }\n+\n+      @Override\n+      public AwsCredentials resolveCredentials() {\n+          return null;\n+      }\n+\n+  }\n+\n   private static class CustomClassLoader extends ClassLoader {\n   }\n \n-  private final ClassLoader customClassLoader = new CustomClassLoader();\n+  private final ClassLoader customClassLoader = spy(new CustomClassLoader());\n+  {\n+    try {\n\nReview Comment:\n   this is a nice way to simulate classloader pain.\r\n   \n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -28,6 +29,14 @@\n \n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.s3a.impl.InstantiationIOException;\n+\n+import software.amazon.awssdk.auth.credentials.AwsCredentials;\n\nReview Comment:\n   nit: put the amazon imports in the same group as the junit ones\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -100,11 +122,26 @@ public void defaultIsolatedClassloader() throws IOException {\n               .isEqualTo(fs.getClass().getClassLoader())\n               .describedAs(\"the classloader that loaded the fs\");\n     });\n+\n+    Throwable thrown = Assertions.catchThrowable(() -> {\n\nReview Comment:\n   Use our `LambdaTestUtils.intercept()`; it's like the spark one and does the casting checks\r\n   \r\n   ```\r\n   InstantiationIOException ex = intercept(InstantiationIOException.class, () -> { assert...})\r\n   ```\r\n   we have a `assertExceptionContains` to look at the inner stuff, but the assert of L136 is fine.\r\n   \r\n   \n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -115,11 +152,31 @@ public void isolatedClassloader() throws IOException {\n               .isEqualTo(fs.getClass().getClassLoader())\n               .describedAs(\"the classloader that loaded the fs\");\n     });\n+\n+    Throwable thrown = Assertions.catchThrowable(() -> {\n\nReview Comment:\n   again `intercept()` and cut the assert at L163\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS\n     }\n   }\n \n-  private Map<String, String> mapOf() {\n-    return new HashMap<>();\n-  }\n-\n-  private Map<String, String> mapOf(String key, String value) {\n-    HashMap<String, String> m = new HashMap<>();\n-    m.put(key, value);\n-    return m;\n-  }\n\nReview Comment:\n   It's because we only switched to java17 yesterday! And in trunk only.\r\n   \r\n   If you want to see this change in Hadoop 3.4.3 it'll still need to be java8 code, so this needs to be restored. Otherwise: trunk/3.5.0 only\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T13:03:14.097+0000", "updated": "2025-10-23T13:03:14.097+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032528", "id": "18032528", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Ok, will also update the custom signer loading to use the configuration, for consistency.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-23T16:33:11.604+0000", "updated": "2025-10-23T16:33:11.604+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032581", "id": "18032581", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brandonvin commented on code in PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#discussion_r2456994430\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS\n     }\n   }\n \n-  private Map<String, String> mapOf() {\n-    return new HashMap<>();\n-  }\n-\n-  private Map<String, String> mapOf(String key, String value) {\n-    HashMap<String, String> m = new HashMap<>();\n-    m.put(key, value);\n-    return m;\n-  }\n\nReview Comment:\n   Thanks, makes sense!\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T19:44:03.691+0000", "updated": "2025-10-23T19:44:03.691+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-10-23T19:44:03.000+0000", "created": "2025-10-22T19:56:55.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13632141", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13632141", "key": "HADOOP-19732", "fields": {"summary": "Namenode Crash Due to Delegation Renewer Runtime Exit (NoMatchingRule)", "description": "The delegation token renewer enters runtime exit when a _NoMatchingRule_ error, which caused the entire namenode to crash. I think returning an error to the client should be fine but bringing down the namenode is not acceptable to anyone.\r\n\r\nAfter the AD change, the new realm was updated, but some jobs are still using the old realm as users are updating them gradually. This migration process will take time, and during this period, other jobs are still catching up with the new realm configuration. However, the namenode down disrupts all of them.\r\n\r\n\u00a0\r\n{code:java}\r\nERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover thread received unexpected exception\r\njava.lang.IllegalArgumentException: Illegal principal name hive/xxxxx@yyyy.COM\r\norg.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule: No rules applied to hive/xxxxx@yyyy.COM \u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.User.<init>(User.java:51)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.User.<init>(User.java:43)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1417)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1401)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier.getUser(AbstractDelegationTokenIdentifier.java:80)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier.getUser(DelegationTokenIdentifier.java:81)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier.toString(DelegationTokenIdentifier.java:91)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.String.valueOf(String.java:2994)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.StringBuilder.append(StringBuilder.java:137)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.formatTokenId(AbstractDelegationTokenSecretManager.java:58)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.logExpireTokens(AbstractDelegationTokenSecretManager.java:642)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.removeExpiredToken(AbstractDelegationTokenSecretManager.java:635)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.access$400(AbstractDelegationTokenSecretManager.java:51)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run(AbstractDelegationTokenSecretManager.java:694)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule: No rules applied to hive/xxxxx@yyyy.COM\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:429)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.User.<init>(User.java:48)\r\n\u00a0 \u00a0 \u00a0 \u00a0 ... 14 more {code}\r\n\u00a0", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13632141/comment/18032471", "id": "18032471", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "looks a duplicate of HDFS-17138.\r\n\r\n[~kpalanisamy] please set the hadoop version you saw it with. If it is a version without HDFS-17138 -please upgrade.\r\n\r\nclosing as a duplicate. If it surfaces on branches with HDFS-17138, re-open", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-23T12:41:51.201+0000", "updated": "2025-10-23T12:41:51.201+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632141/comment/18032558", "id": "18032558", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy", "name": "kpalanisamy", "key": "kpalanisamy", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=43784", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=43784", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=43784", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=43784"}, "displayName": "Karthik Palanisamy", "active": true, "timeZone": "Etc/UTC"}, "body": "You\u2019re right [~stevel@apache.org].\u00a0My user version is 3.1.1, so it is missing this HDFS-17138 fix, which clearly addresses my user scenarios. Thanks for checking so quickly. I should have checked it, but unfortunately I taken your time :)\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy", "name": "kpalanisamy", "key": "kpalanisamy", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=43784", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=43784", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=43784", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=43784"}, "displayName": "Karthik Palanisamy", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T17:47:42.603+0000", "updated": "2025-10-23T17:47:42.603+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-10-23T17:47:42.000+0000", "created": "2025-10-21T18:43:38.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631920", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631920", "key": "HADOOP-19731", "fields": {"summary": "Fix SpotBugs warnings introduced after SpotBugs version upgrade.", "description": "Following the upgrade to SpotBugs {*}4.9.7{*}, several new warnings have emerged.\r\nWe plan to address these warnings to improve code safety and maintain compatibility with the updated analysis rules.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631920/comment/18032459", "id": "18032459", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "body": "Hi [~slfan1989]\u00a0\r\nThanks for tracking this.\r\n\r\nWe do have a bunch of PRs open that are facing issue reported here.\r\nWhat are the expectations here? Do we need to address all warnings with the PR itself or they can be ignored and taken later as part of this Jira?\r\n\r\nI think later would be better. It will help keep the changes in PR limited to what is being done and will ease the review process.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-10-23T12:10:33.527+0000", "updated": "2025-10-23T12:10:33.527+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631920/comment/18032465", "id": "18032465", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=slfan1989", "name": "slfan1989", "key": "slfan1989", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=slfan1989&avatarId=40935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=slfan1989&avatarId=40935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=slfan1989&avatarId=40935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=slfan1989&avatarId=40935"}, "displayName": "Shilun Fan", "active": true, "timeZone": "America/Vancouver"}, "body": "I agree with your point. We\u2019ll work on submitting a common PR that includes a SpotBugs rule to temporarily suppress the new static analysis warnings and restore the state back to the 4.2.0 level.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=slfan1989", "name": "slfan1989", "key": "slfan1989", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=slfan1989&avatarId=40935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=slfan1989&avatarId=40935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=slfan1989&avatarId=40935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=slfan1989&avatarId=40935"}, "displayName": "Shilun Fan", "active": true, "timeZone": "America/Vancouver"}, "created": "2025-10-23T12:20:20.684+0000", "updated": "2025-10-23T12:20:20.684+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631920/comment/18032468", "id": "18032468", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "body": "Sounds awesome.\r\nThanks for all the efforts.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-10-23T12:26:45.915+0000", "updated": "2025-10-23T12:26:45.915+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631920/comment/18034183", "id": "18034183", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "zhtttylz opened a new pull request, #8053:\nURL: https://github.com/apache/hadoop/pull/8053\n\n   ### Description of PR\r\n   HADOOP-19731. Fix SpotBugs warnings introduced after SpotBugs version upgrade.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Ran `mvn -Dspotbugs.skip=false spotbugs:spotbugs` on affected modules and verified the build no longer fails on SpotBugs warnings. No functional code changes, config-only.\r\n   \r\n   ### For code changes:\r\n   \r\n   - Add a project-wide baseline at dev-support/findbugs-exclude-global.xml. \r\n   - Consolidate SpotBugs plugin config in affected module POMs to consistently include local excludes and the new global baseline. \r\n   - Wire the global baseline from hadoop-project-dist/pom.xml; introduce a root path property to reference the repository root. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-30T14:01:10.551+0000", "updated": "2025-10-30T14:01:10.551+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631920/comment/18034274", "id": "18034274", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8053:\nURL: https://github.com/apache/hadoop/pull/8053#issuecomment-3470749232\n\n   @zhtttylz Thank you for following up on this issue.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T00:00:55.072+0000", "updated": "2025-10-31T00:00:55.072+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631920/comment/18034308", "id": "18034308", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8053:\nURL: https://github.com/apache/hadoop/pull/8053#issuecomment-3471069512\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 29s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 39s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 19s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  mvnsite  |   6m 23s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8053/2/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 21s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 44s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  71m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 24s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  25m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  1s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   3m 41s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8053/2/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 15s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 38s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  28m 29s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 589m 16s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8053/2/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   0m 48s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8053/2/artifact/out/results-asflicense.txt) |  The patch generated 1 ASF License warnings.  |\r\n   |  |   | 734m 52s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.router.subcluster.capacity.TestYarnFederationWithCapacityScheduler |\r\n   |   | hadoop.security.ssl.TestDelegatingSSLSocketFactory |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.hdfs.TestDecommission |\r\n   |   | hadoop.hdfs.tools.TestDFSAdmin |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8053/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8053 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient |\r\n   | uname | Linux 2197de4c49c9 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c46c6afc99a346474f5b255749c5a86ae4de90bc |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8053/2/testReport/ |\r\n   | Max. process+thread count | 4391 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project-dist hadoop-common-project/hadoop-minikdc hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-common-project/hadoop-registry hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-mapreduce-project hadoop-tools/hadoop-streaming hadoop-tools/hadoop-archive-logs hadoop-tools/hadoop-rumen hadoop-tools/hadoop-gridmix hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-aliyun hadoop-tools/hadoop-sls hadoop-tools/hadoop-fs2img hadoop-tools/hadoop-gcp hadoop-tools/hadoop-benchmark hadoop-cloud-storage-project/hadoop-cos hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-tos . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8053/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T02:29:09.074+0000", "updated": "2025-10-31T02:29:09.074+0000"}], "maxResults": 6, "total": 6, "startAt": 0}, "updated": "2025-10-31T02:29:09.000+0000", "created": "2025-10-19T09:57:26.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631918", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631918", "key": "HADOOP-19730", "fields": {"summary": "upgrade bouncycastle to 1.82 due to CVE-2025-8916", "description": "https://github.com/advisories/GHSA-4cx2-fc23-5wg6\r\n\r\nThought it was tidier to upgrade to latest version even if the fix was a while ago.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18030931", "id": "18030931", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #8039:\nURL: https://github.com/apache/hadoop/pull/8039\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   HADOOP-19730\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-19T09:15:30.542+0000", "updated": "2025-10-19T09:15:30.542+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18031047", "id": "18031047", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8039:\nURL: https://github.com/apache/hadoop/pull/8039#issuecomment-3420366545\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 51s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  28m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 12s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 28s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  mvnsite  |   8m 58s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 36s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 36s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 37s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  27m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 49s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  14m 49s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 37s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   7m  1s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 42s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 36s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  45m 37s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 807m 40s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1064m 10s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList |\r\n   |   | hadoop.hdfs.tools.TestDFSAdmin |\r\n   |   | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\r\n   |   | hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes |\r\n   |   | hadoop.hdfs.TestRollingUpgrade |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService |\r\n   |   | hadoop.yarn.service.TestYarnNativeServices |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8039 |\r\n   | Optional Tests | dupname asflicense mvnsite codespell detsecrets markdownlint compile javac javadoc mvninstall unit shadedclient xmllint shellcheck shelldocs |\r\n   | uname | Linux 66cf96c27f49 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 695a0a30232b143ec8837d6a6648344ffd4efec0 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/testReport/ |\r\n   | Max. process+thread count | 4498 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-cloud-storage-project/hadoop-cos . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-20T03:00:51.681+0000", "updated": "2025-10-20T03:00:51.681+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18031308", "id": "18031308", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8039:\nURL: https://github.com/apache/hadoop/pull/8039\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T01:42:32.195+0000", "updated": "2025-10-21T01:42:32.195+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18031309", "id": "18031309", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8039:\nURL: https://github.com/apache/hadoop/pull/8039#issuecomment-3424343993\n\n   @pjfanning Thanks for the contribution! Merged into trunk. Could we also open a PR for branch-3.4?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T01:44:38.858+0000", "updated": "2025-10-21T01:44:38.858+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18032298", "id": "18032298", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #8047:\nURL: https://github.com/apache/hadoop/pull/8047\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   backport #6976\r\n   \r\n   * HADOOP-19730. Upgrade Bouncycastle to 1.82 due to CVE-2025-8916\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T00:19:48.036+0000", "updated": "2025-10-23T00:19:48.036+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18032555", "id": "18032555", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8047:\nURL: https://github.com/apache/hadoop/pull/8047#issuecomment-3438232725\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  12m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   2m 54s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  39m 30s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |  18m 44s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  17m 41s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m  5s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 20s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 36s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  50m 39s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  29m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 11s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 31s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  52m 50s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 720m 55s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 49s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1024m 55s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.mapred.gridmix.TestGridmixSubmission |\r\n   |   | hadoop.mapred.gridmix.TestLoadJob |\r\n   |   | hadoop.security.ssl.TestDelegatingSSLSocketFactory |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8047 |\r\n   | Optional Tests | dupname asflicense mvnsite codespell detsecrets markdownlint compile javac javadoc mvninstall unit shadedclient xmllint shellcheck shelldocs |\r\n   | uname | Linux d69a46a8ee67 5.15.0-160-generic #170-Ubuntu SMP Wed Oct 1 10:06:56 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / c8b8fb4e82d33a470f10a447f4799cc872fb3c01 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/testReport/ |\r\n   | Max. process+thread count | 3660 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-cloud-storage-project/hadoop-cos . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T17:26:09.708+0000", "updated": "2025-10-23T17:26:09.708+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18033114", "id": "18033114", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8047:\nURL: https://github.com/apache/hadoop/pull/8047\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T05:46:24.867+0000", "updated": "2025-10-27T05:46:24.867+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631918/comment/18033115", "id": "18033115", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8047:\nURL: https://github.com/apache/hadoop/pull/8047#issuecomment-3449617778\n\n   @pjfanning Thanks for the contribution! Merged into trunk.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T05:46:46.087+0000", "updated": "2025-10-27T05:46:46.087+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-10-27T05:48:06.000+0000", "created": "2025-10-19T09:09:36.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631778", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631778", "key": "HADOOP-19729", "fields": {"summary": "ABFS: [Perf] Network Profiling of Tailing Requests and Killing Bad Connections Proactively", "description": "It has been observed that certain requests taking more time than expected to complete hinders the performance of whole workload. Such requests are known as tailing requests. They can be taking more time due to a number of reasons and the prominent among them is a bad network connection. In Abfs driver we cache network connections and keeping such bad connections in cache and reusing them can be bad for perf.\r\n\r\nIn this effort we try to identify such connections and close them so that new good connetions can be established and perf can be improved. There are two parts of this effort.\r\n # Identifying Tailing Requests: This involves profiling all the network calls and getting percentiles value optimally. By default we consider p99 as the tail latency and all the future requests taking more than tail latency will be considere as Tailing requests.\r\n\r\n # Proactively Killing Socket Connections: With Apache client, we can now kill the socket connection and fail the tailing request. Such failures will not be thrown back to user and retried immediately without any sleep but from another socket connection.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033018", "id": "18033018", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3448411577\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  11m  8s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  21m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 43s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 53s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 21s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 10s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 43 new + 3 unchanged - 0 fixed = 46 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 18s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 34 new + 1472 unchanged - 0 fixed = 1506 total (was 1472)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 33 new + 1413 unchanged - 0 fixed = 1446 total (was 1413)  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 4 new + 177 unchanged - 1 fixed = 181 total (was 178)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 12s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m  8s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  70m  0s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 533] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 81] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux d98c9c1604f2 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7dcac93eec4dc5a48d643ae81372c581b6c3bebf |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/testReport/ |\r\n   | Max. process+thread count | 614 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-26T10:46:14.005+0000", "updated": "2025-10-26T10:46:14.005+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033112", "id": "18033112", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3449602331\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 13s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 43 new + 3 unchanged - 0 fixed = 46 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 35 new + 1472 unchanged - 0 fixed = 1507 total (was 1472)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 34 new + 1413 unchanged - 0 fixed = 1447 total (was 1413)  |\r\n   | -1 :x: |  spotbugs  |   0m 45s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 4 new + 177 unchanged - 1 fixed = 181 total (was 178)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m  8s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  60m 12s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 533] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 81] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 9b5c6baa74d5 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / de244d215362fca4d8ba16b3d01a9f39a3ff0e81 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/testReport/ |\r\n   | Max. process+thread count | 637 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T05:39:12.286+0000", "updated": "2025-10-27T05:39:12.286+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033137", "id": "18033137", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2464810768\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n\nReview Comment:\n   first check should be for isTailLatencyTrackerEnabled\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T08:37:41.756+0000", "updated": "2025-10-27T08:37:41.756+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033140", "id": "18033140", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2464820798\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n+        && getPreferredHttpOperationType().equals(HttpOperationType.APACHE_HTTP_CLIENT);\n+  }\n+\n+  public int getTailLatencyPercentile() {\n+    return tailLatencyPercentile;\n+  }\n+\n+  public int getTailLatencyMinDeviation() {\n+    return tailLatencyMinDeviation;\n+  }\n+\n+  public int getTailLatencyMinSampleSize() {\n+    return tailLatencyMinSampleSize;\n+  }\n+\n+  public int getTailLatencyAnalysisWindowInMillis() {\n+    return tailLatencyAnalysisWindowInMillis;\n+  }\n+\n+  public int getTailLatencyPercentileComputationIntervalInMillis() {\n\nReview Comment:\n   Name should be shortened\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T08:41:50.368+0000", "updated": "2025-10-27T08:41:50.368+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033176", "id": "18033176", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465174540\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n\nReview Comment:\n   Do we not want this feature to be enabled by default ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T10:36:34.608+0000", "updated": "2025-10-27T10:36:34.608+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033183", "id": "18033183", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465238391\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -143,6 +173,51 @@ public HttpResponse execute(HttpRequestBase httpRequest,\n     return httpClient.execute(httpRequest, abfsHttpClientContext);\n   }\n \n+  /**\n+   * Executes the HTTP request with a deadline. If the request does not complete\n+   * within the deadline, it is aborted and an IOException is thrown.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   * @param deadlineMillis Deadline in milliseconds.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error or deadline exceeded.\n+   */\n+  public HttpResponse executeWithDeadline(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long deadlineMillis) throws IOException {\n+    RequestConfig.Builder requestConfigBuilder = RequestConfig\n+        .custom()\n+        .setConnectTimeout(connectTimeout)\n+        .setSocketTimeout(readTimeout);\n+    httpRequest.setConfig(requestConfigBuilder.build());\n+    ExecutorService executor = Executors.newSingleThreadExecutor();\n+    Future<HttpResponse> future = executor.submit(() ->\n+        httpClient.execute(httpRequest, abfsHttpClientContext)\n+    );\n+\n+    try {\n+      return future.get(deadlineMillis, TimeUnit.MILLISECONDS);\n+    } catch (TimeoutException e) {\n+      /* Deadline exceeded, abort the request.\n+       * This will also kill the underlying socket exception in the HttpClient.\n+       * Connection will be marker stale and won't be returned back to KAC for reuse.\n\nReview Comment:\n   nit: typo marked\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:00:11.638+0000", "updated": "2025-10-27T11:00:11.638+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033186", "id": "18033186", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465280967\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/RetryPolicyConstants.java:\n##########\n@@ -32,4 +32,8 @@ private RetryPolicyConstants() {\n    * Constant for Static Retry Policy Abbreviation. {@value}\n    */\n   public static final String STATIC_RETRY_POLICY_ABBREVIATION = \"S\";\n+  /**\n+   * Constant for Static Retry Policy Abbreviation. {@value}\n+   */\n+  public static final String TAIL_LATENCY_TIMEOUT_RETRY_POLICY_ABBREVIATION = \"T\";\n\nReview Comment:\n   Can we make it TL ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:16:02.020+0000", "updated": "2025-10-27T11:16:02.020+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033192", "id": "18033192", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465316539\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n\nReview Comment:\n   Should be numberOfSegments in exception\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:30:48.845+0000", "updated": "2025-10-27T11:30:48.845+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033194", "id": "18033194", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465371723\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n\nReview Comment:\n   We can return here itself\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:53:15.752+0000", "updated": "2025-10-27T11:53:15.752+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033196", "id": "18033196", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465396005\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n\nReview Comment:\n   Chances of division by zero error\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:02:48.630+0000", "updated": "2025-10-27T12:02:48.630+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033204", "id": "18033204", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465418474\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n\nReview Comment:\n   Is less than 0 possible for total count ? It is increment always right \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:10:12.482+0000", "updated": "2025-10-27T12:10:12.482+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033205", "id": "18033205", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465418474\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n\nReview Comment:\n   Is less than 0 possible for total count? It is incremented always right \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:10:29.724+0000", "updated": "2025-10-27T12:10:29.724+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033211", "id": "18033211", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465446936\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n+        currentSegmentStartMillis = alignToSegmentDuration(System.currentTimeMillis());\n+        LOG.debug(\"[{}] No data recorded in current time segment at {}. Skipping Rotation. Current Index is {}.\",\n+            operationType, currentSegmentStartMillis, currentIndex.get());\n+        return;\n+      }\n+\n+      LOG.debug(\"[{}] Rotating current segment with total count {} into slot {}\",\n+          operationType, currentSegmentAccumulation.getTotalCount(), currentIndex.get());\n+\n+      // Place the finished currentAccumulation into the ring buffer slot ahead.\n+      int currentIdx = (currentIndex.getAndIncrement()) % numSegments;\n+      // Next slot is now going to be eradicated. Remove its count from total.\n+      currentTotalCount.set(currentTotalCount.get() - (completedSegments[currentIdx] == null ? 0 : completedSegments[currentIdx].getTotalCount()));\n+      // Store an immutable snapshot (make sure we don't mutate the instance after storing)\n+      completedSegments[currentIdx] = currentSegmentAccumulation;\n\nReview Comment:\n   how are we making sure that this is immutable after this point ? completedSegments[currentIdx] = currentSegmentAccumulation.copy(); ideally we should create a deep copy of the histogram data so that even if currentSegmentAccumulation is reused or reset for the next segment, the data in completedSegments remains unchanged.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:20:21.973+0000", "updated": "2025-10-27T12:20:21.973+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033212", "id": "18033212", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465452348\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n\nReview Comment:\n   what is the use of the variable now ? We can directly use System.currentTimeMillis(); in expectedStart as we are doing later in line 195\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:22:32.912+0000", "updated": "2025-10-27T12:22:32.912+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033216", "id": "18033216", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465506034\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -114,6 +116,7 @@ public class AbfsRestOperation {\n    */\n   private String failureReason;\n   private AbfsRetryPolicy retryPolicy;\n+  private boolean shouldTailLatencyTimeout = true;\n\nReview Comment:\n   Can be renamed to enableTailLatencyTimeout\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:41:20.427+0000", "updated": "2025-10-27T12:41:20.427+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033217", "id": "18033217", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465510352\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n\nReview Comment:\n   Will get updated for -1 status code as well, should be checked between 200 to 300\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:43:01.013+0000", "updated": "2025-10-27T12:43:01.013+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033223", "id": "18033223", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465561509\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n\nReview Comment:\n   add comment for which value represents what\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:55:40.546+0000", "updated": "2025-10-27T12:55:40.546+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033226", "id": "18033226", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465576049\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        0,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Verify that the histogram is created successfully with default values and\n+    // do not report any percentiles\n+    assertThat(histogram).isNotNull();\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(0);\n+    assertThat(histogram.getCurrentIndex()).isEqualTo(0);\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Verify that recording values works as expected\n+    addAndRotate(histogram, 10, 5); // Add 5 values of 10\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(5);\n+\n+    // Verify that percentiles are not computed with insufficient samples\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values to exceed the minimum sample size\n+    addAndRotate(histogram, 20, 5); // Add 5 values of 20\n+\n+    // Verify that percentiles are now computed but tail Latency is still not reported\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values and rotate histogram to fill whole analysis window\n+    addAndRotate(histogram, 30, 5); // Add 5 values of 30\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(15);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 60, 5); // Add 5 values of 60\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(20);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation is skipped if nothing new recorded and hence window not filled\n+    addAndRotate(histogram, 100, 0); // No new values added\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation does not happen if analysis window is not filled\n+    histogram.rotateIfNeeded();\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 80\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(25);\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles and tail latency are computed\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isGreaterThan(0.0);\n+\n+    // Verify that sliding window works. Old values should be evicted\n+    addAndRotate(histogram, 90, 3); // Add 3 values of 90\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(23);\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementNotMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        100,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        50,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n\nReview Comment:\n   nit: should be computed ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T13:00:48.587+0000", "updated": "2025-10-27T13:00:48.587+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033529", "id": "18033529", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2469106859\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT = false;\n+  public static final int DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE = 99;\n\nReview Comment:\n   shouldn't it be float/double instead of int? Tomorrow we can change default percentile to 99.9 or 99.99.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n\nReview Comment:\n   @param missing in the java doc\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -132,6 +138,30 @@ public void close() throws IOException {\n    * @throws IOException network error.\n    */\n   public HttpResponse execute(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long tailLatencyTimeout) throws IOException {\n+    if (tailLatencyTimeout <= 0) {\n+      return executeWithoutDeadline(httpRequest, abfsHttpClientContext,\n+          connectTimeout, readTimeout);\n+    }\n+    return executeWithDeadline(httpRequest, abfsHttpClientContext,\n+        connectTimeout, readTimeout, tailLatencyTimeout);\n+  }\n+\n+  /**\n+   * Executes the HTTP request.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error.\n+   */\n+  public HttpResponse executeWithoutDeadline(HttpRequestBase httpRequest,\n\nReview Comment:\n   executeWithoutDeadline and executeWithDeadline can be private methods.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n+    super(ERR_TAIL_LATENCY_REQUEST_TIMEOUT, innerException);\n+  }\n+\n+  public TailLatencyRequestTimeoutException() {\n\nReview Comment:\n   Java doc missing for this\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n\nReview Comment:\n   We can rename this variable to something which is more relevant.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n\nReview Comment:\n   We should close this thread pool and one below once the use is done or at least during filesystem close.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -611,10 +630,30 @@ AbfsJdkHttpOperation createAbfsHttpOperation() throws IOException {\n \n   @VisibleForTesting\n   AbfsAHCHttpOperation createAbfsAHCHttpOperation() throws IOException {\n+    long tailLatency = getTailLatencyTimeoutIfEnabled();\n     return new AbfsAHCHttpOperation(url, method, requestHeaders,\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpConnectionTimeout()),\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpReadTimeout()),\n-        client.getAbfsApacheHttpClient(), client);\n+        tailLatency, client.getAbfsApacheHttpClient(), client);\n+  }\n+\n+  /**\n+   * Get Tail Latency Timeout value if profiling is enabled, timeout is enabled\n+   * and retries due to tail latency request timeout is allowed.\n+   * @return tail latency timeout value else return zero.\n+   */\n+  long getTailLatencyTimeoutIfEnabled() {\n+    if (isTailLatencyTimeoutEnabled() && shouldTailLatencyTimeout) {\n+      return (long) tailLatencyTracker.getTailLatency(this.operationType);\n+    }\n+    return ZERO;\n+  }\n+\n+  boolean isTailLatencyTimeoutEnabled() {\n\nReview Comment:\n   Java doc missing\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T11:35:24.187+0000", "updated": "2025-10-28T11:35:24.187+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033618", "id": "18033618", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470451730\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n\nReview Comment:\n   Make sense.\r\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:34:58.647+0000", "updated": "2025-10-28T17:34:58.647+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033619", "id": "18033619", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470457723\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n+        && getPreferredHttpOperationType().equals(HttpOperationType.APACHE_HTTP_CLIENT);\n+  }\n+\n+  public int getTailLatencyPercentile() {\n+    return tailLatencyPercentile;\n+  }\n+\n+  public int getTailLatencyMinDeviation() {\n+    return tailLatencyMinDeviation;\n+  }\n+\n+  public int getTailLatencyMinSampleSize() {\n+    return tailLatencyMinSampleSize;\n+  }\n+\n+  public int getTailLatencyAnalysisWindowInMillis() {\n+    return tailLatencyAnalysisWindowInMillis;\n+  }\n+\n+  public int getTailLatencyPercentileComputationIntervalInMillis() {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:36:57.219+0000", "updated": "2025-10-28T17:36:57.219+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033620", "id": "18033620", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470459989\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n\nReview Comment:\n   There is no value add currently to just enable profling as we are not consuming it anywhere.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:37:43.800+0000", "updated": "2025-10-28T17:37:43.800+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033621", "id": "18033621", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470461231\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -143,6 +173,51 @@ public HttpResponse execute(HttpRequestBase httpRequest,\n     return httpClient.execute(httpRequest, abfsHttpClientContext);\n   }\n \n+  /**\n+   * Executes the HTTP request with a deadline. If the request does not complete\n+   * within the deadline, it is aborted and an IOException is thrown.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   * @param deadlineMillis Deadline in milliseconds.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error or deadline exceeded.\n+   */\n+  public HttpResponse executeWithDeadline(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long deadlineMillis) throws IOException {\n+    RequestConfig.Builder requestConfigBuilder = RequestConfig\n+        .custom()\n+        .setConnectTimeout(connectTimeout)\n+        .setSocketTimeout(readTimeout);\n+    httpRequest.setConfig(requestConfigBuilder.build());\n+    ExecutorService executor = Executors.newSingleThreadExecutor();\n+    Future<HttpResponse> future = executor.submit(() ->\n+        httpClient.execute(httpRequest, abfsHttpClientContext)\n+    );\n+\n+    try {\n+      return future.get(deadlineMillis, TimeUnit.MILLISECONDS);\n+    } catch (TimeoutException e) {\n+      /* Deadline exceeded, abort the request.\n+       * This will also kill the underlying socket exception in the HttpClient.\n+       * Connection will be marker stale and won't be returned back to KAC for reuse.\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:38:13.828+0000", "updated": "2025-10-28T17:38:13.828+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033622", "id": "18033622", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470463895\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/RetryPolicyConstants.java:\n##########\n@@ -32,4 +32,8 @@ private RetryPolicyConstants() {\n    * Constant for Static Retry Policy Abbreviation. {@value}\n    */\n   public static final String STATIC_RETRY_POLICY_ABBREVIATION = \"S\";\n+  /**\n+   * Constant for Static Retry Policy Abbreviation. {@value}\n+   */\n+  public static final String TAIL_LATENCY_TIMEOUT_RETRY_POLICY_ABBREVIATION = \"T\";\n\nReview Comment:\n   Other Retry policy abbreviations are already single character. Keeping it likewise\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:39:08.862+0000", "updated": "2025-10-28T17:39:08.862+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033623", "id": "18033623", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470465366\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:39:28.635+0000", "updated": "2025-10-28T17:39:28.635+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033624", "id": "18033624", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470469035\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:40:22.880+0000", "updated": "2025-10-28T17:40:22.880+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033625", "id": "18033625", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470478310\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n\nReview Comment:\n   Nice catch.\r\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:42:19.000+0000", "updated": "2025-10-28T17:42:19.000+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033626", "id": "18033626", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470481704\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n\nReview Comment:\n   Yeah this is primarily for equal to 0\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:42:54.939+0000", "updated": "2025-10-28T17:42:54.939+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033627", "id": "18033627", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470498123\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n+        currentSegmentStartMillis = alignToSegmentDuration(System.currentTimeMillis());\n+        LOG.debug(\"[{}] No data recorded in current time segment at {}. Skipping Rotation. Current Index is {}.\",\n+            operationType, currentSegmentStartMillis, currentIndex.get());\n+        return;\n+      }\n+\n+      LOG.debug(\"[{}] Rotating current segment with total count {} into slot {}\",\n+          operationType, currentSegmentAccumulation.getTotalCount(), currentIndex.get());\n+\n+      // Place the finished currentAccumulation into the ring buffer slot ahead.\n+      int currentIdx = (currentIndex.getAndIncrement()) % numSegments;\n+      // Next slot is now going to be eradicated. Remove its count from total.\n+      currentTotalCount.set(currentTotalCount.get() - (completedSegments[currentIdx] == null ? 0 : completedSegments[currentIdx].getTotalCount()));\n+      // Store an immutable snapshot (make sure we don't mutate the instance after storing)\n+      completedSegments[currentIdx] = currentSegmentAccumulation;\n\nReview Comment:\n   This is happening by reference. The reference earlier held by `currentSegmentAccumulation` is now saved into `completedSegments[currentIdx]`. And a new reference is created  and saved into `currentSegmentAccumulation`\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:45:35.253+0000", "updated": "2025-10-28T17:45:35.253+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033628", "id": "18033628", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470505964\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:47:01.456+0000", "updated": "2025-10-28T17:47:01.456+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033630", "id": "18033630", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470514912\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -114,6 +116,7 @@ public class AbfsRestOperation {\n    */\n   private String failureReason;\n   private AbfsRetryPolicy retryPolicy;\n+  private boolean shouldTailLatencyTimeout = true;\n\nReview Comment:\n   That might be misleading.\r\n   This variable is not a flag for this feature. Even when feature is enabled, we might have this as false.\r\n   \r\n   This is to indicate that all the retried due to TailLatencyTimeout are exhausted and even though the feature is still enabled, for the next retry we should not Timeout due to tail latency\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:48:45.361+0000", "updated": "2025-10-28T17:48:45.361+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033631", "id": "18033631", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470519920\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -114,6 +116,7 @@ public class AbfsRestOperation {\n    */\n   private String failureReason;\n   private AbfsRetryPolicy retryPolicy;\n+  private boolean shouldTailLatencyTimeout = true;\n\nReview Comment:\n   Added javadoc\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:49:35.107+0000", "updated": "2025-10-28T17:49:35.107+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033632", "id": "18033632", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470527273\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:51:16.136+0000", "updated": "2025-10-28T17:51:16.136+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033634", "id": "18033634", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470543064\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        0,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Verify that the histogram is created successfully with default values and\n+    // do not report any percentiles\n+    assertThat(histogram).isNotNull();\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(0);\n+    assertThat(histogram.getCurrentIndex()).isEqualTo(0);\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Verify that recording values works as expected\n+    addAndRotate(histogram, 10, 5); // Add 5 values of 10\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(5);\n+\n+    // Verify that percentiles are not computed with insufficient samples\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values to exceed the minimum sample size\n+    addAndRotate(histogram, 20, 5); // Add 5 values of 20\n+\n+    // Verify that percentiles are now computed but tail Latency is still not reported\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values and rotate histogram to fill whole analysis window\n+    addAndRotate(histogram, 30, 5); // Add 5 values of 30\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(15);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 60, 5); // Add 5 values of 60\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(20);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation is skipped if nothing new recorded and hence window not filled\n+    addAndRotate(histogram, 100, 0); // No new values added\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation does not happen if analysis window is not filled\n+    histogram.rotateIfNeeded();\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 80\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(25);\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles and tail latency are computed\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isGreaterThan(0.0);\n+\n+    // Verify that sliding window works. Old values should be evicted\n+    addAndRotate(histogram, 90, 3); // Add 3 values of 90\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(23);\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementNotMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        100,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        50,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:56:44.091+0000", "updated": "2025-10-28T17:56:44.091+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033635", "id": "18033635", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470552760\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n\nReview Comment:\n   the division could be by 0 if someone sets window granularity as 0\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:00:19.882+0000", "updated": "2025-10-28T18:00:19.882+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033636", "id": "18033636", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470562303\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -519,6 +519,42 @@ public class AbfsConfiguration{\n       DefaultValue = DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY)\n   private boolean enableCreateIdempotency;\n \n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER)\n+  private boolean isTailLatencyTrackerEnabled;\n+\n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT)\n+  private boolean isTailLatencyRequestTimeoutEnabled;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_PERCENTILE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE)\n+  private int tailLatencyPercentile;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_DEVIATION,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_DEVIATION)\n+  private int tailLatencyMinDeviation;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE)\n+  private int tailLatencyMinSampleSize;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS)\n+  private int tailLatencyAnalysisWindowInMillis;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY)\n\nReview Comment:\n   should we have a min, max value for window size above and window granularity?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:04:11.348+0000", "updated": "2025-10-28T18:04:11.348+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033638", "id": "18033638", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470579619\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT = false;\n+  public static final int DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE = 99;\n\nReview Comment:\n   Nice suggestion. Will take it up.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:10:51.707+0000", "updated": "2025-10-28T18:10:51.707+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033639", "id": "18033639", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470580745\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n\nReview Comment:\n   Added\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n+    super(ERR_TAIL_LATENCY_REQUEST_TIMEOUT, innerException);\n+  }\n+\n+  public TailLatencyRequestTimeoutException() {\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:11:15.107+0000", "updated": "2025-10-28T18:11:15.107+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033640", "id": "18033640", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470581573\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n\nReview Comment:\n   we could log the initialization with the granularity etc configs here\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:11:36.763+0000", "updated": "2025-10-28T18:11:36.763+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033641", "id": "18033641", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470582171\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -132,6 +138,30 @@ public void close() throws IOException {\n    * @throws IOException network error.\n    */\n   public HttpResponse execute(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long tailLatencyTimeout) throws IOException {\n+    if (tailLatencyTimeout <= 0) {\n+      return executeWithoutDeadline(httpRequest, abfsHttpClientContext,\n+          connectTimeout, readTimeout);\n+    }\n+    return executeWithDeadline(httpRequest, abfsHttpClientContext,\n+        connectTimeout, readTimeout, tailLatencyTimeout);\n+  }\n+\n+  /**\n+   * Executes the HTTP request.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error.\n+   */\n+  public HttpResponse executeWithoutDeadline(HttpRequestBase httpRequest,\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:11:56.584+0000", "updated": "2025-10-28T18:11:56.584+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033642", "id": "18033642", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470583329\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -611,10 +630,30 @@ AbfsJdkHttpOperation createAbfsHttpOperation() throws IOException {\n \n   @VisibleForTesting\n   AbfsAHCHttpOperation createAbfsAHCHttpOperation() throws IOException {\n+    long tailLatency = getTailLatencyTimeoutIfEnabled();\n     return new AbfsAHCHttpOperation(url, method, requestHeaders,\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpConnectionTimeout()),\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpReadTimeout()),\n-        client.getAbfsApacheHttpClient(), client);\n+        tailLatency, client.getAbfsApacheHttpClient(), client);\n+  }\n+\n+  /**\n+   * Get Tail Latency Timeout value if profiling is enabled, timeout is enabled\n+   * and retries due to tail latency request timeout is allowed.\n+   * @return tail latency timeout value else return zero.\n+   */\n+  long getTailLatencyTimeoutIfEnabled() {\n+    if (isTailLatencyTimeoutEnabled() && shouldTailLatencyTimeout) {\n+      return (long) tailLatencyTracker.getTailLatency(this.operationType);\n+    }\n+    return ZERO;\n+  }\n+\n+  boolean isTailLatencyTimeoutEnabled() {\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:12:21.624+0000", "updated": "2025-10-28T18:12:21.624+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033643", "id": "18033643", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470586126\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:13:35.825+0000", "updated": "2025-10-28T18:13:35.825+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033644", "id": "18033644", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470589733\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n\nReview Comment:\n   Latency tracker are per account basis. They are shared across all filesystem in a single JVM. These are daemon threads and will be killed when JVM gets killed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:14:49.165+0000", "updated": "2025-10-28T18:14:49.165+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033645", "id": "18033645", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470589786\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n+        tailLatencyTracker.updateLatency(operationType,\n\nReview Comment:\n   can 2 threads call updateLatency() for the same operation type simultaneously and create histograms?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:14:50.078+0000", "updated": "2025-10-28T18:14:50.078+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033646", "id": "18033646", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470595674\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:17:16.007+0000", "updated": "2025-10-28T18:17:16.007+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033647", "id": "18033647", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470598024\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -519,6 +519,42 @@ public class AbfsConfiguration{\n       DefaultValue = DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY)\n   private boolean enableCreateIdempotency;\n \n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER)\n+  private boolean isTailLatencyTrackerEnabled;\n+\n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT)\n+  private boolean isTailLatencyRequestTimeoutEnabled;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_PERCENTILE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE)\n+  private int tailLatencyPercentile;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_DEVIATION,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_DEVIATION)\n+  private int tailLatencyMinDeviation;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE)\n+  private int tailLatencyMinSampleSize;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS)\n+  private int tailLatencyAnalysisWindowInMillis;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY)\n\nReview Comment:\n   Added min value for granularity.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:18:16.050+0000", "updated": "2025-10-28T18:18:16.050+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033648", "id": "18033648", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470599110\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n\nReview Comment:\n   Already in SlidingWindowHdrHistogram class\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:18:39.919+0000", "updated": "2025-10-28T18:18:39.919+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033649", "id": "18033649", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470608205\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n+        }\n+      } finally {\n+        LOCK.unlock();\n+      }\n+    }\n+    return singleton;\n+  }\n+\n+  /**\n+   * Updates the latency for a specific operation type.\n+   * @param latency Latency value to be recorded.\n+   * @param operationType Only applicable for read and write operations.\n+   */\n+  public void updateLatency(final AbfsRestOperationType operationType,\n+      final long latency) {\n+    SlidingWindowHdrHistogram histogram = operationLatencyMap.get(operationType);\n+    if (histogram == null) {\n+      LOG.debug(\"Creating new histogram for operation: {}\", operationType);\n+      histogram = new SlidingWindowHdrHistogram(\n+          configuration.getTailLatencyAnalysisWindowInMillis(),\n+          configuration.getTailLatencyAnalysisWindowGranularity(),\n+          configuration.getTailLatencyMinSampleSize(),\n+          configuration.getTailLatencyPercentile(),\n+          configuration.getTailLatencyMinDeviation(),\n+          HISTOGRAM_MAX_VALUE, HISTOGRAM_SIGNIFICANT_FIGURES, operationType);\n+      operationLatencyMap.put(operationType, histogram);\n+    } else {\n+      LOG.debug(\"Using existing histogram for operation: {}\",  operationType);\n+    }\n+    histogram.recordValue(latency);\n+    LOG.debug(\"Updated latency for operation: {} with latency: {}\",\n+        operationType, latency);\n+  }\n+\n+  /**\n+   * Gets the tail latency for a specific operation type.\n+   * @param operationType Only applicable for read and write operations.\n\nReview Comment:\n   why only for read, write operations? \r\n   we are not making the operationType check inside the method\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:20:56.228+0000", "updated": "2025-10-28T18:20:56.228+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033650", "id": "18033650", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470616013\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n+        tailLatencyTracker.updateLatency(operationType,\n\nReview Comment:\n   Nice catch.\r\n   Added Lock while creation.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:22:37.547+0000", "updated": "2025-10-28T18:22:37.547+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033651", "id": "18033651", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470619056\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n+        }\n+      } finally {\n+        LOCK.unlock();\n+      }\n+    }\n+    return singleton;\n+  }\n+\n+  /**\n+   * Updates the latency for a specific operation type.\n+   * @param latency Latency value to be recorded.\n+   * @param operationType Only applicable for read and write operations.\n+   */\n+  public void updateLatency(final AbfsRestOperationType operationType,\n+      final long latency) {\n+    SlidingWindowHdrHistogram histogram = operationLatencyMap.get(operationType);\n+    if (histogram == null) {\n+      LOG.debug(\"Creating new histogram for operation: {}\", operationType);\n+      histogram = new SlidingWindowHdrHistogram(\n+          configuration.getTailLatencyAnalysisWindowInMillis(),\n+          configuration.getTailLatencyAnalysisWindowGranularity(),\n+          configuration.getTailLatencyMinSampleSize(),\n+          configuration.getTailLatencyPercentile(),\n+          configuration.getTailLatencyMinDeviation(),\n+          HISTOGRAM_MAX_VALUE, HISTOGRAM_SIGNIFICANT_FIGURES, operationType);\n+      operationLatencyMap.put(operationType, histogram);\n+    } else {\n+      LOG.debug(\"Using existing histogram for operation: {}\",  operationType);\n+    }\n+    histogram.recordValue(latency);\n+    LOG.debug(\"Updated latency for operation: {} with latency: {}\",\n+        operationType, latency);\n+  }\n+\n+  /**\n+   * Gets the tail latency for a specific operation type.\n+   * @param operationType Only applicable for read and write operations.\n\nReview Comment:\n   Updated\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:23:22.496+0000", "updated": "2025-10-28T18:23:22.496+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033666", "id": "18033666", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3458139061\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 45s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 14s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 44 new + 3 unchanged - 0 fixed = 47 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 34 new + 1472 unchanged - 0 fixed = 1506 total (was 1472)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 33 new + 1413 unchanged - 0 fixed = 1446 total (was 1413)  |\r\n   | -1 :x: |  spotbugs  |   0m 44s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 5 new + 177 unchanged - 1 fixed = 182 total (was 178)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  60m 40s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Possible null pointer dereference of histogram in org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker.updateLatency(AbfsRestOperationType, long)  Dereferenced at AbfsTailLatencyTracker.java:histogram in org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker.updateLatency(AbfsRestOperationType, long)  Dereferenced at AbfsTailLatencyTracker.java:[line 149] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 81] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux c4d12ec6b6d0 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3ca8f94cbd461d8904d9c655d446c2927dac0cd5 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/testReport/ |\r\n   | Max. process+thread count | 611 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T19:25:47.744+0000", "updated": "2025-10-28T19:25:47.744+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034128", "id": "18034128", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2477231657\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -359,7 +369,7 @@ void completeExecute(TracingContext tracingContext)\n   @VisibleForTesting\n   void updateBackoffMetrics(int retryCount, int statusCode) {\n     if (abfsBackoffMetrics != null) {\n-      if (statusCode < HttpURLConnection.HTTP_OK\n\nReview Comment:\n   This change can we reverted.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -453,7 +463,7 @@ private boolean executeHttpOperation(final int retryCount,\n       }\n         incrementCounter(AbfsStatistic.GET_RESPONSES, 1);\n       //Only increment bytesReceived counter when the status code is 2XX.\n-      if (httpOperation.getStatusCode() >= HttpURLConnection.HTTP_OK\n\nReview Comment:\n   same as above\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestAbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AbstractAbfsIntegrationTest;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_NETWORKING_LIBRARY;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ITestAbfsTailLatencyTracker extends AbstractAbfsIntegrationTest {\n+\n+  protected ITestAbfsTailLatencyTracker() throws Exception {\n+  }\n+\n+  @Test\n+  public void testTailLatencyTimeoutEnabled() throws Exception {\n\nReview Comment:\n   Java doc missing. Please add it to all newly added test cases\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-30T09:59:16.677+0000", "updated": "2025-10-30T09:59:16.677+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034320", "id": "18034320", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2480181549\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT = false;\n+  public static final int DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE = 99;\n\nReview Comment:\n   I am not finding an easy way to make this change. Will add a work item for this improvement and take it up in follow up items.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T05:11:13.819+0000", "updated": "2025-10-31T05:11:13.819+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034339", "id": "18034339", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3471759836\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  21m 55s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 44s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 177 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 58s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 12s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 25 new + 3 unchanged - 0 fixed = 28 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 18s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 32 new + 1518 unchanged - 0 fixed = 1550 total (was 1518)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 31 new + 1412 unchanged - 0 fixed = 1443 total (was 1412)  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 4 new + 176 unchanged - 1 fixed = 180 total (was 177)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m  3s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  59m 35s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 95] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 4e580718cb8c 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / a57f2afea1b3be581f31a6595e498ec2b2a42e3a |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/testReport/ |\r\n   | Max. process+thread count | 633 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T08:12:08.548+0000", "updated": "2025-10-31T08:12:08.548+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034353", "id": "18034353", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2480654128\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -453,7 +463,7 @@ private boolean executeHttpOperation(final int retryCount,\n       }\n         incrementCounter(AbfsStatistic.GET_RESPONSES, 1);\n       //Only increment bytesReceived counter when the status code is 2XX.\n-      if (httpOperation.getStatusCode() >= HttpURLConnection.HTTP_OK\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -359,7 +369,7 @@ void completeExecute(TracingContext tracingContext)\n   @VisibleForTesting\n   void updateBackoffMetrics(int retryCount, int statusCode) {\n     if (abfsBackoffMetrics != null) {\n-      if (statusCode < HttpURLConnection.HTTP_OK\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestAbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AbstractAbfsIntegrationTest;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_NETWORKING_LIBRARY;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ITestAbfsTailLatencyTracker extends AbstractAbfsIntegrationTest {\n+\n+  protected ITestAbfsTailLatencyTracker() throws Exception {\n+  }\n+\n+  @Test\n+  public void testTailLatencyTimeoutEnabled() throws Exception {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T09:15:18.495+0000", "updated": "2025-10-31T09:15:18.495+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034373", "id": "18034373", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2480943824\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1949,7 +1950,7 @@ public boolean isTailLatencyTrackerEnabled() {\n   }\n \n   public boolean isTailLatencyRequestTimeoutEnabled() {\n-    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n+    return isTailLatencyTrackerEnabled && isTailLatencyRequestTimeoutEnabled\n\nReview Comment:\n   javadocs for warnings can be added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T10:32:31.656+0000", "updated": "2025-10-31T10:32:31.656+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034406", "id": "18034406", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2481457271\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -131,11 +139,11 @@ public void updateLatency(final AbfsRestOperationType operationType,\n         if (operationLatencyMap.get(operationType) == null) {\n           LOG.debug(\"Creating new histogram for operation: {}\", operationType);\n           histogram = new SlidingWindowHdrHistogram(\n-              configuration.getTailLatencyAnalysisWindowInMillis(),\n-              configuration.getTailLatencyAnalysisWindowGranularity(),\n-              configuration.getTailLatencyMinSampleSize(),\n-              configuration.getTailLatencyPercentile(),\n-              configuration.getTailLatencyMinDeviation(),\n+              talLatencyAnalysisWindowInMillis,\n\nReview Comment:\n   nit: spelling of tail\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:38:21.580+0000", "updated": "2025-10-31T13:38:21.580+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034411", "id": "18034411", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3473362007\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 45s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 177 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 58s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 21 new + 1517 unchanged - 1 fixed = 1538 total (was 1518)  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 19 new + 1412 unchanged - 0 fixed = 1431 total (was 1412)  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 2 new + 176 unchanged - 1 fixed = 178 total (was 177)  |\r\n   | +1 :green_heart: |  shadedclient  |  15m 45s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  63m  1s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 7c5c2cb63961 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 56129accd046c6ae237402d7f64894da6ba44046 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/testReport/ |\r\n   | Max. process+thread count | 639 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T14:33:39.488+0000", "updated": "2025-10-31T14:33:39.488+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034419", "id": "18034419", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3473551869\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  33m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   1m 25s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 177 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  28m 33s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 31s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 21 new + 1517 unchanged - 1 fixed = 1538 total (was 1518)  |\r\n   | -1 :x: |  javadoc  |   0m 28s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 19 new + 1412 unchanged - 0 fixed = 1431 total (was 1412)  |\r\n   | -1 :x: |  spotbugs  |   1m 23s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 2 new + 176 unchanged - 1 fixed = 178 total (was 177)  |\r\n   | +1 :green_heart: |  shadedclient  |  26m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  4s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 105m 11s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 86ea63abc892 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 56129accd046c6ae237402d7f64894da6ba44046 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/testReport/ |\r\n   | Max. process+thread count | 634 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T15:17:41.571+0000", "updated": "2025-10-31T15:17:41.571+0000"}], "maxResults": 59, "total": 59, "startAt": 0}, "updated": "2025-10-31T15:17:41.000+0000", "created": "2025-10-17T05:41:02.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631619", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631619", "key": "HADOOP-19728", "fields": {"summary": "S3A: add ipv6 support", "description": "Support IPv6 with a flag to enable/disable dual stack endpoints\r\n\r\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/ipv6-access.html", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-10-15T13:16:53.000+0000", "created": "2025-10-15T13:16:53.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631523", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631523", "key": "HADOOP-19727", "fields": {"summary": "Release hadoop-thirdparty 1.5.0", "description": "\r\nRelease hadoop-thirdparty 1.5.0", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-10-20T16:40:40.000+0000", "created": "2025-10-14T14:34:32.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631334", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631334", "key": "HADOOP-19726", "fields": {"summary": "Add JDK 17 compile options for maven-surefire-plugin in hadoop-tos module", "description": "Currently, the {{hadoop-tos}} module does not have the JDK 17 compile options configured for the {{{}maven-surefire-plugin{}}}, which causes the following error during unit test execution:\r\n{code:java}\r\njava.lang.IllegalStateException: Failed to set environment variable\tat org.apache.hadoop.fs.tosfs.util.TestUtility.setSystemEnv(TestUtility.java:120)\tat org.apache.hadoop.fs.tosfs.object.ObjectStorageTestBase.setUp(ObjectStorageTestBase.java:59)\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)Caused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Map java.util.Collections$UnmodifiableMap.m accessible: module java.base does not \"opens java.util\" to unnamed module @69eee410\tat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)\tat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\tat java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)\tat java.base/java.lang.reflect.Field.setAccessible(Field.java:172)\tat org.apache.hadoop.fs.tosfs.util.TestUtility.setSystemEnv(TestUtility.java:116)\t... 4 more\r\n {code}\r\nThis error occurs due to the module system restrictions in JDK 17, where reflection cannot access private fields in the java.util.Collections$UnmodifiableMap class.\r\n\r\n\u00a0\r\n\r\nTo resolve this issue, JDK 17 compile options have been added to ensure the maven-surefire-plugin works correctly in a JDK 17 environment. This PR adds the necessary compile options for maven-surefire-plugin to support JDK 17, fixing the error and ensuring that unit tests can run smoothly.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18029349", "id": "18029349", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #8029:\nURL: https://github.com/apache/hadoop/pull/8029\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   JIRA: HADOOP-19726. [JDK17] Add JDK 17 compile options for maven-surefire-plugin in hadoop-tos module.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   CI\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-12T23:48:43.587+0000", "updated": "2025-10-12T23:48:43.587+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18029372", "id": "18029372", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8029:\nURL: https://github.com/apache/hadoop/pull/8029#issuecomment-3395542255\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 39s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  25m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 23s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 13s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  javadoc  |   0m 12s | [/patch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/artifact/out/patch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-tos in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  shadedclient  |   1m 41s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 13s | [/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/artifact/out/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  55m  3s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8029 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux dd7bc96b56b5 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f188198cdec1613ae955ea31795a8cb1ca496139 |\r\n   | Default Java | Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/testReport/ |\r\n   | Max. process+thread count | 576 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T00:44:42.818+0000", "updated": "2025-10-13T00:44:42.818+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18030393", "id": "18030393", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8029:\nURL: https://github.com/apache/hadoop/pull/8029#issuecomment-3411382684\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  24m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 21s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 22s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 13s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 55s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 26s | [/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/artifact/out/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  58m 21s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.fs.tosfs.object.TestObjectMultiRangeInputStream |\r\n   |   | hadoop.fs.tosfs.object.TestObjectRangeInputStream |\r\n   |   | hadoop.fs.tosfs.object.tos.auth.TestEnvironmentCredentialsProvider |\r\n   |   | hadoop.fs.tosfs.object.tos.auth.TestDefaultCredentialsProviderChain |\r\n   |   | hadoop.fs.tosfs.object.TestObjectOutputStream |\r\n   |   | hadoop.fs.tosfs.commit.TestMagicOutputStream |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8029 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 3f25ded462da 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2bd00ae481cc8a6aeb977fef2700e684236375a4 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/testReport/ |\r\n   | Max. process+thread count | 616 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T15:09:25.152+0000", "updated": "2025-10-16T15:09:25.152+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18030409", "id": "18030409", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8029:\nURL: https://github.com/apache/hadoop/pull/8029#issuecomment-3411690102\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  25m  6s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 21s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 35s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html) |  hadoop-cloud-storage-project/hadoop-tos in trunk has 56 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 11s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 12s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 13s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  14m  0s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 27s | [/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/artifact/out/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  60m 57s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.fs.tosfs.object.TestObjectMultiRangeInputStream |\r\n   |   | hadoop.fs.tosfs.object.TestObjectRangeInputStream |\r\n   |   | hadoop.fs.tosfs.object.tos.auth.TestEnvironmentCredentialsProvider |\r\n   |   | hadoop.fs.tosfs.object.tos.auth.TestDefaultCredentialsProviderChain |\r\n   |   | hadoop.fs.tosfs.object.TestObjectOutputStream |\r\n   |   | hadoop.fs.tosfs.commit.TestMagicOutputStream |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8029 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 9e3548929018 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 9ba2bc5bf9cda429475a820bfcf689479e7fdc2d |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/testReport/ |\r\n   | Max. process+thread count | 639 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T16:27:26.865+0000", "updated": "2025-10-16T16:27:26.865+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18030424", "id": "18030424", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8029:\nURL: https://github.com/apache/hadoop/pull/8029#issuecomment-3412145538\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 44s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  24m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 34s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html) |  hadoop-cloud-storage-project/hadoop-tos in trunk has 56 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m  3s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 16s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 13s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 12s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 58s |  |  hadoop-tos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  60m 20s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8029 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 6a680a7543dc 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 1b29c9884dbd1895ea8116fe1c0cf495ce03d39f |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/testReport/ |\r\n   | Max. process+thread count | 643 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T18:01:30.696+0000", "updated": "2025-10-16T18:01:30.696+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18030490", "id": "18030490", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8029:\nURL: https://github.com/apache/hadoop/pull/8029#issuecomment-3413251437\n\n   @wojiaodoubao Could you please help review this PR again? Thanks a lot!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T23:43:30.763+0000", "updated": "2025-10-16T23:43:30.763+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18030819", "id": "18030819", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8029:\nURL: https://github.com/apache/hadoop/pull/8029#issuecomment-3418122640\n\n   I plan to merge this PR, as the unit test errors in TOS have been resolved. If further optimization is needed later, we can submit a separate PR for improvements.\r\n   \r\n   cc: @steveloughran @wojiaodoubao \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-18T09:40:49.588+0000", "updated": "2025-10-18T09:40:49.588+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631334/comment/18030905", "id": "18030905", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8029:\nURL: https://github.com/apache/hadoop/pull/8029\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-19T02:54:48.791+0000", "updated": "2025-10-19T02:54:48.791+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-10-19T03:00:16.000+0000", "created": "2025-10-12T23:47:15.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631333", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631333", "key": "HADOOP-19725", "fields": {"summary": "Upgrade SpotBugs Version to Support JDK 17 Compilation", "description": "The current SpotBugs version used in the project is 4.2.2 (SpotBugs) and 4.2.0 (SpotBugs Maven Plugin), which is not fully compatible with JDK 17 compilation. To ensure proper functionality of the code quality check tool in a JDK 17 environment, SpotBugs needs to be upgraded to the latest version that supports JDK 17.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18029346", "id": "18029346", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #8028:\nURL: https://github.com/apache/hadoop/pull/8028\n\n   ### Description of PR\r\n   \r\n   JIRA: [JDK17] Upgrade SpotBugs Version to Support JDK 17 Compilation.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-12T23:31:04.168+0000", "updated": "2025-10-12T23:31:04.168+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18029532", "id": "18029532", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3397979702\n\n   @cnauroth @szetszwo After upgrading to JDK 17, I found that spotbug could not run properly because the current version does not support JDK 17. To resolve this issue, I upgraded the versions of the two related plugins. The changes have been tested locally, and the results are as expected.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T15:24:29.352+0000", "updated": "2025-10-13T15:24:29.352+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18029579", "id": "18029579", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3398540465\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  36m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 58s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  mvnsite  |   9m 55s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 51s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  | 124m 16s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  28m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 17s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 43s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   7m  2s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m  7s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 45s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 32s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 853m 28s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 44s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1109m 31s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.tools.TestDFSAdmin |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8028 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux da08cd8994df 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3b47bd160a2122ed84df1730e54cbfafa3ab60b8 |\r\n   | Default Java | Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/testReport/ |\r\n   | Max. process+thread count | 3529 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T18:01:47.299+0000", "updated": "2025-10-13T18:01:47.299+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18029634", "id": "18029634", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3399438331\n\n   I have completed the investigation of the mvnsite build issues and confirmed that the problem is related to the JDIFF module. We plan to submit a separate PR to fix and optimize this issue. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T23:56:15.937+0000", "updated": "2025-10-13T23:56:15.937+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18029746", "id": "18029746", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3401292116\n\n   @steveloughran Could you please review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-14T11:14:05.781+0000", "updated": "2025-10-14T11:14:05.781+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18030024", "id": "18030024", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3405489643\n\n   @Hexiaoqiao Could you please review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T09:36:46.070+0000", "updated": "2025-10-15T09:36:46.070+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18030118", "id": "18030118", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on code in PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#discussion_r2433007716\n\n\n##########\npom.xml:\n##########\n@@ -119,8 +119,8 @@ xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/x\n     <maven-checkstyle-plugin.version>3.1.0</maven-checkstyle-plugin.version>\n     <checkstyle.version>8.29</checkstyle.version>\n     <dependency-check-maven.version>7.1.1</dependency-check-maven.version>\n-    <spotbugs.version>4.2.2</spotbugs.version>\n-    <spotbugs-maven-plugin.version>4.2.0</spotbugs-maven-plugin.version>\n+    <spotbugs.version>4.8.3</spotbugs.version>\n+    <spotbugs-maven-plugin.version>4.7.3.6</spotbugs-maven-plugin.version>\n\nReview Comment:\n   Similarly, why not 4.9.7.0 (or 4.8.6.7)?\n\n\n\n##########\npom.xml:\n##########\n@@ -119,8 +119,8 @@ xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/x\n     <maven-checkstyle-plugin.version>3.1.0</maven-checkstyle-plugin.version>\n     <checkstyle.version>8.29</checkstyle.version>\n     <dependency-check-maven.version>7.1.1</dependency-check-maven.version>\n-    <spotbugs.version>4.2.2</spotbugs.version>\n-    <spotbugs-maven-plugin.version>4.2.0</spotbugs-maven-plugin.version>\n+    <spotbugs.version>4.8.3</spotbugs.version>\n\nReview Comment:\n   Why not 4.9.7 (or 4.8.6)?\n   \n   https://mvnrepository.com/artifact/com.github.spotbugs/spotbugs\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T15:23:41.790+0000", "updated": "2025-10-15T15:23:41.790+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18030123", "id": "18030123", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#discussion_r2433103901\n\n\n##########\npom.xml:\n##########\n@@ -119,8 +119,8 @@ xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/x\n     <maven-checkstyle-plugin.version>3.1.0</maven-checkstyle-plugin.version>\n     <checkstyle.version>8.29</checkstyle.version>\n     <dependency-check-maven.version>7.1.1</dependency-check-maven.version>\n-    <spotbugs.version>4.2.2</spotbugs.version>\n-    <spotbugs-maven-plugin.version>4.2.0</spotbugs-maven-plugin.version>\n+    <spotbugs.version>4.8.3</spotbugs.version>\n\nReview Comment:\n   Thank you for reviewing! You made a very good point \u2014 I\u2019ll update this PR accordingly.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T15:48:03.835+0000", "updated": "2025-10-15T15:48:03.835+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18030288", "id": "18030288", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3409917424\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  37m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 40s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  mvnsite  |  10m 13s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 11s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 47s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  | 125m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  28m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 11s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 58s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   7m  5s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m  8s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 40s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 792m 24s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 46s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1035m 29s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.tools.TestDFSAdmin |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8028 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux c50dc2503f2d 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c7ac33f5f774a890079fd002e27829cc7b38c67d |\r\n   | Default Java | Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/testReport/ |\r\n   | Max. process+thread count | 3553 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T09:08:38.874+0000", "updated": "2025-10-16T09:08:38.874+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18030373", "id": "18030373", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3411057566\n\n   > Thanks @slfan1989 . LGTM. +1. I think it is smooth after check spotbug release changes and other apache projects upgrade feedbacks. TBH, I am not check it with new JDK version carefully.\r\n   \r\n   @Hexiaoqiao Many thanks for reviewing the code! The new Sputbug plugin has been tested on JDK 17 and JDK 21 and works properly.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T14:03:44.942+0000", "updated": "2025-10-16T14:03:44.942+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18030377", "id": "18030377", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T14:05:16.623+0000", "updated": "2025-10-16T14:05:16.623+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631333/comment/18030378", "id": "18030378", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8028:\nURL: https://github.com/apache/hadoop/pull/8028#issuecomment-3411067429\n\n   @szetszwo @steveloughran @Hexiaoqiao @zhtttylz Thank you very much for reviewing the code!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T14:05:44.423+0000", "updated": "2025-10-16T14:05:44.423+0000"}], "maxResults": 12, "total": 12, "startAt": 0}, "updated": "2025-10-16T14:06:32.000+0000", "created": "2025-10-12T23:27:49.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631320", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631320", "key": "HADOOP-19724", "fields": {"summary": "[RISC-V]  Add rv bulk CRC32 (non-CRC32C) optimized path", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631320/comment/18029546", "id": "18029546", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc opened a new pull request, #8031:\nURL: https://github.com/apache/hadoop/pull/8031\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   - Introduces a riscv64 native implementation path for CRC32 (CRC32C not optimized).\r\n   - Adds runtime CPU feature detection on linux-riscv64 to enable hardware-accelerated CRC32 when available; falls back to the existing implementation if native is unavailable or disabled.\r\n   \r\n   Below are the performance changes observed using the built-in CRC32 benchmark. Although performance is poor when bpc <= 64, there are substantial improvements when bpc > 64. To keep the codebase simple and maintainable, I did not add bpc-size-specific handling.\r\n   \r\n   | bpc | #T | Native (origin) | Native (new) | \u0394 (MB/s) | \u0394% |\r\n   |---:|---:|---:|---:|---:|---:|\r\n   | 32 | 1 | 661.5 | 463.5 | -198.0 | -29.9% |\r\n   | 32 | 2 | 642.6 | 491.4 | -151.2 | -23.5% |\r\n   | 32 | 4 | 663.7 | 480.5 | -183.2 | -27.6% |\r\n   | 32 | 8 | 653.0 | 472.0 | -181.0 | -27.7% |\r\n   | 32 | 16 | 656.1 | 473.4 | -182.7 | -27.8% |\r\n   | 64 | 1 | 793.9 | 318.0 | -475.9 | -59.9% |\r\n   | 64 | 2 | 771.3 | 322.1 | -449.2 | -58.2% |\r\n   | 64 | 4 | 787.3 | 315.0 | -472.3 | -60.0% |\r\n   | 64 | 8 | 778.0 | 309.3 | -468.7 | -60.2% |\r\n   | 64 | 16 | 773.5 | 308.1 | -465.4 | -60.2% |\r\n   | 128 | 1 | 878.8 | 2398.8 | +1520.0 | +173.0% |\r\n   | 128 | 2 | 846.8 | 1723.9 | +877.1 | +103.6% |\r\n   | 128 | 4 | 861.2 | 1690.0 | +828.8 | +96.2% |\r\n   | 128 | 8 | 857.8 | 1373.3 | +515.5 | +60.1% |\r\n   | 128 | 16 | 853.8 | 1361.3 | +507.5 | +59.4% |\r\n   | 256 | 1 | 783.9 | 2752.5 | +1968.6 | +251.1% |\r\n   | 256 | 2 | 810.0 | 2053.3 | +1243.3 | +153.5% |\r\n   | 256 | 4 | 835.2 | 1966.5 | +1131.3 | +135.5% |\r\n   | 256 | 8 | 812.4 | 1756.3 | +943.9 | +116.2% |\r\n   | 256 | 16 | 811.8 | 1524.7 | +712.9 | +87.8% |\r\n   | 512 | 1 | 923.6 | 3328.9 | +2405.3 | +260.4% |\r\n   | 512 | 2 | 886.5 | 3295.1 | +2408.6 | +271.7% |\r\n   | 512 | 4 | 910.5 | 2359.9 | +1449.4 | +159.2% |\r\n   | 512 | 8 | 888.1 | 1637.4 | +749.3 | +84.4% |\r\n   | 512 | 16 | 897.0 | 1840.1 | +943.1 | +105.1% |\r\n   | 1024 | 1 | 950.4 | 3045.0 | +2094.6 | +220.4% |\r\n   | 1024 | 2 | 918.0 | 2202.9 | +1284.9 | +140.0% |\r\n   | 1024 | 4 | 937.6 | 2040.4 | +1102.8 | +117.6% |\r\n   | 1024 | 8 | 916.5 | 1961.5 | +1045.0 | +114.0% |\r\n   | 1024 | 16 | 927.4 | 2003.9 | +1076.5 | +116.1% |\r\n   | 2048 | 1 | 962.3 | 3189.1 | +2226.8 | +231.4% |\r\n   | 2048 | 2 | 970.1 | 3192.3 | +2222.2 | +229.1% |\r\n   | 2048 | 4 | 943.4 | 2411.2 | +1467.8 | +155.6% |\r\n   | 2048 | 8 | 937.6 | 1837.7 | +900.1 | +96.0% |\r\n   | 2048 | 16 | 933.1 | 1864.0 | +930.9 | +99.8% |\r\n   | 4096 | 1 | 969.9 | 3654.5 | +2684.6 | +276.8% |\r\n   | 4096 | 2 | 972.0 | 2798.0 | +1826.0 | +187.9% |\r\n   | 4096 | 4 | 960.1 | 2307.0 | +1346.9 | +140.3% |\r\n   | 4096 | 8 | 948.2 | 2753.1 | +1804.9 | +190.4% |\r\n   | 4096 | 16 | 938.7 | 2170.5 | +1231.8 | +131.2% |\r\n   | 8192 | 1 | 973.6 | 4008.1 | +3034.5 | +311.7% |\r\n   | 8192 | 2 | 922.5 | 3018.2 | +2095.7 | +227.2% |\r\n   | 8192 | 4 | 955.6 | 2968.7 | +2013.1 | +210.7% |\r\n   | 8192 | 8 | 943.4 | 2077.9 | +1134.5 | +120.3% |\r\n   | 8192 | 16 | 944.9 | 2191.7 | +1246.8 | +132.0% |\r\n   | 16384 | 1 | 974.4 | 4090.3 | +3115.9 | +319.8% |\r\n   | 16384 | 2 | 978.3 | 2999.6 | +2021.3 | +206.6% |\r\n   | 16384 | 4 | 956.6 | 3248.9 | +2292.3 | +239.6% |\r\n   | 16384 | 8 | 950.8 | 3228.0 | +2277.2 | +239.5% |\r\n   | 16384 | 16 | 941.2 | 2832.1 | +1890.9 | +200.9% |\r\n   | 32768 | 1 | 972.2 | 4205.7 | +3233.5 | +332.6% |\r\n   | 32768 | 2 | 938.6 | 4115.2 | +3176.6 | +338.4% |\r\n   | 32768 | 4 | 957.4 | 2508.9 | +1551.5 | +162.1% |\r\n   | 32768 | 8 | 952.8 | 2319.8 | +1367.0 | +143.5% |\r\n   | 32768 | 16 | 944.5 | 1657.7 | +713.2 | +75.5% |\r\n   | 65536 | 1 | 976.3 | 4226.6 | +3250.3 | +332.9% |\r\n   | 65536 | 2 | 940.0 | 3075.8 | +2135.8 | +227.2% |\r\n   | 65536 | 4 | 958.5 | 1345.2 | +386.7 | +40.3% |\r\n   | 65536 | 8 | 950.2 | 1954.7 | +1004.5 | +105.7% |\r\n   | 65536 | 16 | 945.8 | 2414.0 | +1468.2 | +155.2% |\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Built hadoop-common with native profile on riscv64; verified it's function by TestNativeCrc32.\r\n   Ran Hadoop\u2019s CRC32 benchmark on riscv64 (OpenEuler/EulixOS) with JDK 17.\r\n   Here is the commands and results:\r\n   \r\n   Command\uff1a \r\n   \r\n   ```\r\n   mvn -Pnative \\\r\n     -Dtest=org.apache.hadoop.util.TestNativeCrc32 \\\r\n     -Djava.library.path=\"$HADOOP_COMMON_LIB_NATIVE_DIR\" \\\r\n     test\r\n   ```\r\n   \r\n   Results\r\n   \r\n   ```\r\n   [INFO] -------------------------------------------------------\r\n   [INFO]  T E S T S\r\n   [INFO] -------------------------------------------------------\r\n   [INFO] Running org.apache.hadoop.util.TestNativeCrc32\r\n   [INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.017 s ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T15:57:36.992+0000", "updated": "2025-10-13T15:57:36.992+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631320/comment/18029601", "id": "18029601", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8031:\nURL: https://github.com/apache/hadoop/pull/8031#issuecomment-3398778305\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  23m 29s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  47m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  14m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  | 101m 41s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |  13m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |  13m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  13m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 47s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 25s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 57s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 206m 55s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8031/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8031 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux cf2b3cead534 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0e62b049f710f680823489b1a77892ed49252fc4 |\r\n   | Default Java | Red Hat, Inc.-1.8.0_462-b08 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8031/1/testReport/ |\r\n   | Max. process+thread count | 1376 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8031/1/console |\r\n   | versions | git=2.43.7 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T19:25:51.530+0000", "updated": "2025-10-13T19:25:51.530+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631320/comment/18029760", "id": "18029760", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #8031:\nURL: https://github.com/apache/hadoop/pull/8031#issuecomment-3401469367\n\n   @steveloughran could you please review this PR if you have time? thanks!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-14T12:08:33.735+0000", "updated": "2025-10-14T12:08:33.735+0000"}], "maxResults": 3, "total": 3, "startAt": 0}, "updated": "2025-10-14T12:08:33.000+0000", "created": "2025-10-12T12:49:32.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631109", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631109", "key": "HADOOP-19723", "fields": {"summary": "Build multi-arch hadoop image", "description": "Build {{apache/hadoop}} Docker image for both amd64 and arm64.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028773", "id": "18028773", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai opened a new pull request, #8023:\nURL: https://github.com/apache/hadoop/pull/8023\n\n   ## What changes were proposed in this pull request?\r\n   \r\n   - Update `Dockerfile` (on branch `docker-hadoop-3.4.2-lean`) to support building for `arm64`, too.\r\n       - Use `ghcr.io/apache/hadoop-runner:jdk11-u2204` as base, because `apache/hadoop-runner:latest` only has `amd64` image available.\r\n       - Use `TARGETPLATFORM` to decide which tarball to use.\r\n       - Create args for version and flavor, replacing URL.\r\n   - Update the `build-hadoop-image` workflow to create multi-arch images.\r\n   - Add build-arg `BASE_URL` to allow using mirrors (for faster local build).\r\n   - Replace deprecated `ENV HADOOP_CONF_DIR ` syntax.\r\n   \r\n   https://issues.apache.org/jira/browse/HADOOP-19723\r\n   \r\n   ## How was this patch tested?\r\n   \r\n   Workflow [run](https://github.com/adoroszlai/hadoop/actions/runs/18377713437) in my fork created multi-arch [image](https://github.com/adoroszlai/hadoop/pkgs/container/hadoop/539671710?tag=HADOOP-19723).\r\n   \r\n   ```\r\n   #8 0.060 Building for linux/amd64\r\n   ...\r\n   #8 0.060 + export HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2-lean.tar.gz\r\n   ...\r\n   \r\n   #10 0.076 Building for linux/arm64\r\n   ...\r\n   #10 0.077 + export HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2-aarch64-lean.tar.gz\r\n   ```\r\n   \r\n   Tested on both amd64 and arm64 platforms.\r\n   \r\n   ```\r\n   $ docker run -it --rm ghcr.io/adoroszlai/hadoop:HADOOP-19723 bash -c \"uname -a; hadoop version\"\r\n   Linux cdb5cdd5ace9 6.8.0-65-generic #68~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 15 18:06:34 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\r\n   Hadoop 3.4.2\r\n   Source code repository https://github.com/apache/hadoop.git -r 84e8b89ee2ebe6923691205b9e171badde7a495c\r\n   Compiled by ahmarsu on 2025-08-20T10:30Z\r\n   Compiled on platform linux-x86_64\r\n   Compiled with protoc 3.23.4\r\n   From source with checksum fa94c67d4b4be021b9e9515c9b0f7b6\r\n   This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.4.2.jar\r\n   ```\r\n   \r\n   ```\r\n   $ docker run -it --rm ghcr.io/adoroszlai/hadoop:HADOOP-19723 bash -c \"uname -a; hadoop version\"\r\n   Linux 9a1237ba8fbc 6.10.14-linuxkit #1 SMP Thu Oct 24 19:28:55 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux\r\n   Hadoop 3.4.2\r\n   Source code repository https://github.com/apache/hadoop.git -r e1c0dee881820a4d834ec4a4d2c70d0d953bb933\r\n   Compiled by ahmar on 2025-08-07T15:32Z\r\n   Compiled on platform linux-aarch_64\r\n   Compiled with protoc 3.23.4\r\n   From source with checksum fa94c67d4b4be021b9e9515c9b0f7b6\r\n   This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.4.2.jar\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T13:28:31.642+0000", "updated": "2025-10-09T13:28:31.642+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028776", "id": "18028776", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8023:\nURL: https://github.com/apache/hadoop/pull/8023#issuecomment-3385915162\n\n   LGTM.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T13:32:27.838+0000", "updated": "2025-10-09T13:32:27.838+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028778", "id": "18028778", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8023:\nURL: https://github.com/apache/hadoop/pull/8023#issuecomment-3385930578\n\n   @adoroszlai Thank you for the contribution. If there are no additional comments, I\u2019ll proceed to merge this PR shortly.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T13:36:31.183+0000", "updated": "2025-10-09T13:36:31.183+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028836", "id": "18028836", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai commented on PR #8023:\nURL: https://github.com/apache/hadoop/pull/8023#issuecomment-3386892439\n\n   @smengcl would you like to take a look?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T17:36:49.722+0000", "updated": "2025-10-09T17:36:49.722+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028921", "id": "18028921", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8023:\nURL: https://github.com/apache/hadoop/pull/8023#issuecomment-3388049001\n\n   > @smengcl would you like to take a look?\r\n   \r\n   @smengcl I believe this PR is fine, and since @adoroszlai  has extensive experience with this, any issues that may arise in the future can be quickly addressed. I will go ahead and merge this PR.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-10T02:17:01.464+0000", "updated": "2025-10-10T02:17:01.464+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028923", "id": "18028923", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8023:\nURL: https://github.com/apache/hadoop/pull/8023\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-10T02:18:07.403+0000", "updated": "2025-10-10T02:18:07.403+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028950", "id": "18028950", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai commented on PR #8023:\nURL: https://github.com/apache/hadoop/pull/8023#issuecomment-3388373138\n\n   Thanks @slfan1989 for reviewing and merging this.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-10T05:46:22.120+0000", "updated": "2025-10-10T05:46:22.120+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631109/comment/18028951", "id": "18028951", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "smengcl commented on PR #8023:\nURL: https://github.com/apache/hadoop/pull/8023#issuecomment-3388411324\n\n   Thanks @adoroszlai . The patch looks good.\r\n   \r\n   Thanks @slfan1989 for reviewing this as well.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-10T06:07:00.188+0000", "updated": "2025-10-10T06:07:00.188+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-10-10T06:07:00.000+0000", "created": "2025-10-09T09:22:57.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631098", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631098", "key": "HADOOP-19722", "fields": {"summary": "Pin robotframework version", "description": "{{hadoop-runner}} installs {{robotframework}} without version definition.  Re-building the image for unrelated changes may unexpectedly upgrade {{robotframework}}, too.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631098/comment/18028885", "id": "18028885", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai opened a new pull request, #8025:\nURL: https://github.com/apache/hadoop/pull/8025\n\n   ## What changes were proposed in this pull request?\r\n   \r\n   `hadoop-runner` installs `robotframework` without version definition.  Re-building the image for unrelated changes may unexpectedly upgrade `robotframework`, too.\r\n   \r\n   This PR proposes to pin `robotframework` to version 6.1.1.\r\n   \r\n   https://issues.apache.org/jira/browse/HADOOP-19722\r\n   \r\n   ## How was this patch tested?\r\n   \r\n   ```\r\n   $ docker build -t hadoop-runner:dev .\r\n   ...\r\n   \r\n   $ docker run -it --rm hadoop-runner:dev robot --version\r\n   Robot Framework 6.1.1 (Python 3.10.12 on linux)\r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T21:43:03.656+0000", "updated": "2025-10-09T21:43:03.656+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631098/comment/18029081", "id": "18029081", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "smengcl merged PR #8025:\nURL: https://github.com/apache/hadoop/pull/8025\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-10T18:04:51.727+0000", "updated": "2025-10-10T18:04:51.727+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631098/comment/18029328", "id": "18029328", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai commented on PR #8025:\nURL: https://github.com/apache/hadoop/pull/8025#issuecomment-3395090403\n\n   Thanks @slfan1989, @smengcl for the review.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-12T17:54:24.510+0000", "updated": "2025-10-12T17:54:24.510+0000"}], "maxResults": 3, "total": 3, "startAt": 0}, "updated": "2025-10-12T17:54:24.000+0000", "created": "2025-10-09T07:00:41.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631091", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631091", "key": "HADOOP-19721", "fields": {"summary": "Upgrade hadoop-runner to Ubuntu 24.04", "description": "Latest {{hadoop-runner}} images are based on Ubuntu 22.04.  Upgrade to 24.04.", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-10-09T06:23:41.000+0000", "created": "2025-10-09T06:23:41.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13631035", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13631035", "key": "HADOOP-19720", "fields": {"summary": "Publish multi-arch hadoop-runner image to GitHub", "description": "Create GitHub Actions workflow to publish the apache/hadoop-runner Docker image to GitHub Container Registry.  Build for both amd64 and arm64.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631035/comment/18028427", "id": "18028427", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai opened a new pull request, #8021:\nURL: https://github.com/apache/hadoop/pull/8021\n\n   ## What changes were proposed in this pull request?\r\n   \r\n   Add workflow to publish `apache/hadoop-runner` (`jdk11-u2204` in this case) to GitHub Container Registry.\r\n   \r\n   https://issues.apache.org/jira/browse/HADOOP-19720\r\n   \r\n   ## How was this patch tested?\r\n   \r\n   [Workflow run](https://github.com/adoroszlai/hadoop/actions/runs/18353000644) in my fork for push to branch `docker-hadoop-runner-HADOOP-19720-jdk11-u2204` built [image](https://github.com/adoroszlai/hadoop/pkgs/container/hadoop-runner/538747134?tag=HADOOP-19720-jdk11-u2204) `ghcr.io/adoroszlai/hadoop-runner:HADOOP-19720-jdk11-u2204`.  It has both amd64 and arm64 arch.\r\n   \r\n   ```bash\r\n   $ docker run -it --rm ghcr.io/adoroszlai/hadoop-runner:HADOOP-19720-jdk11-u2204 bash -c 'uname -a; cat /etc/lsb-release; java -version'\r\n   Linux 8099f50d7322 6.8.0-65-generic #68~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 15 18:06:34 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\r\n   DISTRIB_ID=Ubuntu\r\n   DISTRIB_RELEASE=22.04\r\n   DISTRIB_CODENAME=jammy\r\n   DISTRIB_DESCRIPTION=\"Ubuntu 22.04.5 LTS\"\r\n   openjdk version \"11.0.28\" 2025-07-15\r\n   OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6)\r\n   OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode, sharing)\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T17:38:33.167+0000", "updated": "2025-10-08T17:38:33.167+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631035/comment/18028500", "id": "18028500", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8021:\nURL: https://github.com/apache/hadoop/pull/8021#issuecomment-3383664657\n\n   @adoroszlai Many thanks for your contribution. Could we consider upgrading the image to ubuntu 24.04?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T00:41:07.390+0000", "updated": "2025-10-09T00:41:07.390+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631035/comment/18028512", "id": "18028512", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "smengcl merged PR #8021:\nURL: https://github.com/apache/hadoop/pull/8021\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T02:06:57.985+0000", "updated": "2025-10-09T02:06:57.985+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631035/comment/18028513", "id": "18028513", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "smengcl commented on PR #8021:\nURL: https://github.com/apache/hadoop/pull/8021#issuecomment-3383797788\n\n   > @adoroszlai Many thanks for your contribution. Could we consider upgrading the image to ubuntu 24.04?\r\n   \r\n   We could file a new jira for that task.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T02:08:15.780+0000", "updated": "2025-10-09T02:08:15.780+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631035/comment/18028515", "id": "18028515", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8021:\nURL: https://github.com/apache/hadoop/pull/8021#issuecomment-3383809271\n\n   > > @adoroszlai Many thanks for your contribution. Could we consider upgrading the image to ubuntu 24.04?\r\n   > \r\n   > We could file a new jira for that task.\r\n   \r\n   You\u2019ve got a valid point. The branch name is indeed for 22.04, so we can address it in the next JIRA task.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T02:16:23.811+0000", "updated": "2025-10-09T02:16:23.811+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631035/comment/18028532", "id": "18028532", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai commented on PR #8021:\nURL: https://github.com/apache/hadoop/pull/8021#issuecomment-3384254098\n\n   Thanks @slfan1989, @smengcl for the review.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T06:05:01.762+0000", "updated": "2025-10-09T06:05:01.762+0000"}], "maxResults": 6, "total": 6, "startAt": 0}, "updated": "2025-10-09T07:01:33.000+0000", "created": "2025-10-08T17:21:10.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630984", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630984", "key": "HADOOP-19719", "fields": {"summary": "Upgrade to wildfly version with support for openssl 3", "description": "Wildfly 2.1.4\r\n* doesn't work with openssl 3 (that symbol change...why did they do that?)\r\n\r\n\r\nwe need a version with \r\nhttps://github.com/wildfly-security/wildfly-openssl-natives/commit/6cecd42a254cd78585fefd9a0e41ad7954ece80d\r\n\r\n2.2.5.Final does the openssl 3 support. ", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630984/comment/18028330", "id": "18028330", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #8019:\nURL: https://github.com/apache/hadoop/pull/8019\n\n   \r\n   ### How was this patch tested?\r\n   \r\n   Going to see if it works on a mac...\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [X] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T10:59:16.505+0000", "updated": "2025-10-08T10:59:16.505+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630984/comment/18028356", "id": "18028356", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #8019:\nURL: https://github.com/apache/hadoop/pull/8019#issuecomment-3381330281\n\n   the test which is parameterized on ssl (and storediag when a store is forced to OpenSSL)\r\n   ```\r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractSeek.testReadFullyZeroBytebufferPastEOF ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T12:41:04.887+0000", "updated": "2025-10-08T12:41:04.887+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630984/comment/18028360", "id": "18028360", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #8019:\nURL: https://github.com/apache/hadoop/pull/8019#issuecomment-3381381104\n\n   s3a tests all good, s3 london `-Dparallel-tests -DtestsThreadCount=8`\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T12:55:21.261+0000", "updated": "2025-10-08T12:55:21.261+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630984/comment/18030051", "id": "18030051", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #8019:\nURL: https://github.com/apache/hadoop/pull/8019#issuecomment-3405882774\n\n   OK, 2.2.5 doesn't include the arm linux binaries. It does in our private builds, which is why I was confused.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T11:07:38.888+0000", "updated": "2025-10-15T11:07:38.888+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630984/comment/18031140", "id": "18031140", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #8019:\nURL: https://github.com/apache/hadoop/pull/8019\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-20T12:45:49.133+0000", "updated": "2025-10-20T12:45:49.133+0000"}], "maxResults": 5, "total": 5, "startAt": 0}, "updated": "2025-10-20T12:47:50.000+0000", "created": "2025-10-08T10:52:33.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630876", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630876", "key": "HADOOP-19718", "fields": {"summary": "[ABFS]: Throw HTTPException when AAD token fetch fails ", "description": "Reported by [~enigma25] :\r\nIn [this code snippet](https://github.com/Azure/azure-data-lake-store-java/blob/26eca936da60286aa70b0dd7823ff5e627987bc4/src/main/java/com/microsoft/azure/datalake/store/oauth2/AzureADAuthenticator.java#L252-L293) from AzureADAuthenticator, the `conn` is being returned as null due to a (possibly) corrupted connection between Azure Data Lake Store Client and AAD while fetching AAD token. The code snippet linked, runs into an NPE. I wanted to know from the maintainers and community if this bug/symptom has been seen by them earlier and what might be the best way to handle this? Secondly, I wanted to know the right place for the fix too - whether it should be the application code or the SDK code itself should handle such NPEs and fail more gracefully?\r\nOpen to thoughts and comments.\r\nCheers,\r\nNikhil\r\n\u00a0\r\n\u00a0\r\n```\r\njava.util.concurrent.ExecutionException: java.lang.NullPointerException: Cannot invoke \"java.io.InputStream.read(byte[], int, int)\" because \"inStream\" is null\r\nat org.apache.kafka.connect.util.ConvertingFutureCallback.result(ConvertingFutureCallback.java:135)\r\nat org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:122)\r\nat org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource.validateConfigs(ConnectorPluginsResource.java:129)\r\nat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\nat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\nat org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)\r\nat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)\r\nat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)\r\nat org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)\r\nat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)\r\nat org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)\r\nat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)\r\nat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)\r\nat org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)\r\nat org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)\r\nat org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)\r\nat org.glassfish.jersey.internal.Errors.process(Errors.java:292)\r\nat org.glassfish.jersey.internal.Errors.process(Errors.java:274)\r\nat org.glassfish.jersey.internal.Errors.process(Errors.java:244)\r\nat org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)\r\nat org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)\r\nat org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)\r\nat org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)\r\nat org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)\r\nat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)\r\nat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)\r\nat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)\r\nat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\r\nat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\nat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\nat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\r\nat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\r\nat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\r\nat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\nat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\r\nat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)\r\nat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\nat org.eclipse.jetty.server.Server.handle(Server.java:516)\r\nat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\r\nat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\r\nat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\r\nat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\r\nat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\r\nat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\r\nat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\r\nat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\r\nat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\r\nat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\r\nat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.lang.NullPointerException: Cannot invoke \"java.io.InputStream.read(byte[], int, int)\" because \"inStream\" is null\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.consumeInputStream(AzureADAuthenticator.java:345)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.getTokenSingleCall(AzureADAuthenticator.java:275)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.getTokenCall(AzureADAuthenticator.java:216)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.getTokenUsingClientCreds(AzureADAuthenticator.java:95)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider.refreshToken(ClientCredsTokenProvider.java:58)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider.getToken(AccessTokenProvider.java:50)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getAccessToken(AbfsClient.java:583)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(AbfsRestOperation.java:162)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.execute(AbfsRestOperation.java:134)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getFilesystemProperties(AbfsClient.java:205)\r\nat io.confluent.connect.azure.datalake.gen2.validation.Validations.verifyClient(Validations.java:175)\r\nat io.confluent.connect.azure.datalake.gen2.validation.Validations.createAndValidateClient(Validations.java:395)\r\nat io.confluent.connect.azure.datalake.gen2.validation.Validations.validateAll(Validations.java:131)\r\nat io.confluent.connect.utils.validators.all.ConfigValidation.lambda$callValidators$0(ConfigValidation.java:222)\r\nat java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)\r\nat java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)\r\nat io.confluent.connect.utils.validators.all.ConfigValidation.callValidators(ConfigValidation.java:222)\r\nat io.confluent.connect.utils.validators.all.ConfigValidation.validate(ConfigValidation.java:182)\r\nat io.confluent.connect.azure.datalake.gen2.AzureDataLakeGen2SinkConnector.validate(AzureDataLakeGen2SinkConnector.java:97)\r\nat org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:641)\r\nat org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$7(AbstractHerder.java:493)\r\nat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\r\nat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\nat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\nat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n... 1 more\r\n```", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-10-07T12:56:26.000+0000", "created": "2025-10-07T12:56:26.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630839", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630839", "key": "HADOOP-19717", "fields": {"summary": "Resolve build error caused by missing Checker Framework (NonNull not recognized)", "description": "In the recent build, we encountered the following issue: *org.checkerframework.checker.nullness.qual.NonNull* could not be recognized, and the following error was observed.\r\n{code:java}\r\n[ERROR] /home/jenkins/jenkins-agent/workspace/hadoop-multibranch_PR-8011/ubuntu-focal/src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[216,50] package org.checkerframework.checker.nullness.qual does not exist\r\n[ERROR] /home/jenkins/jenkins-agent/workspace/hadoop-multibranch_PR-8011/ubuntu-focal/src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[2509,30] cannot find symbol\r\n[ERROR]   symbol:   class NonNull\r\n[ERROR]   location: class org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer.AsyncThreadFactory\r\n {code}\r\nI checked the usage in the related modules, and we should use *org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.NonNull* instead of directly using {*}org.checkerframework.checker.nullness.qual.NonNull{*}.\r\n\r\n\u00a0", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18027976", "id": "18027976", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #8015:\nURL: https://github.com/apache/hadoop/pull/8015\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   JIRA: HADOOP-19717. Resolve build error caused by missing Checker Framework  (NonNull not recognized).\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T04:01:33.037+0000", "updated": "2025-10-07T04:01:33.037+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18027980", "id": "18027980", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#discussion_r2409341008\n\n\n##########\nhadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:\n##########\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.tosfs.util;\n \n import org.apache.hadoop.util.Preconditions;\n-import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n\nReview Comment:\n   I suspect this makes the `Nullable` useless, I don't think the static analyzer tools can recognize such a relocated annotation.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T04:48:15.069+0000", "updated": "2025-10-07T04:48:15.069+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18027988", "id": "18027988", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3375421893\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 31s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 35s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |  22m 41s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   5m 25s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   4m 39s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 18s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   0m 24s | [/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) |  hadoop-hdfs-rbf in trunk failed.  |\r\n   | -1 :x: |  mvnsite  |   0m 18s | [/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 27s | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-hdfs-rbf in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-tos in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  spotbugs  |   0m 25s | [/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) |  hadoop-hdfs-rbf in trunk failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 16s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  24m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 23s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m 37s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |   5m 41s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   5m 41s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   5m 11s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   5m 10s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 21s |  |  hadoop-hdfs-project_hadoop-hdfs-rbf-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  hadoop-cloud-storage-project_hadoop-tos-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2)  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 26s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  38m 54s |  |  hadoop-hdfs-rbf in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 54s |  |  hadoop-tos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 26s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 154m  4s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8015 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 1ad3180c6b2e 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f0c771fd1f48e1cc45617d4e2eb0afb552e5ba1f |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/testReport/ |\r\n   | Max. process+thread count | 4610 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-hdfs-project/hadoop-hdfs-rbf hadoop-cloud-storage-project/hadoop-tos U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T06:36:36.034+0000", "updated": "2025-10-07T06:36:36.034+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028046", "id": "18028046", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#discussion_r2410285097\n\n\n##########\nhadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:\n##########\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.tosfs.util;\n \n import org.apache.hadoop.util.Preconditions;\n-import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n\nReview Comment:\n   I think what you said makes some sense, but there are similar users in AzureBFS as well.\r\n   \r\n   https://github.com/apache/hadoop/blob/1566613c725979d0ccda45822dfa275cbd97467a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java#L38\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T11:19:14.896+0000", "updated": "2025-10-07T11:19:14.896+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028047", "id": "18028047", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#discussion_r2410285097\n\n\n##########\nhadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:\n##########\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.tosfs.util;\n \n import org.apache.hadoop.util.Preconditions;\n-import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n\nReview Comment:\n   I think what you said makes some sense, but there are similar users in AzureBFS as well.\r\n   \r\n   https://github.com/apache/hadoop/blob/1566613c725979d0ccda45822dfa275cbd97467a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java#L38\r\n   \r\n   @steveloughran I\u2019d like to hear your thoughts \u2014 do you think we should reintroduce a new dependency to resolve the issue where org.checkerframework.checker.nullness.qual.Nullable cannot be found?\r\n   \r\n   cc: @szetszwo \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T11:20:49.833+0000", "updated": "2025-10-07T11:20:49.833+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028086", "id": "18028086", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3376863181\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 12s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |  22m 36s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   5m 21s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   4m 43s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 24s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   0m 24s | [/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) |  hadoop-hdfs-rbf in trunk failed.  |\r\n   | -1 :x: |  mvnsite  |   0m 18s | [/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 18s | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-hdfs-rbf in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-tos in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | +1 :green_heart: |  javadoc  |   1m  4s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  spotbugs  |   0m 22s | [/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) |  hadoop-hdfs-rbf in trunk failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 17s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 22s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   1m  4s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |   5m 49s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   5m 49s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   5m  5s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   5m  5s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  hadoop-yarn-server-resourcemanager in the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  hadoop-yarn-server-resourcemanager in the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  hadoop-hdfs-project_hadoop-hdfs-rbf-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  hadoop-cloud-storage-project_hadoop-tos-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2)  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 41s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  90m 40s |  |  hadoop-yarn-server-resourcemanager in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |  38m  2s |  |  hadoop-hdfs-rbf in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 53s |  |  hadoop-tos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 24s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 241m 25s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8015 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux de756f6ac704 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / aca0e73a716b49f41b6eb3e0a57c876842a258a8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/testReport/ |\r\n   | Max. process+thread count | 4761 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-hdfs-project/hadoop-hdfs-rbf hadoop-cloud-storage-project/hadoop-tos U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T13:18:47.987+0000", "updated": "2025-10-07T13:18:47.987+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028098", "id": "18028098", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377007084\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 46s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |  26m 13s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   6m 12s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   5m 18s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 19s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   0m 25s | [/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) |  hadoop-hdfs-rbf in trunk failed.  |\r\n   | -1 :x: |  mvnsite  |   0m 18s | [/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 23s | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-hdfs-rbf in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-tos in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | +1 :green_heart: |  javadoc  |   0m 40s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  spotbugs  |   0m 25s | [/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) |  hadoop-hdfs-rbf in trunk failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 16s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  26m  8s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 25s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m 41s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |   6m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   6m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   5m 50s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   5m 50s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  hadoop-hdfs-project_hadoop-hdfs-rbf-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2)  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  hadoop-cloud-storage-project_hadoop-tos-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2)  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  23m 54s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  39m  4s |  |  hadoop-hdfs-rbf in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 54s |  |  hadoop-tos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 158m 17s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8015 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 30e4a84a468c 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f0c771fd1f48e1cc45617d4e2eb0afb552e5ba1f |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/testReport/ |\r\n   | Max. process+thread count | 4202 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-hdfs-project/hadoop-hdfs-rbf hadoop-cloud-storage-project/hadoop-tos U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T13:54:35.628+0000", "updated": "2025-10-07T13:54:35.628+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028109", "id": "18028109", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377166843\n\n   @szetszwo @pan3793 My thought is that since `AzureBFS` already uses this approach, we should be able to apply the same solution in other places as well. For now, we can use`org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable` instead of `org.checkerframework.checker.nullness.qual.Nullable` to unblock the trunk build issue first. \r\n   \r\n   A follow-up PR can be submitted later to fully resolve this dependency problem in a cleaner way.\r\n   \r\n   Currently, the build result is as expected \u2014 before applying this patch, the trunk could not compile successfully, but after merging it, the build now passes under both JDK 8 and JDK 11.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T14:28:09.076+0000", "updated": "2025-10-07T14:28:09.076+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028128", "id": "18028128", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on code in PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#discussion_r2411050812\n\n\n##########\nhadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:\n##########\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.tosfs.util;\n \n import org.apache.hadoop.util.Preconditions;\n-import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n\nReview Comment:\n   > ...  this makes the Nullable useless, ...\r\n   \r\n   Making it useless seems better than breaking the build.\r\n   \r\n   Unforturately, the the builds after this remain failing.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T15:30:58.356+0000", "updated": "2025-10-07T15:30:58.356+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028129", "id": "18028129", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377457340\n\n   @slfan1989 , if it can fix the build, then it is fine.  But the builds after this remain failing.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T15:32:12.017+0000", "updated": "2025-10-07T15:32:12.017+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028132", "id": "18028132", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377471954\n\n   > @slfan1989 , if it can fix the build, then it is fine. But the builds after this remain failing.\r\n   \r\n   @szetszwo A new issue occurred during the compilation of yarn-ui. The log output is as follows:\r\n   \r\n   ```\r\n   [INFO] [2/4] Fetching packages...\r\n   [INFO] error color@5.0.2: The engine \"node\" is incompatible with this module. Expected version \">=18\". Got \"12.22.1\"\r\n   [INFO] error Found incompatible module.\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T15:36:23.621+0000", "updated": "2025-10-07T15:36:23.621+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028139", "id": "18028139", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377538969\n\n   > > @slfan1989 , if it can fix the build, then it is fine. But the builds after this remain failing.\r\n   > \r\n   > @szetszwo A new issue occurred during the compilation of yarn-ui. The log output is as follows:\r\n   > \r\n   > ```\r\n   > [INFO] [2/4] Fetching packages...\r\n   > [INFO] error color@5.0.2: The engine \"node\" is incompatible with this module. Expected version \">=18\". Got \"12.22.1\"\r\n   > [INFO] error Found incompatible module.\r\n   > ```\r\n   > \r\n   > I tried to apply a local fix for this issue.\r\n   \r\n   I manually specified `color@^3.1.3` in the package.json, and it took effect successfully. I will submit a PR to fix this issue.\r\n   \r\n   ```\r\n   [INFO] -", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T15:55:40.527+0000", "updated": "2025-10-07T15:55:40.527+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028141", "id": "18028141", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T15:58:33.738+0000", "updated": "2025-10-07T15:58:33.738+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028142", "id": "18028142", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377550294\n\n   @szetszwo Thank you very much for the review! \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T15:59:04.147+0000", "updated": "2025-10-07T15:59:04.147+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18028152", "id": "18028152", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #8015:\nURL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377632827\n\n   @slfan1989 , thanks for fixing it!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T16:20:51.703+0000", "updated": "2025-10-07T16:20:51.703+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630839/comment/18031207", "id": "18031207", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "this is complicating the new thirdparty release FWIW. this should all be using the unshaded javax. Nullable/nonnull. And the hadoop-thirdparty release needs to address this stuff getting left out so 1.5.0 can be a drop-in replacement for 1.4.0\r\n{code}\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.10.1:compile (default-compile) on project hadoop-tos: Compilation failure: Compilation failure: \r\n[ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:[22,79] package org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual does not exist\r\n[ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:[89,29] cannot find symbol\r\n[ERROR]   symbol:   class Nullable\r\n[ERROR]   location: class org.apache.hadoop.fs.tosfs.util.Iterables\r\n[ERROR] -> [Help 1]\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.10.1:compile (default-compile) on project hadoop-azure: Compilation failure: Compilation failure: \r\n[ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java:[38,79] package org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual does not exist\r\n[ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java:[183,30] cannot find symbol\r\n[ERROR]   symbol: class Nullable\r\n[ERROR] -> [Help 1]\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.10.1:compile (default-compile) on project hadoop-hdfs-rbf: Compilation failure: Compilation failure: \r\n[ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[102,79] package org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual does not exist\r\n[ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[2509,30] cannot find symbol\r\n[ERROR]   symbol:   class NonNull\r\n[ERROR]   location: class org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer.AsyncThreadFactory\r\n[ERROR] -> [Help 1]\r\n[ERROR] \r\n{code}\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-20T16:32:20.848+0000", "updated": "2025-10-20T16:32:20.848+0000"}], "maxResults": 16, "total": 16, "startAt": 0}, "updated": "2025-10-20T16:32:20.000+0000", "created": "2025-10-07T03:49:55.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630760", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630760", "key": "HADOOP-19716", "fields": {"summary": "Create lean docker image", "description": "Create a new docker image based on the lean tarball.\r\n\r\nhadoop-3.4.2-lean.tar.gz", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630760/comment/18024880", "id": "18024880", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai opened a new pull request, #8013:\nURL: https://github.com/apache/hadoop/pull/8013\n\n   ### Description of PR\r\n   \r\n   Create a new docker image based on `hadoop-3.4.2-lean.tar.gz`, which omits AWS `bundle-2.29.52.jar`.\r\n   \r\n   This PR should not be merged.  I will push it from CLI as a new branch to publish the image with Docker tag `3.4.2-lean`, rather than overwrite the existing image `3.4.2`.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   [Workflow run](https://github.com/adoroszlai/hadoop/actions/runs/18277349554/job/52032416240) in my fork created the [image](https://github.com/adoroszlai/hadoop/pkgs/container/hadoop/535792302?tag=3.4.2-lean).\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T10:21:27.419+0000", "updated": "2025-10-06T10:21:27.419+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630760/comment/18025014", "id": "18025014", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #8013:\nURL: https://github.com/apache/hadoop/pull/8013#issuecomment-3371636931\n\n   I did check the url resolved, BTW.\r\n   \r\n   Note that in #7980 packaging will change where we move hadoop-aws and hadoop azure to common/lib, with all dependencies except bundle.jar; that'll come iff you do a \"-Paws-sdk\" build. And the other cloud modules will come in if you explicitly ask for them.\r\n   \r\n   Still a WiP; hope to be done ASAP with hadoop 3.4.3 like this. No more \"let's strip the build\" work, instead just choose the build options for a release. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T13:24:55.757+0000", "updated": "2025-10-06T13:24:55.757+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630760/comment/18025097", "id": "18025097", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai commented on PR #8013:\nURL: https://github.com/apache/hadoop/pull/8013#issuecomment-3371660323\n\n   Thanks @steveloughran for the review.  Pushed 4cb319a9a98350bb0711029cf13c170f3c9ce043 to `docker-hadoop-3.4.2-lean`.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T13:29:21.550+0000", "updated": "2025-10-06T13:29:21.550+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630760/comment/18025098", "id": "18025098", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai closed pull request #8013: HADOOP-19716. Create lean docker image\nURL: https://github.com/apache/hadoop/pull/8013\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T13:29:23.259+0000", "updated": "2025-10-06T13:29:23.259+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630760/comment/18027970", "id": "18027970", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8013:\nURL: https://github.com/apache/hadoop/pull/8013#issuecomment-3375033744\n\n   > Thanks @steveloughran for the review. Pushed [4cb319a](https://github.com/apache/hadoop/commit/4cb319a9a98350bb0711029cf13c170f3c9ce043) to `docker-hadoop-3.4.2-lean`.\r\n   \r\n   @adoroszlai Thanks for the contribution! LGTM. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T03:27:48.606+0000", "updated": "2025-10-07T03:27:48.606+0000"}], "maxResults": 5, "total": 5, "startAt": 0}, "updated": "2025-10-09T10:04:45.000+0000", "created": "2025-10-06T09:52:36.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630722", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630722", "key": "HADOOP-19715", "fields": {"summary": "Update restrict-imports-enforcer-rule from 2.0.0 to 2.6.1", "description": "The project is currently using {{restrict-imports-enforcer-rule}} version {*}2.0.0{*}, which was released in *2021* and is now outdated. Since then, several new versions have been released with important bug fixes, performance improvements, and enhanced compatibility. To maintain a modern and stable build environment, it is necessary to upgrade to version {*}2.6.1{*}.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630722/comment/18024842", "id": "18024842", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #8012:\nURL: https://github.com/apache/hadoop/pull/8012\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   JIRA: HADOOP-19715. Update restrict-imports-enforcer-rule from 2.0.0 to 2.6.1.\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   CI.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T01:56:49.760+0000", "updated": "2025-10-06T01:56:49.760+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630722/comment/18028247", "id": "18028247", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8012:\nURL: https://github.com/apache/hadoop/pull/8012#issuecomment-3379348657\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 43s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 25s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 25s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  mvnsite  |   0m 25s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  shadedclient  |   3m 37s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 24s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 24s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 22s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 22s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   0m 25s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  shadedclient  |   4m 41s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 25s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 28s |  |  ASF License check generated no output?  |\r\n   |  |   |  13m  6s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8012 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux bcae851086b8 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f59839a3b410ba91d777948cc1b8683d10006e31 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/testReport/ |\r\n   | Max. process+thread count | 55 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T02:31:11.496+0000", "updated": "2025-10-08T02:31:11.496+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630722/comment/18028273", "id": "18028273", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8012:\nURL: https://github.com/apache/hadoop/pull/8012#issuecomment-3379885563\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 41s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   3m 52s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   1m 29s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   3m 18s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  mvnsite  |   1m 41s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 26s | [/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  shadedclient  |  13m 13s |  |  branch has errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   1m 44s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 39s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 39s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 24s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   0m 24s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  shadedclient  |   4m  6s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 24s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 27s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  23m 47s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8012 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 679e127e6ac4 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 67cae1f9eee8d0b5bb049e7b261a4e70c00d46a3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/testReport/ |\r\n   | Max. process+thread count | 106 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T06:30:10.067+0000", "updated": "2025-10-08T06:30:10.067+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630722/comment/18028517", "id": "18028517", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8012:\nURL: https://github.com/apache/hadoop/pull/8012#issuecomment-3383838383\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 42s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  59m 35s |  |  trunk passed  |\r\n   | -1 :x: |  compile  |  19m 32s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   9m 12s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  mvnsite  |   0m 39s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 43s | [/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 45s | [/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  shadedclient  |  93m 50s |  |  branch has errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 24s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 22s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 22s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 21s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 21s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   0m  9s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 27s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  shadedclient  |   3m  9s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 25s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 13s |  |  ASF License check generated no output?  |\r\n   |  |   | 101m 41s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8012 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux cfb99cb39a9f 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 96e6841274b4e99041a4d0bc12af671c07a5d62f |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/testReport/ |\r\n   | Max. process+thread count | 258 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T02:36:22.249+0000", "updated": "2025-10-09T02:36:22.249+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "updated": "2025-10-09T02:36:22.000+0000", "created": "2025-10-06T01:54:13.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630581", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630581", "key": "HADOOP-19713", "fields": {"summary": "make container build work on macOS Tahoe", "description": "macOS Tahoe includes a native container daemon and runtime and it is supposed to be near feature-compatible with docker. In principle, it should be possible to run the container build using the container command line on macOS Tahoe.\r\n\r\nIt would be great if we can add this functionality to the build script so folks can build on macOS natively without creating another VM.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630581/comment/18024364", "id": "18024364", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=sjlee0", "name": "sjlee0", "key": "sjlee0", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=sjlee0&avatarId=16831", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sjlee0&avatarId=16831", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sjlee0&avatarId=16831", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sjlee0&avatarId=16831"}, "displayName": "Sangjin Lee", "active": true, "timeZone": "America/Los_Angeles"}, "body": "This could be someone's good hack project.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=sjlee0", "name": "sjlee0", "key": "sjlee0", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=sjlee0&avatarId=16831", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sjlee0&avatarId=16831", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sjlee0&avatarId=16831", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sjlee0&avatarId=16831"}, "displayName": "Sangjin Lee", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-02T23:16:24.184+0000", "updated": "2025-10-02T23:16:24.184+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630581/comment/18024450", "id": "18024450", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "this means you can run linux in it? cool. puts it on a par with windows -though that has the advantage you can just dual boot the machine to linux or just replace windows entirely", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-03T10:36:51.207+0000", "updated": "2025-10-03T10:36:51.207+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630581/comment/18024517", "id": "18024517", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=sjlee0", "name": "sjlee0", "key": "sjlee0", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=sjlee0&avatarId=16831", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sjlee0&avatarId=16831", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sjlee0&avatarId=16831", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sjlee0&avatarId=16831"}, "displayName": "Sangjin Lee", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Correct. This is a container daemon/runtime that runs natively on Apple (Silicon), which does pretty much all the things that a Docker runtime would do without involving VMs. Also, I understand you can install this on macOS before Tahoe. Here's one article (among many out there): [https://www.infoq.com/news/2025/06/apple-container-linux/]", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=sjlee0", "name": "sjlee0", "key": "sjlee0", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=sjlee0&avatarId=16831", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sjlee0&avatarId=16831", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sjlee0&avatarId=16831", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sjlee0&avatarId=16831"}, "displayName": "Sangjin Lee", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-03T15:05:59.967+0000", "updated": "2025-10-03T15:15:18.905+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630581/comment/18028184", "id": "18028184", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "after the NPM attack last month, I'm thinking I should do all builds which pull in remote artifacts in its own container, one with restricted access to the rest of the system lyes, complicates getting aws credentials, but that's part of what I want to lock down). ...", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-07T19:12:45.062+0000", "updated": "2025-10-07T19:12:45.062+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "updated": "2025-10-07T19:12:45.000+0000", "created": "2025-10-02T23:15:57.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630457", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630457", "key": "HADOOP-19712", "fields": {"summary": "S3A: Deadlock observed in IOStatistics EvaluatingStatisticsMap.entryset()", "description": "\r\nWe have evidence that `IOStatisticsSupport.snapshotIOStatistics()` can hang, specifically on the statistics collected by an S3AInputStream, whose statistics are merged in to the FS stats in close();\r\n\r\n{code}\r\njdk.internal.misc.Unsafe.park(Native Method)\r\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:341)\r\njava.util.concurrent.ForkJoinTask.awaitDone(ForkJoinTask.java:468)\r\njava.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:687)\r\njava.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:927)\r\njava.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\r\njava.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682)\r\norg.apache.hadoop.fs.statistics.impl.EvaluatingStatisticsMap.entrySet(EvaluatingStatisticsMap.java:166)\r\njava.util.Collections$UnmodifiableMap.entrySet(Collections.java:1529)\r\norg.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.copyMap(IOStatisticsBinding.java:172)\r\norg.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.snapshotMap(IOStatisticsBinding.java:216)\r\norg.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.snapshotMap(IOStatisticsBinding.java:199)\r\norg.apache.hadoop.fs.statistics.IOStatisticsSnapshot.snapshot(IOStatisticsSnapshot.java:165)\r\norg.apache.hadoop.fs.statistics.IOStatisticsSnapshot.<init>(IOStatisticsSnapshot.java:125)\r\norg.apache.hadoop.fs.statistics.IOStatisticsSupport.snapshotIOStatistics(IOStatisticsSupport.java:49)\r\n{code}\r\n\r\nthe code in question is calling `parallelStream()`, which uses a fixed pool of threads shared by all uses of the API\r\n{code}\r\n    Set<Entry<String, E>> r = evalEntries.parallelStream().map((e) ->\r\n        new EntryImpl<>(e.getKey(), e.getValue().apply(e.getKey())))\r\n        .collect(Collectors.toSet());\r\n{code}\r\n\r\nProposed: \r\n* move off parallelStream() to stream()\r\n* review code to if there is any other way this iteration can lead to a deadlock, e.g. the apply() calls.\r\n* could we do the merge more efficiently?\r\n\r\n", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18024107", "id": "18024107", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #8006:\nURL: https://github.com/apache/hadoop/pull/8006\n\n   \r\n   Reworked how entrySet() and values() work, using .forEach() iterators after reviewing what ConcurrentHashMap does internally; it does a (safe) traverse.\r\n   \r\n   Add EvaluatingStatisticsMap.forEach() implementation which maps the passed in BiConsumer down to the evaluators.forEach, evaluating each value as it goes.\r\n   \r\n   Use that in IOStatisticsBinding.snapshot() code.\r\n   \r\n   Tests for all this.\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [X] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T17:55:27.857+0000", "updated": "2025-10-01T17:55:27.857+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18024110", "id": "18024110", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006#issuecomment-3357467095\n\n   tested s3 london args ` -Dparallel-tests -DtestsThreadCount=8 -Dscale`\r\n   ```\r\n   [ERROR] Failures: \r\n   [ERROR]   ITestS3APrefetchingInputStream.testReadLargeFileFully:130 [Maxiumum named action_executor_acquired.max] \r\n   Expecting:                                                                                                                                                                                                                                             \r\n    <0L>                                                                                                                                                                                                                                                  \r\n   to be greater than:                                                                                                                                                                                                                                    \r\n    <0L>           \r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T17:56:35.038+0000", "updated": "2025-10-01T17:56:35.038+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18024152", "id": "18024152", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006#issuecomment-3358241968\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |  55m 44s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |  12m 48s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |  10m 53s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  7s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 33s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |  12m 27s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |  12m 27s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |  10m 39s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |  10m 39s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 42s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 3 new + 0 unchanged - 0 fixed = 3 total (was 0)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 57s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 15s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 40s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 223m 40s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8006 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 48973a6e0048 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 40e7c252a5e39fb8e483afe5f900412bf17cd4a3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/testReport/ |\r\n   | Max. process+thread count | 3134 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T21:40:26.267+0000", "updated": "2025-10-01T21:40:26.267+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18024445", "id": "18024445", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006#issuecomment-3365176292\n\n   build failures are in the yarn-ui; it complains that node is too old\r\n   ```\r\n   [INFO] -", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-03T10:25:16.497+0000", "updated": "2025-10-03T10:25:16.497+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18024451", "id": "18024451", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006#issuecomment-3365209898\n\n   I see yarn-ui failure is already covered in a yarn jira.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-03T10:38:19.421+0000", "updated": "2025-10-03T10:38:19.421+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18024497", "id": "18024497", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006#issuecomment-3365792744\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |  52m 57s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |  11m 35s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   9m 54s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  4s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  2s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m  0s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |  11m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |  11m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   9m 47s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   9m 47s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 42s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 5 new + 0 unchanged - 0 fixed = 5 total (was 0)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 58s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 56s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 17s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 40s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 214m 43s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8006 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux bac1487e44d1 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 78880e82a6bb33e328b07c3273a73289ba5e717d |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/testReport/ |\r\n   | Max. process+thread count | 1438 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-03T14:00:21.280+0000", "updated": "2025-10-03T14:00:21.280+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18027900", "id": "18027900", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006#issuecomment-3373592220\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m  3s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |  54m 40s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |  11m 34s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   9m 42s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  5s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 40s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 18s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |  11m 25s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |  11m 25s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 57s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 37s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 51s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 32s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 237m 33s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8006 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 92090e4cf01b 5.15.0-157-generic #167-Ubuntu SMP Wed Sep 17 21:35:53 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c3c15b84a4086d834b4fd9aa71b8078a2cb57b65 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/testReport/ |\r\n   | Max. process+thread count | 1449 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T19:32:56.388+0000", "updated": "2025-10-06T19:32:56.388+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18029900", "id": "18029900", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006#issuecomment-3403808610\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 13s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  checkstyle  |   1m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 55s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 19s |  |  trunk passed  |\r\n   | -1 :x: |  spotbugs  |   1m 36s | [/branch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/artifact/out/branch-spotbugs-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  37m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  16m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 17s |  |  the patch passed  |\r\n   | -1 :x: |  spotbugs  |   1m 37s | [/patch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/artifact/out/patch-spotbugs-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 47s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  3s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 204m 29s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8006 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d65a60138612 5.15.0-157-generic #167-Ubuntu SMP Wed Sep 17 21:35:53 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 93fbc42bff57ec8dc97f2486fa6ba5ba82e31bdf |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/testReport/ |\r\n   | Max. process+thread count | 1474 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-14T22:23:36.914+0000", "updated": "2025-10-14T22:23:36.914+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630457/comment/18030443", "id": "18030443", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #8006:\nURL: https://github.com/apache/hadoop/pull/8006\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T19:17:10.045+0000", "updated": "2025-10-16T19:17:10.045+0000"}], "maxResults": 9, "total": 9, "startAt": 0}, "updated": "2025-10-16T19:22:52.000+0000", "created": "2025-10-01T15:29:06.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630426", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630426", "key": "HADOOP-19711", "fields": {"summary": "Upgrade hadoop3 docker scripts to 3.4.2", "description": "The Hadoop 3.4.2 version has been released, and we need to update the Hadoop Docker image to version 3.4.2.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024011", "id": "18024011", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #8005:\nURL: https://github.com/apache/hadoop/pull/8005\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T09:27:42.622+0000", "updated": "2025-10-01T09:27:42.622+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024012", "id": "18024012", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#issuecomment-3355515590\n\n   @jojochuang @adoroszlai @ayushtkn Hadoop 3.4.2 has been released, and we are preparing a corresponding Docker image for Hadoop 3.4.2. I have created this PR to complete the Docker image release. Could you please review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T09:36:46.410+0000", "updated": "2025-10-01T09:36:46.410+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024018", "id": "18024018", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "adoroszlai commented on code in PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#discussion_r2394132623\n\n\n##########\nDockerfile:\n##########\n@@ -14,7 +14,7 @@\n # limitations under the License.\n \n FROM apache/hadoop-runner\n-ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz\n+ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar\n\nReview Comment:\n   BTW do you know why the tarball is published without `.gz`?  It still seems to be gzipped:\r\n   \r\n   ```\r\n   $ file hadoop-3.4.2.tar\r\n   hadoop-3.4.2.tar: gzip compressed data, ...\r\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T10:41:48.779+0000", "updated": "2025-10-01T10:41:48.779+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024197", "id": "18024197", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#discussion_r2396443322\n\n\n##########\nDockerfile:\n##########\n@@ -14,7 +14,7 @@\n # limitations under the License.\n \n FROM apache/hadoop-runner\n-ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz\n+ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar\n\nReview Comment:\n   Thank you very much for helping to review the code! I'm not sure why this package doesn't have the `.gz`\r\n   \r\n   @ahmarsuhail Could you please help take a look at this question? Thank you very much!\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-02T02:11:48.025+0000", "updated": "2025-10-02T02:11:48.025+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024198", "id": "18024198", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#issuecomment-3358754054\n\n   > Thanks @slfan1989 for the patch.\r\n   > \r\n   > ```\r\n   > $ docker run -it --rm ghcr.io/slfan1989/hadoop:3.4.2 hadoop version\r\n   > ...\r\n   > Hadoop 3.4.2\r\n   > Source code repository https://github.com/apache/hadoop.git -r 84e8b89ee2ebe6923691205b9e171badde7a495c\r\n   > Compiled by ahmarsu on 2025-08-20T10:30Z\r\n   > Compiled on platform linux-x86_64\r\n   > Compiled with protoc 3.23.4\r\n   > From source with checksum fa94c67d4b4be021b9e9515c9b0f7b6\r\n   > This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.4.2.jar\r\n   > ```\r\n   > \r\n   > After this is merged, I suggest someone from Hadoop PMC upload the same image to Docker Hub, something like:\r\n   > \r\n   > ```\r\n   > docker pull ghcr.io/apache/hadoop:3.4.2\r\n   > docker tag ghcr.io/apache/hadoop:3.4.2 apache/hadoop:3.4.2\r\n   > docker push apache/hadoop:3.4.2\r\n   > ```\r\n   \r\n   @adoroszlai Thank you very much for the detailed explanation. However, I have never published a Docker image before, and pushing to Docker Hub should require some additional authentication information. @jojochuang  @ayushtkn , could you please take a look? Thank you very much!\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-02T02:13:53.491+0000", "updated": "2025-10-02T02:13:53.491+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024248", "id": "18024248", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on code in PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#discussion_r2398213215\n\n\n##########\nDockerfile:\n##########\n@@ -14,7 +14,7 @@\n # limitations under the License.\n \n FROM apache/hadoop-runner\n-ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz\n+ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar\n\nReview Comment:\n   Hey, sorry I think I made a mistake while uploading the tar to [the staging repo](https://dist.apache.org/repos/dist/dev/hadoop/3.4.2-RC3/), and the it got copied incorrectly to the release directory. can someone from the PMC please update the file name in the release directory? \r\n   \r\n   it is gzipped, just missing the `.gz` . My apologies for the miss. \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-02T10:25:27.373+0000", "updated": "2025-10-02T10:25:27.373+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024388", "id": "18024388", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#discussion_r2400690548\n\n\n##########\nDockerfile:\n##########\n@@ -14,7 +14,7 @@\n # limitations under the License.\n \n FROM apache/hadoop-runner\n-ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz\n+ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar\n\nReview Comment:\n   @ahmarsuhail Thank you for the information\u2014no need to apologize. I\u2019ll try adding the `.gz` extension. Thanks again for your contribution to the hadoop-3.4.2 release.\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-03T03:34:28.188+0000", "updated": "2025-10-03T03:34:28.188+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024652", "id": "18024652", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#discussion_r2403881944\n\n\n##########\nDockerfile:\n##########\n@@ -14,7 +14,7 @@\n # limitations under the License.\n \n FROM apache/hadoop-runner\n-ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz\n+ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar\n\nReview Comment:\n   I\u2019ve already updated the [dist repo](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/ ), but the dlcdn hasn\u2019t synchronized yet. It may take a few more hours.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-04T09:43:54.256+0000", "updated": "2025-10-04T09:43:54.256+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024653", "id": "18024653", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#discussion_r2403881944\n\n\n##########\nDockerfile:\n##########\n@@ -14,7 +14,7 @@\n # limitations under the License.\n \n FROM apache/hadoop-runner\n-ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz\n+ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar\n\nReview Comment:\n   I\u2019ve already updated the [dist repo](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/ ), but the dlcdn hasn\u2019t synchronized yet. It may take a few more hours.\r\n   \r\n   ```\r\n   ....\r\n   [hadoop-3.4.2.tar.gz](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz)\r\n   [hadoop-3.4.2.tar.gz.asc](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz.asc)\r\n   [hadoop-3.4.2.tar.gz.sha512](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz.sha512)\r\n   ....\r\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-04T09:46:34.209+0000", "updated": "2025-10-04T09:46:34.209+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024819", "id": "18024819", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T00:22:00.422+0000", "updated": "2025-10-06T00:22:00.422+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630426/comment/18024838", "id": "18024838", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8005:\nURL: https://github.com/apache/hadoop/pull/8005#issuecomment-3369556514\n\n   @adoroszlai @ahmarsuhail Thank you very much for helping review the code!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T00:23:24.418+0000", "updated": "2025-10-06T00:23:24.418+0000"}], "maxResults": 11, "total": 11, "startAt": 0}, "updated": "2025-10-09T10:05:02.000+0000", "created": "2025-10-01T08:56:49.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630213", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630213", "key": "HADOOP-19710", "fields": {"summary": "ABFS: Read Buffer Manager V2 should not be allowed untill implemented", "description": "Read Buffer Manager V2 is a Work in progress and not yet fully ready to be used.\r\nThis is to stop any user explicitly enabling the config to enable RBMV2.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630213/comment/18023511", "id": "18023511", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 opened a new pull request, #8002:\nURL: https://github.com/apache/hadoop/pull/8002\n\n   Read Buffer Manager V2 is a Work in progress and not yet fully ready to be used.\r\n   This is to stop any user explicitly enabling the config to enable RBMV2.\r\n   \r\n   JIRA: https://issues.apache.org/jira/browse/HADOOP-19710\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-29T09:01:28.444+0000", "updated": "2025-09-29T09:01:28.444+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630213/comment/18023530", "id": "18023530", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8002:\nURL: https://github.com/apache/hadoop/pull/8002#issuecomment-3346210665\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   9m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  30m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 40s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 16s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 49s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 20s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  90m  2s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8002/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8002 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 7ed8c85f9284 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bc356262478fb82c786dc3bee7c312b2b1a29634 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8002/1/testReport/ |\r\n   | Max. process+thread count | 566 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8002/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-29T10:32:33.803+0000", "updated": "2025-09-29T10:32:33.803+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630213/comment/18028023", "id": "18028023", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #8002:\nURL: https://github.com/apache/hadoop/pull/8002\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T09:54:39.930+0000", "updated": "2025-10-07T09:54:39.930+0000"}], "maxResults": 3, "total": 3, "startAt": 0}, "updated": "2025-10-07T09:54:40.000+0000", "created": "2025-09-29T08:59:21.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630115", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630115", "key": "HADOOP-19709", "fields": {"summary": "[JDK17] Add debian:12 and debian:13 as a build platform with JDK-17 as default", "description": "Add a new Dockerfiles to compile Hadoop on latest Debian:12 and Debian:13 with JDK17 as the default compiler.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18023255", "id": "18023255", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "vinayakumarb opened a new pull request, #8001:\nURL: https://github.com/apache/hadoop/pull/8001\n\n   This commit introduces support for Debian 12 (Bookworm) and Debian 13 (Trixie) as build platforms, following the approach established for Ubuntu 24.\r\n   \r\n   Key changes include:\r\n   - Creation of `Dockerfile_debian_12` and `Dockerfile_debian_13` based on `Dockerfile_ubuntu_24`, with appropriate base images and package resolver arguments.\r\n   - Updates to `dev-support/docker/pkg-resolver/packages.json` to include package definitions for `debian:12` and `debian:13`.\r\n   - Addition of `debian:12` and `debian:13` to `dev-support/docker/pkg-resolver/platforms.json`.\r\n   - Modification of `BUILDING.txt` to list `debian_12` and `debian_13` as supported OS platforms.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-27T04:42:39.625+0000", "updated": "2025-09-27T04:42:39.625+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18023258", "id": "18023258", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3341301544\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  23m 38s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  37m 46s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/1/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 39s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 53s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  98m 48s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8001 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint |\r\n   | uname | Linux 01b5b1df2935 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7ccea846897ea6a8209a2238c06933afb4c489bc |\r\n   | Max. process+thread count | 554 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/1/console |\r\n   | versions | git=2.43.7 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-27T06:22:34.799+0000", "updated": "2025-09-27T06:22:34.799+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18023368", "id": "18023368", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3342170970\n\n   Previously, there were concerns about having many versions of Linux dist Dockerfiles, how about upgrading Debian 10 to 13 directly?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-28T01:26:24.689+0000", "updated": "2025-09-28T01:26:24.689+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18023712", "id": "18023712", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3349642263\n\n   > Previously, there were concerns about having many versions of Linux dist Dockerfiles, how about upgrading Debian 10 to 13 directly?\r\n   \r\n   @vinayakumarb Thank you very much for your contribution. However, I still have some concerns. Expanding support to many operating systems could be a rather heavy undertaking, since it requires us to pay closer attention to their EOL and version lifecycles. I'm wondering if it might be more sustainable to maintain a smaller subset of supported systems instead. If users have other requirements, they could always try customizing the build themselves.\r\n   \r\n   cc: @pan3793 @ayushtkn @cnauroth \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-30T01:48:27.552+0000", "updated": "2025-09-30T01:48:27.552+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18028040", "id": "18028040", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "vinayakumarb commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3376374939\n\n   > > Previously, there were concerns about having many versions of Linux dist Dockerfiles, how about upgrading Debian 10 to 13 directly?\r\n   > \r\n   > @vinayakumarb Thank you very much for your contribution. However, I still have some concerns. Expanding support to many operating systems could be a rather heavy undertaking, since it requires us to pay closer attention to their EOL and version lifecycles. I'm wondering if it might be more sustainable to maintain a smaller subset of supported systems instead. If users have other requirements, they could always try customizing the build themselves.\r\n   > \r\n   > cc: @pan3793 @ayushtkn @cnauroth\r\n   \r\n   I understand the concern.\r\n   Directly upgrading the debian:10 to debian:13 may break existing pipelines.\r\n   \r\n   However, having a Dockerfiles for various platforms provides the developers to build an environment as per their choice. It not necessarily means Hadoop binaries (jars and tar) are compiled in these.\r\n   \r\n   if users are interested in building Hadoop in their own choice of environment, these Dockerfiles will be a good starting point.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T10:59:13.217+0000", "updated": "2025-10-07T10:59:13.217+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18028048", "id": "18028048", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3376469046\n\n   @vinayakumarb Thank you for the clarification \u2014 I agree (+1). However, given the complexity of operating system EOL management, I would carefully evaluate the introduction of Docker support for new systems in the future, considering both maintenance costs and long-term sustainability.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T11:28:11.135+0000", "updated": "2025-10-07T11:28:11.135+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18028077", "id": "18028077", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3376715593\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  31m 43s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  1s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  40m 53s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/2/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 52s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 59s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 113m 29s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8001 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint |\r\n   | uname | Linux 9e7987a7030b 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 92bd7478449829a0e7b987157945cfd72199e4ac |\r\n   | Max. process+thread count | 647 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/2/console |\r\n   | versions | git=2.43.7 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T12:40:28.529+0000", "updated": "2025-10-07T12:40:28.529+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18028250", "id": "18028250", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#discussion_r2412409276\n\n\n##########\ndev-support/docker/pkg-resolver/packages.json:\n##########\n@@ -263,6 +352,14 @@\n       \"openjdk-11-jdk\",\n       \"openjdk-17-jdk\"\n     ],\n+    \"debian:12\": [\n+      \"temurin-17-jdk\",\n+      \"temurin-24-jdk\"\n+    ],\n+    \"debian:13\": [\n+      \"temurin-17-jdk\",\n+      \"temurin-24-jdk\"\n\nReview Comment:\n   temurin-25 is out\n   \n   BTW, I think we should prefer to use the JDK provided by official APT repo if possible, Debian 13 already has `openjdk-25-jdk`\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T03:28:03.011+0000", "updated": "2025-10-08T03:28:03.011+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18028251", "id": "18028251", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#discussion_r2412409614\n\n\n##########\ndev-support/docker/pkg-resolver/packages.json:\n##########\n@@ -353,26 +472,34 @@\n   },\n   \"software-properties-common\": {\n     \"debian:11\": \"software-properties-common\",\n+    \n+\n\nReview Comment:\n   ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T03:28:27.870+0000", "updated": "2025-10-08T03:28:27.870+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18028252", "id": "18028252", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#discussion_r2412425091\n\n\n##########\ndev-support/docker/Dockerfile_debian_13:\n##########\n@@ -0,0 +1,110 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Dockerfile for installing the necessary dependencies for building Hadoop.\n+# See BUILDING.txt.\n+\n+FROM debian:13\n+\n+WORKDIR /root\n+\n+SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"]\n+\n+#####\n+# Disable suggests/recommends\n+#####\n+RUN echo 'APT::Install-Recommends \"0\";' > /etc/apt/apt.conf.d/10disableextras\n+RUN echo 'APT::Install-Suggests \"0\";' >>  /etc/apt/apt.conf.d/10disableextras\n+\n+ENV DEBIAN_FRONTEND=noninteractive\n+ENV DEBCONF_TERSE=true\n+\n+######\n+# Platform package dependency resolver\n+######\n+COPY pkg-resolver pkg-resolver\n+RUN chmod a+x pkg-resolver/*.sh pkg-resolver/*.py \\\n+    && chmod a+r pkg-resolver/*.json\n+\n+######\n+# Install packages from apt\n+######\n+# hadolint ignore=DL3008,SC2046\n+RUN apt-get -q update\n+RUN apt-get -q install -y --no-install-recommends wget apt-transport-https gpg gpg-agent gawk ca-certificates\n+RUN apt-get -q install -y --no-install-recommends python3\n+RUN echo \"deb https://packages.adoptium.net/artifactory/deb $(awk -F= '/^VERSION_CODENAME/{print$2}' /etc/os-release) main\" > /etc/apt/sources.list.d/adoptium.list\n+RUN wget -q -O - https://packages.adoptium.net/artifactory/api/gpg/key/public > /etc/apt/trusted.gpg.d/adoptium.asc\n+RUN apt-get -q update\n+RUN apt-get -q install -y --no-install-recommends $(pkg-resolver/resolve.py debian:13)\n+RUN apt-get clean\n+RUN update-java-alternatives -s temurin-17-jdk-amd64\n+RUN rm -rf /var/lib/apt/lists/*\n\nReview Comment:\n   each RUN produces one image layer, you should concat those shell commands by && instead\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T03:44:34.377+0000", "updated": "2025-10-08T03:44:34.377+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18028253", "id": "18028253", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3379465889\n\n   @vinayakumarb, in addition to creating a dev container from the Dockerfile, have you verified that Hadoop can build successfully with native and frontend components in the created dev container?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T03:48:46.924+0000", "updated": "2025-10-08T03:48:46.924+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029194", "id": "18029194", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "vinayakumarb commented on code in PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#discussion_r2422824903\n\n\n##########\ndev-support/docker/pkg-resolver/packages.json:\n##########\n@@ -263,6 +352,14 @@\n       \"openjdk-11-jdk\",\n       \"openjdk-17-jdk\"\n     ],\n+    \"debian:12\": [\n+      \"temurin-17-jdk\",\n+      \"temurin-24-jdk\"\n+    ],\n+    \"debian:13\": [\n+      \"temurin-17-jdk\",\n+      \"temurin-24-jdk\"\n\nReview Comment:\n   Done. Using openjdk-25-jdk in debian-13 and temurin-25-jdk in debian 12 as openjdk is not available in debian repository for bookworm.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T13:07:53.269+0000", "updated": "2025-10-11T13:07:53.269+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029195", "id": "18029195", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "vinayakumarb commented on code in PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#discussion_r2422825814\n\n\n##########\ndev-support/docker/Dockerfile_debian_13:\n##########\n@@ -0,0 +1,110 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Dockerfile for installing the necessary dependencies for building Hadoop.\n+# See BUILDING.txt.\n+\n+FROM debian:13\n+\n+WORKDIR /root\n+\n+SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"]\n+\n+#####\n+# Disable suggests/recommends\n+#####\n+RUN echo 'APT::Install-Recommends \"0\";' > /etc/apt/apt.conf.d/10disableextras\n+RUN echo 'APT::Install-Suggests \"0\";' >>  /etc/apt/apt.conf.d/10disableextras\n+\n+ENV DEBIAN_FRONTEND=noninteractive\n+ENV DEBCONF_TERSE=true\n+\n+######\n+# Platform package dependency resolver\n+######\n+COPY pkg-resolver pkg-resolver\n+RUN chmod a+x pkg-resolver/*.sh pkg-resolver/*.py \\\n+    && chmod a+r pkg-resolver/*.json\n+\n+######\n+# Install packages from apt\n+######\n+# hadolint ignore=DL3008,SC2046\n+RUN apt-get -q update\n+RUN apt-get -q install -y --no-install-recommends wget apt-transport-https gpg gpg-agent gawk ca-certificates\n+RUN apt-get -q install -y --no-install-recommends python3\n+RUN echo \"deb https://packages.adoptium.net/artifactory/deb $(awk -F= '/^VERSION_CODENAME/{print$2}' /etc/os-release) main\" > /etc/apt/sources.list.d/adoptium.list\n+RUN wget -q -O - https://packages.adoptium.net/artifactory/api/gpg/key/public > /etc/apt/trusted.gpg.d/adoptium.asc\n+RUN apt-get -q update\n+RUN apt-get -q install -y --no-install-recommends $(pkg-resolver/resolve.py debian:13)\n+RUN apt-get clean\n+RUN update-java-alternatives -s temurin-17-jdk-amd64\n+RUN rm -rf /var/lib/apt/lists/*\n\nReview Comment:\n   Done.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T13:08:23.085+0000", "updated": "2025-10-11T13:08:23.085+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029197", "id": "18029197", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "vinayakumarb commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393325468\n\n   > @vinayakumarb, in addition to creating a dev container from the Dockerfile, have you verified that Hadoop can build successfully with native and frontend components in the created dev container?\r\n   \r\n   Yes. I have verified building both native and frontend.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T13:21:27.822+0000", "updated": "2025-10-11T13:21:27.822+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029198", "id": "18029198", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "vinayakumarb commented on code in PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#discussion_r2422836979\n\n\n##########\ndev-support/docker/pkg-resolver/packages.json:\n##########\n@@ -353,26 +472,34 @@\n   },\n   \"software-properties-common\": {\n     \"debian:11\": \"software-properties-common\",\n+    \n+\n\nReview Comment:\n   Forgot to remove empty lines. `software-properties-common` not available for debian 12 and 13. Also does not look like it was needed. \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T13:23:14.869+0000", "updated": "2025-10-11T13:23:14.869+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029201", "id": "18029201", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393364407\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  13m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  1s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  24m 31s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 24s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 41s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  61m 20s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8001 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint |\r\n   | uname | Linux 5a71556ea849 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e371f08075c145585c0d620978733fceb30c93b0 |\r\n   | Max. process+thread count | 559 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console |\r\n   | versions | git=2.43.7 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T14:07:48.325+0000", "updated": "2025-10-11T14:07:48.325+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029203", "id": "18029203", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393395506\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  11m 43s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  1s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  14m  3s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  hadolint  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 26s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 21s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  40m 45s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8001 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint |\r\n   | uname | Linux 4e9b089f3372 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e371f08075c145585c0d620978733fceb30c93b0 |\r\n   | Max. process+thread count | 575 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console |\r\n   | versions | git=2.30.2 maven=3.9.11 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T14:48:41.044+0000", "updated": "2025-10-11T14:48:41.044+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029204", "id": "18029204", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393395990\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T14:49:36.386+0000", "updated": "2025-10-11T14:49:36.386+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18029208", "id": "18029208", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393432943\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  1s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  19m 49s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  hadolint  |   0m  2s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 24s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  49m 15s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8001 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint |\r\n   | uname | Linux 167189e0eac1 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e371f08075c145585c0d620978733fceb30c93b0 |\r\n   | Max. process+thread count | 568 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T15:38:02.482+0000", "updated": "2025-10-11T15:38:02.482+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630115/comment/18031476", "id": "18031476", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "vinayakumarb merged PR #8001:\nURL: https://github.com/apache/hadoop/pull/8001\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T16:28:26.949+0000", "updated": "2025-10-21T16:28:26.949+0000"}], "maxResults": 20, "total": 20, "startAt": 0}, "updated": "2025-10-21T16:28:27.000+0000", "created": "2025-09-27T04:38:55.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630052", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630052", "key": "HADOOP-19708", "fields": {"summary": "volcano tos: disable shading when -DskipShade is set on a build", "description": "hadoop-tos is shaded, includes things like httpclient5, which leads to a big 4M artifact, with unknown content inside\r\n{code}\r\n 92K    share/hadoop/common/lib/hadoop-aliyun-3.5.0-20250916.124028-685.jar\r\n912K    share/hadoop/common/lib/hadoop-aws-3.5.0-20250916.124028-686.jar\r\n808K    share/hadoop/common/lib/hadoop-azure-3.5.0-20250916.124028-685.jar\r\n 36K    share/hadoop/common/lib/hadoop-azure-datalake-3.5.0-20250916.124028-685.jar\r\n 72K    share/hadoop/common/lib/hadoop-cos-3.5.0-20250916.124028-683.jar\r\n136K    share/hadoop/common/lib/hadoop-gcp-3.5.0-SNAPSHOT.jar\r\n140K    share/hadoop/common/lib/hadoop-huaweicloud-3.5.0-SNAPSHOT.jar\r\n3.8M    share/hadoop/common/lib/hadoop-tos-3.5.0-20250916.124028-202.jar\r\n{code}\r\n\r\nOne thing it includes is yet-another mozilla/public-suffix-list.txt. These are a recurrent PITA and I don't want\r\nto find them surfacing again.\r\n{code}\r\n\r\n15. Required Resources\r\n======================\r\n\r\nresource: mozilla/public-suffix-list.txt\r\n       jar:file:/Users/stevel/Projects/Releases/hadoop-3.5.0-SNAPSHOT/share/hadoop/common/lib/hadoop-tos-3.5.0-20250916.124028-202.jar!/mozilla/public-suffix-list.txt\r\n{code}\r\n\r\nPlan\r\n* Move the shade stage behind a profile; off for ASF releases. Exclude mozilla/public-suffix-list.txt  \r\n* Explicitly declare and manage httpclient5 dependency\r\n* hadoop-cloud-storage pom to include hadoop-tos but not dependencies in build, unless asked.\r\n* LICENSE-binary to declare optional redist of ve-tos-java-sdk-hadoop and its license.\r\n\r\n", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630052/comment/18023048", "id": "18023048", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "doing this inside HADOOP-19696, as that's where I need the leaner artifacts", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-09-26T09:31:45.459+0000", "updated": "2025-09-26T09:31:45.459+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630052/comment/18028393", "id": "18028393", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "(note the shading is troubled anyway\r\n{code}\r\n[INFO] Dependency-reduced POM written at: /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/dependency-reduced-pom.xml\r\n[WARNING] httpclient5-5.3.jar, httpcore5-5.2.4.jar, httpcore5-h2-5.2.4.jar define 3 overlapping resources: \r\n[WARNING]   - META-INF/DEPENDENCIES\r\n[WARNING]   - META-INF/LICENSE\r\n[WARNING]   - META-INF/NOTICE\r\n[WARNING] hadoop-tos-3.5.0-SNAPSHOT.jar, httpclient5-5.3.jar, httpcore5-5.2.4.jar, httpcore5-h2-5.2.4.jar, nimbus-jose-jwt-10.4.jar, ve-tos-java-sdk-hadoop-2.8.9.jar define 1 overlapping resource: \r\n[WARNING]   - META-INF/MANIFEST.MF\r\n[WARNING] maven-shade-plugin has detected that some files are\r\n[WARNING] present in two or more JARs. When this happens, only one\r\n[WARNING] single version of the file is copied to the uber jar.\r\n[WARNING] Usually this is not harmful and you can skip these warnings,\r\n[WARNING] otherwise try to manually exclude artifacts based on\r\n[WARNING] mvn dependency:tree -Ddetail=true and the above output.\r\n[WARNING] See https://maven.apache.org/plugins/maven-shade-plugin/\r\n[INFO] Replacing original artifact with shaded artifact.\r\n[INFO] Replacing /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/target/hadoop-tos-3.5.0-SNAPSHOT.jar with /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/target/hadoop-tos-3.5.0-SNAPSHOT-shaded.jar\r\n[INFO] \r\n[INFO] --- cyclonedx:2.9.1:makeBom (default) @ hadoop-tos ---\r\n{code}\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-08T15:13:05.515+0000", "updated": "2025-10-08T15:13:05.515+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-10-09T19:59:47.000+0000", "created": "2025-09-26T09:30:31.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13630003", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13630003", "key": "HADOOP-19707", "fields": {"summary": "Surefire upgrade leads to increased report output, can cause Jenkins OOM", "description": "The Surefire upgrade to 3.3+ added enableOutErrElements which defaults to true and includes system-out and system-err in the xml artifacts. This significantly increases their size: ~45KB to ~1MB in many cases. In my test environment, that leads to\r\n{code}\r\nRecording test results\r\nERROR: Step \u2018Publish JUnit test result report\u2019 aborted due to exception: \r\njava.lang.OutOfMemoryError: Java heap space\r\n{code}\r\n\r\nCapturing stdout seems useful when doing ad-hoc testing or smaller test runs. I'd propose adding a profile to set enableOutErrElements=false for CI environments where that extra output can cause problems.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630003/comment/18022929", "id": "18022929", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "MikaelSmith opened a new pull request, #7998:\nURL: https://github.com/apache/hadoop/pull/7998\n\n   ### Description of PR\r\n   \r\n   Adds the `quiet-surefire` profile to set enableOutErrElements=false for maven-surefire-plugin. This restores the behavior prior to Surefire 3.3 that stdout/stderr are not included in the TEST-<package>.<class>.xml file for passing tests. The newer default behavior results in much larger TEST-*.xml files that can be a problem for CI tools processing them.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Ran `mvn clean test -Dtest=TestHttpServer` and `mvn clean test -Dtest=TestHttpServer -Pquiet-surefire` and compared size and contents of hadoop-common-project/hadoop-common/target/surefire-reports/TEST-org.apache.hadoop.http.TestHttpServer.xml.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-25T23:59:49.919+0000", "updated": "2025-09-25T23:59:49.919+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630003/comment/18022958", "id": "18022958", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7998:\nURL: https://github.com/apache/hadoop/pull/7998#issuecomment-3336586704\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 28s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  56m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  98m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 47s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 17s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 163m 42s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7998/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7998 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 6c02dd609cd9 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 895391e2c52eadd071997eacaaf7bb2f2af8be30 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7998/1/testReport/ |\r\n   | Max. process+thread count | 533 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project U: hadoop-project |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7998/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T02:44:51.291+0000", "updated": "2025-09-26T02:44:51.291+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630003/comment/18024332", "id": "18024332", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7998:\nURL: https://github.com/apache/hadoop/pull/7998\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-02T19:01:55.191+0000", "updated": "2025-10-02T19:01:55.191+0000"}], "maxResults": 3, "total": 3, "startAt": 0}, "updated": "2025-10-02T19:02:11.000+0000", "created": "2025-09-25T23:37:18.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629866", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629866", "key": "HADOOP-19706", "fields": {"summary": "Support Java Modularity", "description": "This is an umbrella JIRA for supporting Java 9 Modularity.", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-24T20:04:21.000+0000", "created": "2025-09-24T20:03:42.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629860", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629860", "key": "HADOOP-19705", "fields": {"summary": "[JDK17] Do not use Long(long) and similar constructors", "description": "'Long(long)' is deprecated since version 9 and marked for removal.", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-24T19:00:19.000+0000", "created": "2025-09-24T19:00:19.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629826", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629826", "key": "HADOOP-19703", "fields": {"summary": "UserGroupInformation.java is using a non-support operation in JDK25", "description": "Hello,\r\n\r\nI'm trying to upgrade my version of ParquetJava and I'm seeing the following error locally\r\n{code:java}\r\n\u00a0\u00a0\u00a0 java.lang.UnsupportedOperationException: getSubject is not supported\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.base/javax.security.auth.Subject.getSubject(Subject.java:277)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3852)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3842)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3630)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:557)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:290)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:541)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.parquet.hadoop.util.HadoopOutputFile.fromPath(HadoopOutputFile.java:58)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at com.amazon.networkvalidator.parquet.ParquetWriter.write(ParquetWriter.kt:75)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at com.amazon.networkvalidator.parquet.ParquetWriterTest$test \r\nwriting to parquet$1.invokeSuspend(ParquetWriterTest.kt:88)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at com.amazon.networkvalidator.parquet.ParquetWriterTest$test writing to parquet$1.invoke(ParquetWriterTest.kt)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at com.amazon.networkvalidator.parquet.ParquetWriterTest$test writing to parquet$1.invoke(ParquetWriterTest.kt)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt$runTest$2$1$1.invokeSuspend(TestBuilders.kt:318)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:101)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestDispatcher.processEvent$kotlinx_coroutines_test(TestDispatcher.kt:24)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at \r\nkotlinx.coroutines.test.TestCoroutineScheduler.tryRunNextTaskUnless$kotlinx_coroutines_test(TestCoroutineScheduler.kt:99)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt$runTest$2$1$workRunner$1.invokeSuspend(TestBuilders.kt:327)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:101)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.EventLoopImplBase.processNextEvent(EventLoop.common.kt:263)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.BlockingCoroutine.joinBlocking(Builders.kt:95)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking(Builders.kt:69)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.BuildersKt.runBlocking(Unknown Source)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking$default(Builders.kt:47)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.BuildersKt.runBlocking$default(Unknown Source)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersJvmKt.createTestResult(TestBuildersJvm.kt:10)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt.runTest-8Mi8wO0(TestBuilders.kt:310)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt.runTest-8Mi8wO0(Unknown Source)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt.runTest-8Mi8wO0(TestBuilders.kt:168)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt.runTest-8Mi8wO0(Unknown Source)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt.runTest-8Mi8wO0$default(TestBuilders.kt:160)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at kotlinx.coroutines.test.TestBuildersKt.runTest-8Mi8wO0$default(Unknown Source)\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at com.amazon.networkvalidator.parquet.ParquetWriterTest.test writing to parquet(ParquetWriterTest.kt:76)\r\n {code}\r\nThe class making this unsupported call is UserGroupInformation, which is part of the common hadoop pkg - https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common/3.4.2", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629826/comment/18022436", "id": "18022436", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=fanningpj", "name": "fanningpj", "key": "fanningpj", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "PJ Fanning", "active": true, "timeZone": "Europe/Madrid"}, "body": "Hadoop only supports Java 11.\r\nhttps://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions\r\n\r\nThere is work in progress to support Java 17. Java 21 and 25 will be worked on later.\r\nHADOOP-19486", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=fanningpj", "name": "fanningpj", "key": "fanningpj", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "PJ Fanning", "active": true, "timeZone": "Europe/Madrid"}, "created": "2025-09-24T13:59:57.267+0000", "updated": "2025-09-24T14:02:43.071+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629826/comment/18022462", "id": "18022462", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=hugocost", "name": "hugocost", "key": "JIRAUSER311050", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Hugo Costa", "active": true, "timeZone": "Europe/Amsterdam"}, "body": "Appreciate the link, thanks PJ, will keep a watch on that :)", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=hugocost", "name": "hugocost", "key": "JIRAUSER311050", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Hugo Costa", "active": true, "timeZone": "Europe/Amsterdam"}, "created": "2025-09-24T15:26:11.203+0000", "updated": "2025-09-24T15:26:11.203+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-09-24T15:26:11.000+0000", "created": "2025-09-24T13:42:31.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629730", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629730", "key": "HADOOP-19702", "fields": {"summary": "Update non-thirdparty Guava version to  33.4.8-jre", "description": "Keep in sync with recently upgraded thirdparty Guava", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629730/comment/18022317", "id": "18022317", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty opened a new pull request, #7994:\nURL: https://github.com/apache/hadoop/pull/7994\n\n   ### Description of PR\r\n   \r\n   Update non-thirdparty Guava version to 33.4.8-jre\r\n   \r\n   The motivation is the same as for updating the thirdparty one.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   CI\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T04:19:26.810+0000", "updated": "2025-09-24T04:19:26.810+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629730/comment/18022323", "id": "18022323", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7994:\nURL: https://github.com/apache/hadoop/pull/7994#issuecomment-3326537486\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 28s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  31m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  33m 33s |  |  branch has errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m  9s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m  8s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 10s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |   1m 22s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 10s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  45m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7994/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7994 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 9c1032fe6d33 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bd6bdde979214be1291cda6a340e8e629a848d7a |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7994/1/testReport/ |\r\n   | Max. process+thread count | 98 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project U: hadoop-project |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7994/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T05:05:59.086+0000", "updated": "2025-09-24T05:05:59.086+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629730/comment/18022642", "id": "18022642", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7994:\nURL: https://github.com/apache/hadoop/pull/7994#issuecomment-3332389576\n\n   @stoty In my opinion, there is no issue with this PR. I have one question, why not upgrade to 33.5.0-jre?\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-25T06:35:55.498+0000", "updated": "2025-09-25T06:35:55.498+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629730/comment/18022667", "id": "18022667", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7994:\nURL: https://github.com/apache/hadoop/pull/7994#issuecomment-3332540273\n\n   > @stoty In my opinion, there is no issue with this PR. I have one question, why not upgrade to 33.5.0-jre?\r\n   \r\n   The hadoop-thirdparty guava is being updated to 33.4.8-jre, and I thought that it's easier to manage if we keep the unshaded version in sync with that, as long as we're able to.\r\n   \r\n   Also, we've already updated to 33.4.8-jre at my day job without issues, but I don't have experience yet with 33.5.0.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-25T07:27:29.617+0000", "updated": "2025-09-25T07:27:29.617+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629730/comment/18023713", "id": "18023713", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7994:\nURL: https://github.com/apache/hadoop/pull/7994#issuecomment-3349644523\n\n   If there are no further comments, I will merge this PR today.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-30T01:49:59.989+0000", "updated": "2025-09-30T01:49:59.989+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629730/comment/18024402", "id": "18024402", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7994:\nURL: https://github.com/apache/hadoop/pull/7994\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-03T06:54:43.146+0000", "updated": "2025-10-03T06:54:43.146+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629730/comment/18024403", "id": "18024403", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7994:\nURL: https://github.com/apache/hadoop/pull/7994#issuecomment-3364494335\n\n   @stoty Thanks for the contribution! Merged into trunk.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-03T06:55:02.753+0000", "updated": "2025-10-03T06:55:02.753+0000"}], "maxResults": 7, "total": 7, "startAt": 0}, "updated": "2025-10-03T06:56:03.000+0000", "created": "2025-09-23T17:28:42.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629664", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629664", "key": "HADOOP-19701", "fields": {"summary": "Remove invalid `licenses` field of `hadoop-aliyun` SBOM by upgradding `cyclonedx` to 2.9.1", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629664/comment/18022029", "id": "18022029", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "dongjoon-hyun opened a new pull request, #7990:\nURL: https://github.com/apache/hadoop/pull/7990\n\n   \u2026\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T04:59:12.692+0000", "updated": "2025-09-23T04:59:12.692+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629664/comment/18022045", "id": "18022045", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "dongjoon-hyun commented on PR #7990:\nURL: https://github.com/apache/hadoop/pull/7990#issuecomment-3322518878\n\n   Thank you, @slfan1989 .\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T05:47:00.951+0000", "updated": "2025-09-23T05:47:00.951+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629664/comment/18022253", "id": "18022253", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7990:\nURL: https://github.com/apache/hadoop/pull/7990#issuecomment-3325310193\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  60m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  20m 20s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m  2s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 22s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  11m 38s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   9m 20s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  | 185m 36s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  49m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  21m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  21m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  18m 49s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  18m 49s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  21m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |  11m 53s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   9m  0s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  88m 52s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 511m 54s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 880m 54s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7990 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 3a691ff72698 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f944112d4216160cc394f6ea7bd013f7b92796a9 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/testReport/ |\r\n   | Max. process+thread count | 2369 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T19:41:31.354+0000", "updated": "2025-09-23T19:41:31.354+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629664/comment/18022255", "id": "18022255", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "dongjoon-hyun commented on PR #7990:\nURL: https://github.com/apache/hadoop/pull/7990#issuecomment-3325322984\n\n   All tests passes except `test4tests` and `unit` tests which checks new or revised test cases. So, I believe this PR is ready.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T19:46:29.998+0000", "updated": "2025-09-23T19:46:29.998+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629664/comment/18022302", "id": "18022302", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7990:\nURL: https://github.com/apache/hadoop/pull/7990\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T01:16:26.495+0000", "updated": "2025-09-24T01:16:26.495+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629664/comment/18022303", "id": "18022303", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7990:\nURL: https://github.com/apache/hadoop/pull/7990#issuecomment-3326078332\n\n   @dongjoon-hyun Thanks for the contribution! Merged into trunk.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T01:16:50.249+0000", "updated": "2025-09-24T01:16:50.249+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629664/comment/18022316", "id": "18022316", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "dongjoon-hyun commented on PR #7990:\nURL: https://github.com/apache/hadoop/pull/7990#issuecomment-3326405610\n\n   Thank you so much, @slfan1989 .\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T04:18:43.614+0000", "updated": "2025-09-24T04:18:43.614+0000"}], "maxResults": 7, "total": 7, "startAt": 0}, "updated": "2025-09-24T04:18:44.000+0000", "created": "2025-09-23T04:55:31.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629596", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629596", "key": "HADOOP-19700", "fields": {"summary": "hadoop-thirdparty build to update maven plugin dependencies", "description": "github action builds of PRs for hadoopHthirdparty fail because of throttling NVE throttling of requests; needs an update to a later version with either retries or use of a github source cve list.\r\n\r\ndependency checker 11+ \r\n\r\n{code}\r\nMandatory Upgrade Notice\r\nUpgrading to 10.0.2 or later is mandatory\r\n\r\nOlder versions of dependency-check are causing numerous, duplicative requests that end in processing failures are causing unnecassary load on the NVD API. Dependency-check 10.0.2 uses an updated User-Agent header that will allow the NVD to block calls from the older client.\r\n{code}\r\n\r\n----\r\n\r\nThe upgraded dependency checker now *requires* java11+, and *prefers* the provision of an API key for the national vulnerabilities database. It also skips the sonatype check as that no longer supports anonymous checks at all\r\n", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629596/comment/18022028", "id": "18022028", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "body": "10.x cannot parse the current DB files, even if it manages to download them, [~stevel@apache.org].", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "created": "2025-09-23T04:51:05.531+0000", "updated": "2025-09-23T04:51:05.531+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629596/comment/18022233", "id": "18022233", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "latest pr does it, just needs java11 for that action. And I've turned off the sonatype checking ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-09-23T18:46:36.540+0000", "updated": "2025-09-23T18:46:36.540+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-09-30T10:02:32.000+0000", "created": "2025-09-22T13:05:13.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629310", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629310", "key": "HADOOP-19698", "fields": {"summary": "S3A Analytics-Accelerator: Update LICENSE-binary", "description": "update LICENSE-binary to include AAL dependency\u00a0", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629310/comment/18021134", "id": "18021134", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail opened a new pull request, #7982:\nURL: https://github.com/apache/hadoop/pull/7982\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Adds in AAL dependency to License-binary.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   not required.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T10:51:11.792+0000", "updated": "2025-09-18T10:51:11.792+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629310/comment/18021135", "id": "18021135", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7982:\nURL: https://github.com/apache/hadoop/pull/7982#issuecomment-3306787342\n\n   @steveloughran PR to add in license binary.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T10:51:30.843+0000", "updated": "2025-09-18T10:51:30.843+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629310/comment/18021154", "id": "18021154", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7982:\nURL: https://github.com/apache/hadoop/pull/7982#issuecomment-3307163564\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  46m  8s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 42s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 40s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  90m 19s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7982/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7982 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux 8e1ed683c4d3 5.15.0-151-generic #161-Ubuntu SMP Tue Jul 22 14:25:40 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bf18e340d1dc826e0c031dc1e88e59a58fcb59d7 |\r\n   | Max. process+thread count | 530 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7982/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T12:22:45.440+0000", "updated": "2025-09-18T12:22:45.440+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629310/comment/18021169", "id": "18021169", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7982:\nURL: https://github.com/apache/hadoop/pull/7982\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T13:23:28.873+0000", "updated": "2025-09-18T13:23:28.873+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "updated": "2025-09-18T13:23:56.000+0000", "created": "2025-09-18T10:46:22.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629211", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629211", "key": "HADOOP-19697", "fields": {"summary": "google gs connector registration failing", "description": "Surfaced during HADOOP-19696 and work with all the cloud connectors on the classpath.\r\n\r\nThere's a missing dependency causing the gcs connector to fail to register *when the first filesystem is instantiated*, because the service registration process loads the gcs connector class, instantiates one and asks for its schema.\r\n\r\nAs well as a sign of a problem, it's better to just add an entry in core-default.xml as this saves all classloading overhead. It's what the other asf bundled ones do.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629211/comment/18020924", "id": "18020924", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "Trying to list local root  \r\n\r\nIf there are dependencies needed in the HADOOP-19696 let's make sure they get into common/lib, but this registration process mustn't fail this way, so let's just have a fs.gs.impl declararation in core-default.xml\r\n\r\n{code}\r\n bin/hadoop fs -ls file:///\r\n2025-09-17 15:03:47,688 [main] WARN  fs.FileSystem (FileSystem.java:loadFileSystems(3539)) - Cannot load filesystem\r\njava.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.gs.GoogleHadoopFileSystem Unable to get public no-arg constructor\r\n        at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)\r\n        at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:679)\r\n        at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1240)\r\n        at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)\r\n        at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)\r\n        at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)\r\n        at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:3522)\r\n        at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3562)\r\n        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3612)\r\n        at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3716)\r\n        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3667)\r\n        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:557)\r\n        at org.apache.hadoop.fs.Path.getFileSystem(Path.java:373)\r\n        at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:347)\r\n        at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:265)\r\n        at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:248)\r\n        at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:105)\r\n        at org.apache.hadoop.fs.shell.Command.run(Command.java:192)\r\n        at org.apache.hadoop.fs.FsShell.run(FsShell.java:327)\r\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82)\r\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:97)\r\n        at org.apache.hadoop.fs.FsShell.main(FsShell.java:390)\r\nCaused by: java.lang.NoClassDefFoundError: com/google/auth/Credentials\r\n        at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)\r\n        at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)\r\n        at java.base/java.lang.Class.getConstructor0(Class.java:3578)\r\n        at java.base/java.lang.Class.getConstructor(Class.java:2271)\r\n        at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:666)\r\n        at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:663)\r\n        at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)\r\n        at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:674)\r\n        ... 20 more\r\nCaused by: java.lang.ClassNotFoundException: com.google.auth.Credentials\r\n        at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\r\n        at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\r\n        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\r\n        ... 28 more\r\nFound 20 items\r\n----------   1 root admin          0 2025-08-16 19:44 file:///.file\r\n...\r\n{code}\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-09-17T14:06:18.904+0000", "updated": "2025-09-17T14:06:18.904+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629211/comment/18028260", "id": "18028260", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=cnauroth", "name": "cnauroth", "key": "cnauroth", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"}, "displayName": "Chris Nauroth", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Hi [~stevel@apache.org]. Not fully caught up on this one, but there is a {{fs.gs.impl}} entry in core-default.xml now. Was that all we needed?\r\n\r\nhttps://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml#L4508", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=cnauroth", "name": "cnauroth", "key": "cnauroth", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"}, "displayName": "Chris Nauroth", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-08T04:44:25.761+0000", "updated": "2025-10-08T04:44:25.761+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-10-08T04:44:25.000+0000", "created": "2025-09-17T14:04:27.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629208", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629208", "key": "HADOOP-19696", "fields": {"summary": "hadoop binary distribution to move cloud connectors to hadoop common/lib", "description": "Place all the cloud connector hadoop-* artifacts and dependencies into hadoop/common/lib so that the stores can be directly accessed.\r\n\r\n* filesystem operations against abfs, s3a, gcs, etc don't need any effort setting things up. \r\n* Releases without the aws bundle.jar can be trivially updated by adding any version of the sdk libraries to the common/lib dir. \r\n\r\nThis adds a lot more stuff into the distribution, so I'm doing the following design\r\n* all hadoop-* modules in common/lib\r\n* minimal dependencies for hadoop-azure and hadoop-gcs (once we get those right!)\r\n* hadoop-aws: everything except bundle.jar\r\n* other connectors: only included with explicit profiles.\r\n\r\nASF releases will support azure out the box, the others once you add the dependencies. And anyone can build their own release with everything\r\n\r\nOne concern here, we make hadoop-cloud-storage artifact incomplete at pulling in things when depended on. We may need a separate module for the distro setup.\r\n\r\nNoticed during this that the hadoop-tos component is shaded and includes stuff (httpclient5) that we need under control. Filed HADOOP-19708 and incorporating here. \r\n\r\n\r\n", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18020919", "id": "18020919", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #7980:\nURL: https://github.com/apache/hadoop/pull/7980\n\n   \r\n   \r\n   * new assembly for hadoop cloud storage\r\n   * hadoop-cloud-storage does the assembly on -Pdist\r\n   * layout stitching to move into share/hadoop/common/lib\r\n   * remove connectors from hadoop-tools-dist\r\n   * cut old jackson version from huawaei cloud dependency -even though it was being upgraded by our own artifacts, it was a complication.\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Manual build, review, storediag, hadoop fs commands\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [=] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T13:51:39.228+0000", "updated": "2025-09-17T13:51:39.228+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18020920", "id": "18020920", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303127263\n\n   \r\n   * This puts the hadoop-azure, hadoop-aws &c binaries into common/lib and so on the classpath everywhere\r\n   * some problem with gcs instantiation during enum (will file later, as while it surfaces here, I think it's unrelated)\r\n   * my local builds end up (today) with some versioned jars as well as the -SNAPSHOT. I think this is from me tainting my maven repo, would like to see what others see\r\n   \r\n   ```\r\n   total 1401704\r\n   -rw-r--r--@ 1 stevel  staff     106151 Sep 17 12:57 aliyun-java-core-0.2.11-beta.jar\r\n   -rw-r--r--@ 1 stevel  staff     194215 Sep 17 12:57 aliyun-java-sdk-core-4.5.10.jar\r\n   -rw-r--r--@ 1 stevel  staff     163698 Sep 17 12:57 aliyun-java-sdk-kms-2.11.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     220800 Sep 17 12:57 aliyun-java-sdk-ram-3.1.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     928456 Sep 17 12:57 aliyun-sdk-oss-3.18.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    2470776 Sep 17 12:57 analyticsaccelerator-s3-1.3.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      27006 Sep 17 13:11 aopalliance-repackaged-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      20891 Sep 17 13:11 audience-annotations-0.12.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     651391 Sep 17 13:11 avro-1.11.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     113966 Sep 17 12:57 azure-data-lake-store-sdk-2.3.9.jar\r\n   -rw-r--r--@ 1 stevel  staff      10288 Sep 17 12:57 azure-keyvault-core-1.0.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     815331 Sep 17 12:57 azure-storage-7.0.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    8324412 Sep 17 13:11 bcprov-jdk18on-1.78.1.jar\r\n   -rw-r--r--@ 1 stevel  staff  641534749 Sep 17 12:57 bundle-2.29.52.jar\r\n   -rw-r--r--@ 1 stevel  staff     223979 Sep 17 13:11 checker-qual-3.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      75479 Sep 17 13:11 commons-cli-1.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     353793 Sep 17 13:11 commons-codec-1.15.jar\r\n   -rw-r--r--@ 1 stevel  staff     751914 Sep 17 13:11 commons-collections4-4.4.jar\r\n   -rw-r--r--@ 1 stevel  staff    1079377 Sep 17 13:11 commons-compress-1.26.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     657516 Sep 17 13:11 commons-configuration2-2.10.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      24239 Sep 17 13:11 commons-daemon-1.0.13.jar\r\n   -rw-r--r--@ 1 stevel  staff     508826 Sep 17 13:11 commons-io-2.16.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     673587 Sep 17 13:11 commons-lang3-3.17.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      70816 Sep 17 13:11 commons-logging-1.3.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    2213560 Sep 17 13:11 commons-math3-3.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     316431 Sep 17 13:11 commons-net-3.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     238400 Sep 17 13:11 commons-text-1.10.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    8661164 Sep 17 12:57 cos_api-bundle-5.6.19.jar\r\n   -rw-r--r--@ 1 stevel  staff    2983237 Sep 17 13:11 curator-client-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     336384 Sep 17 13:11 curator-framework-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     315569 Sep 17 13:11 curator-recipes-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     583996 Sep 17 13:11 dnsjava-3.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     324655 Sep 17 12:57 dom4j-2.1.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     670059 Sep 17 12:57 esdk-obs-java-3.20.4.2.jar\r\n   -rw-r--r--@ 1 stevel  staff       4617 Sep 17 13:11 failureaccess-1.0.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     249277 Sep 17 13:11 gson-2.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    3037368 Sep 17 13:11 guava-32.0.1-jre.jar\r\n   -rw-r--r--@ 1 stevel  staff      94013 Sep 17 12:57 hadoop-aliyun-3.5.0-20250916.124028-685.jar\r\n   -rw-r--r--@ 1 stevel  staff      14456 Sep 17 13:11 hadoop-annotations-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff     114335 Sep 17 13:11 hadoop-auth-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff     930516 Sep 17 12:57 hadoop-aws-3.5.0-20250916.124028-686.jar\r\n   -rw-r--r--@ 1 stevel  staff     827349 Sep 17 12:57 hadoop-azure-3.5.0-20250916.124028-685.jar\r\n   -rw-r--r--@ 1 stevel  staff      33363 Sep 17 12:57 hadoop-azure-datalake-3.5.0-20250916.124028-685.jar\r\n   -rw-r--r--@ 1 stevel  staff      70007 Sep 17 12:57 hadoop-cos-3.5.0-20250916.124028-683.jar\r\n   -rw-r--r--@ 1 stevel  staff     138447 Sep 17 12:57 hadoop-gcp-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff     142274 Sep 17 12:57 hadoop-huaweicloud-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff    3519516 Sep 17 13:11 hadoop-shaded-guava-1.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    1952967 Sep 17 13:11 hadoop-shaded-protobuf_3_25-1.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    4019589 Sep 17 12:57 hadoop-tos-3.5.0-20250916.124028-202.jar\r\n   -rw-r--r--@ 1 stevel  staff     200223 Sep 17 13:11 hk2-api-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     203358 Sep 17 13:11 hk2-locator-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     131590 Sep 17 13:11 hk2-utils-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     780321 Sep 17 13:11 httpclient-4.5.13.jar\r\n   -rw-r--r--@ 1 stevel  staff     328593 Sep 17 13:11 httpcore-4.4.13.jar\r\n   -rw-r--r--@ 1 stevel  staff     102220 Sep 17 12:57 ini4j-0.5.4.jar\r\n   -rw-r--r--@ 1 stevel  staff      29807 Sep 17 13:11 istack-commons-runtime-3.0.12.jar\r\n   -rw-r--r--@ 1 stevel  staff       9301 Sep 17 13:11 j2objc-annotations-2.8.jar\r\n   -rw-r--r--@ 1 stevel  staff      76636 Sep 17 13:11 jackson-annotations-2.14.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     473081 Sep 17 13:11 jackson-core-2.14.3.jar\r\n   -rw-r--r--@ 1 stevel  staff    1617187 Sep 17 13:11 jackson-databind-2.14.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      68453 Sep 17 13:11 jakarta.activation-1.2.2.jar\r\n   -rw-r--r--@ 1 stevel  staff      44399 Sep 17 13:11 jakarta.activation-api-1.2.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      25058 Sep 17 13:11 jakarta.annotation-api-1.3.5.jar\r\n   -rw-r--r--@ 1 stevel  staff      18140 Sep 17 13:11 jakarta.inject-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      82973 Sep 17 13:11 jakarta.servlet-api-4.0.4.jar\r\n   -rw-r--r--@ 1 stevel  staff      53683 Sep 17 13:11 jakarta.servlet.jsp-api-2.3.6.jar\r\n   -rw-r--r--@ 1 stevel  staff      91930 Sep 17 13:11 jakarta.validation-api-2.0.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     140376 Sep 17 13:11 jakarta.ws.rs-api-2.1.6.jar\r\n   -rw-r--r--@ 1 stevel  staff     115638 Sep 17 13:11 jakarta.xml.bind-api-2.3.3.jar\r\n   -rw-r--r--@ 1 stevel  staff       7771 Sep 17 12:57 java-trace-api-0.2.11-beta.jar\r\n   -rw-r--r--@ 1 stevel  staff      18432 Sep 17 12:57 java-xmlbuilder-1.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     794714 Sep 17 13:11 javassist-3.30.2-GA.jar\r\n   -rw-r--r--@ 1 stevel  staff      95806 Sep 17 13:11 javax.servlet-api-3.1.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    1019097 Sep 17 13:11 jaxb-runtime-2.3.9.jar\r\n   -rw-r--r--@ 1 stevel  staff       4722 Sep 17 13:11 jcip-annotations-1.0-1.jar\r\n   -rw-r--r--@ 1 stevel  staff     327806 Sep 17 12:57 jdom2-2.0.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     311826 Sep 17 13:11 jersey-client-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff    1267957 Sep 17 13:11 jersey-common-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      32929 Sep 17 13:11 jersey-container-servlet-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      75742 Sep 17 13:11 jersey-container-servlet-core-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      80272 Sep 17 13:11 jersey-hk2-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff     964550 Sep 17 13:11 jersey-server-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      90184 Sep 17 12:57 jettison-1.5.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     249911 Sep 17 13:11 jetty-http-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     183011 Sep 17 13:11 jetty-io-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     118496 Sep 17 13:11 jetty-security-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     739348 Sep 17 13:11 jetty-server-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     146064 Sep 17 13:11 jetty-servlet-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     588962 Sep 17 13:11 jetty-util-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff      66643 Sep 17 13:11 jetty-util-ajax-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     140308 Sep 17 13:11 jetty-webapp-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff      68894 Sep 17 13:11 jetty-xml-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     282591 Sep 17 13:11 jsch-0.1.55.jar\r\n   -rw-r--r--@ 1 stevel  staff      19936 Sep 17 13:11 jsr305-3.0.2.jar\r\n   -rw-r--r--@ 1 stevel  staff       4519 Sep 17 13:11 jul-to-slf4j-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff     223129 Sep 17 13:11 kerb-core-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     115065 Sep 17 13:11 kerb-crypto-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      36361 Sep 17 13:11 kerb-util-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     100095 Sep 17 13:11 kerby-asn1-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      30190 Sep 17 13:11 kerby-config-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     200581 Sep 17 13:11 kerby-pkix-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      40787 Sep 17 13:11 kerby-util-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff       2199 Sep 17 13:11 listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar\r\n   -rw-r--r--@ 1 stevel  staff     136314 Sep 17 13:11 metrics-core-3.2.4.jar\r\n   -rw-r--r--@ 1 stevel  staff       4554 Sep 17 13:11 netty-all-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     339045 Sep 17 13:11 netty-buffer-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     355199 Sep 17 13:11 netty-codec-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      67192 Sep 17 13:11 netty-codec-dns-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      37789 Sep 17 13:11 netty-codec-haproxy-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     674362 Sep 17 13:11 netty-codec-http-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     490985 Sep 17 13:11 netty-codec-http2-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      44736 Sep 17 13:11 netty-codec-memcache-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     113699 Sep 17 13:11 netty-codec-mqtt-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      46015 Sep 17 13:11 netty-codec-redis-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      21344 Sep 17 13:11 netty-codec-smtp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     121032 Sep 17 13:11 netty-codec-socks-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      34636 Sep 17 13:11 netty-codec-stomp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      19823 Sep 17 13:11 netty-codec-xml-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     719225 Sep 17 13:11 netty-common-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     580162 Sep 17 13:11 netty-handler-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      25650 Sep 17 13:11 netty-handler-proxy-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      26833 Sep 17 13:11 netty-handler-ssl-ocsp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      37842 Sep 17 13:11 netty-resolver-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     188360 Sep 17 13:11 netty-resolver-dns-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff       9145 Sep 17 13:11 netty-resolver-dns-classes-macos-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      19825 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      19629 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff     521428 Sep 17 13:11 netty-transport-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     147621 Sep 17 13:11 netty-transport-classes-epoll-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     108558 Sep 17 13:11 netty-transport-classes-kqueue-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      42321 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      36594 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar\r\n   -rw-r--r--@ 1 stevel  staff      40644 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff       6193 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      25741 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      25170 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      44157 Sep 17 13:11 netty-transport-native-unix-common-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      18241 Sep 17 13:11 netty-transport-rxtx-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      50814 Sep 17 13:11 netty-transport-sctp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      32189 Sep 17 13:11 netty-transport-udt-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     779369 Sep 17 13:11 nimbus-jose-jwt-9.37.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     425763 Sep 17 12:57 okhttp-3.14.2.jar\r\n   -rw-r--r--@ 1 stevel  staff      91980 Sep 17 12:57 okio-1.17.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     141734 Sep 17 12:57 opentelemetry-api-1.38.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      47252 Sep 17 12:57 opentelemetry-context-1.38.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      18189 Sep 17 12:57 opentracing-api-0.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      10542 Sep 17 12:57 opentracing-noop-0.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff       7504 Sep 17 12:57 opentracing-util-0.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     281989 Sep 17 12:57 org.jacoco.agent-0.8.5-runtime.jar\r\n   -rw-r--r--@ 1 stevel  staff      19479 Sep 17 13:11 osgi-resource-locator-1.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     128414 Sep 17 13:11 re2j-1.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      11369 Sep 17 12:57 reactive-streams-1.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     332398 Sep 17 13:11 reload4j-1.2.22.jar\r\n   -rw-r--r--@ 1 stevel  staff      41125 Sep 17 13:11 slf4j-api-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff       9824 Sep 17 13:11 slf4j-reload4j-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff    2112099 Sep 17 13:11 snappy-java-1.1.10.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     195909 Sep 17 13:11 stax2-api-4.2.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      72007 Sep 17 13:11 txw2-2.3.9.jar\r\n   -rw-r--r--@ 1 stevel  staff     443788 Sep 17 12:57 wildfly-openssl-2.1.4.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     522679 Sep 17 13:11 woodstox-core-5.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    1323991 Sep 17 13:11 zookeeper-3.8.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     254932 Sep 17 13:11 zookeeper-jute-3.8.4.jar\r\n   \r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T13:56:19.944+0000", "updated": "2025-09-17T13:56:19.944+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18020921", "id": "18020921", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303133677\n\n   for contrast, here's 3.4.2\r\n   ```\r\n   ../hadoop-3.4.2/:\r\n   total 272\r\n   drwxr-xr-x@ 13 stevel  staff    416 Aug  7 12:58 bin\r\n   -rw-r--r--@  1 stevel  staff    824 Aug 27 16:58 binding.xml\r\n   drwxr-xr-x@  3 stevel  staff     96 Aug 25 17:09 downloads\r\n   drwxr-xr-x@  3 stevel  staff     96 Aug  7 12:16 etc\r\n   drwxr-xr-x@  7 stevel  staff    224 Aug  7 12:58 include\r\n   drwxr-xr-x@  3 stevel  staff     96 Aug  7 12:58 lib\r\n   drwxr-xr-x@ 14 stevel  staff    448 Aug  7 12:58 libexec\r\n   -rw-r--r--@  1 stevel  staff  23682 Aug  7 10:40 LICENSE-binary\r\n   -rw-r--r--@  1 stevel  staff  15791 Aug  7 10:39 LICENSE.txt\r\n   drwxr-xr-x@ 45 stevel  staff   1440 Aug  7 12:58 licenses-binary\r\n   -rw-r--r--@  1 stevel  staff  45514 Aug 27 17:12 log.txt\r\n   -rw-r--r--@  1 stevel  staff  27373 Aug  7 10:39 NOTICE-binary\r\n   -rw-r--r--@  1 stevel  staff   1541 Aug  7 10:39 NOTICE.txt\r\n   -rw-r--r--@  1 stevel  staff    175 Aug  7 10:39 README.txt\r\n   drwxr-xr-x@ 29 stevel  staff    928 Aug  7 12:16 sbin\r\n   -rw-r--r--@  1 stevel  staff    438 Aug 25 16:59 secrets.bin\r\n   drwxr-xr-x@  4 stevel  staff    128 Aug  7 13:23 share\r\n   -rw-r--r--@  1 stevel  staff    275 Aug 27 17:12 system.properties\r\n   \r\n   share/hadoop/common/lib:\r\n   total 1401704\r\n   -rw-r--r--@ 1 stevel  staff     106151 Sep 17 12:57 aliyun-java-core-0.2.11-beta.jar\r\n   -rw-r--r--@ 1 stevel  staff     194215 Sep 17 12:57 aliyun-java-sdk-core-4.5.10.jar\r\n   -rw-r--r--@ 1 stevel  staff     163698 Sep 17 12:57 aliyun-java-sdk-kms-2.11.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     220800 Sep 17 12:57 aliyun-java-sdk-ram-3.1.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     928456 Sep 17 12:57 aliyun-sdk-oss-3.18.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    2470776 Sep 17 12:57 analyticsaccelerator-s3-1.3.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      27006 Sep 17 13:11 aopalliance-repackaged-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      20891 Sep 17 13:11 audience-annotations-0.12.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     651391 Sep 17 13:11 avro-1.11.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     113966 Sep 17 12:57 azure-data-lake-store-sdk-2.3.9.jar\r\n   -rw-r--r--@ 1 stevel  staff      10288 Sep 17 12:57 azure-keyvault-core-1.0.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     815331 Sep 17 12:57 azure-storage-7.0.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    8324412 Sep 17 13:11 bcprov-jdk18on-1.78.1.jar\r\n   -rw-r--r--@ 1 stevel  staff  641534749 Sep 17 12:57 bundle-2.29.52.jar\r\n   -rw-r--r--@ 1 stevel  staff     223979 Sep 17 13:11 checker-qual-3.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      75479 Sep 17 13:11 commons-cli-1.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     353793 Sep 17 13:11 commons-codec-1.15.jar\r\n   -rw-r--r--@ 1 stevel  staff     751914 Sep 17 13:11 commons-collections4-4.4.jar\r\n   -rw-r--r--@ 1 stevel  staff    1079377 Sep 17 13:11 commons-compress-1.26.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     657516 Sep 17 13:11 commons-configuration2-2.10.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      24239 Sep 17 13:11 commons-daemon-1.0.13.jar\r\n   -rw-r--r--@ 1 stevel  staff     508826 Sep 17 13:11 commons-io-2.16.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     673587 Sep 17 13:11 commons-lang3-3.17.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      70816 Sep 17 13:11 commons-logging-1.3.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    2213560 Sep 17 13:11 commons-math3-3.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     316431 Sep 17 13:11 commons-net-3.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     238400 Sep 17 13:11 commons-text-1.10.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    8661164 Sep 17 12:57 cos_api-bundle-5.6.19.jar\r\n   -rw-r--r--@ 1 stevel  staff    2983237 Sep 17 13:11 curator-client-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     336384 Sep 17 13:11 curator-framework-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     315569 Sep 17 13:11 curator-recipes-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     583996 Sep 17 13:11 dnsjava-3.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     324655 Sep 17 12:57 dom4j-2.1.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     670059 Sep 17 12:57 esdk-obs-java-3.20.4.2.jar\r\n   -rw-r--r--@ 1 stevel  staff       4617 Sep 17 13:11 failureaccess-1.0.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     249277 Sep 17 13:11 gson-2.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    3037368 Sep 17 13:11 guava-32.0.1-jre.jar\r\n   -rw-r--r--@ 1 stevel  staff      94013 Sep 17 12:57 hadoop-aliyun-3.5.0-20250916.124028-685.jar\r\n   -rw-r--r--@ 1 stevel  staff      14456 Sep 17 13:11 hadoop-annotations-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff     114335 Sep 17 13:11 hadoop-auth-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff     930516 Sep 17 12:57 hadoop-aws-3.5.0-20250916.124028-686.jar\r\n   -rw-r--r--@ 1 stevel  staff     827349 Sep 17 12:57 hadoop-azure-3.5.0-20250916.124028-685.jar\r\n   -rw-r--r--@ 1 stevel  staff      33363 Sep 17 12:57 hadoop-azure-datalake-3.5.0-20250916.124028-685.jar\r\n   -rw-r--r--@ 1 stevel  staff      70007 Sep 17 12:57 hadoop-cos-3.5.0-20250916.124028-683.jar\r\n   -rw-r--r--@ 1 stevel  staff     138447 Sep 17 12:57 hadoop-gcp-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff     142274 Sep 17 12:57 hadoop-huaweicloud-3.5.0-SNAPSHOT.jar\r\n   -rw-r--r--@ 1 stevel  staff    3519516 Sep 17 13:11 hadoop-shaded-guava-1.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    1952967 Sep 17 13:11 hadoop-shaded-protobuf_3_25-1.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    4019589 Sep 17 12:57 hadoop-tos-3.5.0-20250916.124028-202.jar\r\n   -rw-r--r--@ 1 stevel  staff     200223 Sep 17 13:11 hk2-api-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     203358 Sep 17 13:11 hk2-locator-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     131590 Sep 17 13:11 hk2-utils-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     780321 Sep 17 13:11 httpclient-4.5.13.jar\r\n   -rw-r--r--@ 1 stevel  staff     328593 Sep 17 13:11 httpcore-4.4.13.jar\r\n   -rw-r--r--@ 1 stevel  staff     102220 Sep 17 12:57 ini4j-0.5.4.jar\r\n   -rw-r--r--@ 1 stevel  staff      29807 Sep 17 13:11 istack-commons-runtime-3.0.12.jar\r\n   -rw-r--r--@ 1 stevel  staff       9301 Sep 17 13:11 j2objc-annotations-2.8.jar\r\n   -rw-r--r--@ 1 stevel  staff      76636 Sep 17 13:11 jackson-annotations-2.14.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     473081 Sep 17 13:11 jackson-core-2.14.3.jar\r\n   -rw-r--r--@ 1 stevel  staff    1617187 Sep 17 13:11 jackson-databind-2.14.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      68453 Sep 17 13:11 jakarta.activation-1.2.2.jar\r\n   -rw-r--r--@ 1 stevel  staff      44399 Sep 17 13:11 jakarta.activation-api-1.2.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      25058 Sep 17 13:11 jakarta.annotation-api-1.3.5.jar\r\n   -rw-r--r--@ 1 stevel  staff      18140 Sep 17 13:11 jakarta.inject-2.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      82973 Sep 17 13:11 jakarta.servlet-api-4.0.4.jar\r\n   -rw-r--r--@ 1 stevel  staff      53683 Sep 17 13:11 jakarta.servlet.jsp-api-2.3.6.jar\r\n   -rw-r--r--@ 1 stevel  staff      91930 Sep 17 13:11 jakarta.validation-api-2.0.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     140376 Sep 17 13:11 jakarta.ws.rs-api-2.1.6.jar\r\n   -rw-r--r--@ 1 stevel  staff     115638 Sep 17 13:11 jakarta.xml.bind-api-2.3.3.jar\r\n   -rw-r--r--@ 1 stevel  staff       7771 Sep 17 12:57 java-trace-api-0.2.11-beta.jar\r\n   -rw-r--r--@ 1 stevel  staff      18432 Sep 17 12:57 java-xmlbuilder-1.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     794714 Sep 17 13:11 javassist-3.30.2-GA.jar\r\n   -rw-r--r--@ 1 stevel  staff      95806 Sep 17 13:11 javax.servlet-api-3.1.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    1019097 Sep 17 13:11 jaxb-runtime-2.3.9.jar\r\n   -rw-r--r--@ 1 stevel  staff       4722 Sep 17 13:11 jcip-annotations-1.0-1.jar\r\n   -rw-r--r--@ 1 stevel  staff     327806 Sep 17 12:57 jdom2-2.0.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     311826 Sep 17 13:11 jersey-client-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff    1267957 Sep 17 13:11 jersey-common-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      32929 Sep 17 13:11 jersey-container-servlet-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      75742 Sep 17 13:11 jersey-container-servlet-core-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      80272 Sep 17 13:11 jersey-hk2-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff     964550 Sep 17 13:11 jersey-server-2.46.jar\r\n   -rw-r--r--@ 1 stevel  staff      90184 Sep 17 12:57 jettison-1.5.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     249911 Sep 17 13:11 jetty-http-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     183011 Sep 17 13:11 jetty-io-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     118496 Sep 17 13:11 jetty-security-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     739348 Sep 17 13:11 jetty-server-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     146064 Sep 17 13:11 jetty-servlet-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     588962 Sep 17 13:11 jetty-util-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff      66643 Sep 17 13:11 jetty-util-ajax-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     140308 Sep 17 13:11 jetty-webapp-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff      68894 Sep 17 13:11 jetty-xml-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff     282591 Sep 17 13:11 jsch-0.1.55.jar\r\n   -rw-r--r--@ 1 stevel  staff      19936 Sep 17 13:11 jsr305-3.0.2.jar\r\n   -rw-r--r--@ 1 stevel  staff       4519 Sep 17 13:11 jul-to-slf4j-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff     223129 Sep 17 13:11 kerb-core-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     115065 Sep 17 13:11 kerb-crypto-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      36361 Sep 17 13:11 kerb-util-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     100095 Sep 17 13:11 kerby-asn1-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      30190 Sep 17 13:11 kerby-config-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     200581 Sep 17 13:11 kerby-pkix-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff      40787 Sep 17 13:11 kerby-util-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff       2199 Sep 17 13:11 listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar\r\n   -rw-r--r--@ 1 stevel  staff     136314 Sep 17 13:11 metrics-core-3.2.4.jar\r\n   -rw-r--r--@ 1 stevel  staff       4554 Sep 17 13:11 netty-all-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     339045 Sep 17 13:11 netty-buffer-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     355199 Sep 17 13:11 netty-codec-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      67192 Sep 17 13:11 netty-codec-dns-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      37789 Sep 17 13:11 netty-codec-haproxy-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     674362 Sep 17 13:11 netty-codec-http-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     490985 Sep 17 13:11 netty-codec-http2-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      44736 Sep 17 13:11 netty-codec-memcache-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     113699 Sep 17 13:11 netty-codec-mqtt-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      46015 Sep 17 13:11 netty-codec-redis-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      21344 Sep 17 13:11 netty-codec-smtp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     121032 Sep 17 13:11 netty-codec-socks-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      34636 Sep 17 13:11 netty-codec-stomp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      19823 Sep 17 13:11 netty-codec-xml-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     719225 Sep 17 13:11 netty-common-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     580162 Sep 17 13:11 netty-handler-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      25650 Sep 17 13:11 netty-handler-proxy-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      26833 Sep 17 13:11 netty-handler-ssl-ocsp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      37842 Sep 17 13:11 netty-resolver-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     188360 Sep 17 13:11 netty-resolver-dns-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff       9145 Sep 17 13:11 netty-resolver-dns-classes-macos-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      19825 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      19629 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff     521428 Sep 17 13:11 netty-transport-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     147621 Sep 17 13:11 netty-transport-classes-epoll-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     108558 Sep 17 13:11 netty-transport-classes-kqueue-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      42321 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      36594 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar\r\n   -rw-r--r--@ 1 stevel  staff      40644 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff       6193 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      25741 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      25170 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff      44157 Sep 17 13:11 netty-transport-native-unix-common-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      18241 Sep 17 13:11 netty-transport-rxtx-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      50814 Sep 17 13:11 netty-transport-sctp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff      32189 Sep 17 13:11 netty-transport-udt-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     779369 Sep 17 13:11 nimbus-jose-jwt-9.37.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     425763 Sep 17 12:57 okhttp-3.14.2.jar\r\n   -rw-r--r--@ 1 stevel  staff      91980 Sep 17 12:57 okio-1.17.2.jar\r\n   -rw-r--r--@ 1 stevel  staff     141734 Sep 17 12:57 opentelemetry-api-1.38.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      47252 Sep 17 12:57 opentelemetry-context-1.38.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      18189 Sep 17 12:57 opentracing-api-0.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff      10542 Sep 17 12:57 opentracing-noop-0.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff       7504 Sep 17 12:57 opentracing-util-0.33.0.jar\r\n   -rw-r--r--@ 1 stevel  staff     281989 Sep 17 12:57 org.jacoco.agent-0.8.5-runtime.jar\r\n   -rw-r--r--@ 1 stevel  staff      19479 Sep 17 13:11 osgi-resource-locator-1.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     128414 Sep 17 13:11 re2j-1.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      11369 Sep 17 12:57 reactive-streams-1.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     332398 Sep 17 13:11 reload4j-1.2.22.jar\r\n   -rw-r--r--@ 1 stevel  staff      41125 Sep 17 13:11 slf4j-api-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff       9824 Sep 17 13:11 slf4j-reload4j-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff    2112099 Sep 17 13:11 snappy-java-1.1.10.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     195909 Sep 17 13:11 stax2-api-4.2.1.jar\r\n   -rw-r--r--@ 1 stevel  staff      72007 Sep 17 13:11 txw2-2.3.9.jar\r\n   -rw-r--r--@ 1 stevel  staff     443788 Sep 17 12:57 wildfly-openssl-2.1.4.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     522679 Sep 17 13:11 woodstox-core-5.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    1323991 Sep 17 13:11 zookeeper-3.8.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     254932 Sep 17 13:11 zookeeper-jute-3.8.4.jar\r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T13:57:33.303+0000", "updated": "2025-09-17T13:57:33.303+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18020922", "id": "18020922", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303139199\n\n   by contrast: 3.4.2\r\n   ```\r\n   total 98048\r\n   -rw-r--r--@ 1 stevel  staff     3448 Aug  7 12:16 animal-sniffer-annotations-1.17.jar\r\n   -rw-r--r--@ 1 stevel  staff    20891 Aug  7 12:16 audience-annotations-0.12.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   651391 Aug  7 12:16 avro-1.11.4.jar\r\n   -rw-r--r--@ 1 stevel  staff  8324412 Aug  7 12:15 bcprov-jdk18on-1.78.1.jar\r\n   -rw-r--r--@ 1 stevel  staff   193322 Aug  7 12:16 checker-qual-2.5.2.jar\r\n   -rw-r--r--@ 1 stevel  staff    75479 Aug  7 12:16 commons-cli-1.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   353793 Aug  7 12:16 commons-codec-1.15.jar\r\n   -rw-r--r--@ 1 stevel  staff   751914 Aug  7 12:16 commons-collections4-4.4.jar\r\n   -rw-r--r--@ 1 stevel  staff  1079377 Aug  7 12:16 commons-compress-1.26.1.jar\r\n   -rw-r--r--@ 1 stevel  staff   657516 Aug  7 12:16 commons-configuration2-2.10.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    24239 Aug  7 12:16 commons-daemon-1.0.13.jar\r\n   -rw-r--r--@ 1 stevel  staff   508826 Aug  7 12:16 commons-io-2.16.1.jar\r\n   -rw-r--r--@ 1 stevel  staff   673587 Aug  7 12:16 commons-lang3-3.17.0.jar\r\n   -rw-r--r--@ 1 stevel  staff    70816 Aug  7 12:16 commons-logging-1.3.0.jar\r\n   -rw-r--r--@ 1 stevel  staff  2213560 Aug  7 12:16 commons-math3-3.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff   316431 Aug  7 12:16 commons-net-3.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   238400 Aug  7 12:16 commons-text-1.10.0.jar\r\n   -rw-r--r--@ 1 stevel  staff  2983237 Aug  7 12:16 curator-client-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   336384 Aug  7 12:16 curator-framework-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   315569 Aug  7 12:16 curator-recipes-5.2.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   583996 Aug  7 12:16 dnsjava-3.6.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     3727 Aug  7 12:16 failureaccess-1.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   249277 Aug  7 12:16 gson-2.9.0.jar\r\n   -rw-r--r--@ 1 stevel  staff  2747878 Aug  7 12:16 guava-27.0-jre.jar\r\n   -rw-r--r--@ 1 stevel  staff    25517 Aug  7 12:16 hadoop-annotations-3.4.2.jar\r\n   -rw-r--r--@ 1 stevel  staff   110106 Aug  7 12:16 hadoop-auth-3.4.2.jar\r\n   -rw-r--r--@ 1 stevel  staff   810477 Aug  7 12:39 hadoop-azure-3.4.2.jar\r\n   -rw-r--r--@ 1 stevel  staff  3519516 Aug  7 12:16 hadoop-shaded-guava-1.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff  1952967 Aug  7 12:16 hadoop-shaded-protobuf_3_25-1.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   780321 Aug  7 12:16 httpclient-4.5.13.jar\r\n   -rw-r--r--@ 1 stevel  staff   328593 Aug  7 12:16 httpcore-4.4.13.jar\r\n   -rw-r--r--@ 1 stevel  staff     8782 Aug  7 12:16 j2objc-annotations-1.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    75705 Aug  7 12:16 jackson-annotations-2.12.7.jar\r\n   -rw-r--r--@ 1 stevel  staff   365538 Aug  7 12:16 jackson-core-2.12.7.jar\r\n   -rw-r--r--@ 1 stevel  staff  1512418 Aug  7 12:16 jackson-databind-2.12.7.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    44399 Aug  7 12:16 jakarta.activation-api-1.2.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    95806 Aug  7 12:16 javax.servlet-api-3.1.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   102244 Aug  7 12:16 jaxb-api-2.2.11.jar\r\n   -rw-r--r--@ 1 stevel  staff   890168 Aug  7 12:16 jaxb-impl-2.2.3-1.jar\r\n   -rw-r--r--@ 1 stevel  staff     4722 Aug  7 12:16 jcip-annotations-1.0-1.jar\r\n   -rw-r--r--@ 1 stevel  staff   436731 Aug  7 12:16 jersey-core-1.19.4.jar\r\n   -rw-r--r--@ 1 stevel  staff   158890 Aug  7 12:16 jersey-json-1.22.0.jar\r\n   -rw-r--r--@ 1 stevel  staff   705276 Aug  7 12:16 jersey-server-1.19.4.jar\r\n   -rw-r--r--@ 1 stevel  staff   128990 Aug  7 12:16 jersey-servlet-1.19.4.jar\r\n   -rw-r--r--@ 1 stevel  staff    90184 Aug  7 12:16 jettison-1.5.4.jar\r\n   -rw-r--r--@ 1 stevel  staff   249911 Aug  7 12:16 jetty-http-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff   183011 Aug  7 12:16 jetty-io-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff   118496 Aug  7 12:16 jetty-security-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff   739348 Aug  7 12:16 jetty-server-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff   146064 Aug  7 12:16 jetty-servlet-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff   588962 Aug  7 12:16 jetty-util-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff    66643 Aug  7 12:16 jetty-util-ajax-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff   140308 Aug  7 12:16 jetty-webapp-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff    68894 Aug  7 12:16 jetty-xml-9.4.57.v20241219.jar\r\n   -rw-r--r--@ 1 stevel  staff   282591 Aug  7 12:16 jsch-0.1.55.jar\r\n   -rw-r--r--@ 1 stevel  staff   100636 Aug  7 12:15 jsp-api-2.1.jar\r\n   -rw-r--r--@ 1 stevel  staff    19936 Aug  7 12:16 jsr305-3.0.2.jar\r\n   -rw-r--r--@ 1 stevel  staff    46367 Aug  7 12:16 jsr311-api-1.1.1.jar\r\n   -rw-r--r--@ 1 stevel  staff     4519 Aug  7 12:16 jul-to-slf4j-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff   223129 Aug  7 12:16 kerb-core-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff   115065 Aug  7 12:16 kerb-crypto-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff    36361 Aug  7 12:16 kerb-util-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff   100095 Aug  7 12:16 kerby-asn1-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff    30190 Aug  7 12:16 kerby-config-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff   200581 Aug  7 12:16 kerby-pkix-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff    40787 Aug  7 12:16 kerby-util-2.0.3.jar\r\n   -rw-r--r--@ 1 stevel  staff     2199 Aug  7 12:16 listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar\r\n   -rw-r--r--@ 1 stevel  staff   136314 Aug  7 12:16 metrics-core-3.2.4.jar\r\n   -rw-r--r--@ 1 stevel  staff     4554 Aug  7 12:15 netty-all-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   339045 Aug  7 12:16 netty-buffer-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   355199 Aug  7 12:16 netty-codec-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    67192 Aug  7 12:15 netty-codec-dns-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    37789 Aug  7 12:15 netty-codec-haproxy-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   674362 Aug  7 12:15 netty-codec-http-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   490985 Aug  7 12:15 netty-codec-http2-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    44736 Aug  7 12:15 netty-codec-memcache-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   113699 Aug  7 12:15 netty-codec-mqtt-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    46015 Aug  7 12:15 netty-codec-redis-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    21344 Aug  7 12:15 netty-codec-smtp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   121032 Aug  7 12:15 netty-codec-socks-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    34636 Aug  7 12:15 netty-codec-stomp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    19823 Aug  7 12:15 netty-codec-xml-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   719225 Aug  7 12:16 netty-common-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   580162 Aug  7 12:16 netty-handler-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    25650 Aug  7 12:15 netty-handler-proxy-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    26833 Aug  7 12:15 netty-handler-ssl-ocsp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    37842 Aug  7 12:16 netty-resolver-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   188360 Aug  7 12:15 netty-resolver-dns-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff     9145 Aug  7 12:15 netty-resolver-dns-classes-macos-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    19825 Aug  7 12:15 netty-resolver-dns-native-macos-4.1.118.Final-osx-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff    19629 Aug  7 12:15 netty-resolver-dns-native-macos-4.1.118.Final-osx-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff   521428 Aug  7 12:16 netty-transport-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   147621 Aug  7 12:16 netty-transport-classes-epoll-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   108558 Aug  7 12:15 netty-transport-classes-kqueue-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    42321 Aug  7 12:15 netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff    36594 Aug  7 12:15 netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar\r\n   -rw-r--r--@ 1 stevel  staff    40644 Aug  7 12:15 netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff     6193 Aug  7 12:16 netty-transport-native-epoll-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    25741 Aug  7 12:15 netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar\r\n   -rw-r--r--@ 1 stevel  staff    25170 Aug  7 12:15 netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar\r\n   -rw-r--r--@ 1 stevel  staff    44157 Aug  7 12:16 netty-transport-native-unix-common-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    18241 Aug  7 12:15 netty-transport-rxtx-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    50814 Aug  7 12:15 netty-transport-sctp-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff    32189 Aug  7 12:15 netty-transport-udt-4.1.118.Final.jar\r\n   -rw-r--r--@ 1 stevel  staff   779369 Aug  7 12:16 nimbus-jose-jwt-9.37.2.jar\r\n   -rw-r--r--@ 1 stevel  staff   128414 Aug  7 12:16 re2j-1.1.jar\r\n   -rw-r--r--@ 1 stevel  staff   332398 Aug  7 12:16 reload4j-1.2.22.jar\r\n   -rw-r--r--@ 1 stevel  staff    41125 Aug  7 12:15 slf4j-api-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff     9824 Aug  7 12:15 slf4j-reload4j-1.7.36.jar\r\n   -rw-r--r--@ 1 stevel  staff  2112099 Aug  7 12:16 snappy-java-1.1.10.4.jar\r\n   -rw-r--r--@ 1 stevel  staff   195909 Aug  7 12:16 stax2-api-4.2.1.jar\r\n   -rw-r--r--@ 1 stevel  staff   522679 Aug  7 12:16 woodstox-core-5.4.0.jar\r\n   -rw-r--r--@ 1 stevel  staff  1323991 Aug  7 12:16 zookeeper-3.8.4.jar\r\n   -rw-r--r--@ 1 stevel  staff   254932 Aug  7 12:16 zookeeper-jute-3.8.4.jar\r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T13:58:49.196+0000", "updated": "2025-09-17T13:58:49.196+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18020939", "id": "18020939", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303435683\n\n   Having audited the files coming off the cloud connectors, we have about a dozen whose licenses aren't in the binary\r\n   \r\n   ```\r\n   analyticsaccelerator-s3-1.3.0.jar\r\n   cos_api-bundle-5.6.19.jar\r\n   dom4j-2.1.4.jar\r\n   esdk-obs-java-3.20.4.2.jar\r\n   java-trace-api-0.2.11-beta.jar\r\n   java-xmlbuilder-1.2.jar\r\n   opentracing-api-0.33.0.jar\r\n   opentracing-noop-0.33.0.jar\r\n   opentracing-util-0.33.0.jar\r\n   reactive-streams-1.0.3.jar\r\n   ve-tos-java-sdk-hadoop-2.8.9.jar\r\n   ```\r\n   \r\n   the analyticsaccelerator is @ahmarsuhail 's work to add to the license, not sure about the others. \r\n   \r\n   Proposed: identify which connector the unacknowledged artifacts are coming from, create homework for each team. \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T15:03:51.648+0000", "updated": "2025-09-17T15:03:51.648+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18020958", "id": "18020958", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303936232\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  13m  4s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  43m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m 16s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 53s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 43s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 19s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   1m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 58s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  14m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   2m 47s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 41s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 52s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 39s |  |  hadoop-assemblies in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 41s |  |  hadoop-tools-dist in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 44s |  |  hadoop-huaweicloud in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 41s |  |  hadoop-cloud-storage in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  6s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 214m 20s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7980 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint |\r\n   | uname | Linux 604f3bcd050e 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c59e35149ea17b7cea37be9203a265dcbff118fe |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/1/testReport/ |\r\n   | Max. process+thread count | 548 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-assemblies hadoop-tools/hadoop-tools-dist hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-cloud-storage U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T17:27:14.500+0000", "updated": "2025-09-17T17:27:14.500+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18021393", "id": "18021393", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3311933628\n\n   not very familiar with how the packaging stuff works, so finding this a bit difficult to review. \r\n   \r\n   How are testing the packaging, I just ran `mvn package -Pdist -DskipTests -Dmaven.javadoc.skip=true  -DskipShade`, but the outputs in :\r\n   \r\n   `hadoop-cloud-storage-project/hadoop-cloud-storage/target/hadoop-cloud-storage-3.5.0-SNAPSHOT/share/hadoop/common/lib`, \r\n   \r\n   `hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/share/hadoop/tools/lib`\r\n   \r\n   `hadoop/hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/share/hadoop/common/lib` \r\n   \r\n   \r\n   are all the same before and after your changes, so I must be doing something wrong.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T12:03:19.259+0000", "updated": "2025-09-19T12:03:19.259+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18021417", "id": "18021417", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3312222391\n\n   did you do a `mvn clean package`?\r\n   \r\n   `hadoop-cloud-storage-project/hadoop-cloud-storage/target/hadoop-cloud-storage-3.5.0-SNAPSHOT/share/hadoop/common/lib`  -new, contains all cloud stuff we want in; should cut stuff already going to be there just to reduce copying\r\n   \r\n   `hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/share/hadoop/tools/lib`\r\n   should remove hadoop-azure, hadoop-aws, hadoop-gcs, bundle.jar...\r\n   \r\n   the big distro created under `hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/` is what is shipped.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T13:33:05.736+0000", "updated": "2025-09-19T13:33:05.736+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18022396", "id": "18022396", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3327784078\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  15m 12s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 27s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  38m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m  7s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 50s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  20m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 11s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  18m  3s |  |  branch has errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  38m 59s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 25s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 56s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 56s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   9m  9s | [/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 10 new + 5526 unchanged - 10 fixed = 5536 total (was 5536)  |\r\n   | -1 :x: |  javadoc  |   7m 34s | [/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 10 new + 1418 unchanged - 10 fixed = 1428 total (was 1428)  |\r\n   | -1 :x: |  shadedclient  |  19m 38s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 800m  7s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 46s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1046m 13s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.router.subcluster.capacity.TestYarnFederationWithCapacityScheduler |\r\n   |   | hadoop.mapreduce.v2.TestUberAM |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7980 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint |\r\n   | uname | Linux 271d5e8aaf6a 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0aaa6ce66e8a8fc7fc04fa4e2650badf956d531a |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/testReport/ |\r\n   | Max. process+thread count | 4938 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-assemblies hadoop-tools/hadoop-tools-dist hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-cloud-storage . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T11:03:18.734+0000", "updated": "2025-09-24T11:03:18.734+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18028828", "id": "18028828", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "I've just discovered quite how many things google-cloud-storage jar pulls in if you don't build a shaded release.\r\n\r\nNowhere as big as the aws sdk, but it it is still significant.\r\n\r\n# I'm going to exclude hadoop-gcp dependencies by default in a build, so if you build hadoop distro with -DskipShade you don't get these in common-lib unless you have a -Dhadoop-gcp-package. \r\n# Most of these aren't in our published LICENSE-binary file. some are, but not all.\r\n# the opentelemetry/census artifacts are newer than those from one of the other projects; build both and you get conflict (joy!).\r\n# a protobuf 2.5 comes in from somewhere\r\n\r\nI think for now I'd say \"don't make issues 2-3 blockers on merging the PR\" because they're independent. But ideally the gcs imports should be tuned down and we should go for consistent opentelemetry/opencensus versions wherever imported.\r\n\r\n\r\n{code}\r\n3.0K animal-sniffer-annotations-1.24.jar\r\n3.0K annotations-4.1.1.4.jar\r\n 49K api-common-2.47.2.jar\r\n7.3K auto-value-annotations-1.11.0.jar\r\n232K checker-qual-3.49.0.jar\r\n4.3M conscrypt-openjdk-uber-2.5.2.jar\r\n 18K detector-resources-support-0.33.0.jar\r\n 19K error_prone_annotations-2.36.0.jar\r\n 39K exporter-metrics-0.33.0.jar\r\n4.6K failureaccess-1.0.2.jar\r\n 52K gapic-google-cloud-storage-v2-2.52.0.jar\r\n424K gax-2.64.2.jar\r\n154K gax-grpc-2.64.2.jar\r\n162K gax-httpjson-2.64.2.jar\r\n295K google-api-client-2.7.2.jar\r\n252K google-api-services-storage-v1-rev20250420-2.0.0.jar\r\n8.2K google-auth-library-credentials-1.33.1.jar\r\n294K google-auth-library-oauth2-http-1.33.1.jar\r\n137K google-cloud-core-2.54.2.jar\r\n 16K google-cloud-core-grpc-2.54.2.jar\r\n 15K google-cloud-core-http-2.54.2.jar\r\n249K google-cloud-monitoring-3.52.0.jar\r\n1.3M google-cloud-storage-2.52.0.jar\r\n289K google-http-client-1.46.3.jar\r\n 11K google-http-client-apache-v2-1.46.3.jar\r\n 19K google-http-client-appengine-1.46.3.jar\r\n 13K google-http-client-gson-1.46.3.jar\r\n9.4K google-http-client-jackson2-1.46.3.jar\r\n 80K google-oauth-client-1.37.0.jar\r\n316K grpc-alts-1.70.0.jar\r\n316K grpc-api-1.70.0.jar\r\n 14K grpc-auth-1.70.0.jar\r\n293B grpc-context-1.70.0.jar\r\n639K grpc-core-1.70.0.jar\r\n 30K grpc-google-cloud-storage-v2-2.52.0.jar\r\n 15K grpc-googleapis-1.70.0.jar\r\n175K grpc-grpclb-1.70.0.jar\r\n 39K grpc-inprocess-1.70.0.jar\r\n9.3M grpc-netty-shaded-1.70.0.jar\r\n 67K grpc-opentelemetry-1.70.0.jar\r\n5.2K grpc-protobuf-1.70.0.jar\r\n7.7K grpc-protobuf-lite-1.70.0.jar\r\n248K grpc-rls-1.70.0.jar\r\n928K grpc-services-1.70.0.jar\r\n 59K grpc-stub-1.70.0.jar\r\n 98K grpc-util-1.70.0.jar\r\n9.4M grpc-xds-1.70.0.jar\r\n243K gson-2.9.0.jar\r\n2.9M guava-33.4.8-jre.jar\r\n 12K j2objc-annotations-3.0.0.jar\r\n462K jackson-core-2.14.3.jar\r\n 26K javax.annotation-api-1.3.2.jar\r\n3.7K jspecify-1.0.0.jar\r\n 19K jsr305-3.0.2.jar\r\n2.1K listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar\r\n347K opencensus-api-0.31.1.jar\r\n 23K opencensus-contrib-http-util-0.31.1.jar\r\n155K opentelemetry-api-1.47.0.jar\r\n 48K opentelemetry-context-1.47.0.jar\r\n8.1K opentelemetry-gcp-resources-1.37.0-alpha.jar\r\n6.6K opentelemetry-sdk-1.47.0.jar\r\n 54K opentelemetry-sdk-common-1.47.0.jar\r\n 20K opentelemetry-sdk-extension-autoconfigure-spi-1.47.0.jar\r\n 53K opentelemetry-sdk-logs-1.47.0.jar\r\n322K opentelemetry-sdk-metrics-1.47.0.jar\r\n129K opentelemetry-sdk-trace-1.47.0.jar\r\n 73K opentelemetry-semconv-1.29.0-alpha.jar\r\n6.8K perfmark-api-0.27.0.jar\r\n1.9M proto-google-cloud-monitoring-v3-3.52.0.jar\r\n980K proto-google-cloud-storage-v2-2.52.0.jar\r\n2.6M proto-google-common-protos-2.55.2.jar\r\n182K proto-google-iam-v1-1.50.2.jar\r\n521K protobuf-java-2.5.0.jar\r\n 71K protobuf-java-util-3.25.5.jar\r\n125K re2j-1.1.jar\r\n 91K shared-resourcemapping-0.33.0.jar\r\n 40K slf4j-api-1.7.36.jar\r\n503K threetenbp-1.7.0.jar\r\n{code}\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-09T17:04:53.181+0000", "updated": "2025-10-09T17:04:53.181+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18028867", "id": "18028867", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3387174385\n\n   Latest build generates stack traces from gcs and obs filesystem incomplete CP in service loader. Both need to move to core-default.xml *only* which is faster anyway.\r\n   \r\n   ```\r\n   \r\n   2025-10-09 20:06:44,452 [main] WARN  fs.FileSystem (FileSystem.java:loadFileSystems(3539)) - Cannot load filesystem\r\n   java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.fs.gs.GoogleHadoopFileSystem could not be instantiated    \r\n           at java.util.ServiceLoader.fail(ServiceLoader.java:232)                                                                                            \r\n           at java.util.ServiceLoader.access$100(ServiceLoader.java:185)                                                                                      \r\n           at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384)                                                                        \r\n           at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)                                                                               \r\n           at java.util.ServiceLoader$1.next(ServiceLoader.java:480)                                                                                          \r\n           at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:3525)                                                                           \r\n           at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3562)                                                                        \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.probeForFileSystemClass(StoreDiag.java:671)                                                           \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:223)                                                                               \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:170)                                                                               \r\n           at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82)                                                                                       \r\n           at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:97)                                                                                       \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.exec(StoreDiag.java:1255)                                                                             \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.main(StoreDiag.java:1264)                                                                             \r\n           at storediag.main(storediag.java:25)                                                                                                               \r\n           at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                                     \r\n           at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)                                                                   \r\n           at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)                                                           \r\n           at java.lang.reflect.Method.invoke(Method.java:498)                                                                                                \r\n           at org.apache.hadoop.util.RunJar.run(RunJar.java:333)                                                                                              \r\n           at org.apache.hadoop.util.RunJar.main(RunJar.java:254)                                                                                             \r\n   Caused by: java.lang.NoClassDefFoundError: com/google/auth/Credentials                                                                                     \r\n           at java.lang.Class.getDeclaredConstructors0(Native Method)                                                                                         \r\n           at java.lang.Class.privateGetDeclaredConstructors(Class.java:2671)                                                                                 \r\n           at java.lang.Class.getConstructor0(Class.java:3075)                                                                                                \r\n           at java.lang.Class.newInstance(Class.java:412)                                                                                                     \r\n           at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380)                                                                        \r\n           ... 18 more                                                                                                                                        \r\n   Caused by: java.lang.ClassNotFoundException: com.google.auth.Credentials                                                                                   \r\n           at java.net.URLClassLoader.findClass(URLClassLoader.java:387)                                                                                      \r\n           at java.lang.ClassLoader.loadClass(ClassLoader.java:419)                                                                                           \r\n           at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)                                                                                   \r\n           at java.lang.ClassLoader.loadClass(ClassLoader.java:352)                                                                                           \r\n           ... 23 more                                                                                                                                        \r\n   2025-10-09 20:06:44,456 [main] WARN  fs.FileSystem (FileSystem.java:loadFileSystems(3539)) - Cannot load filesystem                                        \r\n   java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.fs.obs.OBSFileSystem could not be instantiated            \r\n           at java.util.ServiceLoader.fail(ServiceLoader.java:232)                                                                                            \r\n           at java.util.ServiceLoader.access$100(ServiceLoader.java:185)                                                                                      \r\n           at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384)                                                                        \r\n           at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)                                                                               \r\n           at java.util.ServiceLoader$1.next(ServiceLoader.java:480)                                                                                          \r\n           at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:3525)                                                                           \r\n           at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3562)                                                                        \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.probeForFileSystemClass(StoreDiag.java:671)                                                           \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:223)                                                                               \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:170)                                                                               \r\n           at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82)                                                                                       \r\n           at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:97)                                                                                       \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.exec(StoreDiag.java:1255)                                                                             \r\n           at org.apache.hadoop.fs.store.diag.StoreDiag.main(StoreDiag.java:1264)                                                                             \r\n           at storediag.main(storediag.java:25)                                                                                                               \r\n           at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                                     \r\n           at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)                                                                   \r\n           at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)                                                           \r\n           at java.lang.reflect.Method.invoke(Method.java:498)                                                                                                \r\n           at org.apache.hadoop.util.RunJar.run(RunJar.java:333)                                                                                              \r\n           at org.apache.hadoop.util.RunJar.main(RunJar.java:254)                                                                                             \r\n   Caused by: java.lang.NoClassDefFoundError: com/obs/services/exception/ObsException                                                                         \r\n           at java.lang.Class.getDeclaredConstructors0(Native Method)                                                                                         \r\n           at java.lang.Class.privateGetDeclaredConstructors(Class.java:2671)                                                                                 \r\n           at java.lang.Class.getConstructor0(Class.java:3075)                                                                                                \r\n           at java.lang.Class.newInstance(Class.java:412)                                                                                                     \r\n           at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380)                                                                        \r\n           ... 18 more                                                                                                                                        \r\n   Caused by: java.lang.ClassNotFoundException: com.obs.services.exception.ObsException                                                                       \r\n           at java.net.URLClassLoader.findClass(URLClassLoader.java:387)                                                                                      \r\n           at java.lang.ClassLoader.loadClass(ClassLoader.java:419)                                                                                           \r\n           at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)                                                                                   \r\n           at java.lang.ClassLoader.loadClass(ClassLoader.java:352)                                                                                           \r\n           ... 23 more                                                                                                                                        \r\n   FileSystem for s3a:// is: org.apache.hadoop.fs.s3a.S3AFileSystem                                                                                           \r\n   Loaded from: file:/Users/stevel/Projects/Releases/hadoop-3.5.0-SNAPSHOT/share/hadoop/common/lib/hadoop-aws-3.5.0-SNAPSHOT.jar via sun.misc.Launcher$AppClassLoader@41906a77                                                                                                                                           \r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T19:09:29.393+0000", "updated": "2025-10-09T19:09:29.393+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18028889", "id": "18028889", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3387715974\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  9s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  3s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  38m 50s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m  3s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m  6s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  21m  2s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m  0s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 29s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  49m 55s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 40s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  41m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 33s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   9m 58s | [/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 10 new + 5526 unchanged - 10 fixed = 5536 total (was 5536)  |\r\n   | -1 :x: |  javadoc  |   8m  2s | [/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 10 new + 1418 unchanged - 10 fixed = 1428 total (was 1428)  |\r\n   | +1 :green_heart: |  shadedclient  |  63m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   2m 22s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 32s |  |  ASF License check generated no output?  |\r\n   |  |   | 309m 40s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7980 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint |\r\n   | uname | Linux 01b725e22dc7 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 76b4eae78d738ee73cf68118a87c9204d120d752 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/testReport/ |\r\n   | Max. process+thread count | 699 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-assemblies hadoop-tools/hadoop-tools-dist hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-tos hadoop-cloud-storage-project/hadoop-cloud-storage hadoop-cloud-storage-project/hadoop-cloud-storage-dist hadoop-cloud-storage-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T22:50:28.141+0000", "updated": "2025-10-09T22:50:28.141+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18029549", "id": "18029549", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "and full jars if you pull in everything. aws bundle.jar dominates; the rest adds up. \r\n{code}\r\n104K aliyun-java-core-0.2.11-beta.jar\r\n190K aliyun-java-sdk-core-4.5.10.jar\r\n160K aliyun-java-sdk-kms-2.11.0.jar\r\n216K aliyun-java-sdk-ram-3.1.0.jar\r\n907K aliyun-sdk-oss-3.18.1.jar\r\n2.4M analyticsaccelerator-s3-1.3.0.jar\r\n3.0K animal-sniffer-annotations-1.24.jar\r\n3.0K annotations-4.1.1.4.jar\r\n 49K api-common-2.47.2.jar\r\n7.3K auto-value-annotations-1.11.0.jar\r\n111K azure-data-lake-store-sdk-2.3.9.jar\r\n 10K azure-keyvault-core-1.0.0.jar\r\n796K azure-storage-7.0.1.jar\r\n612M bundle-2.29.52.jar\r\n232K checker-qual-3.49.0.jar\r\n346K commons-codec-1.15.jar\r\n 69K commons-logging-1.3.0.jar\r\n4.3M conscrypt-openjdk-uber-2.5.2.jar\r\n8.3M cos_api-bundle-5.6.19.jar\r\n 18K detector-resources-support-0.33.0.jar\r\n317K dom4j-2.1.4.jar\r\n 19K error_prone_annotations-2.36.0.jar\r\n 39K exporter-metrics-0.33.0.jar\r\n4.6K failureaccess-1.0.2.jar\r\n 52K gapic-google-cloud-storage-v2-2.52.0.jar\r\n424K gax-2.64.2.jar\r\n154K gax-grpc-2.64.2.jar\r\n162K gax-httpjson-2.64.2.jar\r\n295K google-api-client-2.7.2.jar\r\n252K google-api-services-storage-v1-rev20250420-2.0.0.jar\r\n8.2K google-auth-library-credentials-1.33.1.jar\r\n294K google-auth-library-oauth2-http-1.33.1.jar\r\n137K google-cloud-core-2.54.2.jar\r\n 16K google-cloud-core-grpc-2.54.2.jar\r\n 15K google-cloud-core-http-2.54.2.jar\r\n249K google-cloud-monitoring-3.52.0.jar\r\n1.3M google-cloud-storage-2.52.0.jar\r\n289K google-http-client-1.46.3.jar\r\n 11K google-http-client-apache-v2-1.46.3.jar\r\n 19K google-http-client-appengine-1.46.3.jar\r\n 13K google-http-client-gson-1.46.3.jar\r\n9.4K google-http-client-jackson2-1.46.3.jar\r\n 80K google-oauth-client-1.37.0.jar\r\n316K grpc-alts-1.70.0.jar\r\n316K grpc-api-1.70.0.jar\r\n 14K grpc-auth-1.70.0.jar\r\n293B grpc-context-1.70.0.jar\r\n639K grpc-core-1.70.0.jar\r\n 30K grpc-google-cloud-storage-v2-2.52.0.jar\r\n 15K grpc-googleapis-1.70.0.jar\r\n175K grpc-grpclb-1.70.0.jar\r\n 39K grpc-inprocess-1.70.0.jar\r\n9.3M grpc-netty-shaded-1.70.0.jar\r\n 67K grpc-opentelemetry-1.70.0.jar\r\n5.2K grpc-protobuf-1.70.0.jar\r\n7.7K grpc-protobuf-lite-1.70.0.jar\r\n248K grpc-rls-1.70.0.jar\r\n928K grpc-services-1.70.0.jar\r\n 59K grpc-stub-1.70.0.jar\r\n 98K grpc-util-1.70.0.jar\r\n9.4M grpc-xds-1.70.0.jar\r\n243K gson-2.9.0.jar\r\n2.9M guava-33.4.8-jre.jar\r\n 92K hadoop-aliyun-3.5.0-SNAPSHOT.jar\r\n910K hadoop-aws-3.5.0-SNAPSHOT.jar\r\n810K hadoop-azure-3.5.0-SNAPSHOT.jar\r\n 33K hadoop-azure-datalake-3.5.0-SNAPSHOT.jar\r\n 68K hadoop-cos-3.5.0-SNAPSHOT.jar\r\n135K hadoop-gcp-3.5.0-SNAPSHOT.jar\r\n142K hadoop-huaweicloud-3.5.0-SNAPSHOT.jar\r\n250K hadoop-tos-3.5.0-SNAPSHOT.jar\r\n762K httpclient-4.5.13.jar\r\n933K httpclient5-5.5.jar\r\n321K httpcore-4.4.13.jar\r\n888K httpcore5-5.3.6.jar\r\n236K httpcore5-h2-5.3.4.jar\r\n100K ini4j-0.5.4.jar\r\n 12K j2objc-annotations-3.0.0.jar\r\n462K jackson-core-2.14.3.jar\r\n7.6K java-trace-api-0.2.11-beta.jar\r\n 26K javax.annotation-api-1.3.2.jar\r\n320K jdom2-2.0.6.1.jar\r\n 88K jettison-1.5.4.jar\r\n575K jetty-util-9.4.57.v20241219.jar\r\n 65K jetty-util-ajax-9.4.57.v20241219.jar\r\n3.7K jspecify-1.0.0.jar\r\n 19K jsr305-3.0.2.jar\r\n2.1K listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar\r\n347K opencensus-api-0.31.1.jar\r\n 23K opencensus-contrib-http-util-0.31.1.jar\r\n155K opentelemetry-api-1.47.0.jar\r\n 48K opentelemetry-context-1.47.0.jar\r\n8.1K opentelemetry-gcp-resources-1.37.0-alpha.jar\r\n6.6K opentelemetry-sdk-1.47.0.jar\r\n 54K opentelemetry-sdk-common-1.47.0.jar\r\n 20K opentelemetry-sdk-extension-autoconfigure-spi-1.47.0.jar\r\n 53K opentelemetry-sdk-logs-1.47.0.jar\r\n322K opentelemetry-sdk-metrics-1.47.0.jar\r\n129K opentelemetry-sdk-trace-1.47.0.jar\r\n 73K opentelemetry-semconv-1.29.0-alpha.jar\r\n275K org.jacoco.agent-0.8.5-runtime.jar\r\n6.8K perfmark-api-0.27.0.jar\r\n1.9M proto-google-cloud-monitoring-v3-3.52.0.jar\r\n980K proto-google-cloud-storage-v2-2.52.0.jar\r\n2.6M proto-google-common-protos-2.55.2.jar\r\n182K proto-google-iam-v1-1.50.2.jar\r\n521K protobuf-java-2.5.0.jar\r\n 71K protobuf-java-util-3.25.5.jar\r\n125K re2j-1.1.jar\r\n 11K reactive-streams-1.0.3.jar\r\n 91K shared-resourcemapping-0.33.0.jar\r\n 40K slf4j-api-1.7.36.jar\r\n503K threetenbp-1.7.0.jar\r\n980K ve-tos-java-sdk-hadoop-2.8.9.jar\r\n433K wildfly-openssl-2.1.4.Final.jar\r\n{code}\r\n\r\nThe default settings will produce something a lot leaner\r\n{code}\r\n2.4M analyticsaccelerator-s3-1.3.0.jar\r\n 10K azure-keyvault-core-1.0.0.jar\r\n796K azure-storage-7.0.1.jar\r\n346K commons-codec-1.15.jar\r\n 69K commons-logging-1.3.0.jar\r\n910K hadoop-aws-3.5.0-SNAPSHOT.jar\r\n810K hadoop-azure-3.5.0-SNAPSHOT.jar\r\n 33K hadoop-azure-datalake-3.5.0-SNAPSHOT.jar\r\n 68K hadoop-cos-3.5.0-SNAPSHOT.jar\r\n135K hadoop-gcp-3.5.0-SNAPSHOT.jar\r\n142K hadoop-huaweicloud-3.5.0-SNAPSHOT.jar\r\n250K hadoop-tos-3.5.0-SNAPSHOT.jar\r\n762K httpclient-4.5.13.jar\r\n321K httpcore-4.4.13.jar\r\n575K jetty-util-9.4.57.v20241219.jar\r\n 65K jetty-util-ajax-9.4.57.v20241219.jar\r\n433K wildfly-openssl-2.1.4.Final.jar\r\n{code}\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-13T16:07:33.413+0000", "updated": "2025-10-13T16:07:33.413+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18029791", "id": "18029791", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3402138222\n\n   shaded test failures\r\n   * some in yarn which are presumably unrelated...let's see\r\n   * lots of more skipped tests in hadoop-azure, hadoop-azuredatalake, such as `TestAbfsInputStreamStatistics` which is skipping  .... Looks like maven is back to running these tests and skipping where they don't have the credentials\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-14T14:23:01.303+0000", "updated": "2025-10-14T14:23:01.303+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18030028", "id": "18030028", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3405523026\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 30s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 15s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  35m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 37s |  |  trunk passed  |\r\n   | +1 :green_heart: |  checkstyle  |   3m 40s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |  11m  2s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 44s |  |  trunk passed  |\r\n   | +0 :ok: |  spotbugs  |   0m 27s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +0 :ok: |  spotbugs  |   0m 22s |  |  branch/hadoop-assemblies no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   1m 19s | [/branch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 32s | [/branch-spotbugs-hadoop-tools_hadoop-gcp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-tools_hadoop-gcp.txt) |  hadoop-gcp in trunk failed.  |\r\n   | +0 :ok: |  spotbugs  |   0m 23s |  |  branch/hadoop-tools/hadoop-tools-dist no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   0m 32s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt) |  hadoop-huaweicloud in trunk failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 37s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in trunk failed.  |\r\n   | +0 :ok: |  spotbugs  |   0m 23s |  |  branch/hadoop-cloud-storage-project/hadoop-cloud-storage no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   0m 31s | [/branch-spotbugs-hadoop-cloud-storage-project.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-cloud-storage-project.txt) |  hadoop-cloud-storage-project in trunk failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 30s | [/branch-spotbugs-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  30m 50s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  43m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m  5s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  17m  5s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   3m 39s |  |  the patch passed  |\r\n   | -1 :x: |  mvnsite  |   7m 36s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   9m 41s | [/results-javadoc-javadoc-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/results-javadoc-javadoc-root.txt) |  root generated 30 new + 42985 unchanged - 30 fixed = 43015 total (was 43015)  |\r\n   | +0 :ok: |  spotbugs  |   0m 22s |  |  hadoop-project has no data from spotbugs  |\r\n   | +0 :ok: |  spotbugs  |   0m 22s |  |  hadoop-assemblies has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   1m 19s | [/patch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +0 :ok: |  spotbugs  |   0m 24s |  |  hadoop-tools/hadoop-tools-dist has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   0m 33s | [/patch-spotbugs-hadoop-tools_hadoop-gcp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-tools_hadoop-gcp.txt) |  hadoop-gcp in the patch failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 32s | [/patch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt) |  hadoop-huaweicloud in the patch failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 36s | [/patch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) |  hadoop-tos in the patch failed.  |\r\n   | +0 :ok: |  spotbugs  |   0m 22s |  |  hadoop-cloud-storage-project/hadoop-cloud-storage has no data from spotbugs  |\r\n   | +0 :ok: |  spotbugs  |   0m 23s |  |  hadoop-cloud-storage-project/hadoop-cloud-storage-dist has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   0m 31s | [/patch-spotbugs-hadoop-cloud-storage-project.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-cloud-storage-project.txt) |  hadoop-cloud-storage-project in the patch failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 30s | [/patch-spotbugs-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  31m 14s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 801m 10s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   1m 45s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/results-asflicense.txt) |  The patch generated 1 ASF License warnings.  |\r\n   |  |   | 1072m 30s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.hdfs.tools.TestDFSAdmin |\r\n   |   | hadoop.yarn.service.TestYarnNativeServices |\r\n   |   | hadoop.yarn.server.router.subcluster.capacity.TestYarnFederationWithCapacityScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.fs.tosfs.object.TestObjectOutputStream |\r\n   |   | hadoop.fs.tosfs.commit.TestMagicOutputStream |\r\n   |   | hadoop.fs.tosfs.object.tos.auth.TestEnvironmentCredentialsProvider |\r\n   |   | hadoop.fs.tosfs.object.tos.auth.TestDefaultCredentialsProviderChain |\r\n   |   | hadoop.fs.tosfs.object.TestObjectRangeInputStream |\r\n   |   | hadoop.fs.tosfs.object.TestObjectMultiRangeInputStream |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7980 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint spotbugs checkstyle |\r\n   | uname | Linux 209e4e5576fc 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0254bb430e1623793f30744d7b32a37202f2d586 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/testReport/ |\r\n   | Max. process+thread count | 3665 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-assemblies hadoop-common-project/hadoop-common hadoop-tools/hadoop-tools-dist hadoop-tools/hadoop-gcp hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-tos hadoop-cloud-storage-project/hadoop-cloud-storage hadoop-cloud-storage-project/hadoop-cloud-storage-dist hadoop-cloud-storage-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T09:44:55.130+0000", "updated": "2025-10-15T09:44:55.130+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18031277", "id": "18031277", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on code in PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#discussion_r2446383325\n\n\n##########\nhadoop-cloud-storage-project/pom.xml:\n##########\n@@ -34,6 +34,7 @@\n     <module>hadoop-cos</module>\n     <module>hadoop-huaweicloud</module>\n     <module>hadoop-tos</module>\n+    <module>hadoop-cloud-storage-dist</module>\n\nReview Comment:\n   It seems like we would never need to enter execution of `hadoop-cloud-storage-dist` unless we are building a distro (activating `-Pdist`). Should we also wrap inclusion of the sub-module here behind activation of the `dist` profile?\n\n\n\n##########\nBUILDING.txt:\n##########\n@@ -388,6 +388,58 @@ Create a local staging version of the website (in /tmp/hadoop-site)\n \n Note that the site needs to be built in a second pass after other artifacts.\n \n+----------------------------------------------------------------------------------\n+Including Cloud Connector Dependencies in Distributions:\n+\n+Hadoop distributions include the hadoop modules need to work with data and services\n\nReview Comment:\n   Nitpick: \"modules needed\".\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-20T23:40:44.245+0000", "updated": "2025-10-20T23:40:44.245+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18031399", "id": "18031399", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#discussion_r2447670994\n\n\n##########\nhadoop-cloud-storage-project/pom.xml:\n##########\n@@ -34,6 +34,7 @@\n     <module>hadoop-cos</module>\n     <module>hadoop-huaweicloud</module>\n     <module>hadoop-tos</module>\n+    <module>hadoop-cloud-storage-dist</module>\n\nReview Comment:\n   valid point. Will do, as it'll save on disk space as well as time.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T10:47:12.420+0000", "updated": "2025-10-21T10:47:12.420+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18031401", "id": "18031401", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#issuecomment-3425948823\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 16s |  |  https://github.com/apache/hadoop/pull/7980 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7980 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/10/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T10:57:22.714+0000", "updated": "2025-10-21T10:57:22.714+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629208/comment/18031911", "id": "18031911", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on code in PR #7980:\nURL: https://github.com/apache/hadoop/pull/7980#discussion_r2449857037\n\n\n##########\nBUILDING.txt:\n##########\n@@ -388,6 +388,57 @@ Create a local staging version of the website (in /tmp/hadoop-site)\n \n Note that the site needs to be built in a second pass after other artifacts.\n \n+----------------------------------------------------------------------------------\n+Including Cloud Connector Dependencies in Distributions:\n+\n+Hadoop distributions include the hadoop modules needed to work with data and services\n+on cloud infrastructure\n+\n+However, dependencies are omitted for all cloud connectors except hadoop-azure\n+(abfs:// and wasb://) and possibly hadoop-gcp (gs://) and hadoop-tos (tos://).\n+For the latter two modules, it depends on shading options.\n+\n+For hadoop-aws the AWS SDK bundle.jar is omitted, but everything else is included.\n+\n+Excluding the extra binaries:\n+* Keeps release artifact size below the limit of the ASF distribution network.\n+* Reduces download and size overhead in docker usage.\n+* Reduces the CVE attack surface and audit-related complaints about those same ScVES.\n\nReview Comment:\n   Nitpick: \"CVEs.\"\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T22:22:36.924+0000", "updated": "2025-10-21T22:22:36.924+0000"}], "maxResults": 19, "total": 19, "startAt": 0}, "updated": "2025-10-21T22:22:37.000+0000", "created": "2025-09-17T13:36:12.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629179", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629179", "key": "HADOOP-19695", "fields": {"summary": "Add dual-stack/IPv6 Support to HttpServer2", "description": "To support clients connecting to JHS via IPv6, we need to equip the YARN WebApp class to bind to an IPv6 address. WebApp uses the HttpServer2, and adding the IPv6 connector to this class makes the solution more elegant.\r\n\r\nTo enable dual-stack or IPv6 support, use InetAddress.getAllByName(hostname) to resolve the IP addresses of a host.\r\nWhen the system property java.net.preferIPv4Stack is set to true, only IPv4 addresses are returned, and any IPv6 addresses are ignored, so no extra check is needed to exclude IPv6.\r\nWhen java.net.preferIPv4Stack is false, both IPv4 and IPv6 addresses may be returned, and any IPv6 addresses will also be added as connectors.\r\nTo disable IPv4, you need to configure the OS at the system level.\r\n ", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18020903", "id": "18020903", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ferdelyi opened a new pull request, #7979:\nURL: https://github.com/apache/hadoop/pull/7979\n\n   To enable dual-stack or IPv6 support, use InetAddress.getAllByName(hostname) to resolve the IP addresses of a host. When the system property java.net.preferIPv4Stack is set to true, only IPv4 addresses are returned, and any IPv6 addresses are ignored, so no extra check is needed to exclude IPv6. When java.net.preferIPv4Stack is false, both IPv4 and IPv6 addresses may be returned, and any IPv6 addresses will also be added as connectors. To disable IPv4, you need to configure the OS at the system level.\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T11:39:42.443+0000", "updated": "2025-09-17T11:39:42.443+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18020952", "id": "18020952", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3303626071\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 47s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  57m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 55s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 18s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 47s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m  1s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 40s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m 14s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 1 new + 68 unchanged - 0 fixed = 69 total (was 68)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 44s |  |  the patch passed  |\r\n   | -1 :x: |  shadedclient  |  42m 42s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 33s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  5s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 251m 12s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 69abc2152550 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 05144e7770fd55d4ed400b5ee8d71ea02d4d37b6 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/testReport/ |\r\n   | Max. process+thread count | 3098 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T15:52:09.794+0000", "updated": "2025-09-17T15:52:09.794+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18020977", "id": "18020977", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3304428637\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 48s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  57m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  0s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 18s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 53s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 16s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 56s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 57s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 43s |  |  the patch passed  |\r\n   | -1 :x: |  shadedclient  |  42m 52s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 37s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  5s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 251m 40s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 2f758f82d727 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4e384cfeaf21c2674e992b6ec288d9403a8d1adb |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/2/testReport/ |\r\n   | Max. process+thread count | 2679 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T20:13:02.240+0000", "updated": "2025-09-17T20:13:02.240+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18021167", "id": "18021167", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brumi1024 commented on code in PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#discussion_r2359223851\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java:\n##########\n@@ -549,25 +550,50 @@ public HttpServer2 build() throws IOException {\n       }\n \n       for (URI ep : endpoints) {\n-        final ServerConnector connector;\n+        //\n+        // To enable dual-stack or IPv6 support, use InetAddress\n+        // .getAllByName(hostname) to resolve the IP addresses of a host.\n+        // When the system property java.net.preferIPv4Stack is set to true,\n+        // only IPv4 addresses are returned, and any IPv6 addresses are\n+        // ignored, so no extra check is needed to exclude IPv6.\n+        // When java.net.preferIPv4Stack is false, both IPv4 and IPv6\n+        // addresses may be returned, and any IPv6 addresses will also be\n+        // added as connectors.\n+        // To disable IPv4, you need to configure the OS at the system level.\n+        //\n+        InetAddress[] addresses = InetAddress.getAllByName(ep.getHost());\n+        server = addConnectors(\n+            ep, addresses, server, httpConfig, backlogSize, idleTimeout);\n+      }\n+      server.loadListeners();\n+      return server;\n+    }\n+\n+    @VisibleForTesting\n+    HttpServer2 addConnectors(\n+        URI ep, InetAddress[] addresses, HttpServer2 server,\n+        HttpConfiguration httpConfig, int backlogSize, int idleTimeout){\n+      for (InetAddress addr : addresses) {\n+        ServerConnector connector;\n         String scheme = ep.getScheme();\n         if (HTTP_SCHEME.equals(scheme)) {\n-          connector = createHttpChannelConnector(server.webServer,\n-              httpConfig);\n+          connector = createHttpChannelConnector(\n+              server.webServer, httpConfig);\n         } else if (HTTPS_SCHEME.equals(scheme)) {\n-          connector = createHttpsChannelConnector(server.webServer,\n-              httpConfig);\n+          connector = createHttpsChannelConnector(\n+              server.webServer, httpConfig);\n         } else {\n           throw new HadoopIllegalArgumentException(\n               \"unknown scheme for endpoint:\" + ep);\n         }\n-        connector.setHost(ep.getHost());\n+        LOG.info(\"Adding connector to WebServer for address {}\",\n\nReview Comment:\n   Do we need info level for this? Debug might be enough.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T13:13:15.989+0000", "updated": "2025-09-18T13:13:15.989+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18021201", "id": "18021201", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ferdelyi commented on code in PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#discussion_r2359742305\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java:\n##########\n@@ -549,25 +550,50 @@ public HttpServer2 build() throws IOException {\n       }\n \n       for (URI ep : endpoints) {\n-        final ServerConnector connector;\n+        //\n+        // To enable dual-stack or IPv6 support, use InetAddress\n+        // .getAllByName(hostname) to resolve the IP addresses of a host.\n+        // When the system property java.net.preferIPv4Stack is set to true,\n+        // only IPv4 addresses are returned, and any IPv6 addresses are\n+        // ignored, so no extra check is needed to exclude IPv6.\n+        // When java.net.preferIPv4Stack is false, both IPv4 and IPv6\n+        // addresses may be returned, and any IPv6 addresses will also be\n+        // added as connectors.\n+        // To disable IPv4, you need to configure the OS at the system level.\n+        //\n+        InetAddress[] addresses = InetAddress.getAllByName(ep.getHost());\n+        server = addConnectors(\n+            ep, addresses, server, httpConfig, backlogSize, idleTimeout);\n+      }\n+      server.loadListeners();\n+      return server;\n+    }\n+\n+    @VisibleForTesting\n+    HttpServer2 addConnectors(\n+        URI ep, InetAddress[] addresses, HttpServer2 server,\n+        HttpConfiguration httpConfig, int backlogSize, int idleTimeout){\n+      for (InetAddress addr : addresses) {\n+        ServerConnector connector;\n         String scheme = ep.getScheme();\n         if (HTTP_SCHEME.equals(scheme)) {\n-          connector = createHttpChannelConnector(server.webServer,\n-              httpConfig);\n+          connector = createHttpChannelConnector(\n+              server.webServer, httpConfig);\n         } else if (HTTPS_SCHEME.equals(scheme)) {\n-          connector = createHttpsChannelConnector(server.webServer,\n-              httpConfig);\n+          connector = createHttpsChannelConnector(\n+              server.webServer, httpConfig);\n         } else {\n           throw new HadoopIllegalArgumentException(\n               \"unknown scheme for endpoint:\" + ep);\n         }\n-        connector.setHost(ep.getHost());\n+        LOG.info(\"Adding connector to WebServer for address {}\",\n\nReview Comment:\n   @brumi1024 thank you for your review! I've pushed a new commit with the suggested change.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T14:58:00.773+0000", "updated": "2025-09-18T14:58:00.773+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18021247", "id": "18021247", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3309202536\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  57m 54s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 54s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 14s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 17s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 53s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 42s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 55s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 33s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 45s |  |  the patch passed  |\r\n   | -1 :x: |  shadedclient  |  42m 49s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 40s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  5s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 253m 33s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d2fb039015c7 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 792d7c033b10af7f44ef638aa249d7594e5f3bcd |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/3/testReport/ |\r\n   | Max. process+thread count | 1273 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T19:07:10.599+0000", "updated": "2025-09-18T19:07:10.599+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18021870", "id": "18021870", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3319347658\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m 12s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  54m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 55s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 29s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 17s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 53s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  44m  9s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m  4s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m  4s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 33s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 41s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 48s |  |  the patch passed  |\r\n   | -1 :x: |  shadedclient  |  43m 28s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m  7s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  6s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 273m 25s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux b753ac7f62a8 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7d394e5b895e03fa9e42057aa4ea2a74b3d0d034 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/4/testReport/ |\r\n   | Max. process+thread count | 3098 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-22T14:22:14.066+0000", "updated": "2025-09-22T14:22:14.066+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18022173", "id": "18022173", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ferdelyi commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3324196841\n\n   Earlier shadedclient failures: [ERROR]   ITUseMiniCluster.clusterUp:78 \u00bb IO Problem starting http server\r\n   Latest failure: ERROR: Failed to write github status. Token expired or missing repo:status write?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T14:11:46.510+0000", "updated": "2025-09-23T14:11:46.510+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18022232", "id": "18022232", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3325156959\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m 16s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  57m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  4s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 24s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 19s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 54s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 52s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 59s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m 59s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 23s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 41s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 54s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 44s |  |  the patch passed  |\r\n   | -1 :x: |  shadedclient  |  42m 44s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 31s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  7s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 273m 56s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux afe6e7544141 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 48a180410434866489d88bb6cfda181f2bcc602d |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/5/testReport/ |\r\n   | Max. process+thread count | 3100 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T18:45:54.266+0000", "updated": "2025-09-23T18:45:54.266+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18022792", "id": "18022792", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3333947403\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 59s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  53m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m 17s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  17m 43s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 50s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 23s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 56s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 55s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 38s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 56s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 55s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 45s |  |  the patch passed  |\r\n   | -1 :x: |  shadedclient  |  42m  1s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 35s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  4s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 248m 51s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 04cfc8fa6705 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2b42d965a1cda228b2307bf26b0444c9b047d8c8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/6/testReport/ |\r\n   | Max. process+thread count | 1249 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/6/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-25T13:13:37.358+0000", "updated": "2025-09-25T13:13:37.358+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18022869", "id": "18022869", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ferdelyi commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3335426490\n\n   shadedclient was failing on this:\r\n   \r\n   [INFO] Running org.apache.hadoop.example.ITUseMiniCluster\r\n   [ERROR] Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 19.60 s <<< FAILURE! ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-25T18:29:25.152+0000", "updated": "2025-09-25T18:29:25.152+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18022963", "id": "18022963", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3336661768\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  4s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 37s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  8s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 47s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   3m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   3m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 40s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   6m  3s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 38s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   2m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 57s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   3m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   3m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 54s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   6m 22s |  |  the patch passed  |\r\n   | -1 :x: |  shadedclient  |  42m 14s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 39s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  | 276m 18s |  |  hadoop-hdfs in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 552m  3s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux ed92b822cf7a 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 8aa88fc3e70c245050e33aab0a585dd5a9606340 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/7/testReport/ |\r\n   | Max. process+thread count | 3098 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/7/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T03:37:41.630+0000", "updated": "2025-09-26T03:37:41.630+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18023091", "id": "18023091", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ferdelyi commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3338485084\n\n   In the patch-shadedclient.txt the exception now is:\r\n   Caused by: java.lang.IllegalStateException: Insufficient configured threads: required=5 < max=5 for QueuedThreadPool[qtp164052991]@9c73fff{STARTED,5<=5<=5,i=3,r=-1,q=0}[ReservedThreadExecutor@29be997f{reserved=0/1,pending=0}]\r\n   \r\n   I've increased HTTP_MAX_THREADS by one, and the required number of threads also increased by one. Just out of curiosity will puch e.g. 10 and see if it keeps increasing.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T12:29:59.857+0000", "updated": "2025-09-26T12:29:59.857+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18023203", "id": "18023203", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3340611486\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 44s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  6s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   3m 14s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   3m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 38s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 50s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   6m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 47s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   2m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m  6s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 23s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   3m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   3m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 47s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   6m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m  6s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 42s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  | 278m  6s |  |  hadoop-hdfs in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 21s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 549m 29s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 2ff86f039bb0 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e14a395fa6450d1aeb2f0054197292b5af1540dc |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/8/testReport/ |\r\n   | Max. process+thread count | 2198 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/8/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T21:45:17.824+0000", "updated": "2025-09-26T21:45:17.824+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18028004", "id": "18028004", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3375718964\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  30m 10s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 52s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |  45m 43s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |  11m 43s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |  10m 13s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 14s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 29s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   5m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m  2s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   2m  9s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |  11m 28s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |  11m 28s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |  10m  9s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |  10m  9s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 49s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m  3s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   5m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 33s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 22s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  | 470m 28s |  |  hadoop-hdfs in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 57s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 741m 16s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 83d811e5f434 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 8e2cd7f590381ff77458ec6a44f0d3b83779eb53 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/testReport/ |\r\n   | Max. process+thread count | 2216 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T08:17:39.726+0000", "updated": "2025-10-07T08:17:39.726+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18028161", "id": "18028161", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3377795853\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 32s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |  46m 25s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |  11m 42s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   9m 59s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 52s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 12s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   5m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 36s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   2m 29s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |  11m 52s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |  11m 52s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m  3s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   5m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 51s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 25s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  | 279m 19s |  |  hadoop-hdfs in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 54s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 521m 50s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d9d0c21591bb 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7adcb39cbe58f85adc3d03fa0ad751c64b87624e |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/testReport/ |\r\n   | Max. process+thread count | 3098 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T17:11:04.220+0000", "updated": "2025-10-07T17:11:04.220+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18028842", "id": "18028842", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979#issuecomment-3386925666\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 36s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m  2s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  41m  3s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 50s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 55s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   3m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 33s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 53s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   5m 55s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m  1s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   2m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 24s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 45s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 49s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   3m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   2m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   6m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 43s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 50s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  | 289m 16s |  |  hadoop-hdfs in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 557m 31s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/12/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7979 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 22968369ed69 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 87e9944f809d56e1c99a5ff5138c93377e99f464 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/12/testReport/ |\r\n   | Max. process+thread count | 3152 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/12/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T17:48:48.839+0000", "updated": "2025-10-09T17:48:48.839+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629179/comment/18029433", "id": "18029433", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brumi1024 merged PR #7979:\nURL: https://github.com/apache/hadoop/pull/7979\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T08:46:17.170+0000", "updated": "2025-10-13T08:46:17.170+0000"}], "maxResults": 18, "total": 18, "startAt": 0}, "updated": "2025-10-13T08:48:57.000+0000", "created": "2025-09-17T11:21:23.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629178", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629178", "key": "HADOOP-19694", "fields": {"summary": "Bump guava to  33.4.8-jre due to EOL", "description": "We can use the latest 33.4.8-jre version as the current one is quite old.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629178/comment/18021854", "id": "18021854", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "When I do a thirdparty build I now get a warning of duplicate module 9 info.\r\n{code}\r\n[INFO] No artifact matching filter org.checkerframework:checker-qual\r\n[WARNING] error_prone_annotations-2.36.0.jar, guava-33.4.8-jre.jar, failureaccess-1.0.3.jar, jspecify-1.0.0.jar, j2objc-annotations-3.0.0.jar define 1 overlapping classes: \r\n[WARNING]   - META-INF.versions.9.module-info\r\n[WARNING] maven-shade-plugin has detected that some class files are\r\n[WARNING] present in two or more JARs. When this happens, only one\r\n[WARNING] single version of the class is copied to the uber jar.\r\n[WARNING] Usually this is not harmful and you can skip these warnings,\r\n[WARNING] otherwise try to manually exclude artifacts based on\r\n[WARNING] mvn dependency:tree -Ddetail=true and the above output.\r\n[WARNING] See http://maven.apache.org/plugins/maven-shade-plugin/\r\n{code}\r\nThis is new.\r\n\r\ngiven we want this to work on java17+ , we need to come up with a way of resolving the conflict, at the very least by making the guava one dominant.\r\n\r\n\r\n\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-09-22T13:37:32.907+0000", "updated": "2025-09-22T13:37:32.907+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629178/comment/18031213", "id": "18031213", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "ahh, the later versions of guava exclude a dependency on checkerframework. So any references in our code (there are four) fail. Which means we have to manually add it if we want a drop in replacement. PITA.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-20T16:41:38.036+0000", "updated": "2025-10-20T16:41:38.036+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-10-20T16:41:38.000+0000", "created": "2025-09-17T11:01:22.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629129", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629129", "key": "HADOOP-19693", "fields": {"summary": "Update Java 24 to 25 in docker images", "description": "Temurin JDK25 packages are expected to be available shortly, update JDK 24 to 25 in the docker images.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18022049", "id": "18022049", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "body": "The ubuntu packages have been released.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "created": "2025-09-23T05:58:19.929+0000", "updated": "2025-09-23T05:58:19.929+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18022052", "id": "18022052", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty opened a new pull request, #7991:\nURL: https://github.com/apache/hadoop/pull/7991\n\n   ### Description of PR\r\n   \r\n   Update Java 24 to 25 in docker images\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Built ubuntu_20 and ubuntu_24 x64 images, and ran java 25 in them.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T06:21:48.009+0000", "updated": "2025-09-23T06:21:48.009+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18022067", "id": "18022067", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7991:\nURL: https://github.com/apache/hadoop/pull/7991#issuecomment-3322708226\n\n   PTAL @slfan1989 \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T07:10:50.258+0000", "updated": "2025-09-23T07:10:50.258+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18022099", "id": "18022099", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7991:\nURL: https://github.com/apache/hadoop/pull/7991#issuecomment-3322950127\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  31m 53s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 51s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 17s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 20s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 58s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 130m 13s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7991 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 7aa6647a89a6 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / edaa6e0885eeb0c0db357ef86e5defa0dfcc28d8 |\r\n   | Max. process+thread count | 525 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/console |\r\n   | versions | git=2.43.7 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T08:33:12.973+0000", "updated": "2025-09-23T08:33:12.973+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18022123", "id": "18022123", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7991:\nURL: https://github.com/apache/hadoop/pull/7991#issuecomment-3323181520\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  27m 28s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 27s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  shadedclient  |   8m 53s |  |  branch has errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 24s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  31m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 32s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  70m  0s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7991 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 242b70b5bd76 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / edaa6e0885eeb0c0db357ef86e5defa0dfcc28d8 |\r\n   | Max. process+thread count | 538 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/console |\r\n   | versions | git=2.30.2 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T09:43:23.005+0000", "updated": "2025-09-23T09:43:23.005+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18022650", "id": "18022650", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7991:\nURL: https://github.com/apache/hadoop/pull/7991#issuecomment-3332430073\n\n   @pan3793 Could you please review this PR? Thank you very much! Pan has some experience with higher versions of JDK.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-25T06:49:56.855+0000", "updated": "2025-09-25T06:49:56.855+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18022664", "id": "18022664", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7991:\nURL: https://github.com/apache/hadoop/pull/7991#issuecomment-3332517143\n\n   Not much to review here @slfan1989 .\r\n   \r\n   This is just the first step to being able to test with JDK25.\r\n   \r\n   TBH I don't see much value in supporting or testing for JDK24, the real goal is JDK25, the stable release.\r\n   \r\n   Generally, I would test with the supported stable Java releases, plus the latest supported non-stable Java release.\r\n   \r\n   i.e when JDK 26 is released it, then keep Java 25 and add Java 26, then keep replacing Java 26 with 27,28,29,29... until the next stable Java is released (with the optimistic assumption that Hadoop is going to keep up with the non-stable Java releases, and we won't have to do any more big bang updates for 10+ java releases)\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-25T07:19:36.547+0000", "updated": "2025-09-25T07:19:36.547+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18024839", "id": "18024839", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7991:\nURL: https://github.com/apache/hadoop/pull/7991\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T00:32:07.196+0000", "updated": "2025-10-06T00:32:07.196+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629129/comment/18024840", "id": "18024840", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7991:\nURL: https://github.com/apache/hadoop/pull/7991#issuecomment-3369570388\n\n   @stoty Thanks for the contribution!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T00:33:24.204+0000", "updated": "2025-10-06T00:33:24.204+0000"}], "maxResults": 9, "total": 9, "startAt": 0}, "updated": "2025-10-06T00:33:24.000+0000", "created": "2025-09-17T07:57:36.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13629073", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13629073", "key": "HADOOP-19692", "fields": {"summary": "Exclude junit 4 transitive dependency", "description": "HADOOP-19617 removed direct junit 4 dependency.  However, junit 4 is still pulled transitively by other dependencies.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020739", "id": "18020739", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "{code}\r\n[INFO] ------------------< org.apache.hadoop:hadoop-common >-------------------\r\n[INFO] Building Apache Hadoop Common 3.5.0-SNAPSHOT                    [11/117]\r\n[INFO]   from hadoop-common-project/hadoop-common/pom.xml\r\n...\r\n[INFO] +- com.squareup.okhttp3:mockwebserver:jar:4.11.0:test\r\n[INFO] |  +- com.squareup.okhttp3:okhttp:jar:4.11.0:test\r\n[INFO] |  |  \\- com.squareup.okio:okio:jar:3.2.0:test\r\n[INFO] |  |     \\- com.squareup.okio:okio-jvm:jar:3.2.0:test\r\n[INFO] |  \\- junit:junit:jar:4.13:test\r\n[INFO] |     \\- org.hamcrest:hamcrest-core:jar:1.3:test\r\n{code}", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-16T18:19:00.169+0000", "updated": "2025-09-16T18:19:00.169+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020741", "id": "18020741", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "{code}\r\n[INFO] ----------------< org.apache.hadoop:hadoop-hdfs-httpfs >----------------\r\n[INFO] Building Apache Hadoop HttpFS 3.5.0-SNAPSHOT                    [19/117]\r\n[INFO]   from hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml\r\n...\r\n[INFO] +- com.googlecode.json-simple:json-simple:jar:1.1.1:compile\r\n[INFO] | \u00a0\\- junit:junit:jar:4.10:compile\r\n{code}", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-16T18:19:28.685+0000", "updated": "2025-09-16T18:19:28.685+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020742", "id": "18020742", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "{code}\r\n[INFO] -----< org.apache.hadoop:hadoop-yarn-applications-catalog-webapp >------\r\n[INFO] Building Apache Hadoop YARN Application Catalog Webapp 3.5.0-SNAPSHOT [63/117]\r\n[INFO]   from hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/pom.xml\r\n...\r\n[INFO] +- org.apache.solr:solr-test-framework:jar:8.11.2:test\r\n[INFO] |  +- org.apache.lucene:lucene-test-framework:jar:8.11.2:test\r\n[INFO] |  +- com.carrotsearch.randomizedtesting:junit4-ant:jar:2.7.2:test\r\n[INFO] |  +- com.carrotsearch.randomizedtesting:randomizedtesting-runner:jar:2.7.2:test\r\n[INFO] |  +- io.opentracing:opentracing-mock:jar:0.33.0:test\r\n[INFO] |  +- junit:junit:jar:4.13.1:test\r\n{code}", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-16T18:20:02.222+0000", "updated": "2025-09-16T18:30:04.951+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020743", "id": "18020743", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "{code}\r\n[INFO] --< org.apache.hadoop.applications.mawo:hadoop-yarn-applications-mawo >--\r\n[INFO] Building Apache Hadoop YARN Application MaWo 3.5.0-SNAPSHOT     [65/117]\r\n[INFO]   from hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/pom.xml\r\n...\r\n[INFO] +- com.googlecode.json-simple:json-simple:jar:1.1.1:compile\r\n[INFO] |  \\- junit:junit:jar:4.10:compile\r\n[INFO] |     \\- org.hamcrest:hamcrest-core:jar:1.1:compile\r\n{code}", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-16T18:21:02.034+0000", "updated": "2025-09-16T18:21:02.034+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020747", "id": "18020747", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo opened a new pull request, #7978:\nURL: https://github.com/apache/hadoop/pull/7978\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   HADOOP-19692\r\n   \r\n   The direct junit 4 dependency was removed by HADOOP-19617. However, junit 4 is still pulled transitively by other dependencies.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   By the pull request action.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [NA] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [NA] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [NA] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T18:37:14.755+0000", "updated": "2025-09-16T18:37:14.755+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020784", "id": "18020784", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3300529165\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  12m 11s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 49s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 15s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   4m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   3m 58s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   3m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  | 146m 52s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |   0m 53s | [/patch-mvninstall-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-mvninstall-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | -1 :x: |  compile  |   1m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   1m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   1m 13s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   1m 13s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   0m 59s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  javadoc  |   2m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 42s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  10m  7s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 14s |  |  hadoop-project in the patch passed.  |\r\n   | -1 :x: |  unit  |   0m 59s | [/patch-unit-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  unit  |   5m 32s |  |  hadoop-hdfs-httpfs in the patch passed.  |\r\n   | -1 :x: |  unit  |   0m 48s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 20s |  |  hadoop-yarn-applications-mawo-core in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 32s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 173m 47s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.appcatalog.application.TestAppCatalogSolrClient |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7978 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux b2d417db0dc5 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 613024d63ccccb96c39f1fab428aa1356b68d2d4 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/testReport/ |\r\n   | Max. process+thread count | 863 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/hadoop-yarn-applications-mawo-core U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T22:21:25.871+0000", "updated": "2025-09-16T22:21:25.871+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020790", "id": "18020790", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3300605779\n\n   It turns out that we have not completely removed junit tests.\r\n   ```\r\n   ERROR] /home/jenkins/jenkins-agent/workspace/hadoop-multibranch_PR-7978/ubuntu-focal/src/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/http/TestHttpFileSystem.java:[57,5] cannot access org.junit.rules.ExternalResource\r\n     class file for org.junit.rules.ExternalResource not found\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T22:59:45.653+0000", "updated": "2025-09-16T22:59:45.653+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020799", "id": "18020799", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3300697473\n\n   > ... we have not completely removed junit tests.\r\n   \r\n   The reason is that `mockwebserver` uses junit 4.  We should replace it with `mockwebserver3-junit5`.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T23:51:07.450+0000", "updated": "2025-09-16T23:51:07.450+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020838", "id": "18020838", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3301302828\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 57s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  49m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 59s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   4m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   3m 54s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   3m 27s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 41s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  5s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 39s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   2m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 21s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   4m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   3m 55s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   3m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 35s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 36s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |  22m 35s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   5m 55s |  |  hadoop-hdfs-httpfs in the patch passed.  |\r\n   | -1 :x: |  unit  |   1m 10s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 42s |  |  hadoop-yarn-applications-mawo-core in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  7s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 298m 25s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.appcatalog.application.TestAppCatalogSolrClient |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7978 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 19a387ca4ff9 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 715044a0192f83d7661d00e9ede87d1067004e52 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/testReport/ |\r\n   | Max. process+thread count | 1294 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/hadoop-yarn-applications-mawo-core U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T04:54:45.219+0000", "updated": "2025-09-17T04:54:45.219+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18020966", "id": "18020966", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3304127134\n\n   ```\r\n   [ERROR] org.apache.hadoop.yarn.appcatalog.application.TestAppCatalogSolrClient.testNotFoundSearch ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T18:30:45.885+0000", "updated": "2025-09-17T18:30:45.885+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18021002", "id": "18021002", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3304842636\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 48s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  11m 52s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  48m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 56s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 19s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   4m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   3m 58s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   3m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 42s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 30s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   2m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 58s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 14s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   4m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   3m 56s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   3m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 37s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 36s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |  22m 38s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   5m 54s |  |  hadoop-hdfs-httpfs in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m 15s |  |  hadoop-yarn-applications-catalog-webapp in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 42s |  |  hadoop-yarn-applications-mawo-core in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  6s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 297m  9s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7978 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux ded193a6470d 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 90ed7ecdaeec392fff06e28edc555a5420794f66 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/4/testReport/ |\r\n   | Max. process+thread count | 2987 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/hadoop-yarn-applications-mawo-core U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T23:30:39.223+0000", "updated": "2025-09-17T23:30:39.223+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18021003", "id": "18021003", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3304863270\n\n   > The junit 4 Assert is in LuceneTestCase. Not sure if updating the solr-test-framework version 8.11.2 could fix it.\r\n   \r\n   The current code in LuceneTestCase still use JUnit 4.\r\n   https://github.com/apache/lucene/blob/13a7e1e53d0e69233e775f2fb241b86c3ac0e527/lucene/test-framework/src/java/org/apache/lucene/tests/util/LuceneTestCase.java#L202C1-L217C3\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T23:41:11.650+0000", "updated": "2025-09-17T23:41:11.650+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18021218", "id": "18021218", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3308469834\n\n   Filed HADOOP-19699  for TestAppCatalogSolrClient\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T16:36:42.876+0000", "updated": "2025-09-18T16:36:42.876+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18021220", "id": "18021220", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo merged PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T16:39:11.824+0000", "updated": "2025-09-18T16:39:11.824+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18021221", "id": "18021221", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3308483383\n\n   Thanks @cnauroth  and @slfan1989 for reviewing this!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T16:39:49.502+0000", "updated": "2025-09-18T16:39:49.502+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18021222", "id": "18021222", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "The pull request was merged.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-18T16:40:48.592+0000", "updated": "2025-09-18T16:40:48.592+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13629073/comment/18021308", "id": "18021308", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7978:\nURL: https://github.com/apache/hadoop/pull/7978#issuecomment-3310127385\n\n   > Thanks @cnauroth and @slfan1989 for reviewing this!\r\n   \r\n   @szetszwo Thank you for the contribution!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T00:56:57.538+0000", "updated": "2025-09-19T00:56:57.538+0000"}], "maxResults": 17, "total": 17, "startAt": 0}, "updated": "2025-09-19T17:06:35.000+0000", "created": "2025-09-16T18:18:40.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628997", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628997", "key": "HADOOP-19691", "fields": {"summary": "[JDK17] Disallow JUnit4 Imports After JUnit5 Migration", "description": "As our project has fully migrated to JUnit5, we should now enforce a rule that prevents the import and usage of JUnit4 classes (such as org.junit.Test, org.junit.Assert, etc.) to ensure consistency, avoid regressions, and allow safe removal of legacy dependencies.\r\n\r\nThis task involves identifying and eliminating any remaining JUnit4 imports, and introducing static code analysis or linting rules to ban future usage.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18020636", "id": "18020636", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976#issuecomment-3297850797\n\n   @TaoYang526 We are currently working on upgrading the project to JUnit 5, and I have added a validation rule to prevent users from reintroducing JUnit 4 dependencies. During the review, I found that the testAsyncScheduleThreadExit method used JUnit 4 features, so I made some modifications. Could you please take a look and let me know if the changes are reasonable?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T11:07:34.654+0000", "updated": "2025-09-16T11:07:34.654+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18020765", "id": "18020765", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976#issuecomment-3300118538\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 33s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 14s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 57s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 16s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 32s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |  36m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  73m 12s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 45s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  48m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 25s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 47s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |  37m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  73m 40s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 503m 15s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   2m 21s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 930m 38s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7976 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets xmllint |\r\n   | uname | Linux 946810b75b42 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 78ed6e9e068b8c35d3eb372e09440128bf4fd0d8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/testReport/ |\r\n   | Max. process+thread count | 3137 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T19:43:10.302+0000", "updated": "2025-09-16T19:43:10.302+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18020828", "id": "18020828", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976#issuecomment-3300985791\n\n   > +1. Thanks @slfan1989 .\r\n   > \r\n   > I was going to suggest also banning `org.hamcrest`, but it looks like there is still a tiny amount of hamcrest remaining in YARN. Maybe this is a topic for a different PR.\r\n   > \r\n   > ```\r\n   > > grep -r --include '*.java' 'org.hamcrest' *\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppListControllerTest.java:import static org.hamcrest.MatcherAssert.assertThat;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppListControllerTest.java:import static org.hamcrest.core.Is.is;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppDetailsControllerTest.java:import static org.hamcrest.MatcherAssert.assertThat;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppDetailsControllerTest.java:import static org.hamcrest.core.Is.is;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppStoreControllerTest.java:import static org.hamcrest.MatcherAssert.assertThat;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppStoreControllerTest.java:import static org.hamcrest.core.Is.is;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/util/TestResourceCalculatorProcessTree.java:import static org.hamcrest.MatcherAssert.assertThat;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/util/TestResourceCalculatorProcessTree.java:import static org.hamcrest.core.IsInstanceOf.instanceOf;\r\n   > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/util/TestResourceCalculatorProcessTree.java:import static org.hamcrest.core.IsSame.sameInstance;\r\n   > ```\r\n   \r\n   @cnauroth Thank you for reviewing the code! I\u2019ll submit a separate PR to replace the usage of `org.hamcrest.`.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T02:28:30.566+0000", "updated": "2025-09-17T02:28:30.566+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18021448", "id": "18021448", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976#issuecomment-3312878887\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  11m 55s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  6s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 15s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 14s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 19s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 43s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |  36m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  72m 58s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 45s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  48m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 26s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 16s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |  20m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 22s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 54s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |  37m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  73m  1s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 509m 47s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 26s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 937m 20s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7976 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets xmllint |\r\n   | uname | Linux b7280a78b909 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b0d0b609f7714de5a35a2e356b8eca12903f5d3b |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/testReport/ |\r\n   | Max. process+thread count | 2676 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T16:33:26.654+0000", "updated": "2025-09-19T16:33:26.654+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18022441", "id": "18022441", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976#issuecomment-3328740044\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  54m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m 17s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m  7s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  | 130m 22s |  |  branch has errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 43s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 32s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  39m 36s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 503m 30s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 16s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 778m 24s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7976 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 0b5b9083f652 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c161c9b215d2498c3c9a2d060a0be1701444b768 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/testReport/ |\r\n   | Max. process+thread count | 3135 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T14:14:18.338+0000", "updated": "2025-09-24T14:14:18.338+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18022447", "id": "18022447", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976#issuecomment-3328991107\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 40s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  54m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  9s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 13s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 49s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  | 130m 34s |  |  branch has errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  47m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 24s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 31s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 46s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  39m 49s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 538m 55s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 47s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 815m 59s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.TestRollingUpgrade |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7976 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 8c48d2e66c3e 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c161c9b215d2498c3c9a2d060a0be1701444b768 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/testReport/ |\r\n   | Max. process+thread count | 3137 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T14:44:13.881+0000", "updated": "2025-09-24T14:44:13.881+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18022574", "id": "18022574", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976#issuecomment-3330876058\n\n   This PR enforces import restrictions to prohibit the use of JUnit4. The previously reported shade error has already been resolved in #7995. Given the lengthy compilation time, I will not re-trigger the build for this PR. I will continue to investigate and address the YARN crash issue separately.\r\n   \r\n   @cnauroth Thanks for the review!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T22:12:21.757+0000", "updated": "2025-09-24T22:12:21.757+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628997/comment/18022575", "id": "18022575", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7976:\nURL: https://github.com/apache/hadoop/pull/7976\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T22:13:26.101+0000", "updated": "2025-09-24T22:13:26.101+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-09-24T22:13:59.000+0000", "created": "2025-09-16T03:05:49.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628970", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628970", "key": "HADOOP-19690", "fields": {"summary": "Bump commons-lang3 to 3.18.0 due to CVE-2025-48924", "description": "https://www.cve.org/CVERecord?id=CVE-2025-48924\r\n\r\nWill update commons-text to 1.14.0 which was released with commons-lang3 3.18.0. Due to https://issues.apache.org/jira/browse/HADOOP-19532 - seems best to upgrade them together.  ", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18020434", "id": "18020434", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #7970:\nURL: https://github.com/apache/hadoop/pull/7970\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   CVE-2025-48924\r\n   \r\n   See https://issues.apache.org/jira/browse/HADOOP-19690 for reason to upgrade commons-text too.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T18:01:43.048+0000", "updated": "2025-09-15T18:01:43.048+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18021044", "id": "18021044", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7970:\nURL: https://github.com/apache/hadoop/pull/7970#issuecomment-3305413646\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 19s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  24m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 23s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 20s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  14m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 34s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 58s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  31m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 23s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  22m 56s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 11s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   7m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  6s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  32m  0s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 963m 33s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  4s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1144m 26s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.mapreduce.v2.TestUberAM |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7970 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux e242a07f343d 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 82dae1282632826d8977c56821441f5b32ee1ec8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/testReport/ |\r\n   | Max. process+thread count | 4334 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T04:48:34.065+0000", "updated": "2025-09-18T04:48:34.065+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18021303", "id": "18021303", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7970:\nURL: https://github.com/apache/hadoop/pull/7970\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T00:43:30.894+0000", "updated": "2025-09-19T00:43:30.894+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18021304", "id": "18021304", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7970:\nURL: https://github.com/apache/hadoop/pull/7970#issuecomment-3310116432\n\n   @pjfanning Thanks for the contribution! The unit test errors are unrelated to this PR. Could you please take a look at the branch-3.4? I think this PR should also be backported there.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T00:48:07.373+0000", "updated": "2025-09-19T00:48:07.373+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18021361", "id": "18021361", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #7985:\nURL: https://github.com/apache/hadoop/pull/7985\n\n   * relates to #7970 \r\n   \r\n   * HADOOP-19690. bump commons-lang3 to 3.18.0 due to CVE-2025-48924\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T08:51:01.996+0000", "updated": "2025-09-19T08:51:01.996+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18021396", "id": "18021396", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7985:\nURL: https://github.com/apache/hadoop/pull/7985#issuecomment-3311953658\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   7m 12s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   2m 18s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  22m 13s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |   8m 32s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 43s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  13m 58s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   4m 40s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 52s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  28m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 21s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  20m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 42s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 47s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   7m 47s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   8m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   4m 44s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 54s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  34m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |  25m 52s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  asflicense  |   0m 19s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/artifact/out/results-asflicense.txt) |  The patch generated 296 ASF License warnings.  |\r\n   |  |   | 197m 56s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.metrics2.source.TestJvmMetrics |\r\n   |   | hadoop.ipc.TestCallQueueManager |\r\n   |   | hadoop.fs.shell.TestHdfsTextCommand |\r\n   |   | hadoop.hdfs.util.TestByteArrayManager |\r\n   |   | hadoop.hdfs.web.TestWebHDFSOAuth2 |\r\n   |   | hadoop.hdfs.web.TestWebHdfsContentLength |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7985 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 71fdfc267120 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / fa8656b628557693f6cd66800a5d84bebd80501c |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/testReport/ |\r\n   | Max. process+thread count | 685 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T12:10:13.990+0000", "updated": "2025-09-19T12:10:13.990+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18022039", "id": "18022039", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7985:\nURL: https://github.com/apache/hadoop/pull/7985\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T05:30:03.160+0000", "updated": "2025-09-23T05:30:03.160+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628970/comment/18022040", "id": "18022040", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7985:\nURL: https://github.com/apache/hadoop/pull/7985#issuecomment-3322481127\n\n   @pjfanning Thanks for the contribution! Merged into branch-3.4.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T05:30:25.482+0000", "updated": "2025-09-23T05:30:25.482+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-09-23T05:30:25.000+0000", "created": "2025-09-15T17:53:25.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628968", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628968", "key": "HADOOP-19689", "fields": {"summary": "Bump netty to 4.1.127 due to CVE-2025-58057", "description": "https://www.cve.org/CVERecord?id=CVE-2025-58057\r\n\r\nfixed in 4.1.125 but no harm upgrading to latest", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628968/comment/18020430", "id": "18020430", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #7969:\nURL: https://github.com/apache/hadoop/pull/7969\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Upgrade netty due to CVE-2025-58057\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:50:24.562+0000", "updated": "2025-09-15T17:50:24.562+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628968/comment/18021305", "id": "18021305", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7969:\nURL: https://github.com/apache/hadoop/pull/7969\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T00:52:13.917+0000", "updated": "2025-09-19T00:52:13.917+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628968/comment/18021307", "id": "18021307", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7969:\nURL: https://github.com/apache/hadoop/pull/7969#issuecomment-3310122835\n\n   @pjfanning Thanks for the contribution! Merged into trunk. The branch-3.4 should also be taken into consideration.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T00:53:10.166+0000", "updated": "2025-09-19T00:53:10.166+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628968/comment/18021360", "id": "18021360", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #7984:\nURL: https://github.com/apache/hadoop/pull/7984\n\n   * HADOOP-19689: bump netty to 4.1.127.Final due to CVE-2025-58057\r\n   \r\n   Signed-off-by: Shilun Fan <slfan1989@apache.org>\r\n   \r\n   Update LICENSE-binary\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T08:45:46.127+0000", "updated": "2025-09-19T08:45:46.127+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628968/comment/18021535", "id": "18021535", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7984:\nURL: https://github.com/apache/hadoop/pull/7984#issuecomment-3314414435\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  13m 42s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   2m 19s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  38m  3s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |  19m  9s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  17m 20s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m  6s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   8m 58s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 19s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  54m 54s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 38s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 43s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 20s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  16m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   8m 22s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  51m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 738m 57s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1050m  3s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.mapred.gridmix.TestGridmixSubmission |\r\n   |   | hadoop.mapred.gridmix.TestLoadJob |\r\n   |   | hadoop.yarn.server.timelineservice.security.TestTimelineAuthFilterForV2 |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7984 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux df829c2020d7 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / 80ba81ead32289cc5ee5aceb75950ca4e5a9c50e |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/testReport/ |\r\n   | Max. process+thread count | 3744 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-20T02:17:12.897+0000", "updated": "2025-09-20T02:17:12.897+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628968/comment/18022041", "id": "18022041", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7984:\nURL: https://github.com/apache/hadoop/pull/7984\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T05:30:51.172+0000", "updated": "2025-09-23T05:30:51.172+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628968/comment/18022042", "id": "18022042", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7984:\nURL: https://github.com/apache/hadoop/pull/7984#issuecomment-3322482594\n\n   @pjfanning Thanks for the contribution! Merged into branch-3.4.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T05:31:15.256+0000", "updated": "2025-09-23T05:31:15.256+0000"}], "maxResults": 7, "total": 7, "startAt": 0}, "updated": "2025-09-23T05:31:15.000+0000", "created": "2025-09-15T17:45:00.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628966", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628966", "key": "HADOOP-19688", "fields": {"summary": "S3A: ITestS3ACommitterMRJob failing on Junit5", "description": "NPE in test200 of ITestS3ACommitterMRJob.\r\n\r\nCause is\r\n* test dir setup and propagation calls Path.getRoot().toUri() which returns the /home dir\r\n* somehow the locatedFileStatus of that path being 1 so a codepath in FileInputFormat NPEs.\r\n\r\nFix is in test code, though FileInputFormat has its NPE messages improved to help understand what is going wrong. ", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628966/comment/18020426", "id": "18020426", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #7968:\nURL: https://github.com/apache/hadoop/pull/7968\n\n   \r\n   Adds extra logging as to what is happening, passes in actual test dir set at class level.\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   s3 london\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [X] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:45:04.356+0000", "updated": "2025-09-15T17:45:04.356+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628966/comment/18020427", "id": "18020427", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7968:\nURL: https://github.com/apache/hadoop/pull/7968#issuecomment-3293282933\n\n   ```\r\n   [INFO] Running org.apache.hadoop.fs.s3a.commit.integration.ITestS3ACommitterMRJob\r\n   [INFO] Running org.apache.hadoop.fs.s3a.commit.integration.ITestS3ACommitterMRJob\r\n   [INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.97 s ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:46:02.551+0000", "updated": "2025-09-15T17:46:02.551+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628966/comment/18020428", "id": "18020428", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7968:\nURL: https://github.com/apache/hadoop/pull/7968#issuecomment-3293285487\n\n   fyi @slfan1989 @ahmarsuhail @mukund-thakur\r\n   one of the final nits of junit5 migration\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:46:46.890+0000", "updated": "2025-09-15T17:46:46.890+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628966/comment/18020468", "id": "18020468", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7968:\nURL: https://github.com/apache/hadoop/pull/7968#issuecomment-3294044978\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  11m 17s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  41m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 54s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   3m  2s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 28s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 15s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 37s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   4m 17s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 1 new + 45 unchanged - 1 fixed = 46 total (was 46)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 40s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 38s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   3m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 11s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   9m 58s |  |  hadoop-mapreduce-client-core in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 47s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  8s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 230m 49s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7968 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 0d73de768dd4 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / a86c300286ffb8cd8884923b5d6a0deaf9095d63 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/testReport/ |\r\n   | Max. process+thread count | 1567 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T21:37:08.520+0000", "updated": "2025-09-15T21:37:08.520+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628966/comment/18020496", "id": "18020496", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7968:\nURL: https://github.com/apache/hadoop/pull/7968#issuecomment-3294374360\n\n   LGTM\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T23:59:34.234+0000", "updated": "2025-09-15T23:59:34.234+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628966/comment/18020656", "id": "18020656", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7968:\nURL: https://github.com/apache/hadoop/pull/7968\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T12:04:51.044+0000", "updated": "2025-09-16T12:04:51.044+0000"}], "maxResults": 6, "total": 6, "startAt": 0}, "updated": "2025-09-16T12:05:03.000+0000", "created": "2025-09-15T17:38:39.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628928", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628928", "key": "HADOOP-19687", "fields": {"summary": "Upgrade nimbus-jose-jwt to 10.0.2+ due to CVE-2025-53864", "description": "*CVE-2025-53864:*\r\n\r\nConnect2id Nimbus JOSE + JWT before 10.0.2 allows a remote attacker to cause a denial of service via a deeply nested JSON object supplied in a JWT claim set, because of uncontrolled recursion. NOTE: this is independent of the Gson 2.11.0 issue because the Connect2id product could have checked the JSON object nesting depth, regardless of what limits (if any) were imposed by Gson.\r\n\r\nSeverity: 6.9 (medium)", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628928/comment/18020318", "id": "18020318", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb opened a new pull request, #7965:\nURL: https://github.com/apache/hadoop/pull/7965\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   1. Bumping nimbus-jose-jwt to 10.4 due to CVEs\r\n   2. com.github.stephenc.jcip:jcip-annotations is being shaded and is no more a transitive dependency from nimbus starting from versions 9.38, so we can add it as an explicit dependency.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T11:36:57.169+0000", "updated": "2025-09-15T11:36:57.169+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628928/comment/18020332", "id": "18020332", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=fanningpj", "name": "fanningpj", "key": "fanningpj", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "PJ Fanning", "active": true, "timeZone": "Europe/Madrid"}, "body": "duplicate of HADOOP-19632 for which there are already PRs", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=fanningpj", "name": "fanningpj", "key": "fanningpj", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "PJ Fanning", "active": true, "timeZone": "Europe/Madrid"}, "created": "2025-09-15T12:11:10.556+0000", "updated": "2025-09-15T12:11:10.556+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628928/comment/18020886", "id": "18020886", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3302275652\n\n   Hi @pjfanning, can we use this patch instead of the original one as I don't see any progress on that? We need this upgrade in the downstream soon. \r\n   \r\n   Also, it seems like the original patch hasn't handled the shading of com.github.stephenc.jcip:jcip-annotations in later nimbus versions. Thanks\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T10:08:17.170+0000", "updated": "2025-09-17T10:08:17.170+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628928/comment/18020888", "id": "18020888", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3302315128\n\n   Could you rebase this to force a new CI run? The tests crashed in the last run.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T10:17:25.975+0000", "updated": "2025-09-17T10:17:25.975+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628928/comment/18020889", "id": "18020889", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3302343034\n\n   Could you change the name of the PR and the git commit to use [HADOOP-19632](https://issues.apache.org/jira/browse/HADOOP-19632)?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T10:25:27.971+0000", "updated": "2025-09-17T10:25:27.971+0000"}], "maxResults": 5, "total": 5, "startAt": 0}, "updated": "2025-09-17T10:25:28.000+0000", "created": "2025-09-15T11:29:00.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628797", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628797", "key": "HADOOP-19685", "fields": {"summary": "Clover breaks on double semicolon", "description": "Building with {{-Pclover}} fails with\r\n{code}\r\n[INFO] Instrumentation error\r\ncom.atlassian.clover.api.CloverException: /home/jenkins/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/ITestS3APutIfMatchAndIfNoneMatch.java:43:43:unexpected token: ;\r\n...\r\nFailed to execute goal org.openclover:clover-maven-plugin:4.4.1:setup (clover-setup) on project hadoop-aws: Clover has failed to instrument the source files in the [/home/jenkins/hadoop/hadoop-tools/hadoop-aws/target/clover/src-test-instrumented] directory -> [Help 1]\r\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.openclover:clover-maven-plugin:4.4.1:setup (clover-setup) on project hadoop-aws: Clover has failed to instrument the source files in the [/home/jenkins/hadoop/hadoop-tools/hadoop-aws/target/clover/src-test-instrumented] directory\r\n{code}\r\n\r\nIt doesn't seem to like a double semicolon in ITestS3APutIfMatchAndIfNoneMatch.java that was added in HADOOP-19256.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628797/comment/18019941", "id": "18019941", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "MikaelSmith opened a new pull request, #7956:\nURL: https://github.com/apache/hadoop/pull/7956\n\n   ### Description of PR\r\n   \r\n   Removes the extra semicolon after an import that causes `-Pclover` to fail with\r\n   \r\n       com.atlassian.clover.api.CloverException: hadoop/hadoop-tools/\r\n       hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/\r\n       ITestS3APutIfMatchAndIfNoneMatch.java:43:43:unexpected token: ;`\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   ```\r\n   mvn -e -Pclover install -DskipTests -DskipShade --projects 'hadoop-tools/hadoop-aws'\r\n   ```\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T20:49:51.569+0000", "updated": "2025-09-12T20:49:51.569+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628797/comment/18019954", "id": "18019954", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7956:\nURL: https://github.com/apache/hadoop/pull/7956#issuecomment-3287077606\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  15m 13s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 27s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 38s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 21s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 140m  9s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7956/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7956 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d1403c764b02 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 9fc528eeb6112dd9b3209b648fb33da720214dff |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7956/1/testReport/ |\r\n   | Max. process+thread count | 709 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7956/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T23:11:11.091+0000", "updated": "2025-09-12T23:11:11.091+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628797/comment/18019959", "id": "18019959", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth closed pull request #7956: HADOOP-19685. Fix double semicolon breaking clover\nURL: https://github.com/apache/hadoop/pull/7956\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T23:47:23.404+0000", "updated": "2025-09-12T23:47:23.404+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628797/comment/18019960", "id": "18019960", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on PR #7956:\nURL: https://github.com/apache/hadoop/pull/7956#issuecomment-3287154332\n\n   I committed this to trunk and branch-3.4. Thank you for the patch @MikaelSmith !\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T23:48:09.653+0000", "updated": "2025-09-12T23:48:09.653+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "updated": "2025-09-12T23:48:23.000+0000", "created": "2025-09-12T20:38:19.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628581", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628581", "key": "HADOOP-19684", "fields": {"summary": "Add JDK 21 to Ubuntu 20.04 docker development images", "description": "We want to support JDK21, we better have it available in the development image for testing.\r\n", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019363", "id": "18019363", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty opened a new pull request, #7947:\nURL: https://github.com/apache/hadoop/pull/7947\n\n   ### Description of PR\r\n   \r\n   Add JDK 21 to Ubuntu 20.04 and 24.04  docker development images\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Built the default image locally and started JDK21.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-10T14:19:26.843+0000", "updated": "2025-09-10T14:19:26.843+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019366", "id": "18019366", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3275227945\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   1m 32s |  |  Docker failed to build run-specific yetus/hadoop:tp-5188}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7947 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/1/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-10T14:25:20.405+0000", "updated": "2025-09-10T14:25:20.405+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019587", "id": "18019587", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#discussion_r2340621524\n\n\n##########\ndev-support/docker/pkg-resolver/packages.json:\n##########\n@@ -268,17 +268,20 @@\n     ],\n     \"ubuntu:focal\": [\n       \"temurin-24-jdk\",\n+      \"temurin-21-jdk\",\n\nReview Comment:\n   the ubuntu official apt repo provides `openjdk-21-jdk`, it's unnecessary to install from 3rd party. let's use the official one and put it at the end of the list.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T12:33:39.929+0000", "updated": "2025-09-11T12:33:39.929+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019588", "id": "18019588", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3280408907\n\n   The Jenkins failure should be fixed by https://github.com/apache/hadoop/pull/7938, @slfan1989 can you help merging that to unblock this patch?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T12:34:17.562+0000", "updated": "2025-09-11T12:34:17.562+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019610", "id": "18019610", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#discussion_r2340811930\n\n\n##########\ndev-support/docker/pkg-resolver/packages.json:\n##########\n@@ -268,17 +268,20 @@\n     ],\n     \"ubuntu:focal\": [\n       \"temurin-24-jdk\",\n+      \"temurin-21-jdk\",\n\nReview Comment:\n   Thanks. Done @pan3793 .\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T13:16:38.729+0000", "updated": "2025-09-11T13:16:38.729+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019611", "id": "18019611", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3280638248\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   1m 21s |  |  Docker failed to build run-specific yetus/hadoop:tp-1035}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7947 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T13:20:02.259+0000", "updated": "2025-09-11T13:20:02.259+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019707", "id": "18019707", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3282893605\n\n   > The Jenkins failure should be fixed by #7938, @slfan1989 can you help merge that to unblock this patch?\r\n   \r\n   @stoty I\u2019ve already merged #7938 into the trunk branch, so we can move forward with this PR.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T22:59:32.390+0000", "updated": "2025-09-11T22:59:32.390+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019758", "id": "18019758", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3283557198\n\n   restarted CI\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T03:53:55.775+0000", "updated": "2025-09-12T03:53:55.775+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019768", "id": "18019768", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3283756503\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  25m 28s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 48s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  46m 30s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 45s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  36m  2s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 56s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 111m 23s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7947 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 68e70612efec 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4ed7fc2da756cc4332d3f9ecc8cce291d094b50d |\r\n   | Max. process+thread count | 708 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/console |\r\n   | versions | git=2.43.7 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T05:41:42.071+0000", "updated": "2025-09-12T05:41:42.071+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019773", "id": "18019773", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3283820061\n\n   The CI results meet expectations. I will proceed with merging the change shortly.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T05:57:53.642+0000", "updated": "2025-09-12T05:57:53.642+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019778", "id": "18019778", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3284002090\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 27s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  26m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 30s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  25m 38s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  74m 57s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7947 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 26f820c8794f 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4ed7fc2da756cc4332d3f9ecc8cce291d094b50d |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/console |\r\n   | versions | git=2.30.2 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T06:56:49.782+0000", "updated": "2025-09-12T06:56:49.782+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18019790", "id": "18019790", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3284223003\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 46s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  33m 55s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  71m 51s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7947 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux cedf7863bb64 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4ed7fc2da756cc4332d3f9ecc8cce291d094b50d |\r\n   | Max. process+thread count | 567 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T08:08:47.595+0000", "updated": "2025-09-12T08:08:47.595+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18020127", "id": "18020127", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T07:11:03.021+0000", "updated": "2025-09-14T07:11:03.021+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628581/comment/18020128", "id": "18020128", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7947:\nURL: https://github.com/apache/hadoop/pull/7947#issuecomment-3289299477\n\n   @stoty Thanks for the contribution! @pan3793 Thanks for the review!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T07:11:29.823+0000", "updated": "2025-09-14T07:11:29.823+0000"}], "maxResults": 14, "total": 14, "startAt": 0}, "updated": "2025-09-14T07:14:28.000+0000", "created": "2025-09-10T14:00:14.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628430", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628430", "key": "HADOOP-19682", "fields": {"summary": "Fix incorrect link from current3 of hadoop-site", "description": "Fix hadoop site incorrect link which reported by https://lists.apache.org/thread/ozvkh0x7qdr8d3vr0tbm5g7jx1jprbct.", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-09T03:57:52.000+0000", "created": "2025-09-09T03:15:33.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628348", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628348", "key": "HADOOP-19681", "fields": {"summary": "Fix S3A failing to initialize S3 buckets having namespace with dot followed by number", "description": "S3A fails to initialize when S3 bucket namespace is having dot followed by a number.\u00a0\r\n\r\n{*}Specific Problem{*}: URI parsing fails when S3 bucket names contain a dot followed by a number (like {{{}bucket-v1.1-us-east-1{}}}). Java's\r\nURI.getHost() method incorrectly interprets the dot-number pattern as a port specification, causing it to return null.\r\n\r\n\u00a0\r\n\r\n{{}}\r\n{code:java}\r\nhadoop dfs -ls s3a://bucket-v1.1-us-east-1/\r\n\r\nWARNING: Use of this script to execute dfs is deprecated.\r\nWARNING: Attempting to execute replacement \"hdfs dfs\" instead.\r\n\r\n2025-09-08 06:13:06,670 WARN fs.FileSystem: Failed to initialize filesystem s3://bucket-v1.1-us-east-1/: java.lang.IllegalArgumentException: bucket is null/empty\r\n-ls: bucket is null/empty{code}\r\n\u00a0\r\n\r\n{*}Please Note{*}: Although there has been discussion on not allowing S3 buckets with such a namespace ([https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/]) , Amazon S3 still allows you to create a bucket with such a namespace.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18018863", "id": "18018863", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "shameersss1 opened a new pull request, #7942:\nURL: https://github.com/apache/hadoop/pull/7942\n\n   ### Description of PR\r\n   \r\n   S3A fails to initialize when S3 bucket namespace is having dot followed by a number. \r\n   \r\n   Specific Problem: URI parsing fails when S3 bucket names contain a dot followed by a number (like bucket-v1.1-us-east-1). Java's\r\n   URI.getHost() method incorrectly interprets the dot-number pattern as a port specification, causing it to return null.\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Tested in us-east-1 with bucket having namespace with dot followed by a number.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [x] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T16:23:38.400+0000", "updated": "2025-09-08T16:23:38.400+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18018864", "id": "18018864", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "shameersss1 commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3267057573\n\n   Test `ITestBucketTool,ITestS3ACommitterMRJob` are failing even without the change.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T16:24:17.463+0000", "updated": "2025-09-08T16:24:17.463+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18018868", "id": "18018868", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "shameersss1 commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3267074576\n\n   @steveloughran  : Could you please review the changes.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T16:28:36.375+0000", "updated": "2025-09-08T16:28:36.375+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18018897", "id": "18018897", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3267937541\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  15m  0s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 25s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 48s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 57s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 38s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 10s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 41s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   3m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 15s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   1m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m  6s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 48s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 10s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 46s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   4m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 59s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |  22m 55s | [/patch-unit-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/1/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 41s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  9s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 253m 43s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7942 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 3434362c830f 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 82914829acf34ecd0b05c57af673c1e4095acb30 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/1/testReport/ |\r\n   | Max. process+thread count | 3056 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T20:38:37.596+0000", "updated": "2025-09-08T20:38:37.596+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18019032", "id": "18019032", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3269845775\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 40s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 52s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 48s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 14s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 50s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   3m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m  5s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   1m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 48s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m  8s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 47s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   4m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 26s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 53s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 49s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  9s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 237m 39s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7942 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux b5e9b0d84482 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ea1308a4c1fdf443562e752e09d43ae0a7f5cd8b |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/2/testReport/ |\r\n   | Max. process+thread count | 1271 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T09:48:21.928+0000", "updated": "2025-09-09T09:48:21.928+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18020317", "id": "18020317", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#discussion_r2348701684\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AConfiguration.java:\n##########\n@@ -594,13 +595,28 @@ private static <T> T getField(Object target, Class<T> fieldType,\n   public void testConfOptionPropagationToFS() throws Exception {\n     Configuration config = new Configuration();\n     String testFSName = config.getTrimmed(TEST_FS_S3A_NAME, \"\");\n-    String bucket = new URI(testFSName).getHost();\n+    URI uri = new URI(testFSName);\n+    String bucket = uri.getHost();\n+    if (bucket == null) {\n+      bucket = uri.getAuthority();\n+    }\n     setBucketOption(config, bucket, \"propagation\", \"propagated\");\n     fs = S3ATestUtils.createTestFileSystem(config);\n     Configuration updated = fs.getConf();\n     assertOptionEquals(updated, \"fs.s3a.propagation\", \"propagated\");\n   }\n \n+  @Test\n+  public void testBucketNameWithDotAndNumber() throws Exception {\n+    Configuration config = new Configuration();\n+    Path path = new Path(\"s3a://test-bucket-v1.1\");\n+    try (FileSystem fs = path.getFileSystem(config)) {\n+      assertThat(fs instanceof S3AFileSystem)\n\nReview Comment:\n   use whatever assertj assertion is about instanceof, so you get a better error.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T11:36:39.215+0000", "updated": "2025-09-15T11:36:39.215+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18020431", "id": "18020431", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "raphaelazzolini commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3293303278\n\n   > Oh, this complicates things. I've been happily treating all issues related to buckets with . in them as WONTFIX. Storediag tells people off too.\r\n   \r\n   @steveloughran, in HADOOP-17241, you referenced this announcement as one of the reasons to not support this buckets with dot in the name: https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/\r\n   \r\n   However, AWS have since revised their stance. AWS has confirmed they will continue supporting buckets with dots in their names through virtual hosted-style URLs due to customer feedback and compatibility requirements.\r\n   \r\n   > We have also heard feedback from customers that virtual hosted-style URLs should support buckets that have dots in their names for compatibility reasons, so we\u2019re working on developing that support.\r\n   \r\n   So I guess it makes sense to add support for it in S3A.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:52:37.128+0000", "updated": "2025-09-15T17:52:37.128+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18020648", "id": "18020648", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3298148674\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 59s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m  1s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 53s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 15s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 47s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   4m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   1m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 39s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 49s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  14m 49s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/3/artifact/out/blanks-eol.txt) |  The patch has 3 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   4m 12s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/3/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 1 new + 63 unchanged - 0 fixed = 64 total (was 63)  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 46s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   4m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 35s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 39s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 44s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  8s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 261m 30s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7942 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets markdownlint |\r\n   | uname | Linux 8e602b48d6d4 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5014c326331ebcc9e8cb30cf2632774733c6ce56 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/3/testReport/ |\r\n   | Max. process+thread count | 1302 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T11:47:15.601+0000", "updated": "2025-09-16T11:47:15.601+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18020717", "id": "18020717", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3299506183\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  11m  7s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  42m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m  8s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 59s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m 13s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 48s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   4m  3s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   1m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m  6s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 49s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 49s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/4/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   2m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   2m  8s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 47s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   4m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 33s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m  4s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 45s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  9s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 251m 11s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7942 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets markdownlint |\r\n   | uname | Linux 2d2f97096065 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f86ae95b09e52b9c71c1d9d937b060aa9409c096 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/4/testReport/ |\r\n   | Max. process+thread count | 1270 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7942/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T16:26:06.769+0000", "updated": "2025-09-16T16:26:06.769+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18020930", "id": "18020930", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "shameersss1 commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3303302768\n\n   Thanks @steveloughran  for the review. I have addressed your comments.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T14:33:13.755+0000", "updated": "2025-09-17T14:33:13.755+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18022465", "id": "18022465", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#issuecomment-3329432114\n\n   @raphaelazzolini \r\n   > AWS has confirmed they will continue supporting buckets with dots in their names through virtual hosted-style URLs due to customer feedback and compatibility requirements.\r\n   \r\n   OK. main issue is that there may be existing code which cares about hostname and may not look at FQDN for differencing names. I can't think of any right now -bucket names which don't map to valid hostnames are more a pain point\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T15:29:46.701+0000", "updated": "2025-09-24T15:29:46.701+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628348/comment/18022471", "id": "18022471", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7942:\nURL: https://github.com/apache/hadoop/pull/7942#discussion_r2376222445\n\n\n##########\nhadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java:\n##########\n@@ -573,8 +573,11 @@ private static void addDeprecatedKeys() {\n    */\n   public void initialize(URI name, Configuration originalConf)\n       throws IOException {\n-    // get the host; this is guaranteed to be non-null, non-empty\n+    // get the host; fallback to authority if getHost() returns null\n     bucket = name.getHost();\n+    if (bucket == null) {\n\nReview Comment:\n   pull this out, stick it in `S3AUtils`, add unit tests that now try to break things. Use everywhere\n\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java:\n##########\n@@ -335,7 +335,7 @@ private URI getUri(URI uri, String supportedScheme,\n     int port = uri.getPort();\n     port = (port == -1 ? defaultPort : port);\n     if (port == -1) { // no port supplied and default port is not specified\n-      return new URI(supportedScheme, authority, \"/\", null);\n+      return URI.create(supportedScheme + \"://\" + authority + \"/\");\n\nReview Comment:\n   why this change?\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md:\n##########\n@@ -31,6 +31,12 @@ before 2021.\n Consult [S3A and Directory Markers](directory_markers.html) for\n full details.\n \n+### <a name=\"bucket-name-compatibility\"></a> S3 Bucket Name Compatibility\n+\n+This release adds support for S3 bucket names containing dots followed by numbers\n+(e.g., `my-bucket-v1.1`, `data-store.v2.3`). Previous versions of the Hadoop S3A\n+client failed to initialize such buckets due to URI parsing limitations.\n+\n\nReview Comment:\n   * highlight that per-bucket settings do not work for dotted buckets (they don't, do they?), so the ability to use them is still very much downgraded.\r\n   * Explain that AWS do not recommend dotted buckets for anything other than web site serving\r\n   * highlight that path style access is needed to access (correct? never tried)\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T15:46:51.115+0000", "updated": "2025-09-24T15:46:51.115+0000"}], "maxResults": 12, "total": 12, "startAt": 0}, "updated": "2025-09-24T15:46:51.000+0000", "created": "2025-09-08T08:51:08.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628326", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628326", "key": "HADOOP-19680", "fields": {"summary": "Update non-thirdparty Guava version to 32.0.1", "description": "Guava has been already updated to 32.0.1 in hadoop-thirdparty.\r\nHowever, Hadoop also dependency manages the non-thirdparty guava version (coming from dependencies), which is still at 27.0-jre , showing up on static scanners.\r\n\r\nSync the non-thirdparty Guava version to the thirdparty one.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18018725", "id": "18018725", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty opened a new pull request, #7940:\nURL: https://github.com/apache/hadoop/pull/7940\n\n   same as the current thirdparty Guava version\r\n   \r\n   ### Description of PR\r\n   \r\n   Guava has been already updated to 32.0.1 in hadoop-thirdparty.\r\n   However, Hadoop also dependency manages the non-thirdparty guava version (coming from dependencies), which is still at 27.0-jre , showing up on static scanners.\r\n   \r\n   Sync the non-thirdparty Guava version to the thirdparty one.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Test suite in CI (on this PR)\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T05:01:01.846+0000", "updated": "2025-09-08T05:01:01.846+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18018749", "id": "18018749", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940#issuecomment-3264930118\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 57s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  87m 32s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 17s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 134m  9s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7940/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7940 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux fe8aa1f6455e 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 8794a7e5b6cf955551d93f3a15effbd83d5174b7 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7940/1/testReport/ |\r\n   | Max. process+thread count | 527 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project U: hadoop-project |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7940/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T07:16:25.395+0000", "updated": "2025-09-08T07:16:25.395+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18019596", "id": "18019596", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940#issuecomment-3280459780\n\n   cc @cnauroth \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T12:44:57.956+0000", "updated": "2025-09-11T12:44:57.956+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18020133", "id": "18020133", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940#issuecomment-3289303390\n\n   > +1 Thank you @stoty . I'm good with this change. Ideally, I would like to see at least one more committer +1, just in case there are some downstream impacts I haven't thought of.\r\n   > \r\n   > CC: @steveloughran , @ayushtkn , @mukund-thakur\r\n   \r\n   @cnauroth Thanks for the review! I think we still need to carefully consider this change and should wait for Steve's confirmation before making a decision. \r\n   \r\n   cc: @steveloughran \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T07:19:44.329+0000", "updated": "2025-09-14T07:19:44.329+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18020137", "id": "18020137", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940#issuecomment-3289335562\n\n   For what it's worth:\r\n   \r\n   I've fought a LOT with guava versions in the last six years, but I haven't seen any issue (apart from Google adding new annotation libraries which throw off some shading tests)  when upgrading from 27 to a newer version.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T08:17:18.920+0000", "updated": "2025-09-14T08:17:18.920+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18020320", "id": "18020320", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940#issuecomment-3291722519\n\n   I've been away. let's do it an update in release notes that  you can change the version without breaking any hadoop code.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T11:37:48.289+0000", "updated": "2025-09-15T11:37:48.289+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18020342", "id": "18020342", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940#issuecomment-3291915610\n\n   > I've been away. let's do it an update in release notes that you can change the version without breaking any hadoop code.\r\n   \r\n   Thanks @steveloughran .\r\n   I'm not sure I understand your comment. I have added a release note that explains the change to the JIRA.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T12:26:10.130+0000", "updated": "2025-09-15T12:26:10.130+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18020432", "id": "18020432", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:56:41.551+0000", "updated": "2025-09-15T17:56:41.551+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18020433", "id": "18020433", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7940:\nURL: https://github.com/apache/hadoop/pull/7940#issuecomment-3293320945\n\n   thanks...your release note is good, added something in the commit too.\r\n   \r\n   can you do a backport PR to branch-3.4; I think we should be looking at a \"dependency update\" release there with minimal actual code changes\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:58:12.394+0000", "updated": "2025-09-15T17:58:12.394+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18021301", "id": "18021301", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7977:\nURL: https://github.com/apache/hadoop/pull/7977\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T00:40:22.813+0000", "updated": "2025-09-19T00:40:22.813+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628326/comment/18021302", "id": "18021302", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7977:\nURL: https://github.com/apache/hadoop/pull/7977#issuecomment-3310107461\n\n   @stoty Sorry for the late reply, thanks for the contribution!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T00:41:04.708+0000", "updated": "2025-09-19T00:41:04.708+0000"}], "maxResults": 11, "total": 11, "startAt": 0}, "updated": "2025-09-23T17:30:25.000+0000", "created": "2025-09-08T04:59:06.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628261", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628261", "key": "HADOOP-19679", "fields": {"summary": "Maven site task fails with Java 17", "description": "If I try to build site with Java 17, I get an IllegalArgumentException from analyze-report\r\n{code}\r\n$ mvn -e -Dmaven.javadoc.skip=true -Dhbase.profile=2.0 -DskipTests -DskipITs clean install site:site\r\n...\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.9.1:site (default-cli) on project hadoop-annotations: Error generating maven-dependency-plugin:3.0.2:analyze-report report: IllegalArgumentException -> [Help 1]\r\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.9.1:site (default-cli) on project hadoop-annotations: Error generating maven-dependency-plugin:3.0.2:analyze-report report\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:347)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\r\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\r\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\r\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\r\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\r\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:910)\r\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:283)\r\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:206)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\r\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke (Method.java:569)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:283)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:226)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:407)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:348)\r\nCaused by: org.apache.maven.plugin.MojoExecutionException: Error generating maven-dependency-plugin:3.0.2:analyze-report report\r\n    at org.apache.maven.plugins.site.render.SiteMojo.execute (SiteMojo.java:153)\r\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:126)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:342)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\r\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\r\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\r\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\r\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\r\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:910)\r\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:283)\r\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:206)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\r\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke (Method.java:569)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:283)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:226)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:407)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:348)\r\nCaused by: org.apache.maven.doxia.siterenderer.RendererException: Error generating maven-dependency-plugin:3.0.2:analyze-report report\r\n    at org.apache.maven.plugins.site.render.ReportDocumentRenderer.renderDocument (ReportDocumentRenderer.java:247)\r\n    at org.apache.maven.doxia.siterenderer.DefaultSiteRenderer.render (DefaultSiteRenderer.java:349)\r\n    at org.apache.maven.plugins.site.render.SiteMojo.renderLocale (SiteMojo.java:194)\r\n    at org.apache.maven.plugins.site.render.SiteMojo.execute (SiteMojo.java:143)\r\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:126)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:342)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\r\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\r\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\r\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\r\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\r\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:910)\r\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:283)\r\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:206)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\r\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke (Method.java:569)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:283)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:226)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:407)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:348)\r\nCaused by: java.lang.IllegalArgumentException\r\n    at org.objectweb.asm.ClassReader.<init> (Unknown Source)\r\n    at org.objectweb.asm.ClassReader.<init> (Unknown Source)\r\n    at org.objectweb.asm.ClassReader.<init> (Unknown Source)\r\n    at org.apache.maven.shared.dependency.analyzer.asm.DependencyClassFileVisitor.visitClass (DependencyClassFileVisitor.java:65)\r\n    at org.apache.maven.shared.dependency.analyzer.ClassFileVisitorUtils.visitClass (ClassFileVisitorUtils.java:163)\r\n    at org.apache.maven.shared.dependency.analyzer.ClassFileVisitorUtils.acceptDirectory (ClassFileVisitorUtils.java:143)\r\n    at org.apache.maven.shared.dependency.analyzer.ClassFileVisitorUtils.accept (ClassFileVisitorUtils.java:71)\r\n    at org.apache.maven.shared.dependency.analyzer.asm.ASMDependencyAnalyzer.analyze (ASMDependencyAnalyzer.java:50)\r\n    at org.apache.maven.shared.dependency.analyzer.DefaultProjectDependencyAnalyzer.buildDependencyClasses (DefaultProjectDependencyAnalyzer.java:211)\r\n    at org.apache.maven.shared.dependency.analyzer.DefaultProjectDependencyAnalyzer.buildDependencyClasses (DefaultProjectDependencyAnalyzer.java:198)\r\n    at org.apache.maven.shared.dependency.analyzer.DefaultProjectDependencyAnalyzer.analyze (DefaultProjectDependencyAnalyzer.java:74)\r\n    at org.apache.maven.plugins.dependency.analyze.AnalyzeReportMojo.executeReport (AnalyzeReportMojo.java:138)\r\n    at org.apache.maven.reporting.AbstractMavenReport.generate (AbstractMavenReport.java:255)\r\n    at org.apache.maven.plugins.site.render.ReportDocumentRenderer.renderDocument (ReportDocumentRenderer.java:226)\r\n    at org.apache.maven.doxia.siterenderer.DefaultSiteRenderer.render (DefaultSiteRenderer.java:349)\r\n    at org.apache.maven.plugins.site.render.SiteMojo.renderLocale (SiteMojo.java:194)\r\n    at org.apache.maven.plugins.site.render.SiteMojo.execute (SiteMojo.java:143)\r\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:126)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:342)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\r\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\r\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\r\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\r\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\r\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:910)\r\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:283)\r\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:206)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\r\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke (Method.java:569)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:283)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:226)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:407)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:348)\r\n[ERROR] \r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR] \r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n[ERROR] \r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n[ERROR]   mvn <args> -rf :hadoop-annotations\r\n{code}\r\n\r\nUpdating to the latest maven-dependency-plugin version (3.8.1) fixes it for me.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628261/comment/18018512", "id": "18018512", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "MikaelSmith opened a new pull request, #7936:\nURL: https://github.com/apache/hadoop/pull/7936\n\n   ### Description of PR\r\n   Updates maven-dependency-plugin to 3.8.1 to fix an IllegalArgumentException when running the `site:site` Maven task with Java 17.\r\n   \r\n   ### How was this patch tested?\r\n   Ran `mvn -e -Dmaven.javadoc.skip=true -Dhbase.profile=2.0 -DskipTests -DskipITs clean install site:site` locally with openjdk-17 and it succeeded.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T23:01:01.035+0000", "updated": "2025-09-05T23:01:01.035+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628261/comment/18018570", "id": "18018570", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7936:\nURL: https://github.com/apache/hadoop/pull/7936#issuecomment-3262110832\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   9m 34s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 19s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  15m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   6m  7s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m 24s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  94m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  19m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   9m  3s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   9m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 20s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   8m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   9m 59s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m  5s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m 21s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 54s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 663m 19s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7936/1/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  6s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 840m 24s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.mapreduce.v2.TestUberAM |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.yarn.server.router.subcluster.capacity.TestYarnFederationWithCapacityScheduler |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7936/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7936 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 33f1385abb00 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e89a211da8c19aed6f68dbd9ea4418f6e657d615 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7936/1/testReport/ |\r\n   | Max. process+thread count | 3913 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7936/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T13:02:22.638+0000", "updated": "2025-09-06T13:02:22.638+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628261/comment/18018672", "id": "18018672", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo merged PR #7936:\nURL: https://github.com/apache/hadoop/pull/7936\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T16:55:03.597+0000", "updated": "2025-09-07T16:55:03.597+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628261/comment/18018674", "id": "18018674", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "The pull request is now merged.  Thanks, [~MikaelSmith]!", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-07T16:58:12.059+0000", "updated": "2025-09-07T16:58:12.059+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628261/comment/18018850", "id": "18018850", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=MikaelSmith", "name": "MikaelSmith", "key": "JIRAUSER288956", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"}, "displayName": "Michael Smith", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Thanks! PR was merged against trunk, so I think current Fix Version would be 3.5.0.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=MikaelSmith", "name": "MikaelSmith", "key": "JIRAUSER288956", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"}, "displayName": "Michael Smith", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-08T15:09:45.585+0000", "updated": "2025-09-08T15:09:45.585+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628261/comment/18018866", "id": "18018866", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "You are right -- updated it to 3.5.0.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-08T16:27:15.108+0000", "updated": "2025-09-08T16:27:15.108+0000"}], "maxResults": 6, "total": 6, "startAt": 0}, "updated": "2025-09-08T16:27:15.000+0000", "created": "2025-09-05T22:47:46.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628243", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628243", "key": "HADOOP-19678", "fields": {"summary": "[JDK17] Remove powermock dependency", "description": "The powermock dependency is specified in\r\n- hadoop-cloud-storage-project/hadoop-huaweicloud/pom.xml\r\n- hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-documentstore/pom.xml\r\n\r\nbut not used anywhere.  We should remove it.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628243/comment/18018462", "id": "18018462", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Will include this in HADOOP-19677.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-05T18:33:04.454+0000", "updated": "2025-09-05T18:33:04.454+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628243/comment/18018669", "id": "18018669", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Reopen for removing unused powermock dependencies.\r\n\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-07T16:44:39.993+0000", "updated": "2025-09-07T16:44:39.993+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628243/comment/18018670", "id": "18018670", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo opened a new pull request, #7939:\nURL: https://github.com/apache/hadoop/pull/7939\n\n   ### Description of PR\r\n   \r\n   HADOOP-19678\r\n   \r\n   The powermock dependency is specified in\r\n   \r\n   - hadoop-cloud-storage-project/hadoop-huaweicloud/pom.xml\r\n   - hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-documentstore/pom.xml\r\n   \r\n   but not used anywhere. We should remove it.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   By existing tests.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [NA] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [NA ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [NA ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T16:47:27.607+0000", "updated": "2025-09-07T16:47:27.607+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628243/comment/18018684", "id": "18018684", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7939:\nURL: https://github.com/apache/hadoop/pull/7939#issuecomment-3264013057\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m  3s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 24s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 39s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 43s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 33s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  | 111m  0s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m  3s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 40s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 28s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   1m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 41s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   1m  4s |  |  hadoop-yarn-server-timelineservice-documentstore in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 44s |  |  hadoop-huaweicloud in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  6s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 201m 38s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7939/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7939 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 9f779bd63474 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / dd72444841a0ec35affd2cf1e058030ef5fe99d2 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7939/1/testReport/ |\r\n   | Max. process+thread count | 708 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-documentstore hadoop-cloud-storage-project/hadoop-huaweicloud U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7939/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T20:10:21.651+0000", "updated": "2025-09-07T20:10:21.651+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628243/comment/18018732", "id": "18018732", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7939:\nURL: https://github.com/apache/hadoop/pull/7939\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T05:55:50.611+0000", "updated": "2025-09-08T05:55:50.611+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628243/comment/18018867", "id": "18018867", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7939:\nURL: https://github.com/apache/hadoop/pull/7939#issuecomment-3267073155\n\n   @slfan1989 , @pan3793 , thanks a lot for reviewing this!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T16:28:18.488+0000", "updated": "2025-09-08T16:28:18.488+0000"}], "maxResults": 6, "total": 6, "startAt": 0}, "updated": "2025-09-08T16:28:18.000+0000", "created": "2025-09-05T18:22:53.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628240", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628240", "key": "HADOOP-19677", "fields": {"summary": "[JDK17] Remove mockito-all 1.10.19 and powermock", "description": "- The mockito-all 1.10.19 dependency should be replaced by mockito-core 4.11.\r\n\r\n - The powermock dependency is specified in the pom below. We should replace it with mockito since it is known to be incompatible with JDK17.\r\n -* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/pom.xml\r\n\r\n\u00a0", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018457", "id": "18018457", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo opened a new pull request, #7935:\nURL: https://github.com/apache/hadoop/pull/7935\n\n   ### Description of PR\r\n   \r\n   The mockito-all 1.10.19 dependency should be replaced by mockito-core 4.11.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   By updating existing tests\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [NA] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [NA] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [NA] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T18:00:30.449+0000", "updated": "2025-09-05T18:00:30.449+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018525", "id": "18018525", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935#issuecomment-3260267569\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  23m 29s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 33s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  41m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  19m 26s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  17m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   7m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 46s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 56s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 28s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +0 :ok: |  spotbugs  |   0m 24s |  |  branch/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 10s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   4m 40s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |   0m 15s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 15s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 14s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 14s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   5m  5s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   4m 41s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   3m 59s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 17s |  |  hadoop-project has no data from spotbugs  |\r\n   | +0 :ok: |  spotbugs  |   0m 18s |  |  hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 25s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 18s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 33s |  |  hadoop-auth in the patch passed.  |\r\n   | -1 :x: |  unit  | 118m 19s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt) |  hadoop-yarn-server-resourcemanager in the patch failed.  |\r\n   | -1 :x: |  unit  | 141m 25s | [/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt) |  hadoop-mapreduce-client in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 50s |  |  hadoop-yarn-server-timelineservice-documentstore in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m 23s |  |  hadoop-yarn-server-globalpolicygenerator in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m  5s |  |  hadoop-yarn-applications-catalog-webapp in the patch passed.  |\r\n   | -1 :x: |  unit  |   0m 20s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-ui.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-ui.txt) |  hadoop-yarn-ui in the patch failed.  |\r\n   | +1 :green_heart: |  unit  |   3m 12s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 47s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 541m 38s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.resourcemanager.reservation.TestCapacityOverTimePolicy |\r\n   |   | hadoop.mapreduce.v2.TestUberAM |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7935 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 21c4e19a37e1 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7dadba11fdeaf702d291642f8b2d59c197ec9ecb |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/testReport/ |\r\n   | Max. process+thread count | 1139 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-auth hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-documentstore hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui hadoop-tools/hadoop-azure U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T03:05:00.617+0000", "updated": "2025-09-06T03:05:00.617+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018526", "id": "18018526", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935#issuecomment-3260284208\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  0s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  4s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  46m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  20m  8s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 16s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   7m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 46s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  9s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 28s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +0 :ok: |  spotbugs  |   0m 24s |  |  branch/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 19s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 31s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |   0m 38s | [/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 16s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 16s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 15s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 15s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 46s |  |  the patch passed  |\r\n   | -1 :x: |  mvnsite  |   0m 39s | [/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | +1 :green_heart: |  javadoc  |   4m 50s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 11s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  hadoop-project has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   0m 34s | [/patch-spotbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-spotbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | +0 :ok: |  spotbugs  |   0m 17s |  |  hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 20s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 29s |  |  hadoop-auth in the patch passed.  |\r\n   | -1 :x: |  unit  | 118m 15s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt) |  hadoop-yarn-server-resourcemanager in the patch failed.  |\r\n   | -1 :x: |  unit  | 139m 46s | [/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt) |  hadoop-mapreduce-client in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 51s |  |  hadoop-yarn-server-timelineservice-documentstore in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m 15s |  |  hadoop-yarn-server-globalpolicygenerator in the patch passed.  |\r\n   | -1 :x: |  unit  |   0m 48s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | -1 :x: |  unit  |   0m 21s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-ui.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-ui.txt) |  hadoop-yarn-ui in the patch failed.  |\r\n   | +1 :green_heart: |  unit  |   3m  4s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 50s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 517m 52s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.resourcemanager.reservation.TestCapacityOverTimePolicy |\r\n   |   | hadoop.mapreduce.v2.TestUberAM |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7935 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 1742a3955488 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 1d5fb3ced9d16f8c847312dfd39d90d69a3f608e |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/testReport/ |\r\n   | Max. process+thread count | 1134 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-auth hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-documentstore hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui hadoop-tools/hadoop-azure U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T03:08:40.856+0000", "updated": "2025-09-06T03:08:40.856+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018594", "id": "18018594", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935#issuecomment-3262843831\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 42s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  38m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  5s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 54s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   7m 54s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   6m 15s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 56s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 28s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +0 :ok: |  spotbugs  |   0m 23s |  |  branch/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 34s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |   0m 34s | [/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | -1 :x: |  compile  |  12m 54s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |  12m 54s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |  11m 40s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |  11m 40s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   5m 19s |  |  the patch passed  |\r\n   | -1 :x: |  mvnsite  |   0m 40s | [/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 24s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  9s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 35s |  |  hadoop-project has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   0m 39s | [/patch-spotbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-spotbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | +0 :ok: |  spotbugs  |   0m 27s |  |  hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 22s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 28s |  |  hadoop-auth in the patch passed.  |\r\n   | -1 :x: |  unit  | 117m 33s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt) |  hadoop-yarn-server-resourcemanager in the patch failed.  |\r\n   | -1 :x: |  unit  | 141m 22s | [/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt) |  hadoop-mapreduce-client in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 55s |  |  hadoop-yarn-server-timelineservice-documentstore in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m 14s |  |  hadoop-yarn-server-globalpolicygenerator in the patch passed.  |\r\n   | -1 :x: |  unit  |   0m 47s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) |  hadoop-yarn-applications-catalog-webapp in the patch failed.  |\r\n   | +1 :green_heart: |  unit  |   2m 10s |  |  hadoop-yarn-ui in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 19s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  9s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 542m 48s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.mapreduce.v2.TestUberAM |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7935 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 2cc4b9991723 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5eec2aa52aaafe54638d427ab3943557b7660e21 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/testReport/ |\r\n   | Max. process+thread count | 1143 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-auth hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-documentstore hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui hadoop-tools/hadoop-azure U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T18:03:29.842+0000", "updated": "2025-09-06T18:03:29.842+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018596", "id": "18018596", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935#issuecomment-3262979489\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 37s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  19m  1s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 31s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   5m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   7m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 29s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 40s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 27s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +0 :ok: |  spotbugs  |   0m 23s |  |  branch/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  43m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   4m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  18m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  18m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 58s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  16m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   7m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 43s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  hadoop-project has no data from spotbugs  |\r\n   | +0 :ok: |  spotbugs  |   0m 22s |  |  hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 52s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 24s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 39s |  |  hadoop-auth in the patch passed.  |\r\n   | -1 :x: |  unit  | 118m 36s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/4/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt) |  hadoop-yarn-server-resourcemanager in the patch failed.  |\r\n   | -1 :x: |  unit  | 142m 36s | [/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/4/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt) |  hadoop-mapreduce-client in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 55s |  |  hadoop-yarn-server-timelineservice-documentstore in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m 16s |  |  hadoop-yarn-server-globalpolicygenerator in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m 10s |  |  hadoop-yarn-applications-catalog-webapp in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   2m  2s |  |  hadoop-yarn-ui in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 18s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 17s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 557m 11s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.mapreduce.v2.TestUberAM |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7935 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux fd48f302fc58 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2d02b1f3029f4fa6964b28470c69a5d603dd995a |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/4/testReport/ |\r\n   | Max. process+thread count | 1130 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-auth hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-documentstore hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui hadoop-tools/hadoop-azure U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7935/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T18:40:23.466+0000", "updated": "2025-09-06T18:40:23.466+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018597", "id": "18018597", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935#issuecomment-3263174197\n\n   The failed tests seem not related.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T20:03:29.389+0000", "updated": "2025-09-06T20:03:29.389+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018646", "id": "18018646", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935#issuecomment-3263559296\n\n   @szetszwo Thank you for your contribution! LGTM.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T07:33:53.329+0000", "updated": "2025-09-07T07:33:53.329+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018666", "id": "18018666", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo merged PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T16:22:11.734+0000", "updated": "2025-09-07T16:22:11.734+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018667", "id": "18018667", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on PR #7935:\nURL: https://github.com/apache/hadoop/pull/7935#issuecomment-3263885757\n\n   @slfan1989 , thanks a lot for reviewing this!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T16:22:30.831+0000", "updated": "2025-09-07T16:22:30.831+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628240/comment/18018668", "id": "18018668", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "body": "The pull request was merged.  Resolving ...", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo", "name": "szetszwo", "key": "szetszwo", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=36841", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=36841", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=36841", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=36841"}, "displayName": "Tsz-wo Sze", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-09-07T16:23:08.231+0000", "updated": "2025-09-07T16:23:08.231+0000"}], "maxResults": 10, "total": 10, "startAt": 0}, "updated": "2025-09-08T16:27:38.000+0000", "created": "2025-09-05T17:51:30.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628135", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628135", "key": "HADOOP-19676", "fields": {"summary": "ABFS: Enhancing ABFS Driver Metrics for Analytical Usability", "description": null, "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-04T16:09:46.000+0000", "created": "2025-09-04T16:09:30.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13628082", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13628082", "key": "HADOOP-19675", "fields": {"summary": "Close stale PRs updated over 100 days ago.", "description": "Close stale PRs on GitHub which updated over 100 days ago, base on the voting thread: https://lists.apache.org/thread/7x6c029fp9k62bxt2995dz6q6j6sg0bh", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018060", "id": "18018060", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao opened a new pull request, #7930:\nURL: https://github.com/apache/hadoop/pull/7930\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   This PR adds a GitHub workflow to automatically close stale PRs which have no activity over 100 days.\r\n   \r\n   ### How was this patch tested?\r\n   No.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [Y] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [N] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [N] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [Y] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T08:37:16.809+0000", "updated": "2025-09-04T08:37:16.809+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018077", "id": "18018077", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#issuecomment-3252923998\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  yamllint  |   0m  0s |  |  yamllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  44m 42s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7930/1/artifact/out/blanks-eol.txt) |  The patch has 3 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 49s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 40s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  88m 49s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7930/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7930 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets yamllint |\r\n   | uname | Linux 8be7cf7a0c05 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5e03454c04c43efa24691ef3d9245d9333a46e70 |\r\n   | Max. process+thread count | 536 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7930/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T10:07:23.615+0000", "updated": "2025-09-04T10:07:23.615+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018111", "id": "18018111", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#issuecomment-3253473455\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  yamllint  |   0m  0s |  |  yamllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  44m 27s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 50s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  87m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7930/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7930 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets yamllint |\r\n   | uname | Linux 013fcfcc6e1b 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bae392d8dfb7f2edb9de956122a07626d8802b20 |\r\n   | Max. process+thread count | 531 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7930/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T12:30:25.020+0000", "updated": "2025-09-04T12:30:25.020+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018315", "id": "18018315", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao commented on PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#issuecomment-3257436978\n\n   Thanks @slfan1989 .\r\n   \r\n   ping @ayushtkn @KeeProMise @ahmarsuhail and other guys, any more suggestions here? Thanks.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T08:01:15.700+0000", "updated": "2025-09-05T08:01:15.700+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018317", "id": "18018317", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on code in PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#discussion_r2324404204\n\n\n##########\n.github/workflows/stale.yml:\n##########\n@@ -0,0 +1,44 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+#\n+\n+name: Close stale PRs\n+on:\n+  schedule:\n+    - cron: \"0 0 * * *\"\n+\n+jobs:\n+  stale:\n+    if: github.repository == 'apache/hadoop'\n+    runs-on: ubuntu-latest\n+    steps:\n+      - uses: actions/stale@v1\n+        with:\n+          stale-pr-message: >\n+            We're closing this stale PR because it has been open 100 days with\n\nReview Comment:\n   nit: open for 100 days\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T08:07:10.868+0000", "updated": "2025-09-05T08:07:10.868+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018726", "id": "18018726", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#issuecomment-3264681771\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 59s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  yamllint  |   0m  0s |  |  yamllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  46m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 46s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  89m 40s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7930/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7930 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets yamllint |\r\n   | uname | Linux c705d2f588b2 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / fbadafe3b09613b1566c16d9c0b7518ad1ec53e0 |\r\n   | Max. process+thread count | 525 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7930/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T05:36:36.892+0000", "updated": "2025-09-08T05:36:36.892+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018734", "id": "18018734", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao commented on code in PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#discussion_r2329238358\n\n\n##########\n.github/workflows/stale.yml:\n##########\n@@ -0,0 +1,44 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+#\n+\n+name: Close stale PRs\n+on:\n+  schedule:\n+    - cron: \"0 0 * * *\"\n+\n+jobs:\n+  stale:\n+    if: github.repository == 'apache/hadoop'\n+    runs-on: ubuntu-latest\n+    steps:\n+      - uses: actions/stale@v1\n+        with:\n+          stale-pr-message: >\n+            We're closing this stale PR because it has been open 100 days with\n\nReview Comment:\n   Thanks. Fixed.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T06:16:13.896+0000", "updated": "2025-09-08T06:16:13.896+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018736", "id": "18018736", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao merged PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T06:19:09.511+0000", "updated": "2025-09-08T06:19:09.511+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018737", "id": "18018737", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao commented on PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#issuecomment-3264769501\n\n   Committed. Thanks all.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T06:19:14.623+0000", "updated": "2025-09-08T06:19:14.623+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018960", "id": "18018960", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao opened a new pull request, #7943:\nURL: https://github.com/apache/hadoop/pull/7943\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   This PR adds a GitHub workflow to automatically close stale PRs which have no activity over 100 days, linked https://github.com/apache/hadoop/pull/7930.\r\n   \r\n   Addendum. add github token.\r\n   \r\n   ### How was this patch tested?\r\n   No.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T03:05:05.941+0000", "updated": "2025-09-09T03:05:05.941+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018961", "id": "18018961", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7943:\nURL: https://github.com/apache/hadoop/pull/7943#issuecomment-3268690888\n\n   LGTM\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T03:07:49.238+0000", "updated": "2025-09-09T03:07:49.238+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018963", "id": "18018963", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "KeeProMise commented on PR #7943:\nURL: https://github.com/apache/hadoop/pull/7943#issuecomment-3268702731\n\n   LGTM.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T03:13:14.668+0000", "updated": "2025-09-09T03:13:14.668+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018972", "id": "18018972", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7943:\nURL: https://github.com/apache/hadoop/pull/7943#issuecomment-3268837255\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  yamllint  |   0m  0s |  |  yamllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  shadedclient  |  45m 25s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 53s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  88m 29s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7943/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7943 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets yamllint |\r\n   | uname | Linux 5223952659a9 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 612de4cfeddb2b582bed25abb524eec88f366245 |\r\n   | Max. process+thread count | 527 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7943/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T04:34:53.380+0000", "updated": "2025-09-09T04:34:53.380+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018973", "id": "18018973", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao merged PR #7943:\nURL: https://github.com/apache/hadoop/pull/7943\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T04:42:46.965+0000", "updated": "2025-09-09T04:42:46.965+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18018974", "id": "18018974", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao commented on PR #7943:\nURL: https://github.com/apache/hadoop/pull/7943#issuecomment-3268849533\n\n   Committed. Thanks @slfan1989 and @KeeProMise .\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T04:43:06.256+0000", "updated": "2025-09-09T04:43:06.256+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18020651", "id": "18020651", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#issuecomment-3298194311\n\n   Hey @Hexiaoqiao, just curious, number of open PRs is still 1.1K, is that expected?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T11:53:25.380+0000", "updated": "2025-09-16T11:53:25.380+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628082/comment/18020665", "id": "18020665", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao commented on PR #7930:\nURL: https://github.com/apache/hadoop/pull/7930#issuecomment-3298596092\n\n   Thanks @ahmarsuhail , Yes, it works fine from my side. ref: https://github.com/apache/hadoop/actions/workflows/stale.yml\r\n   It will keep for a long time because rate limit. I didn't dig if the rate limit could be tuning or disable. Any thought?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T12:42:55.000+0000", "updated": "2025-09-16T12:42:55.000+0000"}], "maxResults": 17, "total": 17, "startAt": 0}, "updated": "2025-09-16T12:42:55.000+0000", "created": "2025-09-04T07:59:48.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627987", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627987", "key": "HADOOP-19674", "fields": {"summary": "[JDK 17] Implementation of JAXB-API has not been found on module path or classpath", "description": "When i try to run the *org.apache.hadoop.yarn.webapp.TestWebApp* tests over JDK17 i am facing the following errors:\r\n\r\n{noformat}\r\nCaused by: A MultiException has 2 exceptions.  They are:\r\n1. javax.xml.bind.JAXBException: Implementation of JAXB-API has not been found on module path or classpath.\r\n2. java.lang.IllegalStateException: Unable to perform operation: create on org.apache.hadoop.yarn.webapp.MyTestJAXBContextResolver\r\n{noformat}\r\n\r\nRepro steps:\r\n- run: ./start-build-env.sh ubuntu_24\r\n- in docker run: mvn clean install -Pjdk17+ -T 32 -DskipTests \r\n- in hadoop-yarn-common modul run: mvn test -Dtest=org.apache.hadoop.yarn.webapp.TestWebApp\r\n\r\nI found a similar error here:\r\nhttps://issues.apache.org/jira/browse/HDDS-5068\r\n\r\nBased on my understanding the problem is the JDK11+ environments does not have the JAXB runtime, so we have to explicit provide them. Maybe this is just a temporal solution, till the whole Jakarta upgrade can be done.\r\n\r\n{panel:title=Full error log}\r\n{code}\r\n[ERROR] testRobotsText  Time elapsed: 0.064 s  <<< ERROR!\r\norg.apache.hadoop.yarn.webapp.WebAppException: Error starting http server\r\n\tat org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:506)\r\n\tat org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:492)\r\n\tat org.apache.hadoop.yarn.webapp.TestWebApp.testRobotsText(TestWebApp.java:324)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)\r\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\r\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\r\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)\r\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)\r\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)\r\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)\r\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)\r\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\r\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\r\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\r\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\r\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)\r\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)\r\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)\r\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\r\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\r\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\r\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\r\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\r\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\r\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\r\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\r\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\r\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\r\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\r\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\r\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\r\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\r\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\r\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\r\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)\r\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)\r\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)\r\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)\r\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)\r\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)\r\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)\r\n\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)\r\n\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)\r\n\tat org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:142)\r\n\tat org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:113)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)\r\nCaused by: java.io.IOException: Unable to initialize WebAppContext\r\n\tat org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1453)\r\n\tat org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:503)\r\n\t... 71 more\r\nCaused by: javax.servlet.ServletException: org.glassfish.jersey.servlet.ServletContainer-640d604==org.glassfish.jersey.servlet.ServletContainer@f679d7ba{jsp=null,order=-1,inst=true,async=true,src=EMBEDDED:null,STARTED}\r\n\tat org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:650)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:415)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750)\r\n\tat java.base/java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:357)\r\n\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:510)\r\n\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\r\n\tat java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:310)\r\n\tat java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:735)\r\n\tat java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:774)\r\n\tat org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)\r\n\tat org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1449)\r\n\tat org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1414)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:916)\r\n\tat org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)\r\n\tat org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:524)\r\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)\r\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)\r\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)\r\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)\r\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)\r\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)\r\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)\r\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)\r\n\tat org.eclipse.jetty.server.handler.StatisticsHandler.doStart(StatisticsHandler.java:264)\r\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)\r\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)\r\n\tat org.eclipse.jetty.server.Server.start(Server.java:423)\r\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)\r\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)\r\n\tat org.eclipse.jetty.server.Server.doStart(Server.java:387)\r\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)\r\n\tat org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1416)\r\n\t... 72 more\r\nCaused by: A MultiException has 2 exceptions.  They are:\r\n1. javax.xml.bind.JAXBException: Implementation of JAXB-API has not been found on module path or classpath.\r\n2. java.lang.IllegalStateException: Unable to perform operation: create on org.apache.hadoop.yarn.webapp.MyTestJAXBContextResolver\r\n\r\n\tat org.jvnet.hk2.internal.ClazzCreator.create(ClazzCreator.java:368)\r\n\tat org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)\r\n\tat org.jvnet.hk2.internal.SingletonContext$1.compute(SingletonContext.java:59)\r\n\tat org.jvnet.hk2.internal.SingletonContext$1.compute(SingletonContext.java:47)\r\n\tat org.glassfish.hk2.utilities.cache.Cache$OriginThreadAwareFuture$1.call(Cache.java:74)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat org.glassfish.hk2.utilities.cache.Cache$OriginThreadAwareFuture.run(Cache.java:131)\r\n\tat org.glassfish.hk2.utilities.cache.Cache.compute(Cache.java:176)\r\n\tat org.jvnet.hk2.internal.SingletonContext.findOrCreate(SingletonContext.java:98)\r\n\tat org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)\r\n\tat org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetAllServiceHandles(ServiceLocatorImpl.java:1481)\r\n\tat org.jvnet.hk2.internal.ServiceLocatorImpl.getAllServices(ServiceLocatorImpl.java:799)\r\n\tat org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getAllInstances(AbstractHk2InjectionManager.java:171)\r\n\tat org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getAllInstances(ImmediateHk2InjectionManager.java:30)\r\n\tat org.glassfish.jersey.internal.ContextResolverFactory$ContextResolversConfigurator.postInit(ContextResolverFactory.java:69)\r\n\tat org.glassfish.jersey.server.ApplicationHandler.lambda$initialize$2(ApplicationHandler.java:353)\r\n\tat java.base/java.util.Arrays$ArrayList.forEach(Arrays.java:4204)\r\n\tat org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:353)\r\n\tat org.glassfish.jersey.server.ApplicationHandler.lambda$initialize$1(ApplicationHandler.java:297)\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:292)\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:274)\r\n\tat org.glassfish.jersey.internal.Errors.processWithException(Errors.java:232)\r\n\tat org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:296)\r\n\tat org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:261)\r\n\tat org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:314)\r\n\tat org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:154)\r\n\tat org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:360)\r\n\tat javax.servlet.GenericServlet.init(GenericServlet.java:244)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:632)\r\n\t... 104 more\r\nCaused by: javax.xml.bind.JAXBException: Implementation of JAXB-API has not been found on module path or classpath.\r\n - with linked exception:\r\n[java.lang.ClassNotFoundException: com.sun.xml.bind.v2.ContextFactory]\r\n\tat javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:232)\r\n\tat javax.xml.bind.ContextFinder.find(ContextFinder.java:375)\r\n\tat javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:691)\r\n\tat javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:632)\r\n\tat org.glassfish.jersey.jettison.JettisonJaxbContext.<init>(JettisonJaxbContext.java:73)\r\n\tat org.glassfish.jersey.jettison.JettisonJaxbContext.<init>(JettisonJaxbContext.java:54)\r\n\tat org.apache.hadoop.yarn.webapp.MyTestJAXBContextResolver.<init>(MyTestJAXBContextResolver.java:45)\r\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\r\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)\r\n\tat org.glassfish.hk2.utilities.reflection.ReflectionHelper.makeMe(ReflectionHelper.java:1356)\r\n\tat org.jvnet.hk2.internal.ClazzCreator.createMe(ClazzCreator.java:248)\r\n\tat org.jvnet.hk2.internal.ClazzCreator.create(ClazzCreator.java:342)\r\n\t... 132 more\r\nCaused by: java.lang.ClassNotFoundException: com.sun.xml.bind.v2.ContextFactory\r\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\r\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\r\n\tat org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:538)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\r\n\tat javax.xml.bind.ServiceLoaderUtil.nullSafeLoadClass(ServiceLoaderUtil.java:92)\r\n\tat javax.xml.bind.ServiceLoaderUtil.safeLoadClass(ServiceLoaderUtil.java:125)\r\n\tat javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:230)\r\n\t... 146 more\r\n{code}\r\n{panel}\r\n\r\n", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017911", "id": "18017911", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "body": "Thank you. I was able to repro the problem\r\n\r\nDo you plan to provide a patch [~bkosztolnik] ?", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "created": "2025-09-03T14:06:50.272+0000", "updated": "2025-09-03T14:06:50.272+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017920", "id": "18017920", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K opened a new pull request, #7928:\nURL: https://github.com/apache/hadoop/pull/7928\n\n   https://issues.apache.org/jira/browse/HADOOP-19674\r\n   \r\n   ### Description of PR\r\n   \r\n   When we try to create an instance of `JettisonJaxbContext` a `JAXBContext.newInstance` call will happen. With my understanding JAXB is removed since JDK11 ([source](https://docs.oracle.com/en/java/javase/24/migrate/removed-tools-and-components.html#GUID-11F78105-D735-430D-92DD-6C37958FCBC3)) and if we would like to access JAXB, then we should explicit include them to the jars. So a new **jaxb-runtime** dependency is included in the code base. I used test scope where ever it was possible but for example in the `MRClientService` the `JAXBContextResolver` is in use, so i left the test scope there.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Unit tests\r\n   - I created a JDK8 build and run the `org.apache.hadoop.yarn.webapp.TestWebApp` test\r\n   - I created a JDK17 build and run the` org.apache.hadoop.yarn.webapp.TestWebApp` test\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-03T14:57:59.912+0000", "updated": "2025-09-03T14:57:59.912+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017922", "id": "18017922", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=bkosztolnik", "name": "bkosztolnik", "key": "JIRAUSER292672", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"}, "displayName": "Bence Kosztolnik", "active": true, "timeZone": "Etc/UTC"}, "body": "Hi [~stoty]!\r\n\r\nYes, just now.\r\nI am not 100% sure this is a good solution in point of architecture, security or long term maintenance, so i am grateful to every review.\r\nThanks!  ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=bkosztolnik", "name": "bkosztolnik", "key": "JIRAUSER292672", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"}, "displayName": "Bence Kosztolnik", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-03T15:02:10.557+0000", "updated": "2025-09-03T15:02:37.347+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017952", "id": "18017952", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "body": "I have looked into this a bit:\r\n\r\nIn 3.4, jaxb-impl is a transitive dependency of jersey-json:\r\n\r\n{noformat}\r\n[INFO] +- com.github.pjfanning:jersey-json:jar:1.22.0:compile\r\n[INFO] |  \\- com.sun.xml.bind:jaxb-impl:jar:2.2.3-1:compile\r\n[INFO] |     \\- javax.xml.bind:jaxb-api:jar:2.2.11:compile\r\n{noformat}\r\n\r\nIn 3.5 Jersey has been upgraded, and we've lost the transitive dependency.\r\n\r\nHadoop does use java.xml.bind, so in the modules where it's used it should be added as a compile / test dependency (depending on where it is used).\r\n\r\nIt is also required by Jetty (and possibly other libraries) so it may need to be added to some modules that do not directly use javax.bind.\r\n\r\nYes, at some point we should update to Jakarta, but that is a future issue, IMO adding the dependency now is fine.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "created": "2025-09-03T17:42:41.846+0000", "updated": "2025-09-03T17:42:41.846+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017953", "id": "18017953", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2319677719\n\n\n##########\nhadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/pom.xml:\n##########\n@@ -144,6 +144,11 @@\n       <artifactId>jersey-media-jaxb</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n\nReview Comment:\n   How did you decide where to add jaxb-imp and with what scope ?\n\n\n\n##########\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/pom.xml:\n##########\n@@ -122,6 +122,12 @@\n       <artifactId>jersey-test-framework-provider-jetty</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.glassfish.jaxb</groupId>\n+      <artifactId>jaxb-runtime</artifactId>\n+      <version>${jaxb.version}</version>\n\nReview Comment:\n   The version should be set in once in the hadoop-project pom dependencyManagement section\n\n\n\n##########\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/pom.xml:\n##########\n@@ -208,6 +208,12 @@\n       <artifactId>jersey-media-json-jettison</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.glassfish.jaxb</groupId>\n+      <artifactId>jaxb-runtime</artifactId>\n+      <version>${jaxb.version}</version>\n+      <scope>test</scope>\n\nReview Comment:\n   This is needed by Jetty. (at least)\r\n   This should be compile scope, as javax.xml.bind is directly used in the main code.\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-03T17:46:57.209+0000", "updated": "2025-09-03T17:46:57.209+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017963", "id": "18017963", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2319820574\n\n\n##########\nhadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/pom.xml:\n##########\n@@ -144,6 +144,11 @@\n       <artifactId>jersey-media-jaxb</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n\nReview Comment:\n   I checked the usage of the `JettisonJaxbContext` in the projects where only used in the tests i added with test scope, otherwise i set no scope.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-03T18:17:11.108+0000", "updated": "2025-09-03T18:17:11.108+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017968", "id": "18017968", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2319871051\n\n\n##########\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/pom.xml:\n##########\n@@ -208,6 +208,12 @@\n       <artifactId>jersey-media-json-jettison</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.glassfish.jaxb</groupId>\n+      <artifactId>jaxb-runtime</artifactId>\n+      <version>${jaxb.version}</version>\n+      <scope>test</scope>\n\nReview Comment:\n   I was not sure this needed in every case for the Jetty.\r\n   But in that case if i see well we will need this every where where we are using the HttpServer2.\r\n   So if i see well this will be needed in HDFS NN also.\r\n   \r\n   In that case shall we add this to the just to the `hadoop-common` project and let others use it transitively?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-03T18:41:55.686+0000", "updated": "2025-09-03T18:41:55.686+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18017969", "id": "18017969", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2319871051\n\n\n##########\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/pom.xml:\n##########\n@@ -208,6 +208,12 @@\n       <artifactId>jersey-media-json-jettison</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.glassfish.jaxb</groupId>\n+      <artifactId>jaxb-runtime</artifactId>\n+      <version>${jaxb.version}</version>\n+      <scope>test</scope>\n\nReview Comment:\n   I was not sure this needed in every case for the Jetty.\r\n   But in that case if i see well we will need this every where where we are using the HttpServer2.\r\n   So if i see well this will be needed in HDFS NN also.\r\n   \r\n   In that case shall we add this to the `hadoop-common` project only and let others use it transitively?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-03T18:43:59.763+0000", "updated": "2025-09-03T18:43:59.763+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018031", "id": "18018031", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "susheelgupta7 commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3252006029\n\n   Build issue observed on JDK 8\r\n   The Maven enforcer plugin failed due to a dependency convergence conflict for jaxb-runtime:\r\n   \r\n   ```java\r\n   [ERROR] Rule 0: org.apache.maven.enforcer.rules.dependency.DependencyConvergence failed with message:\r\n   [ERROR] Failed while enforcing releasability.\r\n   [ERROR] \r\n   [ERROR] Dependency convergence error for org.glassfish.jaxb:jaxb-runtime:jar:2.3.1 paths to dependency are:\r\n   [ERROR] +-org.apache.hadoop:hadoop-mapreduce-client-app:jar:3.5.0-SNAPSHOT\r\n   [ERROR]   +-org.apache.hadoop:hadoop-yarn-server-web-proxy:jar:3.5.0-SNAPSHOT:compile\r\n   [ERROR]     +-org.apache.hadoop:hadoop-yarn-server-common:jar:3.5.0-SNAPSHOT:compile\r\n   [ERROR]       +-org.ehcache:ehcache:jar:3.8.2:compile\r\n   [ERROR]         +-org.glassfish.jaxb:jaxb-runtime:jar:2.3.1:compile\r\n   [ERROR] and\r\n   [ERROR] +-org.apache.hadoop:hadoop-mapreduce-client-app:jar:3.5.0-SNAPSHOT\r\n   [ERROR]   +-org.glassfish.jaxb:jaxb-runtime:jar:2.3.9:compile\r\n   ``` \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T05:48:37.679+0000", "updated": "2025-09-04T05:48:37.679+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018036", "id": "18018036", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2321030300\n\n\n##########\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/pom.xml:\n##########\n@@ -208,6 +208,12 @@\n       <artifactId>jersey-media-json-jettison</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.glassfish.jaxb</groupId>\n+      <artifactId>jaxb-runtime</artifactId>\n+      <version>${jaxb.version}</version>\n+      <scope>test</scope>\n\nReview Comment:\n   > I was not sure this needed in every case for the Jetty.\r\n   \r\n   The stack strace seems to be coming from Jetty initialization.\r\n   \r\n   > But in that case if i see well we will need this every where where we are using the HttpServer2. So if i see well this will be needed in HDFS NN also.\r\n   \r\n   Yes, that's likely.\r\n   \r\n   > \r\n   > In that case shall we add this to the `hadoop-common` project only and let others use it transitively?\r\n   \r\n   I think it's better to add it separately where needed.\r\n   Most modules don't use Jetty.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T06:52:44.406+0000", "updated": "2025-09-04T06:52:44.406+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018037", "id": "18018037", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2321033382\n\n\n##########\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/pom.xml:\n##########\n@@ -208,6 +208,12 @@\n       <artifactId>jersey-media-json-jettison</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.glassfish.jaxb</groupId>\n+      <artifactId>jaxb-runtime</artifactId>\n+      <version>${jaxb.version}</version>\n+      <scope>test</scope>\n\nReview Comment:\n   One other issue is the binary assembly\r\n   \r\n   We also need to make sure that jaxb-impl is included there.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T06:54:15.448+0000", "updated": "2025-09-04T06:54:15.448+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018041", "id": "18018041", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3252296131\n\n   > Build issue observed on JDK 8 The Maven enforcer plugin failed due to a dependency convergence conflict for jaxb-runtime:\r\n   > \r\n   > ```java\r\n   > [ERROR] Rule 0: org.apache.maven.enforcer.rules.dependency.DependencyConvergence failed with message:\r\n   > [ERROR] Failed while enforcing releasability.\r\n   > [ERROR] \r\n   > [ERROR] Dependency convergence error for org.glassfish.jaxb:jaxb-runtime:jar:2.3.1 paths to dependency are:\r\n   > [ERROR] +-org.apache.hadoop:hadoop-mapreduce-client-app:jar:3.5.0-SNAPSHOT\r\n   > [ERROR]   +-org.apache.hadoop:hadoop-yarn-server-web-proxy:jar:3.5.0-SNAPSHOT:compile\r\n   > [ERROR]     +-org.apache.hadoop:hadoop-yarn-server-common:jar:3.5.0-SNAPSHOT:compile\r\n   > [ERROR]       +-org.ehcache:ehcache:jar:3.8.2:compile\r\n   > [ERROR]         +-org.glassfish.jaxb:jaxb-runtime:jar:2.3.1:compile\r\n   > [ERROR] and\r\n   > [ERROR] +-org.apache.hadoop:hadoop-mapreduce-client-app:jar:3.5.0-SNAPSHOT\r\n   > [ERROR]   +-org.glassfish.jaxb:jaxb-runtime:jar:2.3.9:compile\r\n   > ```\r\n   \r\n   Thanks @susheelgupta7 for the finding!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T07:29:11.400+0000", "updated": "2025-09-04T07:29:11.400+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018169", "id": "18018169", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2322802024\n\n\n##########\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/pom.xml:\n##########\n@@ -208,6 +208,12 @@\n       <artifactId>jersey-media-json-jettison</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.glassfish.jaxb</groupId>\n+      <artifactId>jaxb-runtime</artifactId>\n+      <version>${jaxb.version}</version>\n+      <scope>test</scope>\n\nReview Comment:\n   I tried to upload a corrected version.\r\n   With my understanding every Hadoop based Jetty server is instance of the `HttpServer2`, what is in the `hadoop-common`, so i added the dependency there.\r\n   \r\n   Some other modules what use` hadoop-common`, but not the Jetty server are already excludes the `jetty-server`.\r\n   I extended these cases with `jaxb-runtime` exculsion. This means: not 100% these modules dont need `jaxb-runtime`, but pretty sure not because the Jetty.\r\n   \r\n   In the httpfs modul i dont know why but seems like the `jetty-server` transitive dependency is excluded from `hadoop-common`, but there is an explicit dependency for it also in the pom.\r\n   \r\n   I run a clean install with -Pdist and i can see the jaxb-runtime jar in the `hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/share/hadoop/common/lib/jaxb-runtime-2.3.9.jar` path\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T16:57:05.309+0000", "updated": "2025-09-04T16:57:05.309+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018179", "id": "18018179", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2322987219\n\n\n##########\nhadoop-client-modules/hadoop-client/pom.xml:\n##########\n@@ -53,6 +53,10 @@\n           <groupId>org.eclipse.jetty</groupId>\n           <artifactId>jetty-server</artifactId>\n         </exclusion>\n+        <exclusion>\n\nReview Comment:\n   These are for java 8, right ?\n\n\n\n##########\nhadoop-client-modules/hadoop-client/pom.xml:\n##########\n@@ -53,6 +53,10 @@\n           <groupId>org.eclipse.jetty</groupId>\n           <artifactId>jetty-server</artifactId>\n         </exclusion>\n+        <exclusion>\n\nReview Comment:\n   These are for java 8, right ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T17:56:55.539+0000", "updated": "2025-09-04T17:56:55.539+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018182", "id": "18018182", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2323018571\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -2152,6 +2155,11 @@\n         <artifactId>jersey-media-json-jettison</artifactId>\n         <version>${jersey2.version}</version>\n       </dependency>\n+      <dependency>\n\nReview Comment:\n   Since we're globally dependency managing jaxb-runtime, I think that we don't need all the excludes in this patch.\r\n   They should all be dependency managed to 2.3.9 by maven, and the dependency convergence check should pass.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T18:05:51.035+0000", "updated": "2025-09-04T18:05:51.035+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018183", "id": "18018183", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2323027545\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -2152,6 +2155,11 @@\n         <artifactId>jersey-media-json-jettison</artifactId>\n         <version>${jersey2.version}</version>\n       </dependency>\n+      <dependency>\n\nReview Comment:\n   I think that the reported error was for the earlier patch without the global dependency management.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T18:07:35.924+0000", "updated": "2025-09-04T18:07:35.924+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018251", "id": "18018251", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3256455260\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 54s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 20s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  38m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m 54s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 43s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   8m  2s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   7m 13s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   6m 15s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  | 150m  1s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 40s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   4m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  18m 21s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  18m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  16m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   7m 41s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   7m  7s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   6m 11s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  65m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 31s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |  24m  7s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   3m 52s |  |  hadoop-kms in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   6m  0s |  |  hadoop-hdfs-httpfs in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   6m 16s |  |  hadoop-yarn-server-common in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   1m 35s |  |  hadoop-yarn-server-web-proxy in the patch passed.  |\r\n   | -1 :x: |  unit  | 145m 56s | [/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/2/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client.txt) |  hadoop-mapreduce-client in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   2m 38s |  |  hadoop-yarn-services-api in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 53s |  |  hadoop-client in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 451m 50s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.mapreduce.v2.TestUberAM |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7928 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 4eb1be1e663a 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 6086bd5ba19b4e4de56b0eba69be70962117a85a |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/2/testReport/ |\r\n   | Max. process+thread count | 1273 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api hadoop-client-modules/hadoop-client U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T23:50:44.113+0000", "updated": "2025-09-04T23:50:44.113+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018306", "id": "18018306", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3257284211\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m 54s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  4s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  42m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m 38s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  24m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  11m  2s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   9m 33s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  62m 19s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  42m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  19m 10s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  19m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 22s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  16m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  21m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |  11m  2s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 13s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  62m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 488m 32s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/3/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 15s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 831m 35s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.TestRollingUpgrade |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7928 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux a9562a3960c9 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 450d122aa0923580d4ddfe2b8ad9a734265fe7d9 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/3/testReport/ |\r\n   | Max. process+thread count | 2197 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api hadoop-client-modules/hadoop-client . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T07:00:06.575+0000", "updated": "2025-09-05T07:00:06.575+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018308", "id": "18018308", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2324319353\n\n\n##########\nhadoop-client-modules/hadoop-client/pom.xml:\n##########\n@@ -53,6 +53,10 @@\n           <groupId>org.eclipse.jetty</groupId>\n           <artifactId>jetty-server</artifactId>\n         </exclusion>\n+        <exclusion>\n+          <groupId>org.glassfish.jaxb</groupId>\n+          <artifactId>jaxb-runtime</artifactId>\n+        </exclusion>\n\nReview Comment:\n   I think this one is necessary otherwise at the end on install i am facing this error:\r\n   \r\n   ```\r\n   [INFO] Total time:  05:20 min (Wall Clock)\r\n   [INFO] Finished at: 2025-09-05T09:02:10+02:00\r\n   [INFO] ------------------------------------------------------------------------\r\n   [ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:3.5.0:enforce (enforce-banned-dependencies) on project hadoop-client-check-test-invariants: \r\n   [ERROR] Rule 1: org.apache.maven.plugins.enforcer.BanDuplicateClasses failed with message:\r\n   [ERROR] Duplicate classes found:\r\n   [ERROR] \r\n   [ERROR]   Found in:\r\n   [ERROR]     org.apache.hadoop:hadoop-client-minicluster:jar:3.5.0-SNAPSHOT:compile\r\n   [ERROR]     org.apache.hadoop:hadoop-client-runtime:jar:3.5.0-SNAPSHOT:compile\r\n   [ERROR]   Duplicate classes:\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/registries/MimeTypeEntry.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/localization/LocalizableMessageFactory$ResourceBundleSupplier.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/registries/MailcapTokenizer.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/FinalArrayList.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/Pool$Impl.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/registries/MailcapParseException.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/registries/LogSupport.class\r\n   [ERROR]     META-INF/versions/9/com/sun/istack/logging/StackHelper.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/NotNull.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/XMLStreamException2.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/viewers/TextEditor.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/XMLStreamReaderToContentHandler$1.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/localization/Localizable.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/viewers/ImageViewerCanvas.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/viewers/TextViewer.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/Interned.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/localization/Localizer.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/localization/LocalizableMessageFactory.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/registries/MailcapFile.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/logging/Logger.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/ByteArrayDataSource.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/Nullable.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/localization/NullLocalizable.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/SAXException2.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/registries/MimeTypeFile.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/logging/StackHelper.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/registries/LineTokenizer.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/Builder.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/FragmentContentHandler.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/Pool.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/localization/LocalizableMessage.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/activation/viewers/ImageViewer.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/SAXParseException2.class\r\n   [ERROR]     org/apache/hadoop/shaded/com/sun/istack/XMLStreamReaderToContentHandler.class\r\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T07:24:24.444+0000", "updated": "2025-09-05T07:24:24.444+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018323", "id": "18018323", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#discussion_r2324475248\n\n\n##########\nhadoop-client-modules/hadoop-client/pom.xml:\n##########\n@@ -53,6 +53,10 @@\n           <groupId>org.eclipse.jetty</groupId>\n           <artifactId>jetty-server</artifactId>\n         </exclusion>\n+        <exclusion>\n+          <groupId>org.glassfish.jaxb</groupId>\n+          <artifactId>jaxb-runtime</artifactId>\n+        </exclusion>\n\nReview Comment:\n   I have checked 3.4.2, and these classes are not present there.\r\n   Based on that, it seems that hadoop-client-runtime indeed does not include jaxb-impl traditionally.\r\n   \r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T08:39:25.242+0000", "updated": "2025-09-05T08:39:25.242+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018468", "id": "18018468", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3259566698\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  15m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 17s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |   5m 15s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/7/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  compile  |  17m 32s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m 30s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m  7s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 13s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  56m  8s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  36m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m  1s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 40s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  14m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |  10m 38s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 20s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  61m 21s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 446m 39s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/7/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 10s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 744m 47s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7928 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux a22a22156e0a 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c5a26a7263c9a5c356216b6426d5fe903213cd15 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/7/testReport/ |\r\n   | Max. process+thread count | 3607 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api hadoop-client-modules/hadoop-client . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T19:48:41.437+0000", "updated": "2025-09-05T19:48:41.437+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018473", "id": "18018473", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3259596835\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 56s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 56s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  19m 53s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 46s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 34s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  58m 27s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |  37m 21s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/4/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  compile  |  17m 10s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 11s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  21m  2s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   9m 54s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/4/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   7m 32s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/4/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  shadedclient  |  61m 30s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 480m  5s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/4/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 14s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 810m  1s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\r\n   |   | hadoop.hdfs.server.namenode.TestNameNodeMXBean |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7928 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux bd7276601e6c 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 835934188aaa69fac727bbe178075cadfc87e0a9 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/4/testReport/ |\r\n   | Max. process+thread count | 2322 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api hadoop-client-modules/hadoop-client . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T20:00:51.100+0000", "updated": "2025-09-05T20:00:51.100+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018501", "id": "18018501", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3259909698\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 51s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  37m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  19m 47s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  17m 16s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  24m  2s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  11m 10s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  59m 48s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |  35m 24s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/5/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  compile  |  18m  7s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  18m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 15s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  17m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |  11m 51s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/5/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   8m 21s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/5/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  shadedclient  |  63m  0s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 611m 20s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/5/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 944m 54s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7928 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux f7e642f299bc 5.15.0-151-generic #161-Ubuntu SMP Tue Jul 22 14:25:40 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 835934188aaa69fac727bbe178075cadfc87e0a9 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/5/testReport/ |\r\n   | Max. process+thread count | 3138 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api hadoop-client-modules/hadoop-client . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T22:18:38.634+0000", "updated": "2025-09-05T22:18:38.634+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018603", "id": "18018603", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3263251404\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 46s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  37m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 22s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 21s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 43s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  58m 26s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  41m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 44s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 13s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  20m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |  10m  6s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 45s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  59m 47s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 481m 54s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/8/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 15s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 824m 39s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7928 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 117987a87daa 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7d1831a9a0ae7b1f73edfce600e8a818b5ec5de6 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/8/testReport/ |\r\n   | Max. process+thread count | 3135 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api hadoop-client-modules/hadoop-client . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T22:13:56.000+0000", "updated": "2025-09-06T22:13:56.000+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018647", "id": "18018647", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3263561534\n\n   @K0K0V0K Thank you for your contribution! LGTM. However, we need to trigger the compilation again as the current process seems to have been interrupted.\r\n   \r\n   I also noticed some warning messages. Could you please double-check?\r\n   \r\n   \r\n   ```\r\n   [WARNING] \r\n   \r\n   Some dependencies of Maven Plugins are expected to be in provided scope.\r\n   Please make sure that dependencies listed below declared in POM\r\n   have set '<scope>provided</scope>' as well.\r\n   \r\n   The following dependencies are in wrong scope:\r\n    * org.apache.maven:maven-plugin-api:jar:3.9.5:compile\r\n    * org.apache.maven:maven-model:jar:3.9.5:compile\r\n    * org.apache.maven:maven-artifact:jar:3.9.5:compile\r\n    * org.apache.maven:maven-core:jar:3.9.5:compile\r\n    * org.apache.maven:maven-settings:jar:3.9.5:compile\r\n    * org.apache.maven:maven-settings-builder:jar:3.9.5:compile\r\n    * org.apache.maven:maven-builder-support:jar:3.9.5:compile\r\n    * org.apache.maven:maven-repository-metadata:jar:3.9.5:compile\r\n    * org.apache.maven:maven-model-builder:jar:3.9.5:compile\r\n    * org.apache.maven:maven-resolver-provider:jar:3.9.5:compile\r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T07:38:08.913+0000", "updated": "2025-09-07T07:38:08.913+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018778", "id": "18018778", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3265388602\n\n   Hi @slfan1989!\r\n   \r\n   Thanks for the review. I checked the latest console, output and seems like the waring is not present anymore:\r\n   https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/8/consoleFull\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T09:23:49.419+0000", "updated": "2025-09-08T09:23:49.419+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18018958", "id": "18018958", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3268664561\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 51s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  38m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 56s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 29s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 16s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 46s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  58m 11s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 39s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  41m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  18m  0s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  18m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 40s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |  10m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 44s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  59m 50s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 656m 49s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/9/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 17s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 980m 24s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.TestRollingUpgrade |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/9/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7928 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux ca1384aa87d7 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 56b01d2c3fd0ade4f966d40068b9fdc9c53dc7ff |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/9/testReport/ |\r\n   | Max. process+thread count | 3135 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api hadoop-client-modules/hadoop-client . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7928/9/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T02:49:02.810+0000", "updated": "2025-09-09T02:49:02.810+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18019050", "id": "18019050", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brumi1024 merged PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T11:09:19.171+0000", "updated": "2025-09-09T11:09:19.171+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627987/comment/18019053", "id": "18019053", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on PR #7928:\nURL: https://github.com/apache/hadoop/pull/7928#issuecomment-3270292832\n\n   Thanks! @stoty @slfan1989 @brumi1024 @susheelgupta7 for the review and for the help here!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T11:39:08.697+0000", "updated": "2025-09-09T11:39:08.697+0000"}], "maxResults": 29, "total": 29, "startAt": 0}, "updated": "2025-09-09T13:06:35.000+0000", "created": "2025-09-03T11:30:33.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627890", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627890", "key": "HADOOP-19673", "fields": {"summary": "BloomMapFile: invalid io.mapfile.bloom.error.rate (\u22640 or \u22651) causes NaN/zero vector size and writer construction failure", "description": "{{BloomMapFile.Writer#initBloomFilter(Configuration)}} computes the Bloom filter vector size as:\r\n{code:java}\r\nint numKeys = conf.getInt(IO_MAPFILE_BLOOM_SIZE_KEY, IO_MAPFILE_BLOOM_SIZE_DEFAULT);\r\nfloat errorRate = conf.getFloat(IO_MAPFILE_BLOOM_ERROR_RATE_KEY, IO_MAPFILE_BLOOM_ERROR_RATE_DEFAULT);\r\nint vectorSize = (int) Math.ceil(\r\n\u00a0 (double)(-HASH_COUNT * numKeys) /\r\n\u00a0 Math.log(1.0 - Math.pow(errorRate, 1.0 / HASH_COUNT))\r\n); {code}\r\nWhen {{io.mapfile.bloom.error.rate}} is *\u2264 0*\u00a0or {*}\u2265 1{*}:\r\n * {{Math.pow(errorRate, 1/k)}} produces *NaN* (negative base with non-integer exponent) or an invalid value;\r\n * {{Math.log(1 - NaN)}} becomes {*}NaN{*};\r\n * {{Math.ceil(NaN)}} cast to {{int}} yields {*}0{*}, so {{{}vectorSize == 0{}}};\r\n * constructing {{DynamicBloomFilter}} subsequently fails, and {{BloomMapFile.Writer}} construction fails (observed as assertion failure in tests).\r\n\r\nThe code misses input validation for {{io.mapfile.bloom.error.rate}} which should be strictly within {{{}(0, 1){}}}. With invalid values, the math silently degrades to NaN/0 and fails at runtime.\r\n\r\n*Reproduction*\r\n\r\nInjected values: {{io.mapfile.bloom.error.rate = 0,-1}}\r\n\r\nTest: {{org.apache.hadoop.io.TestBloomMapFile#testBloomMapFileConstructors}}\r\n{code:java}\r\n[INFO] Running org.apache.hadoop.io.TestBloomMapFile\r\n[ERROR] Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.358 s <<< FAILURE! - in org.apache.hadoop.io.TestBloomMapFile\r\n[ERROR] org.apache.hadoop.io.TestBloomMapFile.testBloomMapFileConstructors \u00a0Time elapsed: 0.272 s \u00a0<<< FAILURE!\r\njava.lang.AssertionError: testBloomMapFileConstructors error !!!\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.io.TestBloomMapFile.testBloomMapFileConstructors(TestBloomMapFile.java:287{code}", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-07T07:57:06.000+0000", "created": "2025-09-02T14:20:00.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627795", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627795", "key": "HADOOP-19672", "fields": {"summary": "ABFS: Network Error-Based Client Switchover: Apache to JDK (continuous failure))", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18020384", "id": "18020384", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 opened a new pull request, #7967:\nURL: https://github.com/apache/hadoop/pull/7967\n\n   JIRA \u2013 https://issues.apache.org/jira/browse/HADOOP-19672\r\n   \r\n   In case of a network error while using the Apache client, we allow the client to switch over from Apache to JDK. This network fallback occurs in two scenarios:\r\n   \r\n   1. During file system initialization \u2013 When warming up the cache, if no connection is created (indicating an issue with the Apache client), the system will fall back to the JDK.\r\n   2. During a network call \u2013 If an I/O or Unknown Host exception occurs for three consecutive retries, the system will fall back to the JDK.\r\n   \r\n   This fallback is applied at the JVM level, so all file system calls will use the JDK client once the switch occurs.\r\n   \r\n   There is also a possibility of recovery. During cache warmup, if connections are successfully created using the Apache client, the system will automatically switch back to the Apache client.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T14:55:52.052+0000", "updated": "2025-09-15T14:55:52.052+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18020418", "id": "18020418", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3293191749\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 36s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  57m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 50s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 2 unchanged - 0 fixed = 3 total (was 2)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 16s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 59s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 41s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 47s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7967 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux b7ef8b2a88ce 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 1dad672faf42fbfb0ada2a95456b922a50b2becf |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/1/testReport/ |\r\n   | Max. process+thread count | 693 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:22:46.350+0000", "updated": "2025-09-15T17:22:46.350+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18020465", "id": "18020465", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3293931499\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  15m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  50m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 48s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  6s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 156m 38s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7967 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux f1f4dba85ce3 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 6faa4c9c8ad8083e0a636b6439146a24c66c0ce3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/2/testReport/ |\r\n   | Max. process+thread count | 555 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T20:58:18.410+0000", "updated": "2025-09-15T20:58:18.410+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023064", "id": "18023064", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2381728892\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -73,18 +80,21 @@ static boolean usable() {\n   }\n \n   AbfsApacheHttpClient(DelegatingSSLSocketFactory delegatingSSLSocketFactory,\n-      final AbfsConfiguration abfsConfiguration, final KeepAliveCache keepAliveCache,\n-      URL baseUrl) {\n+      final AbfsConfiguration abfsConfiguration,\n+      final KeepAliveCache keepAliveCache,\n+      URL baseUrl,\n+      final boolean isCacheWarmupNeeded) {\n     final AbfsConnectionManager connMgr = new AbfsConnectionManager(\n         createSocketFactoryRegistry(\n             new SSLConnectionSocketFactory(delegatingSSLSocketFactory,\n                 getDefaultHostnameVerifier())),\n         new AbfsHttpClientConnectionFactory(), keepAliveCache,\n-        abfsConfiguration, baseUrl);\n+        abfsConfiguration, baseUrl, isCacheWarmupNeeded);\n     final HttpClientBuilder builder = HttpClients.custom();\n     builder.setConnectionManager(connMgr)\n         .setRequestExecutor(\n-            new AbfsManagedHttpRequestExecutor(abfsConfiguration.getHttpReadTimeout()))\n+            new AbfsManagedHttpRequestExecutor(\n\nReview Comment:\n   As we were discussing last time, if we keep it to read timeout the 100 continue timeout would become 30 seconds, this should be another config for 100 continue timeout\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T09:54:12.608+0000", "updated": "2025-09-26T09:54:12.608+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023066", "id": "18023066", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2381745959\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -254,7 +259,8 @@ private AbfsClient(final URL baseUrl,\n \n       abfsApacheHttpClient = new AbfsApacheHttpClient(\n           DelegatingSSLSocketFactory.getDefaultFactory(),\n-          abfsConfiguration, keepAliveCache, baseUrl);\n+          abfsConfiguration, keepAliveCache, baseUrl,\n+          abfsConfiguration.getFsConfiguredServiceType() == abfsServiceType);\n\nReview Comment:\n   Can you add some comments around this change as to how it would affect the need for cache warmup\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T09:57:59.745+0000", "updated": "2025-09-26T09:57:59.745+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023070", "id": "18023070", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2381793492\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsConnectionManager.java:\n##########\n@@ -91,26 +92,34 @@ class AbfsConnectionManager implements HttpClientConnectionManager {\n   /**\n    * The base host for which connections are managed.\n    */\n-  private HttpHost baseHost;\n+  private final HttpHost baseHost;\n \n   AbfsConnectionManager(Registry<ConnectionSocketFactory> socketFactoryRegistry,\n-      AbfsHttpClientConnectionFactory connectionFactory, KeepAliveCache kac,\n-      final AbfsConfiguration abfsConfiguration, final URL baseUrl) {\n+      AbfsHttpClientConnectionFactory connectionFactory,\n+      KeepAliveCache kac,\n+      final AbfsConfiguration abfsConfiguration,\n+      final URL baseUrl,\n+      final boolean isCacheWarmupNeeded) {\n     this.httpConnectionFactory = connectionFactory;\n     this.kac = kac;\n     this.connectionOperator = new DefaultHttpClientConnectionOperator(\n         socketFactoryRegistry, null, null);\n     this.abfsConfiguration = abfsConfiguration;\n-    if (abfsConfiguration.getApacheCacheWarmupCount() > 0\n+    this.baseHost = new HttpHost(baseUrl.getHost(),\n+        baseUrl.getDefaultPort(), baseUrl.getProtocol());\n+    if (isCacheWarmupNeeded && abfsConfiguration.getApacheCacheWarmupCount() > 0\n         && kac.getFixedThreadPool() != null) {\n       // Warm up the cache with connections.\n       LOG.debug(\"Warming up the KeepAliveCache with {} connections\",\n           abfsConfiguration.getApacheCacheWarmupCount());\n-      this.baseHost = new HttpHost(baseUrl.getHost(),\n-          baseUrl.getDefaultPort(), baseUrl.getProtocol());\n       HttpRoute route = new HttpRoute(baseHost, null, true);\n-      cacheExtraConnection(route,\n+      int totalConnectionsCreated = cacheExtraConnection(route,\n           abfsConfiguration.getApacheCacheWarmupCount());\n+      if (totalConnectionsCreated == 0) {\n\nReview Comment:\n   even if we fail or catch rejected exception for any one of the tasks we want to register fallback as the successfully submitted tasks might have increased the count of totalConnectionsCreated\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T10:08:30.641+0000", "updated": "2025-09-26T10:08:30.641+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023071", "id": "18023071", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2381815558\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestApacheClientConnectionPool.java:\n##########\n@@ -118,6 +121,38 @@ public void testConnectedConnectionLogging() throws Exception {\n         .isEqualTo(4);\n   }\n \n+  /**\n+   * Test to verify that the ApacheHttpClient falls back to JDK client\n+   * when connection warmup fails.\n+   * This test is applicable only for ApacheHttpClient.\n+   */\n+  @Test\n+  public void testApacheClientFallbackDuringConnectionWarmup()\n+      throws Exception {\n+    try (KeepAliveCache keepAliveCache = new KeepAliveCache(\n+        new AbfsConfiguration(new Configuration(), EMPTY_STRING))) {\n+      // Create a connection manager with invalid URL to force fallback to JDK client\n+      // during connection warmup.\n+      // This is to simulate failure during connection warmup in the connection manager.\n+      // The invalid URL will cause the connection manager to fail to create connections\n+      // during warmup, forcing it to fall back to JDK client.\n+      final AbfsConnectionManager connMgr = new AbfsConnectionManager(\n+          RegistryBuilder.<ConnectionSocketFactory>create()\n+              .register(HTTPS_SCHEME, new SSLConnectionSocketFactory(\n+                  DelegatingSSLSocketFactory.getDefaultFactory(),\n+                  getDefaultHostnameVerifier()))\n+              .build(),\n+          new AbfsHttpClientConnectionFactory(), keepAliveCache,\n+          new AbfsConfiguration(new Configuration(), EMPTY_STRING),\n+          new URL(\"https://test.com\"), true);\n+\n+      Assertions.assertThat(AbfsApacheHttpClient.usable())\n+          .describedAs(\"Apache HttpClient should be not usable\")\n\nReview Comment:\n   Can you make one http call and validate now jdk is being used, user agent can be used for validation\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T10:13:16.449+0000", "updated": "2025-09-26T10:13:16.449+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023084", "id": "18023084", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2382005373\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClientHandler.java:\n##########\n@@ -68,13 +68,13 @@ public AbfsClientHandler(final URL baseUrl,\n       final SASTokenProvider sasTokenProvider,\n       final EncryptionContextProvider encryptionContextProvider,\n       final AbfsClientContext abfsClientContext) throws IOException {\n+    initServiceType(abfsConfiguration);\n\nReview Comment:\n   Why this change?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -188,7 +189,7 @@ public AbfsBlobClient(final URL baseUrl,\n       final EncryptionContextProvider encryptionContextProvider,\n       final AbfsClientContext abfsClientContext) throws IOException {\n     super(baseUrl, sharedKeyCredentials, abfsConfiguration, tokenProvider,\n-        encryptionContextProvider, abfsClientContext);\n+        encryptionContextProvider, abfsClientContext, AbfsServiceType.BLOB);\n\nReview Comment:\n   Why this change?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -73,18 +80,21 @@ static boolean usable() {\n   }\n \n   AbfsApacheHttpClient(DelegatingSSLSocketFactory delegatingSSLSocketFactory,\n-      final AbfsConfiguration abfsConfiguration, final KeepAliveCache keepAliveCache,\n-      URL baseUrl) {\n+      final AbfsConfiguration abfsConfiguration,\n+      final KeepAliveCache keepAliveCache,\n+      URL baseUrl,\n+      final boolean isCacheWarmupNeeded) {\n     final AbfsConnectionManager connMgr = new AbfsConnectionManager(\n         createSocketFactoryRegistry(\n             new SSLConnectionSocketFactory(delegatingSSLSocketFactory,\n                 getDefaultHostnameVerifier())),\n         new AbfsHttpClientConnectionFactory(), keepAliveCache,\n-        abfsConfiguration, baseUrl);\n+        abfsConfiguration, baseUrl, isCacheWarmupNeeded);\n     final HttpClientBuilder builder = HttpClients.custom();\n     builder.setConnectionManager(connMgr)\n         .setRequestExecutor(\n-            new AbfsManagedHttpRequestExecutor(abfsConfiguration.getHttpReadTimeout()))\n+            new AbfsManagedHttpRequestExecutor(\n\nReview Comment:\n   +1\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -254,7 +259,8 @@ private AbfsClient(final URL baseUrl,\n \n       abfsApacheHttpClient = new AbfsApacheHttpClient(\n           DelegatingSSLSocketFactory.getDefaultFactory(),\n-          abfsConfiguration, keepAliveCache, baseUrl);\n+          abfsConfiguration, keepAliveCache, baseUrl,\n+          abfsConfiguration.getFsConfiguredServiceType() == abfsServiceType);\n\nReview Comment:\n   +1\r\n   What are we trying to achieve here?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T11:06:00.544+0000", "updated": "2025-09-26T11:06:00.544+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023086", "id": "18023086", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2381793492\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsConnectionManager.java:\n##########\n@@ -91,26 +92,34 @@ class AbfsConnectionManager implements HttpClientConnectionManager {\n   /**\n    * The base host for which connections are managed.\n    */\n-  private HttpHost baseHost;\n+  private final HttpHost baseHost;\n \n   AbfsConnectionManager(Registry<ConnectionSocketFactory> socketFactoryRegistry,\n-      AbfsHttpClientConnectionFactory connectionFactory, KeepAliveCache kac,\n-      final AbfsConfiguration abfsConfiguration, final URL baseUrl) {\n+      AbfsHttpClientConnectionFactory connectionFactory,\n+      KeepAliveCache kac,\n+      final AbfsConfiguration abfsConfiguration,\n+      final URL baseUrl,\n+      final boolean isCacheWarmupNeeded) {\n     this.httpConnectionFactory = connectionFactory;\n     this.kac = kac;\n     this.connectionOperator = new DefaultHttpClientConnectionOperator(\n         socketFactoryRegistry, null, null);\n     this.abfsConfiguration = abfsConfiguration;\n-    if (abfsConfiguration.getApacheCacheWarmupCount() > 0\n+    this.baseHost = new HttpHost(baseUrl.getHost(),\n+        baseUrl.getDefaultPort(), baseUrl.getProtocol());\n+    if (isCacheWarmupNeeded && abfsConfiguration.getApacheCacheWarmupCount() > 0\n         && kac.getFixedThreadPool() != null) {\n       // Warm up the cache with connections.\n       LOG.debug(\"Warming up the KeepAliveCache with {} connections\",\n           abfsConfiguration.getApacheCacheWarmupCount());\n-      this.baseHost = new HttpHost(baseUrl.getHost(),\n-          baseUrl.getDefaultPort(), baseUrl.getProtocol());\n       HttpRoute route = new HttpRoute(baseHost, null, true);\n-      cacheExtraConnection(route,\n+      int totalConnectionsCreated = cacheExtraConnection(route,\n           abfsConfiguration.getApacheCacheWarmupCount());\n+      if (totalConnectionsCreated == 0) {\n\nReview Comment:\n   even if we fail or catch rejected exception for any one of the tasks we want to register fallback ? as the successfully submitted tasks might have increased the count of totalConnectionsCreated\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T12:01:54.816+0000", "updated": "2025-09-26T12:01:54.816+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023512", "id": "18023512", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2387212747\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -214,7 +214,7 @@ public final class FileSystemConfigurations {\n   public static final long THOUSAND = 1000L;\n \n   public static final HttpOperationType DEFAULT_NETWORKING_LIBRARY\n-      = HttpOperationType.JDK_HTTP_URL_CONNECTION;\n+      = HttpOperationType.APACHE_HTTP_CLIENT;\n\nReview Comment:\n   Nit: We should change this in our md file as well\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-29T09:02:01.277+0000", "updated": "2025-09-29T09:02:01.277+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023766", "id": "18023766", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2390726345\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -214,7 +214,7 @@ public final class FileSystemConfigurations {\n   public static final long THOUSAND = 1000L;\n \n   public static final HttpOperationType DEFAULT_NETWORKING_LIBRARY\n-      = HttpOperationType.JDK_HTTP_URL_CONNECTION;\n+      = HttpOperationType.APACHE_HTTP_CLIENT;\n \n   public static final int DEFAULT_APACHE_HTTP_CLIENT_MAX_IO_EXCEPTION_RETRIES = 3;\n\nReview Comment:\n   where are we checking after 3 retries we'll fallback to JDK?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-30T10:14:45.238+0000", "updated": "2025-09-30T10:14:45.238+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023767", "id": "18023767", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2390726345\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -214,7 +214,7 @@ public final class FileSystemConfigurations {\n   public static final long THOUSAND = 1000L;\n \n   public static final HttpOperationType DEFAULT_NETWORKING_LIBRARY\n-      = HttpOperationType.JDK_HTTP_URL_CONNECTION;\n+      = HttpOperationType.APACHE_HTTP_CLIENT;\n \n   public static final int DEFAULT_APACHE_HTTP_CLIENT_MAX_IO_EXCEPTION_RETRIES = 3;\n\nReview Comment:\n   where are we checking after 3 retries we'll fallback to JDK?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-30T10:15:32.677+0000", "updated": "2025-09-30T10:15:32.677+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023970", "id": "18023970", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2393513847\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -73,18 +80,21 @@ static boolean usable() {\n   }\n \n   AbfsApacheHttpClient(DelegatingSSLSocketFactory delegatingSSLSocketFactory,\n-      final AbfsConfiguration abfsConfiguration, final KeepAliveCache keepAliveCache,\n-      URL baseUrl) {\n+      final AbfsConfiguration abfsConfiguration,\n+      final KeepAliveCache keepAliveCache,\n+      URL baseUrl,\n+      final boolean isCacheWarmupNeeded) {\n     final AbfsConnectionManager connMgr = new AbfsConnectionManager(\n         createSocketFactoryRegistry(\n             new SSLConnectionSocketFactory(delegatingSSLSocketFactory,\n                 getDefaultHostnameVerifier())),\n         new AbfsHttpClientConnectionFactory(), keepAliveCache,\n-        abfsConfiguration, baseUrl);\n+        abfsConfiguration, baseUrl, isCacheWarmupNeeded);\n     final HttpClientBuilder builder = HttpClients.custom();\n     builder.setConnectionManager(connMgr)\n         .setRequestExecutor(\n-            new AbfsManagedHttpRequestExecutor(abfsConfiguration.getHttpReadTimeout()))\n+            new AbfsManagedHttpRequestExecutor(\n\nReview Comment:\n   Sure, will create a new config for read timeout and use that when 100 continue is enabled.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T05:45:47.150+0000", "updated": "2025-10-01T05:45:47.150+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023971", "id": "18023971", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2393517614\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -254,7 +259,8 @@ private AbfsClient(final URL baseUrl,\n \n       abfsApacheHttpClient = new AbfsApacheHttpClient(\n           DelegatingSSLSocketFactory.getDefaultFactory(),\n-          abfsConfiguration, keepAliveCache, baseUrl);\n+          abfsConfiguration, keepAliveCache, baseUrl,\n+          abfsConfiguration.getFsConfiguredServiceType() == abfsServiceType);\n\nReview Comment:\n   The reason for this change: Since the keep alive cache is on client level and we were doing cache warmup for both the client separately. Now with this change, we will do cache warmup only for the default client, not for both the clients.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T05:49:04.577+0000", "updated": "2025-10-01T05:49:04.577+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023972", "id": "18023972", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2393517614\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -254,7 +259,8 @@ private AbfsClient(final URL baseUrl,\n \n       abfsApacheHttpClient = new AbfsApacheHttpClient(\n           DelegatingSSLSocketFactory.getDefaultFactory(),\n-          abfsConfiguration, keepAliveCache, baseUrl);\n+          abfsConfiguration, keepAliveCache, baseUrl,\n+          abfsConfiguration.getFsConfiguredServiceType() == abfsServiceType);\n\nReview Comment:\n   The reason for this change: Since the keep alive cache is on client level and we were doing cache warmup for both the client separately. Now with this change, we will do cache warmup only for the default client, not for both the clients.\r\n   Will add the comment in the code as well\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T05:49:59.660+0000", "updated": "2025-10-01T05:49:59.660+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023973", "id": "18023973", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2393520715\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestApacheClientConnectionPool.java:\n##########\n@@ -118,6 +121,38 @@ public void testConnectedConnectionLogging() throws Exception {\n         .isEqualTo(4);\n   }\n \n+  /**\n+   * Test to verify that the ApacheHttpClient falls back to JDK client\n+   * when connection warmup fails.\n+   * This test is applicable only for ApacheHttpClient.\n+   */\n+  @Test\n+  public void testApacheClientFallbackDuringConnectionWarmup()\n+      throws Exception {\n+    try (KeepAliveCache keepAliveCache = new KeepAliveCache(\n+        new AbfsConfiguration(new Configuration(), EMPTY_STRING))) {\n+      // Create a connection manager with invalid URL to force fallback to JDK client\n+      // during connection warmup.\n+      // This is to simulate failure during connection warmup in the connection manager.\n+      // The invalid URL will cause the connection manager to fail to create connections\n+      // during warmup, forcing it to fall back to JDK client.\n+      final AbfsConnectionManager connMgr = new AbfsConnectionManager(\n+          RegistryBuilder.<ConnectionSocketFactory>create()\n+              .register(HTTPS_SCHEME, new SSLConnectionSocketFactory(\n+                  DelegatingSSLSocketFactory.getDefaultFactory(),\n+                  getDefaultHostnameVerifier()))\n+              .build(),\n+          new AbfsHttpClientConnectionFactory(), keepAliveCache,\n+          new AbfsConfiguration(new Configuration(), EMPTY_STRING),\n+          new URL(\"https://test.com\"), true);\n+\n+      Assertions.assertThat(AbfsApacheHttpClient.usable())\n+          .describedAs(\"Apache HttpClient should be not usable\")\n\nReview Comment:\n   Sure, will do that.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T05:51:19.732+0000", "updated": "2025-10-01T05:51:19.732+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023974", "id": "18023974", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2393522594\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -188,7 +189,7 @@ public AbfsBlobClient(final URL baseUrl,\n       final EncryptionContextProvider encryptionContextProvider,\n       final AbfsClientContext abfsClientContext) throws IOException {\n     super(baseUrl, sharedKeyCredentials, abfsConfiguration, tokenProvider,\n-        encryptionContextProvider, abfsClientContext);\n+        encryptionContextProvider, abfsClientContext, AbfsServiceType.BLOB);\n\nReview Comment:\n   As described in the previous comment, we need to find out default client and for that we are comparing these values with the default value configured.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T05:52:49.824+0000", "updated": "2025-10-01T05:52:49.824+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023975", "id": "18023975", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2393523578\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -214,7 +214,7 @@ public final class FileSystemConfigurations {\n   public static final long THOUSAND = 1000L;\n \n   public static final HttpOperationType DEFAULT_NETWORKING_LIBRARY\n-      = HttpOperationType.JDK_HTTP_URL_CONNECTION;\n+      = HttpOperationType.APACHE_HTTP_CLIENT;\n\nReview Comment:\n   Sure, will make the change in .md file as well\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T05:53:34.855+0000", "updated": "2025-10-01T05:53:34.855+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18023989", "id": "18023989", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2393620859\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsConnectionManager.java:\n##########\n@@ -91,26 +92,34 @@ class AbfsConnectionManager implements HttpClientConnectionManager {\n   /**\n    * The base host for which connections are managed.\n    */\n-  private HttpHost baseHost;\n+  private final HttpHost baseHost;\n \n   AbfsConnectionManager(Registry<ConnectionSocketFactory> socketFactoryRegistry,\n-      AbfsHttpClientConnectionFactory connectionFactory, KeepAliveCache kac,\n-      final AbfsConfiguration abfsConfiguration, final URL baseUrl) {\n+      AbfsHttpClientConnectionFactory connectionFactory,\n+      KeepAliveCache kac,\n+      final AbfsConfiguration abfsConfiguration,\n+      final URL baseUrl,\n+      final boolean isCacheWarmupNeeded) {\n     this.httpConnectionFactory = connectionFactory;\n     this.kac = kac;\n     this.connectionOperator = new DefaultHttpClientConnectionOperator(\n         socketFactoryRegistry, null, null);\n     this.abfsConfiguration = abfsConfiguration;\n-    if (abfsConfiguration.getApacheCacheWarmupCount() > 0\n+    this.baseHost = new HttpHost(baseUrl.getHost(),\n+        baseUrl.getDefaultPort(), baseUrl.getProtocol());\n+    if (isCacheWarmupNeeded && abfsConfiguration.getApacheCacheWarmupCount() > 0\n         && kac.getFixedThreadPool() != null) {\n       // Warm up the cache with connections.\n       LOG.debug(\"Warming up the KeepAliveCache with {} connections\",\n           abfsConfiguration.getApacheCacheWarmupCount());\n-      this.baseHost = new HttpHost(baseUrl.getHost(),\n-          baseUrl.getDefaultPort(), baseUrl.getProtocol());\n       HttpRoute route = new HttpRoute(baseHost, null, true);\n-      cacheExtraConnection(route,\n+      int totalConnectionsCreated = cacheExtraConnection(route,\n           abfsConfiguration.getApacheCacheWarmupCount());\n+      if (totalConnectionsCreated == 0) {\n\nReview Comment:\n   Yes, make sense. I have updated the returned value in case of rejected exception; other thing will remain the same.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClientHandler.java:\n##########\n@@ -68,13 +68,13 @@ public AbfsClientHandler(final URL baseUrl,\n       final SASTokenProvider sasTokenProvider,\n       final EncryptionContextProvider encryptionContextProvider,\n       final AbfsClientContext abfsClientContext) throws IOException {\n+    initServiceType(abfsConfiguration);\n\nReview Comment:\n   This will initialize the default and ingress service types. This is needed before crating the clients so that we can do cache warmup only for default client.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T07:11:40.076+0000", "updated": "2025-10-01T07:11:40.076+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18028193", "id": "18028193", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3378551948\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 48s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  1s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |  54m 51s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/3/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 40s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 31s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m  2s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  8s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 150m 19s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7967 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets markdownlint |\r\n   | uname | Linux 6778220a7832 5.15.0-157-generic #167-Ubuntu SMP Wed Sep 17 21:35:53 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 44765c0ae41d29a78198cb113bc06780be7092af |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/3/testReport/ |\r\n   | Max. process+thread count | 561 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-07T20:12:06.452+0000", "updated": "2025-10-07T20:12:06.452+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18028533", "id": "18028533", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#discussion_r2415677758\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClientHandler.java:\n##########\n@@ -68,6 +68,9 @@ public AbfsClientHandler(final URL baseUrl,\n       final SASTokenProvider sasTokenProvider,\n       final EncryptionContextProvider encryptionContextProvider,\n       final AbfsClientContext abfsClientContext) throws IOException {\n+    // This will initialize the default and ingress service types.\n+    // This is needed before crating the clients so that we can do cache warmup\n\nReview Comment:\n   nit: typo creating\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T06:17:29.239+0000", "updated": "2025-10-09T06:17:29.239+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18028807", "id": "18028807", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3386392364\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  53m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 31s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 32s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  7s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 150m 27s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7967 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets markdownlint |\r\n   | uname | Linux a733619d79ed 5.15.0-157-generic #167-Ubuntu SMP Wed Sep 17 21:35:53 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7ff70868cc0483c55d875f66cf2379f04e75075e |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/4/testReport/ |\r\n   | Max. process+thread count | 526 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7967/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T15:44:50.580+0000", "updated": "2025-10-09T15:44:50.580+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18028945", "id": "18028945", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3388294934\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 872, Failures: 0, Errors: 0, Skipped: 217\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 8\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 875, Failures: 0, Errors: 0, Skipped: 169\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 8\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 714, Failures: 0, Errors: 0, Skipped: 282\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 9\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 872, Failures: 0, Errors: 0, Skipped: 228\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 9\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 721, Failures: 0, Errors: 0, Skipped: 140\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 711, Failures: 0, Errors: 0, Skipped: 284\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 9\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 718, Failures: 0, Errors: 0, Skipped: 152\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 713, Failures: 0, Errors: 0, Skipped: 198\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 746, Failures: 0, Errors: 0, Skipped: 226\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 8\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 194, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 711, Failures: 0, Errors: 0, Skipped: 281\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 9\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-10T04:58:37.773+0000", "updated": "2025-10-10T04:58:37.773+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18029407", "id": "18029407", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T06:19:02.121+0000", "updated": "2025-10-13T06:19:02.121+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18029740", "id": "18029740", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3401193052\n\n   I understand why the startup mechanism makes sense, but I'm curious about doing it on a live connection. What problems were occurring with hostname lookup that changing client would fix?\r\n   \r\n   Do you want this in 3.4.3? if so do a backport PR ASAP\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-14T10:43:56.693+0000", "updated": "2025-10-14T10:43:56.693+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18032070", "id": "18032070", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3432065456\n\n   @steveloughran We\u2019re performing cache refresh when the number of available connections in the cache drops below a certain threshold. The warmup normally happens during file system initialization, but if the file system is already active and making multiple parallel network calls, creating new connections on demand with the Apache client tends to take longer.\r\n   \r\n   To avoid delays in such cases, we asynchronously pre-create and cache a few additional connections whenever the pool runs low. This ensures that subsequent network calls can use already-established connections and spend time on actual data processing rather than connection setup.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-22T12:13:35.113+0000", "updated": "2025-10-22T12:13:35.113+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627795/comment/18032343", "id": "18032343", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7967:\nURL: https://github.com/apache/hadoop/pull/7967#issuecomment-3435042669\n\n   > Do you want this in 3.4.3? if so do a backport PR ASAP\r\n   \r\n   The previous PR that includes the Apache client changes was also not included in release 3.4.3. We\u2019re planning to include this change in the next major release.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T04:38:43.011+0000", "updated": "2025-10-23T04:38:43.011+0000"}], "maxResults": 27, "total": 27, "startAt": 0}, "updated": "2025-10-23T04:38:43.000+0000", "created": "2025-09-01T10:54:52.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627731", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627731", "key": "HADOOP-19671", "fields": {"summary": "Migrate to AssertJ for Assertion Verification", "description": "Currently, the unit tests in the project do not fully leverage modern assertion capabilities, resulting in lower readability and maintainability of the test code. To improve test clarity and extensibility, we plan to migrate the existing assertion library to {*}AssertJ{*}.\r\n\r\n\u00a0\r\n\r\n*Objective:*\r\n * Migrate all assertions in existing tests from JUnit or other assertion libraries to AssertJ.\r\n\r\n * Utilize AssertJ\u2019s rich assertion methods (e.g., fluent API, more readable assertions) to enhance the expressiveness of unit tests.\r\n\r\n * Ensure that all existing unit tests continue to run correctly after migration.\r\n\r\n\u00a0\r\n\r\n*Implementation Steps:*\r\n # Analyze existing unit test code to identify assertions that need to be replaced.\r\n\r\n # Replace existing assertions with AssertJ assertion syntax.\r\n\r\n # Run unit tests to ensure the tests pass and function correctly after migration.\r\n\r\n # Update relevant documentation to ensure the team is aware of how to use AssertJ for assertions.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627731/comment/18017153", "id": "18017153", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=slfan1989", "name": "slfan1989", "key": "slfan1989", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=slfan1989&avatarId=40935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=slfan1989&avatarId=40935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=slfan1989&avatarId=40935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=slfan1989&avatarId=40935"}, "displayName": "Shilun Fan", "active": true, "timeZone": "America/Vancouver"}, "body": "[~stevel@apache.org]\u00a0The JUnit 5 upgrade for Hadoop is nearing completion, and I will soon initiate a new upgrade plan to migrate the unit tests to AssertJ in order to improve test readability and maintainability.\r\n\u00a0\r\n\u00a0We need to establish a new set of unit testing standards. If you have any relevant suggestions or rules, feel free to share.\r\n\u00a0\r\n\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=slfan1989", "name": "slfan1989", "key": "slfan1989", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=slfan1989&avatarId=40935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=slfan1989&avatarId=40935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=slfan1989&avatarId=40935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=slfan1989&avatarId=40935"}, "displayName": "Shilun Fan", "active": true, "timeZone": "America/Vancouver"}, "created": "2025-08-30T06:36:38.342+0000", "updated": "2025-08-30T06:39:18.991+0000"}], "maxResults": 1, "total": 1, "startAt": 0}, "updated": "2025-08-30T06:39:18.000+0000", "created": "2025-08-30T06:33:03.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627643", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627643", "key": "HADOOP-19670", "fields": {"summary": "Replace Thread with SubjectPreservingThread", "description": null, "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-24T16:11:48.000+0000", "created": "2025-08-29T08:22:44.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627641", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627641", "key": "HADOOP-19669", "fields": {"summary": "Update Daemon to restore pre JDK22 Subject behaviour in Threads", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627641/comment/18019346", "id": "18019346", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "body": "Merged into HADOOP-196668", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stoty", "name": "stoty", "key": "stoty", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stoty&avatarId=42544", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stoty&avatarId=42544", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stoty&avatarId=42544", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stoty&avatarId=42544"}, "displayName": "Istvan Toth", "active": true, "timeZone": "Europe/Budapest"}, "created": "2025-09-10T13:21:24.017+0000", "updated": "2025-09-10T13:21:24.017+0000"}], "maxResults": 1, "total": 1, "startAt": 0}, "updated": "2025-09-10T13:21:24.000+0000", "created": "2025-08-29T07:57:27.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627637", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627637", "key": "HADOOP-19668", "fields": {"summary": "Add SubjectInheritingThread to restore pre JDK22 Subject behaviour in Threads", "description": "This is the first part of HADOOP-19574 which adds the compatibility code, and fixes Daemon, but does not replace native Thread instances.\r\n", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-10T13:21:24.000+0000", "created": "2025-08-29T07:23:38.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627442", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627442", "key": "HADOOP-19667", "fields": {"summary": "Clarify legal value constraints for hadoop.security.crypto.buffer.size (min=512; floor to cipher block size)", "description": "In core-default.xml, the property hadoop.security.crypto.buffer.size is currently documented as \u201cThe buffer size used by CryptoInputStream and CryptoOutputStream.\u201d It does not specify the legal value constraints.\r\n{code:java}\r\n<property>\u00a0 \r\n<name>hadoop.security.crypto.buffer.size</name>\u00a0 \r\n<value>8192</value>\u00a0 \r\n<description>The buffer size used by CryptoInputStream and CryptoOutputStream.\u00a0 </description>\r\n</property> {code}\r\nThe runtime enforces two hidden constraints that are not documented:\r\n1. Minimum value is 512 bytes. Values below 512 cause IllegalArgumentException at stream construction time.\r\n2. Block-size flooring: The effective buffer size is floored to a multiple of the cipher algorithm\u2019s block size (e.g., 16 bytes for AES/CTR/NoPadding).\r\n\r\nAs a result, users may be surprised that:\r\n1. Setting a value like 4100 results in an actual capacity of 4096.\r\n2. Setting values <512 fails fast with IllegalArgumentException.\r\n\r\n*Expected*\r\ncore-default.xml (and user-facing docs) should explicitly document:\r\n1. Minimum legal value: 512 bytes.\r\n\r\n2. The effective value is floored to the nearest multiple of the cipher algorithm block size (e.g., 16 for AES).", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627442/comment/18016483", "id": "18016483", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "please provide a pull request in trunk which updates the file with the relevant information.\r\nhadoop-hdfs-project/hadoop-hdfs/src/site/markdown/TransparentEncryption.md", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-08-27T10:22:23.035+0000", "updated": "2025-08-27T10:22:23.035+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627442/comment/18016534", "id": "18016534", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "zzz0706 opened a new pull request, #7907:\nURL: https://github.com/apache/hadoop/pull/7907\n\n   ### Description of PR\r\n   \r\n   Docs-only change to **TransparentEncryption.md** clarifying the hidden constraints for\r\n   `hadoop.security.crypto.buffer.size`:\r\n   \r\n   - **Minimum value is 512 bytes** (values <512 throw `IllegalArgumentException` at stream construction).\r\n   - **Block alignment:** the effective value is **floored** to the nearest multiple of the cipher algorithm\r\n     **block size** (e.g., 16 for AES/CTR/NoPadding). Examples: `4100 -> 4096`, `8195 -> 8192`.\r\n   \r\n   This is a minimal wording update (single-sentence addition) to avoid operator surprise, with no behavior change.\r\n   \r\n   **Target branch:** `trunk` (per contributor guide)\r\n   \r\n   **JIRA:** HADOOP-19667\r\n   \r\n   **Files changed:**\r\n   - `hadoop-hdfs-project/hadoop-hdfs/src/site/markdown/TransparentEncryption.md`\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   - Docs-only; built site/module locally to validate formatting:\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T12:46:00.053+0000", "updated": "2025-08-27T12:46:00.053+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627442/comment/18016539", "id": "18016539", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=AMC-team", "name": "AMC-team", "key": "amc-team", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"}, "displayName": "AMC-team", "active": true, "timeZone": "Etc/UTC"}, "body": "Thanks for the guidance. I\u2019ve opened a PR against trunk updating the requested file.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=AMC-team", "name": "AMC-team", "key": "amc-team", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"}, "displayName": "AMC-team", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T12:54:59.439+0000", "updated": "2025-08-27T12:54:59.439+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627442/comment/18016568", "id": "18016568", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7907:\nURL: https://github.com/apache/hadoop/pull/7907#issuecomment-3228575609\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  77m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m  4s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 27s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 134m 51s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7907/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7907 |\r\n   | JIRA Issue | HADOOP-19667 |\r\n   | Optional Tests | dupname asflicense mvnsite codespell detsecrets markdownlint |\r\n   | uname | Linux 04003553fdc2 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ce5422f5a2696efe7d65ae74ebcb3413fe33abde |\r\n   | Max. process+thread count | 667 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7907/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T15:02:06.351+0000", "updated": "2025-08-27T15:02:06.351+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "updated": "2025-08-27T15:02:06.000+0000", "created": "2025-08-27T10:08:02.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627413", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627413", "key": "HADOOP-19666", "fields": {"summary": "Add hardware-accelerated CRC32 support for riscv64 using the v,zbc,zvbc extension", "description": "This PR implements vector-accelerated CRC32 using the RISC-V V, Zbc and Zvbc\r\ninstruction sets, with full functional verification and performance testing completed.\r\n\r\nThe implementation uses the vclmul.v and vclmulh.v (carry-less multiply) instructions for data folding and computes the final checksum via Barrett reduction.\r\n\r\nKey Features: \r\n1. Runtime Hardware Detection\r\nThe PR uses kernel hardware probing and cpuinfo parsing to dynamically detect hardware support for CRC32 acceleration (via v, zbc, and zvbc extensions) at runtime.\r\n\r\n2. Performance Improvement\r\nHardware-accelerated CRC32 achieves a performance boost of over *3x* compared to the software implementation.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18016705", "id": "18016705", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leiwen2025 opened a new pull request, #7912:\nURL: https://github.com/apache/hadoop/pull/7912\n\n   This PR implements vector-accelerated CRC32 using the RISC-V V, Zbc and Zvbc\r\n   instruction sets, with full functional verification and performance testing completed.\r\n   \r\n   The implementation uses the vclmul.v and vclmulh.v (carry-less multiply) instructions for data folding and computes the final checksum via Barrett reduction.\r\n   \r\n   Key Features:\r\n   1. Runtime Hardware Detection\r\n   The PR uses kernel hardware probing and cpuinfo parsing to dynamically detect hardware support for CRC32 acceleration (via v, zbc, and zvbc extensions) at runtime.\r\n   \r\n   2. Performance Improvement\r\n   Hardware-accelerated CRC32 achieves a performance boost of over **3X** compared to the software implementation.\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T06:49:54.702+0000", "updated": "2025-08-28T06:49:54.702+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18016732", "id": "18016732", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7912:\nURL: https://github.com/apache/hadoop/pull/7912#issuecomment-3232576752\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  13m  5s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   7m 30s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 29s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/1/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  56m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |   7m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |   7m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |   7m  3s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/1/artifact/out/blanks-eol.txt) |  The patch has 20 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-tabs.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/1/artifact/out/blanks-tabs.txt) |  The patch 2 line(s) with tabs.  |\r\n   | -1 :x: |  mvnsite  |   1m 29s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/1/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  22m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  19m 44s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 123m  6s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7912 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux 3c797fab6900 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 67c832e1dc930b52b9a68c261f372b14e6cf1639 |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/1/testReport/ |\r\n   | Max. process+thread count | 1262 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/1/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T08:54:04.337+0000", "updated": "2025-08-28T08:54:04.337+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18016787", "id": "18016787", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7912:\nURL: https://github.com/apache/hadoop/pull/7912#issuecomment-3233497529\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   7m 37s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 30s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/2/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  57m 17s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   6m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |   6m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |   6m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |   6m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 29s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/2/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  23m 35s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  19m 38s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 111m 26s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7912 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux 9af82b84cde2 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / be2c9c5dfefc7f4ad7591c58f7857b177bef5b0e |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/2/testReport/ |\r\n   | Max. process+thread count | 3150 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7912/2/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T13:24:50.096+0000", "updated": "2025-08-28T13:24:50.096+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18030240", "id": "18030240", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leiwen2025 commented on PR #7912:\nURL: https://github.com/apache/hadoop/pull/7912#issuecomment-3409341544\n\n   @steveloughran @ayushtkn Hi, this PR has been open for a while. Could you please take a look when you have time? Thanks!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T06:18:04.852+0000", "updated": "2025-10-16T06:18:04.852+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18030699", "id": "18030699", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7912:\nURL: https://github.com/apache/hadoop/pull/7912#issuecomment-3416334594\n\n   It's been a long time since I did C code, I'll have to stare at this a while.\r\n   \r\n   In #7903 that creation of the file bulk_crc32_riscv.c should be what the new code goes into; work with @PeterPtroc to get something you are both happy with *and tested*.\r\n   \r\n   Having two people who are set up to build and test this on riscv hardware is exactly what we need to get this done\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-17T16:46:45.561+0000", "updated": "2025-10-17T16:46:45.561+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18030700", "id": "18030700", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "how does this differ from HADOOP-19655? I think that PR got there just before this one, so takes precedence number-wise; I'm not in a position to evaluate the code.\r\n\r\nCan you and [~peterptroc] collaborate on this? I'll give you both credit in the patches", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-17T16:49:52.534+0000", "updated": "2025-10-17T16:49:52.534+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18032989", "id": "18032989", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leiwen2025 commented on PR #7912:\nURL: https://github.com/apache/hadoop/pull/7912#issuecomment-3448014826\n\n   @steveloughran Thanks for the review! I'll be happy to work with @PeterPtroc on this. \r\n   \r\n   If someone in the community could help connect me with Peter, that'd be much appreciated. I'd like to coordinate testing and integration on RISC-V.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-26T04:52:16.381+0000", "updated": "2025-10-26T04:52:16.381+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627413/comment/18032990", "id": "18032990", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=leiwen2025", "name": "leiwen2025", "key": "JIRAUSER310279", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"}, "displayName": "Lei Wen", "active": true, "timeZone": "Etc/UTC"}, "body": "Thanks! This patch implements CRC32 on RISC-V using Zvbc vector instructions, while HADOOP-19655 uses Zbc scalar ones.\r\n\r\nHappy to work together with [~peterptroc] to coordinate and test both implementations.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=leiwen2025", "name": "leiwen2025", "key": "JIRAUSER310279", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"}, "displayName": "Lei Wen", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-26T05:02:39.383+0000", "updated": "2025-10-26T05:02:39.383+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-10-26T05:02:39.000+0000", "created": "2025-08-27T03:08:41.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627372", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627372", "key": "HADOOP-19665", "fields": {"summary": "[kms] Negative hadoop.security.kms.client.encrypted.key.cache.expiry causes KMSClientProvider init failure with generic IllegalArgumentException; ", "description": "When the client-side config hadoop.security.kms.client.encrypted.key.cache.expiry is set to a negative value in core-site.xml, any tool that initializes KMSClientProvider (e.g., KeyShell) fails immediately with:\r\n\r\n{code:java}\r\njava.lang.IllegalArgumentException: expiry must be > 0\r\n    at org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:xxx)\r\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:xxx)\r\n    ...\r\n\r\n{code}\r\n\r\nThis is a controlled failure (JVM doesn\u2019t crash), but the error message does not mention which property and what value triggered it. Users typically see a stack trace without a clear remediation hint.\r\n\r\n*Expected behavior*\r\n\r\nFail fast with a clear configuration error that names the property and value, e.g.:\r\nInvalid configuration: hadoop.security.kms.client.encrypted.key.cache.expiry = -1 (must be > 0 ms)\r\n\r\n*Steps to Reproduce*\r\n1. In the client core-site.xml, set:\r\n\r\n{code:xml}\r\n<property>\r\n  <name>hadoop.security.kms.client.encrypted.key.cache.expiry</name>\r\n  <value>-1</value>\r\n</property>\r\n{code}\r\n2. Ensure the conf is active (echo $HADOOP_CONF_DIR points to this dir).\r\n3. Run:\r\n\r\n{code:java}\r\n./bin/hadoop key list -provider kms://http@localhost:9600/kms -metadata\r\n{code}\r\n", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-09-07T07:39:00.000+0000", "created": "2025-08-26T14:11:12.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627343", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627343", "key": "HADOOP-19664", "fields": {"summary": "S3A Analytics-Accelerator: Move AAL to use Java sync client", "description": "Java sync client is giving the best performance for our use case, especially for readVectored() where a large number of requests can be made concurrently.\u00a0", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18016484", "id": "18016484", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "sync or async?", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-08-27T10:22:53.187+0000", "updated": "2025-08-27T10:22:53.187+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18016496", "id": "18016496", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ahmar", "name": "ahmar", "key": "JIRAUSER283484", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Ahmar Suhail", "active": true, "timeZone": "Etc/UTC"}, "body": "Sync.\u00a0\r\n\r\nIt's using async currently. But the readVectored + AAL use case is not ideal for the async client. As we already have our own thread pool, and each thread is responsible for making a single S3 request, and start reading data from that input stream immediately to fill the internal buffers..\u00a0\r\n\r\nWith the async client, this means you need to join() immediately, and when at a higher concurrency things get stuck in the Netty thread pool and the AsyncResponseTransformer.toBlockingInputStream() of\r\n\r\ns3AsyncClient\r\n.getObject(builder.build(), AsyncResponseTransformer.toBlockingInputStream()).\r\n\u00a0\r\nS3Async client works well (I think) when you have high concurrency but don't need to join on the data immediately, so the netty io pool is sufficient to satisfy those requests.\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ahmar", "name": "ahmar", "key": "JIRAUSER283484", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Ahmar Suhail", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T10:46:31.862+0000", "updated": "2025-08-27T10:46:31.862+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18016497", "id": "18016497", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ahmar", "name": "ahmar", "key": "JIRAUSER283484", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Ahmar Suhail", "active": true, "timeZone": "Etc/UTC"}, "body": "internal benchmarking has been showing a 4-5% improvement with the Sync client consistently.\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ahmar", "name": "ahmar", "key": "JIRAUSER283484", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Ahmar Suhail", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T10:47:13.617+0000", "updated": "2025-08-27T10:47:13.617+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18016563", "id": "18016563", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail opened a new pull request, #7909:\nURL: https://github.com/apache/hadoop/pull/7909\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Moves AAL to use the Java sync client as this is giving us the best performance in internal benchmarks. \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Tested in \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T14:31:16.624+0000", "updated": "2025-08-27T14:31:16.624+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18016564", "id": "18016564", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3228451753\n\n   @steveloughran @mukund-thakur @shameersss1  \r\n   \r\n   small PR to move to AAL to use the Java sync client\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T14:32:07.629+0000", "updated": "2025-08-27T14:32:07.629+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18016591", "id": "18016591", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3228959531\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 23s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 15s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  22m 54s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 28s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 31s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   2m  1s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m  1s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  0s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 58s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 30s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 40s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 25s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 25s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   8m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   2m 25s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/1/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 1 new + 1 unchanged - 0 fixed = 2 total (was 1)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 44s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 56s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 18s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  24m 21s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 25s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   2m 44s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 42s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 130m 37s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7909 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 9825a7b540bf 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 77adf896d34aa6259543a9fc93161a029a208438 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/1/testReport/ |\r\n   | Max. process+thread count | 555 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T16:42:49.941+0000", "updated": "2025-08-27T16:42:49.941+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18017723", "id": "18017723", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "mukund-thakur commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3246075386\n\n   checkstyle failure. \r\n   ./hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/streams/TestStreamFactories.java:26:import software.amazon.awssdk.services.s3.S3AsyncClient;:8: Unused import - software.amazon.awssdk.services.s3.S3AsyncClient. [UnusedImports]\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-02T16:45:16.194+0000", "updated": "2025-09-02T16:45:16.194+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18020326", "id": "18020326", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3291747586\n\n   (oh, and include S3A: in the commit message. THX)\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T11:44:51.277+0000", "updated": "2025-09-15T11:44:51.277+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18020629", "id": "18020629", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3297498659\n\n   Test results are all good, except the known `ITestS3AContractOpen>AbstractContractOpenTest.testInputStreamReadNegativePosition` failure. Will merge. \r\n   \r\n   I don't see any failures in ITestS3AContractAnalyticsStreamVectoredRead that Steve saw in the SDK upgrade PR: https://github.com/apache/hadoop/pull/7882, will take a look at that separately. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T10:23:45.793+0000", "updated": "2025-09-16T10:23:45.793+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18020631", "id": "18020631", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail merged PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T10:27:06.818+0000", "updated": "2025-09-16T10:27:06.818+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18020653", "id": "18020653", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3298248022\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 28s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |  26m 11s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/2/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  compile  |   9m  1s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 18s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 51s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 48s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 24s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  23m 50s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 25s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   9m  8s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   9m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 15s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   8m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   2m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 49s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 48s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  23m 47s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 18s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   2m 19s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 136m 42s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7909 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux f17818206b60 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 112594c60b788e6c2f51021c0bcd017b3e0467ed |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/2/testReport/ |\r\n   | Max. process+thread count | 554 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T12:00:18.599+0000", "updated": "2025-09-16T12:00:18.599+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18020657", "id": "18020657", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3298290502\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  2s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  26m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   9m 31s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 14s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   2m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 50s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 44s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 24s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  23m 13s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 25s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   9m  5s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   9m  5s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  2s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   8m  2s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   2m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 47s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 45s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 20s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  22m 46s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 26s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   2m 42s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 45s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 135m 27s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7909 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 304e885133c5 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 65d16df11981860e9a6ef04a84e13672d7bb1ee3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/3/testReport/ |\r\n   | Max. process+thread count | 553 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7909/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T12:05:33.362+0000", "updated": "2025-09-16T12:05:33.362+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627343/comment/18020964", "id": "18020964", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7909:\nURL: https://github.com/apache/hadoop/pull/7909#issuecomment-3304093797\n\n   @ahmarsuhail can you do a followup to add the library to LICENSE-binary? thanks\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T18:19:37.735+0000", "updated": "2025-09-17T18:19:37.735+0000"}], "maxResults": 13, "total": 13, "startAt": 0}, "updated": "2025-09-18T13:22:04.000+0000", "created": "2025-08-26T10:26:15.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627337", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627337", "key": "HADOOP-19663", "fields": {"summary": "Add RISC-V build infrastructure and placeholder implementation for CRC32 acceleration", "description": "Establish the foundational build infrastructure for RISC-V CRC32 hardware acceleration support while maintaining full backward compatibility with existing software implementations.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18016359", "id": "18016359", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc opened a new pull request, #7903:\nURL: https://github.com/apache/hadoop/pull/7903\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Add a RISC-V-specific compilation unit: org/apache/hadoop/util/bulk_crc32_riscv.c.\r\n   \r\n   - Contains a no-op constructor reserved for future HW capability detection and dispatch.\r\n   - Keeps runtime behavior unchanged (falls back to the generic software path in bulk_crc32.c).\r\n   - Wire CMake to select bulk_crc32_riscv.c on riscv32/riscv64, mirroring other platforms.\r\n   \r\n   This PR establishes the foundational build infrastructure for future RISC-V Zbc (CLMUL) CRC32/CRC32C acceleration without changing current behavior. Follow-ups (HADOOP-19655) will introduce HW-accelerated implementations and runtime dispatch.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   - Ensured native build for hadoop-common compiles cleanly with RISC-V selection.\r\n   - Verified by test_bulk_crc32.\r\n   - No new tests added, as this patch is scaffolding-only without any behavior change.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [x] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T17:53:40.969+0000", "updated": "2025-08-26T17:53:40.969+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18016382", "id": "18016382", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3225752648\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m 29s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  14m 21s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 56s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/1/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  94m 44s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |  13m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |  13m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  13m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 54s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/1/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 33s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 54s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 57s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 198m 14s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7903 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux af19edaaec5b 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 1b159b6f8fadc7e4229a3aa0eeaa184b6d2f25cc |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/1/testReport/ |\r\n   | Max. process+thread count | 1279 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/1/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T21:13:49.505+0000", "updated": "2025-08-26T21:13:49.505+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18016425", "id": "18016425", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3226747056\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m  2s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  14m  4s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 55s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/2/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  94m 56s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |  13m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |  13m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  13m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 57s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/2/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 42s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 39s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 53s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 176m 33s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7903 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux c0759ac9ab3e 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3d607d41a2a311260c28800135009dfca09fb4f3 |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/2/testReport/ |\r\n   | Max. process+thread count | 2145 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/2/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T05:05:23.656+0000", "updated": "2025-08-27T05:05:23.656+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18016588", "id": "18016588", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3228926064\n\n   Due to some CI infrastructure issues, I will paste the result of validating this patch on a RISC-V machine. Below are the command and the results.\r\n   \r\n   Command\uff1a \r\n   \r\n   ```\r\n   mvn -Pnative \\\r\n     -Dtest=org.apache.hadoop.util.TestNativeCrc32 \\\r\n     -Djava.library.path=\"$HADOOP_COMMON_LIB_NATIVE_DIR\" \\\r\n     test\r\n   ```\r\n   \r\n   Results\r\n   \r\n   ```\r\n   [INFO] -------------------------------------------------------\r\n   [INFO]  T E S T S\r\n   [INFO] -------------------------------------------------------\r\n   [INFO] Running org.apache.hadoop.util.TestNativeCrc32\r\n   [INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.72 s ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T16:32:31.265+0000", "updated": "2025-08-27T16:32:31.265+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18016592", "id": "18016592", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3228966982\n\n   Hi @pan3793 @slfan1989 , could you please take a look when you have a moment? This PR adds RISC-V CRC32 scaffolding and keeps behavior unchanged. Happy to address any feedback. Thanks!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T16:45:34.024+0000", "updated": "2025-08-27T16:45:34.024+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18016715", "id": "18016715", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3232286543\n\n   @PeterPtroc I suppose most developers here do not have RISC-V env, is it possible to have a docs about how to verify it by leveraging QEMU or some common tools?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T07:31:11.011+0000", "updated": "2025-08-28T07:31:11.011+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18016942", "id": "18016942", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3235836592\n\n   \r\n   @pan3793 Thanks for the suggestion! Below is a concise doc to verify the correctness of the crc32riscv implementation:\r\n   \r\n   I mainly verify on RISC\u2011V by using QEMU together with the openEuler RISC\u2011V image.\r\n   \r\n   Download the image\r\n   - https://dl-cdn.openeuler.openatom.cn/openEuler-25.03/virtual_machine_img/riscv64/\r\n   \r\n   For me, from the above link, download these four files: RISCV_VIRT_CODE.fd, RISCV_VIRT_VARS.fd, openEuler-25.03-riscv64.qcow2.xz, and start_vm.sh; then log in as root with the password: openEuler12#$.\r\n   \r\n   Install required packages\r\n   ````bash\r\n   yum install -y gcc gcc-c++ gcc-gfortran libgcc cmake\r\n   yum install -y wget openssl openssl-devel zlib zlib-devel automake libtool make libstdc++-static glibc-static git snappy snappy-devel fuse fuse-devel doxygen clang cyrus-sasl cyrus-sasl-devel libtirpc libtirpc-devel\r\n   yum install -y java-17-openjdk.riscv64 java-17-openjdk-devel.riscv64 java-17-openjdk-headless.riscv64\r\n   ````\r\n   \r\n   Install Protobuf 2.5.0 (with RISC\u2011V patches)\r\n   ````bash\r\n   mkdir protobuf && cd protobuf\r\n   \r\n   # Fetch sources\r\n   git clone https://gitee.com/src-openeuler/protobuf2.git\r\n   cd protobuf2\r\n   tar -xjf protobuf-2.5.0.tar.bz2\r\n   cp *.patch protobuf-2.5.0 && cd protobuf-2.5.0\r\n   \r\n   # Apply patches (adds riscv64 support and build fixes)\r\n   patch -p1 < 0001-Add-generic-GCC-support-for-atomic-operations.patch\r\n   patch -p1 < protobuf-2.5.0-gtest.patch\r\n   patch -p1 < protobuf-2.5.0-java-fixes.patch\r\n   patch -p1 < protobuf-2.5.0-makefile.patch\r\n   patch -p1 < add-riscv64-support.patch\r\n   \r\n   # Autotools setup\r\n   libtoolize\r\n   yum install -y automake\r\n   automake-1.17 -a\r\n   chmod +x configure\r\n   \r\n   # Configure, build, install\r\n   ./configure --build=riscv64-unknown-linux --prefix=/usr/local/protobuf-2.5.0\r\n   make\r\n   make check\r\n   make install\r\n   ldconfig\r\n   \r\n   # Publish protoc 2.5.0 into local Maven repo (riscv64 classifier)\r\n   mvn install:install-file \\\r\n     -DgroupId=com.google.protobuf \\\r\n     -DartifactId=protoc \\\r\n     -Dversion=2.5.0 \\\r\n     -Dclassifier=linux-riscv64 \\\r\n     -Dpackaging=exe \\\r\n     -Dfile=/usr/local/protobuf-2.5.0/bin/protoc\r\n   \r\n   cd ..\r\n   ````\r\n   \r\n   Install Protobuf 3.25.5\r\n   ````bash\r\n   # Download and unpack\r\n   wget -c https://github.com/protocolbuffers/protobuf/releases/download/v25.5/protobuf-25.5.tar.gz\r\n   tar -xzf protobuf-25.5.tar.gz\r\n   cd protobuf-25.5\r\n   \r\n   # Abseil dependency\r\n   git clone https://github.com/abseil/abseil-cpp third_party/abseil-cpp\r\n   \r\n   # Configure and build\r\n   cmake ./ \\\r\n     -DCMAKE_BUILD_TYPE=RELEASE \\\r\n     -Dprotobuf_BUILD_TESTS=off \\\r\n     -DCMAKE_CXX_STANDARD=20 \\\r\n     -DCMAKE_INSTALL_PREFIX=/usr/local/protobuf-3.25.5\r\n   \r\n   make install -j \"$(nproc)\"\r\n   \r\n   # Publish protoc 3.25.5 into local Maven repo (riscv64 classifier)\r\n   mvn install:install-file \\\r\n     -DgroupId=com.google.protobuf \\\r\n     -DartifactId=protoc \\\r\n     -Dversion=3.25.5 \\\r\n     -Dclassifier=linux-riscv64 \\\r\n     -Dpackaging=exe \\\r\n     -Dfile=/usr/local/protobuf-3.25.5/bin/protoc\r\n   \r\n   # Make protoc available on PATH and verify\r\n   sudo ln -sfn /usr/local/protobuf-3.25.5/bin/protoc /usr/local/bin/protoc\r\n   protoc --version\r\n   ````\r\n   \r\n   Verify CRC32 using Hadoop native\r\n   ````bash\r\n   # Clone Hadoop\r\n   git clone https://github.com/apache/hadoop.git\r\n   cd hadoop\r\n   \r\n   # Increase Maven memory\r\n   export MAVEN_OPTS=\"-Xmx8g -Xms6g\"\r\n   \r\n   # Build Hadoop Common (native enabled)\r\n   nohup mvn -pl hadoop-common-project/hadoop-common -am -Pnative -DskipTests clean install > build.log 2>&1 &\r\n   \r\n   # Point to built native library directory\r\n   export HADOOP_COMMON_LIB_NATIVE_DIR=\"$PWD/hadoop-common-project/hadoop-common/target/native/target/usr/local/lib\"\r\n   export LD_LIBRARY_PATH=\"$HADOOP_COMMON_LIB_NATIVE_DIR:$LD_LIBRARY_PATH\"\r\n   \r\n   # Run the CRC32 native test\r\n   nohup mvn -Pnative -Dtest=org.apache.hadoop.util.TestNativeCrc32 \\\r\n     -Djava.library.path=\"$HADOOP_COMMON_LIB_NATIVE_DIR\" test > test.log 2>&1 &\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:07:14.966+0000", "updated": "2025-08-29T06:07:14.966+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18017262", "id": "18017262", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3240157752\n\n   Hi @cnauroth , could you please have a look? This PR adds RISC-V CRC32 scaffolding and keeps behavior unchanged. Thanks!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-31T13:46:15.112+0000", "updated": "2025-08-31T13:46:15.112+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18018977", "id": "18018977", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3269017471\n\n   Hi @brumi1024 , this PR has been open for a while. Could you please take a look when you have time? Thanks!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-09T06:10:23.636+0000", "updated": "2025-09-09T06:10:23.636+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18019535", "id": "18019535", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3279207867\n\n   @steveloughran\u00a0\r\n   Hi, this PR has been open for a while. Could you please take a look when you have time? Thanks!\r\n   \r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T08:38:26.699+0000", "updated": "2025-09-11T08:38:26.699+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028415", "id": "18028415", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#discussion_r2414452670\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/util/bulk_crc32_riscv.c:\n##########\n@@ -0,0 +1,39 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/**\n+ * RISC-V CRC32 hardware acceleration (placeholder)\n+ *\n+ * Phase 1: provide a RISC-V-specific compilation unit that currently makes\n+ * no runtime changes and falls back to the generic software path in\n+ * bulk_crc32.c. Future work will add Zbc-based acceleration and runtime\n+ * dispatch.\n+ */\n+\n+#include <assert.h>\n+#include <stddef.h> // for size_t\n+\n+#include \"bulk_crc32.h\"\n+#include \"gcc_optimizations.h\"\n+\n+/* Constructor hook reserved for future HW capability detection and\n+ * function-pointer dispatch. Intentionally a no-op for the initial phase. */\n+void __attribute__((constructor)) init_riscv_crc_support(void)\n+{\n+  /* No-op: keep using the default software implementations. */\n+}\n\nReview Comment:\n   nit: add a newline\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T16:42:39.554+0000", "updated": "2025-10-08T16:42:39.554+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028535", "id": "18028535", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on code in PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#discussion_r2415703394\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/util/bulk_crc32_riscv.c:\n##########\n@@ -0,0 +1,39 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/**\n+ * RISC-V CRC32 hardware acceleration (placeholder)\n+ *\n+ * Phase 1: provide a RISC-V-specific compilation unit that currently makes\n+ * no runtime changes and falls back to the generic software path in\n+ * bulk_crc32.c. Future work will add Zbc-based acceleration and runtime\n+ * dispatch.\n+ */\n+\n+#include <assert.h>\n+#include <stddef.h> // for size_t\n+\n+#include \"bulk_crc32.h\"\n+#include \"gcc_optimizations.h\"\n+\n+/* Constructor hook reserved for future HW capability detection and\n+ * function-pointer dispatch. Intentionally a no-op for the initial phase. */\n+void __attribute__((constructor)) init_riscv_crc_support(void)\n+{\n+  /* No-op: keep using the default software implementations. */\n+}\n\nReview Comment:\n   thanks, a newline has been added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T06:32:24.343+0000", "updated": "2025-10-09T06:32:24.343+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028545", "id": "18028545", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3384419165\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  31m 41s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 35s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   0m 34s | [/branch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/branch-compile-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  mvnsite  |   0m 35s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   3m 12s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 34s | [/patch-mvninstall-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/patch-mvninstall-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 34s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  cc  |   0m 34s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  golang  |   0m 34s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  javac  |   0m 34s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   0m 35s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   1m 52s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 34s | [/patch-unit-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 34s |  |  ASF License check generated no output?  |\r\n   |  |   |  41m  2s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7903 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux 9c4b8be6f414 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / d4a02dc4d4cdadab4fab43b36f756826e4ace9ba |\r\n   | Default Java | Red Hat, Inc.-1.8.0_462-b08 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/testReport/ |\r\n   | Max. process+thread count | 29 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/3/console |\r\n   | versions | git=2.43.7 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T07:05:15.784+0000", "updated": "2025-10-09T07:05:15.784+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028555", "id": "18028555", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3384529552\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 44s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   1m  8s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   1m  9s | [/branch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/branch-compile-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  mvnsite  |   0m 37s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   4m 24s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 26s | [/patch-mvninstall-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/patch-mvninstall-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 28s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  cc  |   0m 28s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  golang  |   0m 28s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  javac  |   0m 28s | [/patch-compile-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/patch-compile-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 31s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | -1 :x: |  shadedclient  |   2m 54s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 37s | [/patch-unit-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 37s |  |  ASF License check generated no output?  |\r\n   |  |   |  12m  9s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7903 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux c62a15e0c2ed 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 8fee308fe2f2e2eaf4cc8631fc41b9bcd471609d |\r\n   | Default Java | Red Hat, Inc.-1.8.0_462-b08 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/testReport/ |\r\n   | Max. process+thread count | 51 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7903/4/console |\r\n   | versions | git=2.43.7 maven=3.9.11 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T07:30:38.009+0000", "updated": "2025-10-09T07:30:38.009+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028556", "id": "18028556", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3384544541\n\n   It seems the CI failure (unable to create new native thread) is due to a resource issue on the build agent, not related to the code changes.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T07:35:36.939+0000", "updated": "2025-10-09T07:35:36.939+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028766", "id": "18028766", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T13:17:13.230+0000", "updated": "2025-10-09T13:17:13.230+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028768", "id": "18028768", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3385847214\n\n   Merged\r\n   * Ignored the CI failure; it does that sometimes, and as your code is #ifdef'd out, I'm not worried. Anything bigger and we'd have to retry the CI run\r\n   * added a [RISC-V] category for this change -if future work does the same then it'll be consistent.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T13:20:48.914+0000", "updated": "2025-10-09T13:20:48.914+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627337/comment/18028791", "id": "18028791", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7903:\nURL: https://github.com/apache/hadoop/pull/7903#issuecomment-3386121381\n\n   Thanks @pan3793 @steveloughran for the review and the merge!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-09T14:21:49.651+0000", "updated": "2025-10-09T14:21:49.651+0000"}], "maxResults": 18, "total": 18, "startAt": 0}, "updated": "2025-10-09T14:21:49.000+0000", "created": "2025-08-26T09:30:19.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627332", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627332", "key": "HADOOP-19662", "fields": {"summary": " Remove duplicate include of gcc_optimizations.h in bulk_crc32_x86.c", "description": "## Description\r\n\u00a0\r\nThere is a duplicate include statement for `gcc_optimizations.h` in `bulk_crc32_x86.c` at lines 29-30.\r\n\r\n## Current Code\r\n```c\r\n#include \"gcc_optimizations.h\"\r\n#include \"gcc_optimizations.h\"\r\n```", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627332/comment/18016237", "id": "18016237", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc opened a new pull request, #7899:\nURL: https://github.com/apache/hadoop/pull/7899\n\n   \u2026_crc32_x86.c\r\n   \r\n   Removes duplicate #include \"gcc_optimizations.h\" statement.\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Removes duplicate include statement for `gcc_optimizations.h` in `bulk_crc32_x86.c`.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   - [x] Code compiles without issues\r\n   - [x] No functional changes expected\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T09:08:56.073+0000", "updated": "2025-08-26T09:08:56.073+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627332/comment/18016288", "id": "18016288", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7899:\nURL: https://github.com/apache/hadoop/pull/7899#issuecomment-3224065363\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  28m 36s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  47m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 57s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 50s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/1/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  | 107m 57s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |  14m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |  14m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  14m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 54s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/1/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 43s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 14s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 57s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 223m 13s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7899 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux e8837fccd16c 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c1d9fb6a820785db99554892fe312f5135201bf3 |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/1/testReport/ |\r\n   | Max. process+thread count | 1253 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/1/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T12:55:07.682+0000", "updated": "2025-08-26T12:55:07.682+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627332/comment/18016290", "id": "18016290", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc commented on PR #7899:\nURL: https://github.com/apache/hadoop/pull/7899#issuecomment-3224106808\n\n   I'll push an empty commit to re-run the tests.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T13:07:18.179+0000", "updated": "2025-08-26T13:07:18.179+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627332/comment/18016345", "id": "18016345", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7899:\nURL: https://github.com/apache/hadoop/pull/7899#issuecomment-3224890091\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 34s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 57s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/2/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  | 103m 45s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |  14m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |  14m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  14m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 53s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/2/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 24s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m  9s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 57s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 190m 57s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7899 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux 4cb5f960ad43 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7baa586bb254bf11e9f074aaae0aebb1ddca3f87 |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/2/testReport/ |\r\n   | Max. process+thread count | 1863 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7899/2/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T16:23:08.134+0000", "updated": "2025-08-26T16:23:08.134+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "updated": "2025-08-26T16:23:08.000+0000", "created": "2025-08-26T09:00:41.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627323", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627323", "key": "HADOOP-19661", "fields": {"summary": "Migrate CentOS 8 to Rocky Linux 8 in build env Dockerfile", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016249", "id": "18016249", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7900:\nURL: https://github.com/apache/hadoop/pull/7900\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Rocky Linux is supposed to be a drop-in replacement for the discontinued CentOS. See more details at https://rockylinux.org/about\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   ```\r\n   $ ./start-build-env.sh rockylinux_8\r\n   ...\r\n   \r\n    _   _           _                    ______\r\n   | | | |         | |                   |  _  \\\r\n   | |_| | __ _  __| | ___   ___  _ __   | | | |_____   __\r\n   |  _  |/ _` |/ _` |/ _ \\ / _ \\| '_ \\  | | | / _ \\ \\ / /\r\n   | | | | (_| | (_| | (_) | (_) | |_) | | |/ /  __/\\ V /\r\n   \\_| |_/\\__,_|\\__,_|\\___/ \\___/| .__/  |___/ \\___| \\_(_)\r\n                                 | |\r\n                                 |_|\r\n   \r\n   This is the standard Hadoop Developer build environment.\r\n   This has all the right tools installed required to build\r\n   Hadoop from source.\r\n   \r\n   [chengpan@4af99dc981b9 hadoop]$\r\n   ```\r\n   \r\n   ```\r\n   $ mvn clean install -DskipTests -Pnative -Pyarn-ui -DskipShade\r\n   ...\r\n   [INFO] Reactor Summary for Apache Hadoop Main 3.5.0-SNAPSHOT:\r\n   [INFO]\r\n   [INFO] Apache Hadoop Main ................................. SUCCESS [  0.675 s]\r\n   [INFO] Apache Hadoop Build Tools .......................... SUCCESS [  1.518 s]\r\n   [INFO] Apache Hadoop Project POM .......................... SUCCESS [  0.651 s]\r\n   [INFO] Apache Hadoop Annotations .......................... SUCCESS [  0.686 s]\r\n   [INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [  0.072 s]\r\n   [INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.077 s]\r\n   [INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [  1.476 s]\r\n   [INFO] Apache Hadoop MiniKDC .............................. SUCCESS [  0.316 s]\r\n   [INFO] Apache Hadoop Auth ................................. SUCCESS [  2.002 s]\r\n   [INFO] Apache Hadoop Auth Examples ........................ SUCCESS [  0.535 s]\r\n   [INFO] Apache Hadoop Common ............................... SUCCESS [ 18.943 s]\r\n   [INFO] Apache Hadoop NFS .................................. SUCCESS [  1.071 s]\r\n   [INFO] Apache Hadoop KMS .................................. SUCCESS [  1.085 s]\r\n   [INFO] Apache Hadoop Registry ............................. SUCCESS [  1.282 s]\r\n   [INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.046 s]\r\n   [INFO] Apache Hadoop HDFS Client .......................... SUCCESS [ 10.259 s]\r\n   [INFO] Apache Hadoop HDFS ................................. SUCCESS [ 17.829 s]\r\n   [INFO] Apache Hadoop HDFS Native Client ................... SUCCESS [02:26 min]\r\n   [INFO] Apache Hadoop HttpFS ............................... SUCCESS [  1.772 s]\r\n   [INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  1.020 s]\r\n   [INFO] Apache Hadoop YARN ................................. SUCCESS [  0.041 s]\r\n   [INFO] Apache Hadoop YARN API ............................. SUCCESS [  5.855 s]\r\n   [INFO] Apache Hadoop YARN Common .......................... SUCCESS [  4.910 s]\r\n   [INFO] Apache Hadoop YARN Server .......................... SUCCESS [  0.038 s]\r\n   [INFO] Apache Hadoop YARN Server Common ................... SUCCESS [  3.994 s]\r\n   [INFO] Apache Hadoop YARN ApplicationHistoryService ....... SUCCESS [  1.619 s]\r\n   [INFO] Apache Hadoop YARN Timeline Service ................ SUCCESS [  1.207 s]\r\n   [INFO] Apache Hadoop YARN Web Proxy ....................... SUCCESS [  1.058 s]\r\n   [INFO] Apache Hadoop YARN ResourceManager ................. SUCCESS [ 10.150 s]\r\n   [INFO] Apache Hadoop YARN NodeManager ..................... SUCCESS [ 28.435 s]\r\n   [INFO] Apache Hadoop YARN Server Tests .................... SUCCESS [  1.134 s]\r\n   [INFO] Apache Hadoop YARN Client .......................... SUCCESS [  1.959 s]\r\n   [INFO] Apache Hadoop MapReduce Client ..................... SUCCESS [  0.616 s]\r\n   [INFO] Apache Hadoop MapReduce Core ....................... SUCCESS [  4.440 s]\r\n   [INFO] Apache Hadoop MapReduce Common ..................... SUCCESS [  2.062 s]\r\n   [INFO] Apache Hadoop MapReduce Shuffle .................... SUCCESS [  1.414 s]\r\n   [INFO] Apache Hadoop MapReduce App ........................ SUCCESS [  2.901 s]\r\n   [INFO] Apache Hadoop MapReduce HistoryServer .............. SUCCESS [  1.887 s]\r\n   [INFO] Apache Hadoop MapReduce JobClient .................. SUCCESS [  3.319 s]\r\n   [INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [  1.954 s]\r\n   [INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  1.113 s]\r\n   [INFO] Apache Hadoop Federation Balance ................... SUCCESS [  1.234 s]\r\n   [INFO] Apache Hadoop HDFS-RBF ............................. SUCCESS [  5.733 s]\r\n   [INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop YARN SharedCacheManager .............. SUCCESS [  0.886 s]\r\n   [INFO] Apache Hadoop YARN Timeline Plugin Storage ......... SUCCESS [  0.866 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Backend ... SUCCESS [  0.035 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Common .... SUCCESS [  1.291 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Client .... SUCCESS [  1.709 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Servers ... SUCCESS [  0.036 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Server 2.5  SUCCESS [  1.677 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase tests ..... SUCCESS [  1.493 s]\r\n   [INFO] Apache Hadoop YARN Router .......................... SUCCESS [  1.912 s]\r\n   [INFO] Apache Hadoop YARN TimelineService DocumentStore ... SUCCESS [  1.018 s]\r\n   [INFO] Apache Hadoop YARN GlobalPolicyGenerator ........... SUCCESS [  1.175 s]\r\n   [INFO] Apache Hadoop YARN Applications .................... SUCCESS [  0.036 s]\r\n   [INFO] Apache Hadoop YARN DistributedShell ................ SUCCESS [  1.166 s]\r\n   [INFO] Apache Hadoop YARN Unmanaged Am Launcher ........... SUCCESS [  0.689 s]\r\n   [INFO] Apache Hadoop YARN Services ........................ SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop YARN Services Core ................... SUCCESS [  2.393 s]\r\n   [INFO] Apache Hadoop YARN Services API .................... SUCCESS [  1.552 s]\r\n   [INFO] Apache Hadoop YARN Application Catalog ............. SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop YARN Application Catalog Webapp ...... SUCCESS [ 10.674 s]\r\n   [INFO] Apache Hadoop YARN Application Catalog Docker Image  SUCCESS [  0.046 s]\r\n   [INFO] Apache Hadoop YARN Application MaWo ................ SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop YARN Application MaWo Core ........... SUCCESS [  0.781 s]\r\n   [INFO] Apache Hadoop YARN Site ............................ SUCCESS [  0.036 s]\r\n   [INFO] Apache Hadoop YARN Registry ........................ SUCCESS [  0.439 s]\r\n   [INFO] Apache Hadoop YARN UI .............................. SUCCESS [ 51.592 s]\r\n   [INFO] Apache Hadoop YARN CSI ............................. SUCCESS [  2.776 s]\r\n   [INFO] Apache Hadoop YARN Project ......................... SUCCESS [  1.155 s]\r\n   [INFO] Apache Hadoop MapReduce HistoryServer Plugins ...... SUCCESS [  0.854 s]\r\n   [INFO] Apache Hadoop MapReduce NativeTask ................. SUCCESS [ 19.795 s]\r\n   [INFO] Apache Hadoop MapReduce Uploader ................... SUCCESS [  0.777 s]\r\n   [INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  1.427 s]\r\n   [INFO] Apache Hadoop MapReduce ............................ SUCCESS [  1.079 s]\r\n   [INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [  1.533 s]\r\n   [INFO] Apache Hadoop Client Aggregator .................... SUCCESS [  0.642 s]\r\n   [INFO] Apache Hadoop Dynamometer Workload Simulator ....... SUCCESS [  1.110 s]\r\n   [INFO] Apache Hadoop Dynamometer Cluster Simulator ........ SUCCESS [  2.098 s]\r\n   [INFO] Apache Hadoop Dynamometer Block Listing Generator .. SUCCESS [  0.994 s]\r\n   [INFO] Apache Hadoop Dynamometer Dist ..................... SUCCESS [  1.063 s]\r\n   [INFO] Apache Hadoop Dynamometer .......................... SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop Archives ............................. SUCCESS [  0.908 s]\r\n   [INFO] Apache Hadoop Archive Logs ......................... SUCCESS [  1.125 s]\r\n   [INFO] Apache Hadoop Rumen ................................ SUCCESS [  1.466 s]\r\n   [INFO] Apache Hadoop Gridmix .............................. SUCCESS [  1.450 s]\r\n   [INFO] Apache Hadoop Data Join ............................ SUCCESS [  1.002 s]\r\n   [INFO] Apache Hadoop Extras ............................... SUCCESS [  0.995 s]\r\n   [INFO] Apache Hadoop Pipes ................................ SUCCESS [  3.333 s]\r\n   [INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [  4.599 s]\r\n   [INFO] Apache Hadoop Kafka Library support ................ SUCCESS [  0.636 s]\r\n   [INFO] Apache Hadoop Azure support ........................ SUCCESS [  4.082 s]\r\n   [INFO] Apache Hadoop Aliyun OSS support ................... SUCCESS [  0.878 s]\r\n   [INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  1.312 s]\r\n   [INFO] Apache Hadoop Resource Estimator Service ........... SUCCESS [  0.868 s]\r\n   [INFO] Apache Hadoop Azure Data Lake support .............. SUCCESS [  0.844 s]\r\n   [INFO] Apache Hadoop Image Generation Tool ................ SUCCESS [  0.893 s]\r\n   [INFO] Apache Hadoop Tools Dist ........................... SUCCESS [  0.624 s]\r\n   [INFO] Apache Hadoop OpenStack support .................... SUCCESS [  0.042 s]\r\n   [INFO] Apache Hadoop Common Benchmark ..................... SUCCESS [  9.870 s]\r\n   [INFO] Apache Hadoop Compatibility Benchmark .............. SUCCESS [  0.598 s]\r\n   [INFO] Apache Hadoop Tools ................................ SUCCESS [  0.032 s]\r\n   [INFO] Apache Hadoop Client API ........................... SUCCESS [  0.851 s]\r\n   [INFO] Apache Hadoop Client Runtime ....................... SUCCESS [  0.639 s]\r\n   [INFO] Apache Hadoop Client Packaging Invariants .......... SUCCESS [  0.373 s]\r\n   [INFO] Apache Hadoop Client Test Minicluster .............. SUCCESS [  0.690 s]\r\n   [INFO] Apache Hadoop Client Packaging Invariants for Test . SUCCESS [  0.171 s]\r\n   [INFO] Apache Hadoop Client Packaging Integration Tests ... SUCCESS [  0.639 s]\r\n   [INFO] Apache Hadoop Distribution ......................... SUCCESS [  0.447 s]\r\n   [INFO] Apache Hadoop Client Modules ....................... SUCCESS [  0.032 s]\r\n   [INFO] Apache Hadoop Tencent COS Support .................. SUCCESS [  0.640 s]\r\n   [INFO] Apache Hadoop OBS support .......................... SUCCESS [  1.068 s]\r\n   [INFO] Apache Hadoop Volcano Engine Services support ...... SUCCESS [  1.601 s]\r\n   [INFO] Apache Hadoop Cloud Storage ........................ SUCCESS [  0.401 s]\r\n   [INFO] Apache Hadoop Cloud Storage Project ................ SUCCESS [  0.033 s]\r\n   [INFO] ------------------------------------------------------------------------\r\n   [INFO] BUILD SUCCESS\r\n   [INFO] ------------------------------------------------------------------------\r\n   [INFO] Total time:  07:35 min\r\n   [INFO] Finished at: 2025-08-26T10:05:06Z\r\n   [INFO] ------------------------------------------------------------------------\r\n   [chengpan@4af99dc981b9 hadoop]$\r\n   ```\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T10:06:34.610+0000", "updated": "2025-08-26T10:06:34.610+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016250", "id": "18016250", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3223525111\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   0m 21s |  |  Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7900/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7900 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/1/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T10:10:11.945+0000", "updated": "2025-08-26T10:10:11.945+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016251", "id": "18016251", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3223527763\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   0m 21s |  |  Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7900/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7900 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T10:11:03.527+0000", "updated": "2025-08-26T10:11:03.527+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016252", "id": "18016252", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3223534265\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   0m 21s |  |  Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7900@2/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7900 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/3/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T10:13:18.314+0000", "updated": "2025-08-26T10:13:18.314+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016255", "id": "18016255", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3223579339\n\n   Looks like Yetus finds Dockerfile from the trunk branch instead of the PR branch, I'm not very familiar with this part. If the behavior is not easy to change, I'm afraid this PR must be committed first, then we will know what is going to happen.\r\n   ```\r\n   [2025-08-26T10:13:14.863Z] Already on 'trunk'\r\n   [2025-08-26T10:13:14.863Z] Your branch is up to date with 'origin/trunk'.\r\n   [2025-08-26T10:13:14.863Z] HEAD is now at 9d2a83d18ba HADOOP-19636. [JDK17] Remove CentOS 7 Support and Clean Up Dockerfile. (#7822)\r\n   [2025-08-26T10:13:15.444Z] \r\n   [2025-08-26T10:13:15.444Z] Testing https://github.com/apache/hadoop/pull/7900 patch on trunk.\r\n   [2025-08-26T10:13:15.444Z] ERROR: Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7900@2/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T10:28:15.278+0000", "updated": "2025-08-26T10:28:15.278+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016404", "id": "18016404", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3226472958\n\n   > Looks like Yetus finds Dockerfile from the trunk branch instead of the PR branch, I'm not very familiar with this part. If the behavior is not easy to change, I'm afraid this PR must be committed first, then we will know what is going to happen.\r\n   > \r\n   > ```\r\n   > [2025-08-26T10:13:14.863Z] Already on 'trunk'\r\n   > [2025-08-26T10:13:14.863Z] Your branch is up to date with 'origin/trunk'.\r\n   > [2025-08-26T10:13:14.863Z] HEAD is now at 9d2a83d18ba HADOOP-19636. [JDK17] Remove CentOS 7 Support and Clean Up Dockerfile. (#7822)\r\n   > [2025-08-26T10:13:15.444Z] \r\n   > [2025-08-26T10:13:15.444Z] Testing https://github.com/apache/hadoop/pull/7900 patch on trunk.\r\n   > [2025-08-26T10:13:15.444Z] ERROR: Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7900@2/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.\r\n   > ```\r\n   \r\n   @pan3793 Currently, Hadoop's Yetus performs the build twice: first with the trunk code, and then again after applying the patch. At this point, I\u2019m not certain whether what you pointed out is actually an issue.\r\n   \r\n   @aajisaka @ayushtkn @GauthamBanasandra Could you please take a look at this issue? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T01:54:33.835+0000", "updated": "2025-08-27T01:54:33.835+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016418", "id": "18016418", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "aajisaka commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3226645951\n\n   Would you push the commit to a new branch and then create a test PR based on the branch to check Yetus is working fine?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T03:49:16.555+0000", "updated": "2025-08-27T03:49:16.555+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016420", "id": "18016420", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3226672783\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   0m 20s |  |  Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7900/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7900 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/4/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T04:09:23.192+0000", "updated": "2025-08-27T04:09:23.192+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016421", "id": "18016421", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3226674179\n\n   > Would you push the commit to a new branch and then create a test PR based on the branch to check Yetus is working fine?\r\n   \r\n   @aajisaka I don't have the permission to commit hadoop repo ...\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T04:10:24.957+0000", "updated": "2025-08-27T04:10:24.957+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016427", "id": "18016427", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3226783929\n\n   > > Would you push the commit to a new branch and then create a test PR based on the branch to check Yetus is working fine?\r\n   > \r\n   > @aajisaka I don't have the permission to commit hadoop repo ...\r\n   \r\n   @pan3793 let\u2019s keep the file name unchanged as `Dockerfile_centos_8`. If needed, I can help create a branch.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T05:27:39.920+0000", "updated": "2025-08-27T05:27:39.920+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016479", "id": "18016479", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3227608632\n\n   with the help of @slfan1989, branch `HADOOP-19661` was created at `apache/hadoop` repo, I opened https://github.com/apache/hadoop/pull/7898 targeting branch `HADOOP-19661`, the `Dockerfile_rockylinux_8 not found` issue is gone, but it seems platform change is not detected thus the Docker building test was skipped ...\r\n   \r\n   <img width=\"1201\" height=\"408\" alt=\"image\" src=\"https://github.com/user-attachments/assets/cb8f314b-3c7a-41b0-81ee-cea21d3f04e3\" />\r\n   \r\n   @aajisaka do you have other suggestions?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T10:14:25.105+0000", "updated": "2025-08-27T10:14:25.105+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016672", "id": "18016672", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3231574620\n\n   > with the help of @slfan1989, branch `HADOOP-19661` was created at `apache/hadoop` repo, I opened #7898 targeting branch `HADOOP-19661`, the `Dockerfile_rockylinux_8 not found` issue is gone, but it seems platform change is not detected thus the Docker building test was skipped ...\r\n   > \r\n   > <img alt=\"image\" width=\"1201\" height=\"408\" src=\"https://private-user-images.githubusercontent.com/26535726/482609828-cb8f314b-3c7a-41b0-81ee-cea21d3f04e3.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTYzNDk4ODgsIm5iZiI6MTc1NjM0OTU4OCwicGF0aCI6Ii8yNjUzNTcyNi80ODI2MDk4MjgtY2I4ZjMxNGItM2M3YS00MWIwLTgxZWUtY2VhMjFkM2YwNGUzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODI4VDAyNTMwOFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWJiNTY3MTUzMmY0ZWJlYWIzMTMwODhhODMyNzhlMjcxZGQxNzhiYjcwYzdkNTI1NDU1Zjk0M2U4ZTAwODAyZDgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.8bGH6guvb6ZgikJ021xLnCWaef1WTDj3ge5b1cbxxcA\">\r\n   > @aajisaka do you have other suggestions?\r\n   \r\n   @pan3793 Although we can compile locally, there are some issues with Yetus, so I cannot confirm whether this PR will affect other team members' code submissions. I still need @aajisaka @GauthamBanasandra  to help verify it.\r\n   \r\n   cc: @steveloughran @ayushtkn \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T02:56:24.041+0000", "updated": "2025-08-28T02:56:24.041+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016806", "id": "18016806", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7913:\nURL: https://github.com/apache/hadoop/pull/7913\n\n   (no comment)\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T15:04:37.804+0000", "updated": "2025-08-28T15:04:37.804+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016808", "id": "18016808", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3233914038\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/5/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T15:13:18.068+0000", "updated": "2025-08-28T15:13:18.068+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016831", "id": "18016831", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 closed pull request #7913: DO-NOT-MERGE. HADOOP-19661. Test auxiliary patch\nURL: https://github.com/apache/hadoop/pull/7913\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T16:51:24.734+0000", "updated": "2025-08-28T16:51:24.734+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016841", "id": "18016841", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7913:\nURL: https://github.com/apache/hadoop/pull/7913#issuecomment-3234393664\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m 45s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ HADOOP-19661 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 44s |  |  HADOOP-19661 passed  |\r\n   | +1 :green_heart: |  compile  |   3m 36s |  |  HADOOP-19661 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   3m 36s |  |  HADOOP-19661 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  HADOOP-19661 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  85m  0s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   3m 46s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  cc  |   3m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |   3m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |   3m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   3m 40s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  cc  |   3m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |   3m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |   3m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 19s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  10m  8s |  |  hadoop-hdfs-native-client in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 156m 33s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7913/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7913 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux c6281ba91ece 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | HADOOP-19661 / df44bca1341e8d0b97bc0d7d75bc90fb50ec87b8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7913/1/testReport/ |\r\n   | Max. process+thread count | 553 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-hdfs-project/hadoop-hdfs-native-client U: hadoop-hdfs-project/hadoop-hdfs-native-client |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7913/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T17:42:25.852+0000", "updated": "2025-08-28T17:42:25.852+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016862", "id": "18016862", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3234661592\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  23m 24s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 54s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  | 106m 45s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  | 107m 19s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  34m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  20m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  60m 45s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  16m 17s |  |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 45s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 245m 14s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7900 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint mvnsite unit jsonlint |\r\n   | uname | Linux 5842e2ca7744 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b2e037215b456012892b30f6e4adcca349e53794 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/5/testReport/ |\r\n   | Max. process+thread count | 554 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/5/console |\r\n   | versions | git=2.43.7 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T19:17:17.763+0000", "updated": "2025-08-28T19:17:17.763+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016929", "id": "18016929", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3235763986\n\n   I have to rename it back to workaround the `Dockerfile_rockylinux_8 not found` issue in https://github.com/apache/hadoop/pull/7900/commits/b2e037215b456012892b30f6e4adcca349e53794.\r\n   \r\n   @slfan1989 @aajisaka, please take a look, and ping me to revert the renaming change if you think it's ready to go.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T05:24:07.438+0000", "updated": "2025-08-29T05:24:07.438+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016931", "id": "18016931", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3235795315\n\n   @pan3793 LGTM. I don't see any issues. I checked the compilation results and didn't find any problems.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T05:44:29.801+0000", "updated": "2025-08-29T05:44:29.801+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016932", "id": "18016932", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3235798705\n\n   @cnauroth @stoty Could you please help review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T05:46:46.695+0000", "updated": "2025-08-29T05:46:46.695+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016936", "id": "18016936", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth closed pull request #7900: HADOOP-19661. Migrate CentOS 8 to Rocky Linux 8 in build env Dockerfile\nURL: https://github.com/apache/hadoop/pull/7900\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T05:58:46.311+0000", "updated": "2025-08-29T05:58:46.311+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016937", "id": "18016937", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3235821612\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 20s |  |  https://github.com/apache/hadoop/pull/7900 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7900 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7900/6/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:00:16.413+0000", "updated": "2025-08-29T06:00:16.413+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016938", "id": "18016938", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3235821982\n\n   @cnauroth I need to revert the renaming change before committing to trunk ... let me send a follow up to address it\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:00:27.810+0000", "updated": "2025-08-29T06:00:27.810+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016939", "id": "18016939", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on PR #7900:\nURL: https://github.com/apache/hadoop/pull/7900#issuecomment-3235825803\n\n   > @cnauroth I need to revert the renaming change before committing to trunk ... let me send a follow up to address it\r\n   \r\n   @pan3793 , oops, I committed. :-D LMK, and I'll watch for more patches required.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:02:10.108+0000", "updated": "2025-08-29T06:02:10.108+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016940", "id": "18016940", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7917:\nURL: https://github.com/apache/hadoop/pull/7917\n\n   I have to keep the Dockerfile name to bypass Yetus issue, see discussion in https://github.com/apache/hadoop/pull/7900\r\n   \r\n   But should rename it back before committing to trunk, since the thing has already happened, send a followup to fix it.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:05:34.350+0000", "updated": "2025-08-29T06:05:34.350+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016941", "id": "18016941", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7917:\nURL: https://github.com/apache/hadoop/pull/7917#issuecomment-3235833407\n\n   @cnauroth \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:05:59.876+0000", "updated": "2025-08-29T06:05:59.876+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016943", "id": "18016943", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7917:\nURL: https://github.com/apache/hadoop/pull/7917#issuecomment-3235839287\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   0m 21s |  |  Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7917/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7917 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7917/1/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:08:10.532+0000", "updated": "2025-08-29T06:08:10.532+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016944", "id": "18016944", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7917:\nURL: https://github.com/apache/hadoop/pull/7917#issuecomment-3235842248\n\n   no need to wait for Yetus's report since Yetus will fail with `Dockerfile_rockylinux_8 not found` immediately\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:09:19.849+0000", "updated": "2025-08-29T06:09:19.849+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016945", "id": "18016945", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7917:\nURL: https://github.com/apache/hadoop/pull/7917#issuecomment-3235854584\n\n   @cnauroth I suggest waiting for a day to see if tomorrow's auto-build email triggers RockyLinux_8 completely. If it doesn't trigger properly, we'll look for a solution.\r\n   \r\n   cc: @pan3793\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:15:35.736+0000", "updated": "2025-08-29T06:15:35.736+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016947", "id": "18016947", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7917:\nURL: https://github.com/apache/hadoop/pull/7917#issuecomment-3235873037\n\n   > @cnauroth I suggest waiting for a day to see if tomorrow's auto-build email triggers RockyLinux_8 completely. If it doesn't trigger properly, we'll look for a solution.\r\n   > \r\n   > cc: @pan3793\r\n   \r\n   @cnauroth @pan3793 \r\n   \r\n   After offline discussion with Pan, we've decided to merge this PR for now. If any issues arise, we'll make updates accordingly.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:25:02.988+0000", "updated": "2025-08-29T06:25:02.988+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18016948", "id": "18016948", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7917:\nURL: https://github.com/apache/hadoop/pull/7917\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T06:26:12.421+0000", "updated": "2025-08-29T06:26:12.421+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018110", "id": "18018110", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7931:\nURL: https://github.com/apache/hadoop/pull/7931\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   The issue is identified by https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7760/\r\n   \r\n   ```\r\n   00:08:13                Reason | Tests\r\n   00:08:13   Failed junit tests  |  hadoop.fs.compat.common.TestHdfsCompatShellCommand \r\n   00:08:13                       |  hadoop.fs.compat.common.TestHdfsCompatDefaultSuites \r\n   00:08:13                       |  hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints \r\n   ```\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Manually checked the failed tests after installing the missing deps inside the dev container.\r\n   \r\n   ```\r\n   $ ./start-build-env.sh rockylinux_8\r\n   ```\r\n   \r\n   ```\r\n   $ mvn clean install -DskipTests -Pnative\r\n   ```\r\n   \r\n   ```\r\n   $ mvn test -pl :hadoop-compat-bench -Dtest=hadoop.fs.compat.common.TestHdfsCompatShellCommand\r\n   ...\r\n   [INFO]  T E S T S\r\n   [INFO] -------------------------------------------------------\r\n   [INFO] Running org.apache.hadoop.fs.compat.common.TestHdfsCompatShellCommand\r\n   [INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.64 s ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T12:29:53.237+0000", "updated": "2025-09-04T12:29:53.237+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018129", "id": "18018129", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7931:\nURL: https://github.com/apache/hadoop/pull/7931#issuecomment-3253960302\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  24m  9s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 52s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  44m 17s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 16s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 58s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 106m 24s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7931/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7931 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux e8aea56e1b0c 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2ba58898a54a722abb39526a9e95468802f00470 |\r\n   | Max. process+thread count | 554 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7931/1/console |\r\n   | versions | git=2.43.7 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T14:17:21.800+0000", "updated": "2025-09-04T14:17:21.800+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018143", "id": "18018143", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7931:\nURL: https://github.com/apache/hadoop/pull/7931#issuecomment-3254275709\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  23m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 24s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  26m 23s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 22s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  25m 16s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 33s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  79m  7s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7931/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7931 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 912e624ed05f 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2ba58898a54a722abb39526a9e95468802f00470 |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7931/1/console |\r\n   | versions | git=2.30.2 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T15:36:39.382+0000", "updated": "2025-09-04T15:36:39.382+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018166", "id": "18018166", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7931:\nURL: https://github.com/apache/hadoop/pull/7931#issuecomment-3254585161\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 45s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  34m  5s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  72m 16s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7931/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7931 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 53ab742d41d0 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2ba58898a54a722abb39526a9e95468802f00470 |\r\n   | Max. process+thread count | 561 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7931/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-04T16:49:02.235+0000", "updated": "2025-09-04T16:49:02.235+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018303", "id": "18018303", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7931:\nURL: https://github.com/apache/hadoop/pull/7931\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T06:54:38.920+0000", "updated": "2025-09-05T06:54:38.920+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018304", "id": "18018304", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7931:\nURL: https://github.com/apache/hadoop/pull/7931#issuecomment-3257273745\n\n   @pan3793 Thanks for the contribution! Merged into trunk.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T06:54:55.967+0000", "updated": "2025-09-05T06:54:55.967+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018613", "id": "18018613", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7938:\nURL: https://github.com/apache/hadoop/pull/7938\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   I see some CI starts to fail due to\r\n   \r\n   https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7760/27/console\r\n   \r\n   ```\r\n   23:59:25  58.82 Last metadata expiration check: 0:00:40 ago on Sat Sep  6 15:58:37 2025.\r\n   23:59:25  59.80 No match for argument: bats\r\n   ```\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   ```\r\n   $ ./start-build-env.sh rockylinux_8\r\n   ...\r\n    _   _           _                    ______\r\n   | | | |         | |                   |  _  \\\r\n   | |_| | __ _  __| | ___   ___  _ __   | | | |_____   __\r\n   |  _  |/ _` |/ _` |/ _ \\ / _ \\| '_ \\  | | | / _ \\ \\ / /\r\n   | | | | (_| | (_| | (_) | (_) | |_) | | |/ /  __/\\ V /\r\n   \\_| |_/\\__,_|\\__,_|\\___/ \\___/| .__/  |___/ \\___| \\_(_)\r\n                                 | |\r\n                                 |_|\r\n   \r\n   This is the standard Hadoop Developer build environment.\r\n   This has all the right tools installed required to build\r\n   Hadoop from source.\r\n   \r\n   [chengpan@c79114c5d3d4 hadoop]$\r\n   ```\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T02:13:05.700+0000", "updated": "2025-09-07T02:13:05.700+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018614", "id": "18018614", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3263376365\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7938/1/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T02:15:33.426+0000", "updated": "2025-09-07T02:15:33.426+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018622", "id": "18018622", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3263454078\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  31m 16s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 21s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  52m 11s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 40s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 52s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 128m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7938/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7938 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs |\r\n   | uname | Linux 11b4c3233f9f 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 117e7c2d608809997f7eeb57f6f6a5e924595dc7 |\r\n   | Max. process+thread count | 538 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7938/1/console |\r\n   | versions | git=2.43.7 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T04:22:47.236+0000", "updated": "2025-09-07T04:22:47.236+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018623", "id": "18018623", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3263456222\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7938/1/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T04:24:21.841+0000", "updated": "2025-09-07T04:24:21.841+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018625", "id": "18018625", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3263508181\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 31s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 55s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 31s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  hadolint  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 50s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  85m 13s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7938/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7938 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs |\r\n   | uname | Linux 1632828a4b30 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 117e7c2d608809997f7eeb57f6f6a5e924595dc7 |\r\n   | Max. process+thread count | 525 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7938/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-07T05:48:12.227+0000", "updated": "2025-09-07T05:48:12.227+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18018733", "id": "18018733", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3264759129\n\n   @pan3793 Thank you for your contribution, but I think we still need other members to take another look.\r\n   \r\n   @GauthamBanasandra Could you please help review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-08T06:14:50.064+0000", "updated": "2025-09-08T06:14:50.064+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18019458", "id": "18019458", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3276952959\n\n   @GauthamBanasandra Thanks for helping with the review \u2014 LGTM.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T00:20:09.075+0000", "updated": "2025-09-11T00:20:09.075+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18019459", "id": "18019459", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3276955337\n\n   @pan3793 Thank you for your contribution! If there are no further comments today, this PR will be merged.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T00:21:38.930+0000", "updated": "2025-09-11T00:21:38.930+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18019704", "id": "18019704", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T22:55:52.966+0000", "updated": "2025-09-11T22:55:52.966+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627323/comment/18019705", "id": "18019705", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7938:\nURL: https://github.com/apache/hadoop/pull/7938#issuecomment-3282884265\n\n   @pan3793 Thanks for the contribution! @GauthamBanasandra Thanks for the review!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T22:56:17.304+0000", "updated": "2025-09-11T22:56:17.304+0000"}], "maxResults": 47, "total": 47, "startAt": 0}, "updated": "2025-09-11T22:56:17.000+0000", "created": "2025-08-26T08:04:43.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627314", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627314", "key": "HADOOP-19660", "fields": {"summary": "ABFS: Proposed Enhancement in WorkloadIdentityTokenProvider", "description": "Externally Reported Enhancement:\r\n\r\n*Current Limitation*\r\nThe current WorkloadIdentityTokenProvider implementation works well for file-based token scenarios, but it's tightly coupled to file system operations and cannot be easily extended for alternative token sources\r\n\r\n{*}Use Case{*}:\u00a0*Kubernetes TokenRequest API*\u00a0\r\nIn modern Kubernetes environments, the recommended approach is to use the TokenRequest API to generate short-lived, on-demand service account tokens rather than relying on projected volume mounts.\r\n\r\n*Proposed Enhancement*\u00a0\r\nI propose modifying WorkloadIdentityTokenProvider to accept a Supplier for token retrieval instead of being hardcoded to file operations:", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18016269", "id": "18016269", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=kunalsevkani", "name": "kunalsevkani", "key": "JIRAUSER309200", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"}, "displayName": "Kunal Sevkani", "active": true, "timeZone": "Etc/UTC"}, "body": "[~anujmodi] can you assign this to me?", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=kunalsevkani", "name": "kunalsevkani", "key": "JIRAUSER309200", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"}, "displayName": "Kunal Sevkani", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T12:05:17.557+0000", "updated": "2025-08-26T12:05:17.557+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18016274", "id": "18016274", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=kunalsevkani", "name": "kunalsevkani", "key": "JIRAUSER309200", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"}, "displayName": "Kunal Sevkani", "active": true, "timeZone": "Etc/UTC"}, "body": "Draft PR without test to see if the structure looks okay - [https://github.com/apache/hadoop/pull/7901]\r\n\r\ncc: [~anujmodi]\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=kunalsevkani", "name": "kunalsevkani", "key": "JIRAUSER309200", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"}, "displayName": "Kunal Sevkani", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T12:09:23.445+0000", "updated": "2025-08-26T12:09:23.445+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18016283", "id": "18016283", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "body": "Its not showing your name somehow", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-08-26T12:40:57.472+0000", "updated": "2025-08-26T12:40:57.472+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18016331", "id": "18016331", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3224527888\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 38s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  1s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 37s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/1/artifact/out/blanks-eol.txt) |  The patch has 17 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   0m 23s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 2 unchanged - 0 fixed = 3 total (was 2)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 54s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 166m 34s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 91770e23ae15 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / dee5a7d480a91f1099224b2565ed93ab8587e580 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/1/testReport/ |\r\n   | Max. process+thread count | 607 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T14:56:18.017+0000", "updated": "2025-08-26T14:56:18.017+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18018268", "id": "18018268", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3256894074\n\n   Thanks for the patch @kunalmnnit \r\n   We will review this PR and add comments if any.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T02:42:00.459+0000", "updated": "2025-09-05T02:42:00.459+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18019829", "id": "18019829", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#discussion_r2344037166\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java:\n##########\n@@ -38,11 +38,72 @@ public class WorkloadIdentityTokenProvider extends AccessTokenProvider {\n   private static final String EMPTY_TOKEN_FILE_ERROR = \"Empty token file found at specified path: \";\n   private static final String TOKEN_FILE_READ_ERROR = \"Error reading token file at specified path: \";\n \n+  /**\n+   * Internal implementation of ClientAssertionProvider for file-based token reading.\n+   * This provides backward compatibility for the file-based constructor.\n+   */\n+  private static class FileBasedClientAssertionProvider implements ClientAssertionProvider {\n+    private final String tokenFile;\n+\n+    public FileBasedClientAssertionProvider(String tokenFile) {\n+      this.tokenFile = tokenFile;\n+    }\n+\n+    @Override\n+    public void initialize(Configuration configuration, String accountName) throws IOException {\n+      // No initialization needed for file-based provider\n+    }\n+\n+    @Override\n+    public String getClientAssertion() throws IOException {\n+      String clientAssertion = \"\";\n+      try {\n+        File file = new File(tokenFile);\n+        clientAssertion = FileUtils.readFileToString(file, \"UTF-8\");\n\nReview Comment:\n   encoding should come from constants, should not be hardcoded\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T12:05:53.437+0000", "updated": "2025-09-12T12:05:53.437+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18019830", "id": "18019830", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#discussion_r2344048057\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java:\n##########\n@@ -38,11 +38,72 @@ public class WorkloadIdentityTokenProvider extends AccessTokenProvider {\n   private static final String EMPTY_TOKEN_FILE_ERROR = \"Empty token file found at specified path: \";\n   private static final String TOKEN_FILE_READ_ERROR = \"Error reading token file at specified path: \";\n \n+  /**\n+   * Internal implementation of ClientAssertionProvider for file-based token reading.\n+   * This provides backward compatibility for the file-based constructor.\n+   */\n+  private static class FileBasedClientAssertionProvider implements ClientAssertionProvider {\n+    private final String tokenFile;\n+\n+    public FileBasedClientAssertionProvider(String tokenFile) {\n+      this.tokenFile = tokenFile;\n+    }\n+\n+    @Override\n+    public void initialize(Configuration configuration, String accountName) throws IOException {\n+      // No initialization needed for file-based provider\n+    }\n+\n+    @Override\n+    public String getClientAssertion() throws IOException {\n+      String clientAssertion = \"\";\n+      try {\n+        File file = new File(tokenFile);\n+        clientAssertion = FileUtils.readFileToString(file, \"UTF-8\");\n+      } catch (Exception e) {\n+        throw new IOException(TOKEN_FILE_READ_ERROR + tokenFile, e);\n+      }\n+      if (Strings.isNullOrEmpty(clientAssertion)) {\n\nReview Comment:\n   If the token only contains whitespaces the empty check will pass, token can be trimmed before checking for empty.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T12:08:33.493+0000", "updated": "2025-09-12T12:08:33.493+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18019831", "id": "18019831", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#discussion_r2344049708\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java:\n##########\n@@ -38,11 +38,72 @@ public class WorkloadIdentityTokenProvider extends AccessTokenProvider {\n   private static final String EMPTY_TOKEN_FILE_ERROR = \"Empty token file found at specified path: \";\n   private static final String TOKEN_FILE_READ_ERROR = \"Error reading token file at specified path: \";\n \n+  /**\n+   * Internal implementation of ClientAssertionProvider for file-based token reading.\n+   * This provides backward compatibility for the file-based constructor.\n+   */\n+  private static class FileBasedClientAssertionProvider implements ClientAssertionProvider {\n+    private final String tokenFile;\n+\n+    public FileBasedClientAssertionProvider(String tokenFile) {\n+      this.tokenFile = tokenFile;\n+    }\n+\n+    @Override\n+    public void initialize(Configuration configuration, String accountName) throws IOException {\n+      // No initialization needed for file-based provider\n+    }\n+\n+    @Override\n+    public String getClientAssertion() throws IOException {\n+      String clientAssertion = \"\";\n\nReview Comment:\n   use constant for EMPTY_STRING\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T12:08:58.659+0000", "updated": "2025-09-12T12:08:58.659+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18019832", "id": "18019832", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#discussion_r2344054829\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java:\n##########\n@@ -38,11 +38,72 @@ public class WorkloadIdentityTokenProvider extends AccessTokenProvider {\n   private static final String EMPTY_TOKEN_FILE_ERROR = \"Empty token file found at specified path: \";\n   private static final String TOKEN_FILE_READ_ERROR = \"Error reading token file at specified path: \";\n \n+  /**\n+   * Internal implementation of ClientAssertionProvider for file-based token reading.\n+   * This provides backward compatibility for the file-based constructor.\n+   */\n+  private static class FileBasedClientAssertionProvider implements ClientAssertionProvider {\n+    private final String tokenFile;\n+\n+    public FileBasedClientAssertionProvider(String tokenFile) {\n+      this.tokenFile = tokenFile;\n+    }\n+\n+    @Override\n+    public void initialize(Configuration configuration, String accountName) throws IOException {\n+      // No initialization needed for file-based provider\n+    }\n+\n+    @Override\n+    public String getClientAssertion() throws IOException {\n+      String clientAssertion = \"\";\n+      try {\n+        File file = new File(tokenFile);\n+        clientAssertion = FileUtils.readFileToString(file, \"UTF-8\");\n\nReview Comment:\n   Here we are reading the whole token file as a string every time getClientAssertion() is called. If file is large or accessed frequently, it could be inefficient. Can we cache the value until the token provider explicitly refreshes ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T12:11:28.545+0000", "updated": "2025-09-12T12:11:28.545+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18019837", "id": "18019837", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#discussion_r2344089164\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java:\n##########\n@@ -20,13 +20,13 @@\n \n import java.io.File;\n import java.io.IOException;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n import org.apache.commons.io.FileUtils;\n import org.apache.hadoop.classification.VisibleForTesting;\n+import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.thirdparty.com.google.common.base.Strings;\n import org.apache.hadoop.util.Preconditions;\n+import org.slf4j.Logger;\n\nReview Comment:\n   Import ordering is incorrect\r\n   \r\n   import java.io.File;\r\n   import java.io.IOException;\r\n   \r\n   import org.slf4j.Logger;\r\n   import org.slf4j.LoggerFactory;\r\n   \r\n   import org.apache.commons.io.FileUtils;\r\n   import org.apache.hadoop.classification.VisibleForTesting;\r\n   import org.apache.hadoop.conf.Configuration;\r\n   import org.apache.hadoop.thirdparty.com.google.common.base.Strings;\r\n   import org.apache.hadoop.util.Preconditions;\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T12:25:43.809+0000", "updated": "2025-09-12T12:25:43.809+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020151", "id": "18020151", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "kunalmnnit commented on code in PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#discussion_r2347334850\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java:\n##########\n@@ -38,11 +38,72 @@ public class WorkloadIdentityTokenProvider extends AccessTokenProvider {\n   private static final String EMPTY_TOKEN_FILE_ERROR = \"Empty token file found at specified path: \";\n   private static final String TOKEN_FILE_READ_ERROR = \"Error reading token file at specified path: \";\n \n+  /**\n+   * Internal implementation of ClientAssertionProvider for file-based token reading.\n+   * This provides backward compatibility for the file-based constructor.\n+   */\n+  private static class FileBasedClientAssertionProvider implements ClientAssertionProvider {\n+    private final String tokenFile;\n+\n+    public FileBasedClientAssertionProvider(String tokenFile) {\n+      this.tokenFile = tokenFile;\n+    }\n+\n+    @Override\n+    public void initialize(Configuration configuration, String accountName) throws IOException {\n+      // No initialization needed for file-based provider\n+    }\n+\n+    @Override\n+    public String getClientAssertion() throws IOException {\n+      String clientAssertion = \"\";\n+      try {\n+        File file = new File(tokenFile);\n+        clientAssertion = FileUtils.readFileToString(file, \"UTF-8\");\n\nReview Comment:\n   Can we take this optimization in subsequent PR since this was existing piece of code?\r\n   https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java#L103-L115\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T13:35:23.474+0000", "updated": "2025-09-14T13:35:23.474+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020152", "id": "18020152", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "kunalmnnit commented on code in PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#discussion_r2347335431\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/WorkloadIdentityTokenProvider.java:\n##########\n@@ -38,11 +38,72 @@ public class WorkloadIdentityTokenProvider extends AccessTokenProvider {\n   private static final String EMPTY_TOKEN_FILE_ERROR = \"Empty token file found at specified path: \";\n   private static final String TOKEN_FILE_READ_ERROR = \"Error reading token file at specified path: \";\n \n+  /**\n+   * Internal implementation of ClientAssertionProvider for file-based token reading.\n+   * This provides backward compatibility for the file-based constructor.\n+   */\n+  private static class FileBasedClientAssertionProvider implements ClientAssertionProvider {\n+    private final String tokenFile;\n+\n+    public FileBasedClientAssertionProvider(String tokenFile) {\n+      this.tokenFile = tokenFile;\n+    }\n+\n+    @Override\n+    public void initialize(Configuration configuration, String accountName) throws IOException {\n+      // No initialization needed for file-based provider\n+    }\n+\n+    @Override\n+    public String getClientAssertion() throws IOException {\n+      String clientAssertion = \"\";\n+      try {\n+        File file = new File(tokenFile);\n+        clientAssertion = FileUtils.readFileToString(file, \"UTF-8\");\n\nReview Comment:\n   Additionally, this will only be invoked when the actual AAD token is expired which is roughly every hour and directly coincides with expiry of KSA token so don't think this will be unnecessarily invoked. wdyt?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T13:36:43.464+0000", "updated": "2025-09-14T13:36:43.464+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020172", "id": "18020172", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "kunalmnnit commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3289649227\n\n   Thanks @anmolanmol1234 for the review. PTAL again for second pass.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T15:58:27.834+0000", "updated": "2025-09-14T15:58:27.834+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020175", "id": "18020175", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3289669768\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  56m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 31s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 31s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/2/artifact/out/blanks-eol.txt) |  The patch has 17 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 18s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 53s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 174m 53s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux e0210d80824e 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e368af43811f9fdd335c0e43ac1d5e0c2d1f33f0 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/2/testReport/ |\r\n   | Max. process+thread count | 575 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T16:28:55.016+0000", "updated": "2025-09-14T16:28:55.016+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020183", "id": "18020183", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3289765623\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  58m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  9s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/3/artifact/out/blanks-eol.txt) |  The patch has 17 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 56s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 156m 44s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 3f98b80109aa 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 33ec902359aea0f83b7a9dfe6cea176f740f3878 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/3/testReport/ |\r\n   | Max. process+thread count | 584 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T18:36:30.536+0000", "updated": "2025-09-14T18:36:30.536+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020184", "id": "18020184", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3289771396\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   9m 30s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  33m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 21s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m  5s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/5/artifact/out/blanks-eol.txt) |  The patch has 45 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 48s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 25s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  94m 55s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 9639e6676688 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / d5030434aa067cdc77378bb13bac5579ecaea881 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/5/testReport/ |\r\n   | Max. process+thread count | 545 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T18:42:14.299+0000", "updated": "2025-09-14T18:42:14.299+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020185", "id": "18020185", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3289810843\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  58m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 48s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 10s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/4/artifact/out/blanks-eol.txt) |  The patch has 16 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 58s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 53s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 157m 10s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 42faac865c3a 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 992ac17ec35adde9c4f27c307c0362a5d6d79cb0 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/4/testReport/ |\r\n   | Max. process+thread count | 587 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T19:26:58.982+0000", "updated": "2025-09-14T19:26:58.982+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020273", "id": "18020273", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3291004596\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  57m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  3s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/6/artifact/out/blanks-eol.txt) |  The patch has 33 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 46s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 51s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 154m 30s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 06eef491e2ea 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 9495f55f855656096b3d593248a2e8b74f51de26 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/6/testReport/ |\r\n   | Max. process+thread count | 533 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T08:25:12.394+0000", "updated": "2025-09-15T08:25:12.394+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020334", "id": "18020334", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3291863724\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  55m 50s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 47s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  44m 15s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 31s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 31s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/7/artifact/out/blanks-eol.txt) |  The patch has 3 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 26s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 56s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 159m 23s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 7f151f599e70 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 68a5b0b9735b0bfd79a577d7ce292ad2399be467 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/7/testReport/ |\r\n   | Max. process+thread count | 530 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T12:14:27.139+0000", "updated": "2025-09-15T12:14:27.139+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18020444", "id": "18020444", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3293541604\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 54s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  56m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 46s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  45m  0s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  44m 22s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  7s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 41s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 163m  6s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7901 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 587337ec2872 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 31906ea3983a99845ff3205fdb889fafdb7fe89b |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/8/testReport/ |\r\n   | Max. process+thread count | 525 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7901/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T19:07:12.500+0000", "updated": "2025-09-15T19:07:12.500+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18021880", "id": "18021880", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "kunalmnnit commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3319670981\n\n   @anujmodi2021 @anmolanmol1234 Appreciate your review here again. Thanks!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-22T15:15:40.165+0000", "updated": "2025-09-22T15:15:40.165+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18022992", "id": "18022992", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "kunalmnnit commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3336856485\n\n   @anmolanmol1234 Gentle bump if you could please have a pass. This change would be really helpful for us to use k8s TokenRequest API\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T05:43:54.459+0000", "updated": "2025-09-26T05:43:54.459+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18023023", "id": "18023023", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "kunalmnnit commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3337137345\n\n   @anmolanmol1234 Thank you for the approval. Would you know who would be able to help with merge? I do not seem to have access\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T07:27:26.864+0000", "updated": "2025-09-26T07:27:26.864+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18023025", "id": "18023025", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901#issuecomment-3337219417\n\n   @anujmodi2021 should be able to help with the merge\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T07:53:46.477+0000", "updated": "2025-09-26T07:53:46.477+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627314/comment/18023153", "id": "18023153", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7901:\nURL: https://github.com/apache/hadoop/pull/7901\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-26T16:37:27.720+0000", "updated": "2025-09-26T16:37:27.720+0000"}], "maxResults": 25, "total": 25, "startAt": 0}, "updated": "2025-09-26T16:37:27.000+0000", "created": "2025-08-26T06:53:52.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13627296", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13627296", "key": "HADOOP-19659", "fields": {"summary": "Upgrade Debian 10 to 11 in build env Dockerfile", "description": "Debian 10 EOL, and the apt repo is unavailable\r\n{code:bash}\r\ndocker run --rm -it debian:10 bash\r\nroot@bc2a4c509cb3:/# apt update\r\nIgn:1 http://deb.debian.org/debian buster InRelease\r\nIgn:2 http://deb.debian.org/debian-security buster/updates InRelease\r\nIgn:3 http://deb.debian.org/debian buster-updates InRelease\r\nErr:4 http://deb.debian.org/debian buster Release\r\n  404  Not Found [IP: 151.101.90.132 80]\r\nErr:5 http://deb.debian.org/debian-security buster/updates Release\r\n  404  Not Found [IP: 151.101.90.132 80]\r\nErr:6 http://deb.debian.org/debian buster-updates Release\r\n  404  Not Found [IP: 151.101.90.132 80]\r\nReading package lists... Done\r\nE: The repository 'http://deb.debian.org/debian buster Release' does not have a Release file.\r\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\nN: See apt-secure(8) manpage for repository creation and user configuration details.\r\nE: The repository 'http://deb.debian.org/debian-security buster/updates Release' does not have a Release file.\r\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\nN: See apt-secure(8) manpage for repository creation and user configuration details.\r\nE: The repository 'http://deb.debian.org/debian buster-updates Release' does not have a Release file.\r\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\nN: See apt-secure(8) manpage for repository creation and user configuration details.\r\nroot@bc2a4c509cb3:/#\r\n{code}", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016192", "id": "18016192", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7898:\nURL: https://github.com/apache/hadoop/pull/7898\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Debian 10 EOL, and the apt repo is unavailable, this PR upgrades it to Debian 11\r\n   \r\n   ```\r\n   docker run --rm -it debian:10 bash\r\n   root@bc2a4c509cb3:/# apt update\r\n   Ign:1 http://deb.debian.org/debian buster InRelease\r\n   Ign:2 http://deb.debian.org/debian-security buster/updates InRelease\r\n   Ign:3 http://deb.debian.org/debian buster-updates InRelease\r\n   Err:4 http://deb.debian.org/debian buster Release\r\n     404  Not Found [IP: 151.101.90.132 80]\r\n   Err:5 http://deb.debian.org/debian-security buster/updates Release\r\n     404  Not Found [IP: 151.101.90.132 80]\r\n   Err:6 http://deb.debian.org/debian buster-updates Release\r\n     404  Not Found [IP: 151.101.90.132 80]\r\n   Reading package lists... Done\r\n   E: The repository 'http://deb.debian.org/debian buster Release' does not have a Release file.\r\n   N: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\n   N: See apt-secure(8) manpage for repository creation and user configuration details.\r\n   E: The repository 'http://deb.debian.org/debian-security buster/updates Release' does not have a Release file.\r\n   N: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\n   N: See apt-secure(8) manpage for repository creation and user configuration details.\r\n   E: The repository 'http://deb.debian.org/debian buster-updates Release' does not have a Release file.\r\n   N: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\n   N: See apt-secure(8) manpage for repository creation and user configuration details.\r\n   root@bc2a4c509cb3:/#\r\n   ```\r\n   \r\n   [Debian 11 will be EOL after 31 Aug 2026](https://endoflife.date/debian). I didn't switch it to Debian 12 or 13 because the new version does not have `openjdk-11-jdk` in the apt repo.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   ```\r\n   $ ./start-build-env.sh debian_11\r\n   ...\r\n    _   _           _                    ______\r\n   | | | |         | |                   |  _  \\\r\n   | |_| | __ _  __| | ___   ___  _ __   | | | |_____   __\r\n   |  _  |/ _` |/ _` |/ _ \\ / _ \\| '_ \\  | | | / _ \\ \\ / /\r\n   | | | | (_| | (_| | (_) | (_) | |_) | | |/ /  __/\\ V /\r\n   \\_| |_/\\__,_|\\__,_|\\___/ \\___/| .__/  |___/ \\___| \\_(_)\r\n                                 | |\r\n                                 |_|\r\n   \r\n   This is the standard Hadoop Developer build environment.\r\n   This has all the right tools installed required to build\r\n   Hadoop from source.\r\n   \r\n   chengpan@c85a4426ba52:~/hadoop$\r\n   ```\r\n   \r\n   ```\r\n   $ mvn clean install -DskipTests -Pnative -Pyarn-ui -DskipShade\r\n   ...\r\n   [INFO] Reactor Summary for Apache Hadoop Main 3.5.0-SNAPSHOT:\r\n   [INFO]\r\n   [INFO] Apache Hadoop Main ................................. SUCCESS [  0.662 s]\r\n   [INFO] Apache Hadoop Build Tools .......................... SUCCESS [  1.010 s]\r\n   [INFO] Apache Hadoop Project POM .......................... SUCCESS [  0.592 s]\r\n   [INFO] Apache Hadoop Annotations .......................... SUCCESS [  0.618 s]\r\n   [INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [  0.069 s]\r\n   [INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.109 s]\r\n   [INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [  1.754 s]\r\n   [INFO] Apache Hadoop MiniKDC .............................. SUCCESS [  0.416 s]\r\n   [INFO] Apache Hadoop Auth ................................. SUCCESS [  2.437 s]\r\n   [INFO] Apache Hadoop Auth Examples ........................ SUCCESS [  0.581 s]\r\n   [INFO] Apache Hadoop Common ............................... SUCCESS [ 22.868 s]\r\n   [INFO] Apache Hadoop NFS .................................. SUCCESS [  1.273 s]\r\n   [INFO] Apache Hadoop KMS .................................. SUCCESS [  1.393 s]\r\n   [INFO] Apache Hadoop Registry ............................. SUCCESS [  1.533 s]\r\n   [INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.040 s]\r\n   [INFO] Apache Hadoop HDFS Client .......................... SUCCESS [ 11.693 s]\r\n   [INFO] Apache Hadoop HDFS ................................. SUCCESS [ 22.103 s]\r\n   [INFO] Apache Hadoop HDFS Native Client ................... SUCCESS [02:13 min]\r\n   [INFO] Apache Hadoop HttpFS ............................... SUCCESS [  2.320 s]\r\n   [INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  1.312 s]\r\n   [INFO] Apache Hadoop YARN ................................. SUCCESS [  0.042 s]\r\n   [INFO] Apache Hadoop YARN API ............................. SUCCESS [  7.877 s]\r\n   [INFO] Apache Hadoop YARN Common .......................... SUCCESS [  6.436 s]\r\n   [INFO] Apache Hadoop YARN Server .......................... SUCCESS [  0.038 s]\r\n   [INFO] Apache Hadoop YARN Server Common ................... SUCCESS [  5.022 s]\r\n   [INFO] Apache Hadoop YARN ApplicationHistoryService ....... SUCCESS [  2.078 s]\r\n   [INFO] Apache Hadoop YARN Timeline Service ................ SUCCESS [  1.541 s]\r\n   [INFO] Apache Hadoop YARN Web Proxy ....................... SUCCESS [  1.331 s]\r\n   [INFO] Apache Hadoop YARN ResourceManager ................. SUCCESS [ 13.285 s]\r\n   [INFO] Apache Hadoop YARN NodeManager ..................... SUCCESS [ 24.058 s]\r\n   [INFO] Apache Hadoop YARN Server Tests .................... SUCCESS [  1.467 s]\r\n   [INFO] Apache Hadoop YARN Client .......................... SUCCESS [  2.682 s]\r\n   [INFO] Apache Hadoop MapReduce Client ..................... SUCCESS [  0.682 s]\r\n   [INFO] Apache Hadoop MapReduce Core ....................... SUCCESS [  5.570 s]\r\n   [INFO] Apache Hadoop MapReduce Common ..................... SUCCESS [  2.672 s]\r\n   [INFO] Apache Hadoop MapReduce Shuffle .................... SUCCESS [  1.767 s]\r\n   [INFO] Apache Hadoop MapReduce App ........................ SUCCESS [  3.697 s]\r\n   [INFO] Apache Hadoop MapReduce HistoryServer .............. SUCCESS [  2.380 s]\r\n   [INFO] Apache Hadoop MapReduce JobClient .................. SUCCESS [  4.119 s]\r\n   [INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [  2.581 s]\r\n   [INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  1.206 s]\r\n   [INFO] Apache Hadoop Federation Balance ................... SUCCESS [  1.630 s]\r\n   [INFO] Apache Hadoop HDFS-RBF ............................. SUCCESS [ 15.224 s]\r\n   [INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.035 s]\r\n   [INFO] Apache Hadoop YARN SharedCacheManager .............. SUCCESS [  1.195 s]\r\n   [INFO] Apache Hadoop YARN Timeline Plugin Storage ......... SUCCESS [  1.104 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Backend ... SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Common .... SUCCESS [  1.532 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Client .... SUCCESS [  4.403 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Servers ... SUCCESS [  0.039 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase Server 2.5  SUCCESS [  1.835 s]\r\n   [INFO] Apache Hadoop YARN TimelineService HBase tests ..... SUCCESS [  1.916 s]\r\n   [INFO] Apache Hadoop YARN Router .......................... SUCCESS [  2.665 s]\r\n   [INFO] Apache Hadoop YARN TimelineService DocumentStore ... SUCCESS [  1.284 s]\r\n   [INFO] Apache Hadoop YARN GlobalPolicyGenerator ........... SUCCESS [  1.474 s]\r\n   [INFO] Apache Hadoop YARN Applications .................... SUCCESS [  0.033 s]\r\n   [INFO] Apache Hadoop YARN DistributedShell ................ SUCCESS [  1.413 s]\r\n   [INFO] Apache Hadoop YARN Unmanaged Am Launcher ........... SUCCESS [  0.925 s]\r\n   [INFO] Apache Hadoop YARN Services ........................ SUCCESS [  0.033 s]\r\n   [INFO] Apache Hadoop YARN Services Core ................... SUCCESS [  3.138 s]\r\n   [INFO] Apache Hadoop YARN Services API .................... SUCCESS [  1.914 s]\r\n   [INFO] Apache Hadoop YARN Application Catalog ............. SUCCESS [  0.038 s]\r\n   [INFO] Apache Hadoop YARN Application Catalog Webapp ...... SUCCESS [ 11.624 s]\r\n   [INFO] Apache Hadoop YARN Application Catalog Docker Image  SUCCESS [  0.048 s]\r\n   [INFO] Apache Hadoop YARN Application MaWo ................ SUCCESS [  0.035 s]\r\n   [INFO] Apache Hadoop YARN Application MaWo Core ........... SUCCESS [  0.991 s]\r\n   [INFO] Apache Hadoop YARN Site ............................ SUCCESS [  0.075 s]\r\n   [INFO] Apache Hadoop YARN Registry ........................ SUCCESS [  0.458 s]\r\n   [INFO] Apache Hadoop YARN UI .............................. SUCCESS [02:07 min]\r\n   [INFO] Apache Hadoop YARN CSI ............................. SUCCESS [  3.403 s]\r\n   [INFO] Apache Hadoop YARN Project ......................... SUCCESS [  1.283 s]\r\n   [INFO] Apache Hadoop MapReduce HistoryServer Plugins ...... SUCCESS [  1.046 s]\r\n   [INFO] Apache Hadoop MapReduce NativeTask ................. SUCCESS [ 18.413 s]\r\n   [INFO] Apache Hadoop MapReduce Uploader ................... SUCCESS [  1.040 s]\r\n   [INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  1.912 s]\r\n   [INFO] Apache Hadoop MapReduce ............................ SUCCESS [  1.140 s]\r\n   [INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [  2.034 s]\r\n   [INFO] Apache Hadoop Client Aggregator .................... SUCCESS [  0.728 s]\r\n   [INFO] Apache Hadoop Dynamometer Workload Simulator ....... SUCCESS [  1.363 s]\r\n   [INFO] Apache Hadoop Dynamometer Cluster Simulator ........ SUCCESS [  1.878 s]\r\n   [INFO] Apache Hadoop Dynamometer Block Listing Generator .. SUCCESS [  1.241 s]\r\n   [INFO] Apache Hadoop Dynamometer Dist ..................... SUCCESS [  1.161 s]\r\n   [INFO] Apache Hadoop Dynamometer .......................... SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop Archives ............................. SUCCESS [  1.310 s]\r\n   [INFO] Apache Hadoop Archive Logs ......................... SUCCESS [  1.536 s]\r\n   [INFO] Apache Hadoop Rumen ................................ SUCCESS [  1.914 s]\r\n   [INFO] Apache Hadoop Gridmix .............................. SUCCESS [  1.920 s]\r\n   [INFO] Apache Hadoop Data Join ............................ SUCCESS [  1.347 s]\r\n   [INFO] Apache Hadoop Extras ............................... SUCCESS [  1.377 s]\r\n   [INFO] Apache Hadoop Pipes ................................ SUCCESS [  2.679 s]\r\n   [INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [  7.690 s]\r\n   [INFO] Apache Hadoop Kafka Library support ................ SUCCESS [  0.901 s]\r\n   [INFO] Apache Hadoop Azure support ........................ SUCCESS [  5.553 s]\r\n   [INFO] Apache Hadoop Aliyun OSS support ................... SUCCESS [  1.183 s]\r\n   [INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  1.679 s]\r\n   [INFO] Apache Hadoop Resource Estimator Service ........... SUCCESS [  1.213 s]\r\n   [INFO] Apache Hadoop Azure Data Lake support .............. SUCCESS [  1.156 s]\r\n   [INFO] Apache Hadoop Image Generation Tool ................ SUCCESS [  1.256 s]\r\n   [INFO] Apache Hadoop Tools Dist ........................... SUCCESS [  0.704 s]\r\n   [INFO] Apache Hadoop OpenStack support .................... SUCCESS [  0.047 s]\r\n   [INFO] Apache Hadoop Common Benchmark ..................... SUCCESS [  9.812 s]\r\n   [INFO] Apache Hadoop Compatibility Benchmark .............. SUCCESS [  0.853 s]\r\n   [INFO] Apache Hadoop Tools ................................ SUCCESS [  0.032 s]\r\n   [INFO] Apache Hadoop Client API ........................... SUCCESS [  0.911 s]\r\n   [INFO] Apache Hadoop Client Runtime ....................... SUCCESS [  0.763 s]\r\n   [INFO] Apache Hadoop Client Packaging Invariants .......... SUCCESS [  0.367 s]\r\n   [INFO] Apache Hadoop Client Test Minicluster .............. SUCCESS [  0.756 s]\r\n   [INFO] Apache Hadoop Client Packaging Invariants for Test . SUCCESS [  0.174 s]\r\n   [INFO] Apache Hadoop Client Packaging Integration Tests ... SUCCESS [  0.778 s]\r\n   [INFO] Apache Hadoop Distribution ......................... SUCCESS [  0.493 s]\r\n   [INFO] Apache Hadoop Client Modules ....................... SUCCESS [  0.034 s]\r\n   [INFO] Apache Hadoop Tencent COS Support .................. SUCCESS [ 56.113 s]\r\n   [INFO] Apache Hadoop OBS support .......................... SUCCESS [  1.335 s]\r\n   [INFO] Apache Hadoop Volcano Engine Services support ...... SUCCESS [  2.005 s]\r\n   [INFO] Apache Hadoop Cloud Storage ........................ SUCCESS [  0.444 s]\r\n   [INFO] Apache Hadoop Cloud Storage Project ................ SUCCESS [  0.032 s]\r\n   [INFO] ------------------------------------------------------------------------\r\n   [INFO] BUILD SUCCESS\r\n   [INFO] ------------------------------------------------------------------------\r\n   [INFO] Total time:  10:25 min\r\n   [INFO] Finished at: 2025-08-26T05:03:57Z\r\n   [INFO] ------------------------------------------------------------------------\r\n   ```\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T05:14:33.829+0000", "updated": "2025-08-26T05:14:33.829+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016193", "id": "18016193", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#discussion_r2299802155\n\n\n##########\nstart-build-env.sh:\n##########\n@@ -93,7 +93,7 @@ RUN userdel -r \\$(getent passwd ${USER_ID} | cut -d: -f1) 2>/dev/null || :\n RUN groupadd --non-unique -g ${GROUP_ID} ${USER_NAME}\n RUN useradd -g ${GROUP_ID} -u ${USER_ID} -k /root -m ${USER_NAME} -d \"${DOCKER_HOME_DIR}\"\n RUN echo \"${USER_NAME} ALL=NOPASSWD: ALL\" > \"/etc/sudoers.d/hadoop-build-${USER_ID}\"\n-ENV HOME \"${DOCKER_HOME_DIR}\"\n+ENV HOME=\"${DOCKER_HOME_DIR}\"\n\nReview Comment:\n   update because\r\n   ```\r\n    1 warning found (use docker --debug to expand):\r\n    - LegacyKeyValueFormat: \"ENV key=value\" should be used instead of legacy \"ENV key value\" format (line 7)\r\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T05:15:58.051+0000", "updated": "2025-08-26T05:15:58.051+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016224", "id": "18016224", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3223070232\n\n   LGTM.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T08:05:01.861+0000", "updated": "2025-08-26T08:05:01.861+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016233", "id": "18016233", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3223228361\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m  6s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 22s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |  17m 26s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/1/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  94m 11s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  32m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |  11m 20s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/1/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  47m 38s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  14m 13s |  |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 57s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 214m 23s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7898 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint mvnsite unit jsonlint |\r\n   | uname | Linux 71b5c8e33180 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f40defe72ea1f0f9d9778a4da76097fa2e1fa02b |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/1/testReport/ |\r\n   | Max. process+thread count | 707 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/1/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T08:50:06.507+0000", "updated": "2025-08-26T08:50:06.507+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016238", "id": "18016238", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3223320943\n\n   > We need to solve the compilation error issue.\r\n   \r\n   The building error occurs on CentOS 8 stage, looks like I need to fix it first\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T09:16:23.857+0000", "updated": "2025-08-26T09:16:23.857+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016422", "id": "18016422", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3226674242\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   0m 19s |  |  Dockerfile '/home/jenkins/jenkins-home/workspace/hadoop-multibranch_PR-7898/rockylinux-8/src/dev-support/docker/Dockerfile_rockylinux_8' not found.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7898 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T04:10:27.951+0000", "updated": "2025-08-27T04:10:27.951+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016432", "id": "18016432", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3226834289\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/3/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T06:00:04.826+0000", "updated": "2025-08-27T06:00:04.826+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016475", "id": "18016475", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3227579915\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 58s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  1s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ HADOOP-19661 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 24s |  |  HADOOP-19661 passed  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 56s |  |  HADOOP-19661 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 21s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  36m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  hadolint  |   0m  2s |  |  No new issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  20m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  16m  4s |  |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  5s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 246m 11s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7898 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs mvnsite unit jsonlint |\r\n   | uname | Linux 1b828c1875fb 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | HADOOP-19661 / 7f02ba4fa4464804763bb80838673e37361a7f6b |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/3/testReport/ |\r\n   | Max. process+thread count | 588 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T10:04:47.684+0000", "updated": "2025-08-27T10:04:47.684+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18016533", "id": "18016533", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3228059389\n\n   I think it would be useful to run at least the native (C code) tests.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-27T12:42:47.609+0000", "updated": "2025-08-27T12:42:47.609+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18017118", "id": "18017118", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3238250392\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  36m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  1s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  1s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  1s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 34s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  39m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 55s |  |  trunk passed  |\r\n   | +1 :green_heart: |  checkstyle  |   5m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  24m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   8m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  spotbugs  |  39m 38s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  83m 13s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  83m 51s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 43s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  39m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 47s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  16m 47s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   6m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |  24m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  spotbugs  |  42m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  83m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 438m 25s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/5/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   2m 27s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 861m 21s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.fs.compat.common.TestHdfsCompatShellCommand |\r\n   |   | hadoop.fs.compat.common.TestHdfsCompatDefaultSuites |\r\n   |   | hadoop.hdfs.tools.TestDFSAdmin |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7898 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint mvnsite unit jsonlint compile javac javadoc mvninstall shadedclient spotbugs checkstyle |\r\n   | uname | Linux b15de39f0892 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / d7d9893cf80efe73d802c253eb12508143e8a636 |\r\n   | Default Java | Red Hat, Inc.-1.8.0_462-b08 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/5/testReport/ |\r\n   | Max. process+thread count | 2833 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/5/console |\r\n   | versions | git=2.43.7 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T20:53:21.132+0000", "updated": "2025-08-29T20:53:21.132+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18017136", "id": "18017136", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#discussion_r2311396990\n\n\n##########\nhadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/cli/TestCLI.java:\n##########\n@@ -43,7 +43,6 @@ public void tearDown() throws Exception {\n   @Override\n   protected CommandExecutor.Result execute(CLICommand cmd) throws Exception {\n     return cmd.getExecutor(\"\", conf).executeCommand(cmd.getCmd());\n-\n\nReview Comment:\n   The changes in Debian are as expected, and we can roll back the modifications to this unit as they are unrelated to our main changes.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T21:58:41.421+0000", "updated": "2025-08-29T21:58:41.421+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18017373", "id": "18017373", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3241344735\n\n   @slfan1989, unnecessary changes are reverted, should be good to go\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T08:16:20.030+0000", "updated": "2025-09-01T08:16:20.030+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18017379", "id": "18017379", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3241445604\n\n   > @slfan1989, unnecessary changes are reverted, should be good to go\r\n   \r\n   @pan3793 Thank you for your contribution, LGTM. I will merge this PR soon.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T08:42:38.014+0000", "updated": "2025-09-01T08:42:38.014+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18017429", "id": "18017429", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3242127699\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  1s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  1s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  1s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  25m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  | 111m 52s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  | 112m 30s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  21m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  62m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  15m 40s |  |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 56s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 234m 15s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7898 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint mvnsite unit jsonlint |\r\n   | uname | Linux f4938eb59c7e 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 131b7dbbd530ccac5ad0d41775484cb7bc2306e2 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/6/testReport/ |\r\n   | Max. process+thread count | 524 (vs. ulimit of 5500) |\r\n   | modules | C: . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7898/6/console |\r\n   | versions | git=2.43.7 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T12:11:16.007+0000", "updated": "2025-09-01T12:11:16.007+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18017498", "id": "18017498", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T15:31:44.330+0000", "updated": "2025-09-01T15:31:44.330+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18017499", "id": "18017499", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7898:\nURL: https://github.com/apache/hadoop/pull/7898#issuecomment-3242753656\n\n   @pan3793 Thanks for the contribution! Merged into trunk.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T15:32:11.852+0000", "updated": "2025-09-01T15:32:11.852+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18018347", "id": "18018347", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7932:\nURL: https://github.com/apache/hadoop/pull/7932\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Fix the issue that `kill` command is not found\r\n   \r\n   ```\r\n   [INFO] -------------------------------------------------------\r\n   [INFO]  T E S T S\r\n   [INFO] -------------------------------------------------------\r\n   [INFO] Running org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree\r\n   [ERROR] Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.950 s <<< FAILURE! ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T10:28:44.266+0000", "updated": "2025-09-05T10:28:44.266+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18018349", "id": "18018349", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3257889051\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   3m  0s |  |  Docker failed to build run-specific yetus/hadoop:tp-500}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7932 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/1/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T10:34:18.077+0000", "updated": "2025-09-05T10:34:18.077+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18018359", "id": "18018359", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3258044364\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   2m 35s |  |  Docker failed to build run-specific yetus/hadoop:tp-8139}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7932 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T11:37:41.580+0000", "updated": "2025-09-05T11:37:41.580+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18018364", "id": "18018364", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3258108386\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   2m 35s |  |  Docker failed to build run-specific yetus/hadoop:tp-26905}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7932 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/3/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-05T12:04:02.637+0000", "updated": "2025-09-05T12:04:02.637+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18018584", "id": "18018584", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3262448562\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   2m 40s |  |  Docker failed to build run-specific yetus/hadoop:tp-22814}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7932 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/4/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-06T15:43:12.634+0000", "updated": "2025-09-06T15:43:12.634+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18019774", "id": "18019774", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3283858265\n\n   @pan3793 Thanks for the contribution! LGTM. I plan to merge this PR shortly.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T06:15:33.308+0000", "updated": "2025-09-12T06:15:33.308+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18019791", "id": "18019791", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3284225600\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  30m  3s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 16s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  50m 57s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 45s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  9s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 58s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 125m 49s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7932 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 43d6fc34e5bc 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / df78520ad4a7647e76e2bafd68ab5ce287573783 |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/5/console |\r\n   | versions | git=2.43.7 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T08:09:46.365+0000", "updated": "2025-09-12T08:09:46.365+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18019805", "id": "18019805", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3284551565\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  27m  0s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 26s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  30m 36s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 22s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  31m  5s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 33s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  91m 20s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7932 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux 74aa9d50bdcb 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / df78520ad4a7647e76e2bafd68ab5ce287573783 |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/5/console |\r\n   | versions | git=2.30.2 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T09:41:14.927+0000", "updated": "2025-09-12T09:41:14.927+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18019819", "id": "18019819", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3284832335\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 46s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 23s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  84m 46s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7932 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets jsonlint |\r\n   | uname | Linux a725f8615e43 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / df78520ad4a7647e76e2bafd68ab5ce287573783 |\r\n   | Max. process+thread count | 530 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7932/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T11:06:08.889+0000", "updated": "2025-09-12T11:06:08.889+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18020129", "id": "18020129", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T07:13:25.662+0000", "updated": "2025-09-14T07:13:25.662+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13627296/comment/18020130", "id": "18020130", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7932:\nURL: https://github.com/apache/hadoop/pull/7932#issuecomment-3289300445\n\n   @pan3793 Thanks for the contribution!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-14T07:13:36.802+0000", "updated": "2025-09-14T07:13:36.802+0000"}], "maxResults": 27, "total": 27, "startAt": 0}, "updated": "2025-09-14T07:13:37.000+0000", "created": "2025-08-26T03:33:48.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626944", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626944", "key": "HADOOP-19658", "fields": {"summary": "ABFS: [FNS Over Blob] Support create and rename idempotency on FNS Blob from client side", "description": "\u00a0Support create and rename idempotency on FNS Blob from client side", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18016869", "id": "18016869", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3234744350\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  46m  3s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 46s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 23s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 29s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 40s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 147m 33s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux bf9d5b01e663 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3ef89e1b92e564468a24cb8d200567b30f283b10 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/1/testReport/ |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T19:48:14.900+0000", "updated": "2025-08-28T19:48:14.900+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18016870", "id": "18016870", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3234745585\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 51s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 23s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 22s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 59s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 16s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 5ba8302b1e20 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3ef89e1b92e564468a24cb8d200567b30f283b10 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/2/testReport/ |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T19:48:48.774+0000", "updated": "2025-08-28T19:48:48.774+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18016984", "id": "18016984", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#discussion_r2309688341\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemCreate.java:\n##########\n@@ -2236,6 +2238,98 @@ public void testFailureInGetPathStatusDuringCreateRecovery() throws Exception {\n     }\n   }\n \n+  /**\n+   * Test to simulate a successful create operation followed by a connection reset\n+   * on the response, triggering a retry.\n+   *\n+   * This test verifies that the create operation is retried in the event of a\n+   * connection reset during the response phase. The test creates a mock\n+   * AzureBlobFileSystem and its associated components to simulate the create\n+   * operation and the connection reset. It then verifies that the create\n+   * operation is retried once before succeeding.\n+   *\n+   * @throws Exception if an error occurs during the test execution.\n+   */\n+  @Test\n+  public void testCreateIdempotencyForNonHnsBlob() throws Exception {\n+    assumeThat(isAppendBlobEnabled()).as(\"Not valid for APPEND BLOB\").isFalse();\n+    // Create a spy of AzureBlobFileSystem\n+    try (AzureBlobFileSystem fs = Mockito.spy(\n+        (AzureBlobFileSystem) FileSystem.newInstance(getRawConfiguration()))) {\n+      assumeHnsDisabled();\n+      // Create a spy of AzureBlobFileSystemStore\n+      AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+      assumeBlobServiceType();\n\nReview Comment:\n   We can move all assume before any other statement\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1702,6 +1705,85 @@ public void testRenamePathRetryIdempotency() throws Exception {\n     }\n   }\n \n+  /**\n+   * Test to simulate a successful copy blob operation followed by a connection reset\n+   * on the response, triggering a retry.\n+   *\n+   * This test verifies that the copy blob operation is retried in the event of a\n+   * connection reset during the response phase. The test creates a mock\n+   * AzureBlobFileSystem and its associated components to simulate the copy blob\n+   * operation and the connection reset. It then verifies that the create\n+   * operation is retried once before succeeding.\n+   *\n+   * @throws Exception if an error occurs during the test execution.\n+   */\n+  @Test\n+  public void testRenameIdempotencyForNonHnsBlob() throws Exception {\n+    assumeThat(isAppendBlobEnabled()).as(\"Not valid for APPEND BLOB\").isFalse();\n+    // Create a spy of AzureBlobFileSystem\n+    try (AzureBlobFileSystem fs = Mockito.spy(\n+        (AzureBlobFileSystem) FileSystem.newInstance(getRawConfiguration()))) {\n+      assumeHnsDisabled();\n\nReview Comment:\n   Same here, move all assume to first few lines\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -509,9 +509,30 @@ public AbfsRestOperation createPath(final String path,\n       final TracingContext tracingContext) throws AzureBlobFileSystemException {\n     AbfsRestOperation op;\n     if (isFileCreation) {\n-      // Create a file with the specified parameters\n-      op = createFile(path, overwrite, permissions, isAppendBlob, eTag,\n-          contextEncryptionAdapter, tracingContext);\n+      AbfsRestOperation statusOp = null;\n+      try {\n+        // Check if the file already exists by calling GetPathStatus\n+        statusOp = getPathStatus(path, false, tracingContext, null);\n\nReview Comment:\n   In case of override true, flow might come here with already a Head call done on path. \r\n   Can we avoid this head call in that case?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T09:37:22.288+0000", "updated": "2025-08-29T09:37:22.288+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18016993", "id": "18016993", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3236588656\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 17s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 35s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 53s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 163m 44s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 08a9e7f8f5d9 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 99bc8f51316f94c4c90e429cce43b8e1bfbbf9f7 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/3/testReport/ |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T10:40:41.435+0000", "updated": "2025-08-29T10:40:41.435+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017028", "id": "18017028", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3237131417\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 55s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m  2s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 53s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 22s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 8b01375fdcf8 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5bbeb2334a61e143c467bda06c0c3aaca8dfcfae |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/4/testReport/ |\r\n   | Max. process+thread count | 534 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T13:56:57.517+0000", "updated": "2025-08-29T13:56:57.517+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017362", "id": "18017362", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#discussion_r2313015686\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/ConfigurationKeys.java:\n##########\n@@ -427,6 +427,8 @@ public static String containerProperty(String property, String fsName, String ac\n   public static final String FS_AZURE_BLOB_DIR_DELETE_MAX_THREAD = \"fs.azure.blob.dir.delete.max.thread\";\n   /**Flag to enable/disable sending client transactional ID during create/rename operations: {@value}*/\n   public static final String FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = \"fs.azure.enable.client.transaction.id\";\n+  /**Flag to enable/disable create idempotency during create operation: {@value}*/\n+  public static final String FS_AZURE_ENABLE_CREATE_IDEMPOTENCY = \"fs.azure.enable.create.idempotency\";\n\nReview Comment:\n   This is only for Blob Idempotency, may be we can keep config name accordingly\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -239,5 +239,7 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_ENABLE_CREATE_IDEMPOTENCY = true;\n\nReview Comment:\n   Typo, ENABLE added twice\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsIoUtils.java:\n##########\n@@ -54,7 +56,15 @@ public static void dumpHeadersToDebugLog(final String origin,\n         if (key == null) {\n           key = \"HTTP Response\";\n         }\n-        String values = StringUtils.join(\";\", entry.getValue());\n+        List<String> valuesList = entry.getValue();\n\nReview Comment:\n   Why this change?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T06:38:38.154+0000", "updated": "2025-09-01T06:38:38.154+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017364", "id": "18017364", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#discussion_r2313023120\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsIoUtils.java:\n##########\n@@ -54,7 +56,15 @@ public static void dumpHeadersToDebugLog(final String origin,\n         if (key == null) {\n           key = \"HTTP Response\";\n         }\n-        String values = StringUtils.join(\";\", entry.getValue());\n+        List<String> valuesList = entry.getValue();\n\nReview Comment:\n   Due to null pointer exceptions on enabling AbfsIoUtils logging if value is null.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T06:41:13.527+0000", "updated": "2025-09-01T06:41:13.527+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017365", "id": "18017365", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#discussion_r2313027848\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/ConfigurationKeys.java:\n##########\n@@ -427,6 +427,8 @@ public static String containerProperty(String property, String fsName, String ac\n   public static final String FS_AZURE_BLOB_DIR_DELETE_MAX_THREAD = \"fs.azure.blob.dir.delete.max.thread\";\n   /**Flag to enable/disable sending client transactional ID during create/rename operations: {@value}*/\n   public static final String FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = \"fs.azure.enable.client.transaction.id\";\n+  /**Flag to enable/disable create idempotency during create operation: {@value}*/\n+  public static final String FS_AZURE_ENABLE_CREATE_IDEMPOTENCY = \"fs.azure.enable.create.idempotency\";\n\nReview Comment:\n   taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -239,5 +239,7 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_ENABLE_CREATE_IDEMPOTENCY = true;\n\nReview Comment:\n   taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T06:43:33.630+0000", "updated": "2025-09-01T06:43:33.630+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017388", "id": "18017388", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3241561632\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  6s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  5s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 54s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 142m 37s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 820b22f42029 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 61f56c9f98a43e05563fbe7b4fb4683a5e9912ea |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/5/testReport/ |\r\n   | Max. process+thread count | 528 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T09:17:23.494+0000", "updated": "2025-09-01T09:17:23.494+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017403", "id": "18017403", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#discussion_r2313575382\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1043,6 +1047,12 @@ public String getAzureAtomicRenameDirs() {\n   }\n \n   public boolean isConditionalCreateOverwriteEnabled() {\n+    // If either the configured FS service type or the ingress service type is BLOB,\n+    // conditional create-overwrite is not used.\n+    if (getFsConfiguredServiceType() == AbfsServiceType.BLOB\n\nReview Comment:\n   why is this change needed?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T10:37:59.018+0000", "updated": "2025-09-01T10:37:59.018+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017407", "id": "18017407", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3241959922\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 56s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 52s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 46s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  5s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 59s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 53s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 143m 30s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux ba0b32cbb7fa 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 417c97d09cd9160e443ed9e355437d9d49037297 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/6/testReport/ |\r\n   | Max. process+thread count | 599 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T11:10:15.381+0000", "updated": "2025-09-01T11:10:15.381+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017533", "id": "18017533", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3243070175\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 54s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m  5s |  |  https://github.com/apache/hadoop/pull/7914 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/7/console |\r\n   | versions | git=2.25.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T18:32:21.536+0000", "updated": "2025-09-01T18:32:21.536+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017548", "id": "18017548", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3243278526\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 6 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 14s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  41m 37s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/8/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 2 unchanged - 0 fixed = 3 total (was 2)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 19s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 53s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 143m 58s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7914 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d4a1cb1bcff9 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4948a4f00c6d3afad2416ed34d88533c201b4c24 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/8/testReport/ |\r\n   | Max. process+thread count | 525 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7914/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T21:29:29.932+0000", "updated": "2025-09-01T21:29:29.932+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017635", "id": "18017635", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914#issuecomment-3244719265\n\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 819, Failures: 0, Errors: 0, Skipped: 167\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n    \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   [ERROR] org.apache.hadoop.fs.azurebfs.ITestAzureBlobFileSystemFileStatus.testLastModifiedTime ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-02T10:23:11.467+0000", "updated": "2025-09-02T10:23:11.467+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626944/comment/18017819", "id": "18017819", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7914:\nURL: https://github.com/apache/hadoop/pull/7914\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-03T04:12:38.253+0000", "updated": "2025-09-03T04:12:38.253+0000"}], "maxResults": 15, "total": 15, "startAt": 0}, "updated": "2025-09-03T04:12:38.000+0000", "created": "2025-08-21T12:01:50.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626756", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626756", "key": "HADOOP-19657", "fields": {"summary": "Update 3.4.2 docs landing page to highlight changes shipped in the release", "description": "The landing page for the 3.4.2 docs mostly lists changes that already shipped in 3.4.0. Update this to highlight 3.4.2 changes.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18014898", "id": "18014898", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail opened a new pull request, #7887:\nURL: https://github.com/apache/hadoop/pull/7887\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Updates landing page with 3.4.2 changes.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T13:18:25.644+0000", "updated": "2025-08-19T13:18:25.644+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18014899", "id": "18014899", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7887:\nURL: https://github.com/apache/hadoop/pull/7887#issuecomment-3200748949\n\n   @anujmodi2021 could you please review the ABFS changes, and let me know if there's anything else you want to highlight. \r\n   \r\n    @steveloughran anything else in S3A we want to highlight?\r\n   \r\n   I'll merge this in tomorrow and kick off the new build.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T13:21:21.133+0000", "updated": "2025-08-19T13:21:21.133+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18014919", "id": "18014919", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7887:\nURL: https://github.com/apache/hadoop/pull/7887#issuecomment-3201009350\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   7m  4s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ branch-3.4.2 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  24m 22s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 17s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 32s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  18m 37s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  71m  0s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7887/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7887 |\r\n   | Optional Tests | dupname asflicense mvnsite codespell detsecrets |\r\n   | uname | Linux 85cc1ac66933 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4.2 / 62e2fc17c26865e8b191c7b34617af0ea7a5fa95 |\r\n   | Max. process+thread count | 717 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project U: hadoop-project |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7887/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T14:30:25.676+0000", "updated": "2025-08-19T14:30:25.676+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18015028", "id": "18015028", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "iwasakims commented on code in PR #7887:\nURL: https://github.com/apache/hadoop/pull/7887#discussion_r2286735439\n\n\n##########\nhadoop-project/src/site/markdown/index.md.vm:\n##########\n@@ -23,75 +23,33 @@ Overview of Changes\n Users are encouraged to read the full set of release notes.\n This page provides an overview of the major changes.\n \n-Bulk Delete API\n-----------------------------------------\n-\n-[HADOOP-18679](https://issues.apache.org/jira/browse/HADOOP-18679) Bulk Delete API.\n-\n-This release provides an API to perform bulk delete of files/objects\n-in an object store or filesystem.\n-\n New binary distribution\n -----------------------\n \n-[HADOOP-19083](https://issues.apache.org/jira/browse/HADOOP-19083) provide hadoop binary tarball without aws v2 sdk\n-\n-Hadoop has added a new variant of the binary distribution tarball, labeled with \"lean\" in the file\n-name. This tarball excludes the full AWS SDK v2 bundle, resulting in approximately 50% reduction in\n-file size.\n+As of v3.4.2, Hadoop will only be distributed with a lean tarball, which excludes the full AWS SDK v2 bundle to reduce\n+overall file size. This release has been tested with AWS SDK v2 2.29.52, which can be downloaded from Maven\n+[here](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.29.52).\n \n S3A improvements\n ----------------\n \n **Improvement**\n \n-[HADOOP-18886](https://issues.apache.org/jira/browse/HADOOP-18886) S3A: AWS SDK V2 Migration: stabilization and S3Express\n-\n-This release completes stabilization efforts on the AWS SDK v2 migration and support of Amazon S3\n-Express One Zone storage. S3 Select is no longer supported.\n-\n-[HADOOP-18993](https://issues.apache.org/jira/browse/HADOOP-18993) S3A: Add option fs.s3a.classloader.isolation (#6301)\n-\n-This introduces configuration property `fs.s3a.classloader.isolation`, which defaults to `true`.\n-Set to `false` to disable S3A classloader isolation, which can be useful for installing custom\n-credential providers in user-provided jars.\n-\n-[HADOOP-19047](https://issues.apache.org/jira/browse/HADOOP-19047) Support InMemory Tracking Of S3A Magic Commits\n-\n-The S3A magic committer now supports configuration property\n-`fs.s3a.committer.magic.track.commits.in.memory.enabled`. Set this to `true` to track commits in\n-memory instead of on the file system, which reduces the number of remote calls.\n+[HADOOP-19363](https://issues.apache.org/jira/browse/HADOOP-19363) S3A: Support analytics-accelerator-s3 input streams\n+for parquet read performance.\n \n-[HADOOP-19161](https://issues.apache.org/jira/browse/HADOOP-19161) S3A: option \u201cfs.s3a.performance.flags\u201d to take list of performance flags\n-\n-S3A now supports configuration property `fs.s3a.performance.flag` for controlling activation of\n-multiple performance optimizations. Refer to the S3A performance documentation for details.\n+HADOOP-19256](https://issues.apache.org/jira/browse/HADOOP-19256) S3A: Adds support for S3 Conditional Writes.\n\nReview Comment:\n   formatting error due to missing leading `[`. @ahmarsuhail \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T01:09:57.224+0000", "updated": "2025-08-20T01:09:57.224+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18015049", "id": "18015049", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7887:\nURL: https://github.com/apache/hadoop/pull/7887#discussion_r2286959916\n\n\n##########\nhadoop-project/src/site/markdown/index.md.vm:\n##########\n@@ -23,75 +23,33 @@ Overview of Changes\n Users are encouraged to read the full set of release notes.\n This page provides an overview of the major changes.\n \n-Bulk Delete API\n-----------------------------------------\n-\n-[HADOOP-18679](https://issues.apache.org/jira/browse/HADOOP-18679) Bulk Delete API.\n-\n-This release provides an API to perform bulk delete of files/objects\n-in an object store or filesystem.\n-\n New binary distribution\n -----------------------\n \n-[HADOOP-19083](https://issues.apache.org/jira/browse/HADOOP-19083) provide hadoop binary tarball without aws v2 sdk\n-\n-Hadoop has added a new variant of the binary distribution tarball, labeled with \"lean\" in the file\n-name. This tarball excludes the full AWS SDK v2 bundle, resulting in approximately 50% reduction in\n-file size.\n+As of v3.4.2, Hadoop will only be distributed with a lean tarball, which excludes the full AWS SDK v2 bundle to reduce\n+overall file size. This release has been tested with AWS SDK v2 2.29.52, which can be downloaded from Maven\n+[here](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.29.52).\n \n S3A improvements\n ----------------\n \n **Improvement**\n \n-[HADOOP-18886](https://issues.apache.org/jira/browse/HADOOP-18886) S3A: AWS SDK V2 Migration: stabilization and S3Express\n-\n-This release completes stabilization efforts on the AWS SDK v2 migration and support of Amazon S3\n-Express One Zone storage. S3 Select is no longer supported.\n-\n-[HADOOP-18993](https://issues.apache.org/jira/browse/HADOOP-18993) S3A: Add option fs.s3a.classloader.isolation (#6301)\n-\n-This introduces configuration property `fs.s3a.classloader.isolation`, which defaults to `true`.\n-Set to `false` to disable S3A classloader isolation, which can be useful for installing custom\n-credential providers in user-provided jars.\n-\n-[HADOOP-19047](https://issues.apache.org/jira/browse/HADOOP-19047) Support InMemory Tracking Of S3A Magic Commits\n-\n-The S3A magic committer now supports configuration property\n-`fs.s3a.committer.magic.track.commits.in.memory.enabled`. Set this to `true` to track commits in\n-memory instead of on the file system, which reduces the number of remote calls.\n+[HADOOP-19363](https://issues.apache.org/jira/browse/HADOOP-19363) S3A: Support analytics-accelerator-s3 input streams\n+for parquet read performance.\n \n-[HADOOP-19161](https://issues.apache.org/jira/browse/HADOOP-19161) S3A: option \u201cfs.s3a.performance.flags\u201d to take list of performance flags\n-\n-S3A now supports configuration property `fs.s3a.performance.flag` for controlling activation of\n-multiple performance optimizations. Refer to the S3A performance documentation for details.\n+HADOOP-19256](https://issues.apache.org/jira/browse/HADOOP-19256) S3A: Adds support for S3 Conditional Writes.\n \n ABFS improvements\n -----------------\n \n **Improvement**\n \n-[HADOOP-18516](https://issues.apache.org/jira/browse/HADOOP-18516) [ABFS]: Support fixed SAS token config in addition to Custom SASTokenProvider Implementation\n-\n-ABFS now supports authentication via a fixed Shared Access Signature token. Refer to ABFS\n-documentation of configuration property `fs.azure.sas.fixed.token` for details.\n-\n-[HADOOP-19089](https://issues.apache.org/jira/browse/HADOOP-19089) [ABFS] Reverting Back Support of setXAttr() and getXAttr() on root path\n-\n-[HADOOP-18869](https://issues.apache.org/jira/browse/HADOOP-18869) previously implemented support for xattrs on the root path in the 3.4.0 release. Support for this has been removed in 3.4.1 to prevent the need for calling container APIs.\n-\n-[HADOOP-19178](https://issues.apache.org/jira/browse/HADOOP-19178) WASB Driver Deprecation and eventual removal\n-\n-This release announces deprecation of the WASB file system in favor of ABFS. Refer to ABFS\n-documentation for additional guidance.\n-\n-**Bug**\n-\n-[HADOOP-18542](https://issues.apache.org/jira/browse/HADOOP-18542) Azure Token provider requires tenant and client IDs despite being optional\n+[HADOOP-19226](https://issues.apache.org/jira/browse/HADOOP-19226) ABFS: [FnsOverBlob] Implementing Azure Rest APIs on\n+Blob Endpoint for AbfsBlobClient.\n \n-It is no longer necessary to specify a tenant and client ID in configuration for MSI authentication\n-when running in an Azure instance.\n+[HADOOP-19474](https://issues.apache.org/jira/browse/HADOOP-19474)  ABFS: [FnsOverBlob] Listing Optimizations to avoid\n\nReview Comment:\n   https://issues.apache.org/jira/browse/HADOOP-19543 also can be added.\n\n\n\n##########\nhadoop-project/src/site/markdown/index.md.vm:\n##########\n@@ -23,75 +23,33 @@ Overview of Changes\n Users are encouraged to read the full set of release notes.\n This page provides an overview of the major changes.\n \n-Bulk Delete API\n-----------------------------------------\n-\n-[HADOOP-18679](https://issues.apache.org/jira/browse/HADOOP-18679) Bulk Delete API.\n-\n-This release provides an API to perform bulk delete of files/objects\n-in an object store or filesystem.\n-\n New binary distribution\n -----------------------\n \n-[HADOOP-19083](https://issues.apache.org/jira/browse/HADOOP-19083) provide hadoop binary tarball without aws v2 sdk\n-\n-Hadoop has added a new variant of the binary distribution tarball, labeled with \"lean\" in the file\n-name. This tarball excludes the full AWS SDK v2 bundle, resulting in approximately 50% reduction in\n-file size.\n+As of v3.4.2, Hadoop will only be distributed with a lean tarball, which excludes the full AWS SDK v2 bundle to reduce\n+overall file size. This release has been tested with AWS SDK v2 2.29.52, which can be downloaded from Maven\n+[here](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.29.52).\n \n S3A improvements\n ----------------\n \n **Improvement**\n \n-[HADOOP-18886](https://issues.apache.org/jira/browse/HADOOP-18886) S3A: AWS SDK V2 Migration: stabilization and S3Express\n-\n-This release completes stabilization efforts on the AWS SDK v2 migration and support of Amazon S3\n-Express One Zone storage. S3 Select is no longer supported.\n-\n-[HADOOP-18993](https://issues.apache.org/jira/browse/HADOOP-18993) S3A: Add option fs.s3a.classloader.isolation (#6301)\n-\n-This introduces configuration property `fs.s3a.classloader.isolation`, which defaults to `true`.\n-Set to `false` to disable S3A classloader isolation, which can be useful for installing custom\n-credential providers in user-provided jars.\n-\n-[HADOOP-19047](https://issues.apache.org/jira/browse/HADOOP-19047) Support InMemory Tracking Of S3A Magic Commits\n-\n-The S3A magic committer now supports configuration property\n-`fs.s3a.committer.magic.track.commits.in.memory.enabled`. Set this to `true` to track commits in\n-memory instead of on the file system, which reduces the number of remote calls.\n+[HADOOP-19363](https://issues.apache.org/jira/browse/HADOOP-19363) S3A: Support analytics-accelerator-s3 input streams\n+for parquet read performance.\n \n-[HADOOP-19161](https://issues.apache.org/jira/browse/HADOOP-19161) S3A: option \u201cfs.s3a.performance.flags\u201d to take list of performance flags\n-\n-S3A now supports configuration property `fs.s3a.performance.flag` for controlling activation of\n-multiple performance optimizations. Refer to the S3A performance documentation for details.\n+HADOOP-19256](https://issues.apache.org/jira/browse/HADOOP-19256) S3A: Adds support for S3 Conditional Writes.\n \n ABFS improvements\n -----------------\n \n **Improvement**\n \n-[HADOOP-18516](https://issues.apache.org/jira/browse/HADOOP-18516) [ABFS]: Support fixed SAS token config in addition to Custom SASTokenProvider Implementation\n-\n-ABFS now supports authentication via a fixed Shared Access Signature token. Refer to ABFS\n-documentation of configuration property `fs.azure.sas.fixed.token` for details.\n-\n-[HADOOP-19089](https://issues.apache.org/jira/browse/HADOOP-19089) [ABFS] Reverting Back Support of setXAttr() and getXAttr() on root path\n-\n-[HADOOP-18869](https://issues.apache.org/jira/browse/HADOOP-18869) previously implemented support for xattrs on the root path in the 3.4.0 release. Support for this has been removed in 3.4.1 to prevent the need for calling container APIs.\n-\n-[HADOOP-19178](https://issues.apache.org/jira/browse/HADOOP-19178) WASB Driver Deprecation and eventual removal\n-\n-This release announces deprecation of the WASB file system in favor of ABFS. Refer to ABFS\n-documentation for additional guidance.\n-\n-**Bug**\n-\n-[HADOOP-18542](https://issues.apache.org/jira/browse/HADOOP-18542) Azure Token provider requires tenant and client IDs despite being optional\n+[HADOOP-19226](https://issues.apache.org/jira/browse/HADOOP-19226) ABFS: [FnsOverBlob] Implementing Azure Rest APIs on\n\nReview Comment:\n   For FNSOverBlob support,may be we can use parent JIRA here as it will track all the related work items.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T04:39:27.048+0000", "updated": "2025-08-20T04:39:27.048+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18015089", "id": "18015089", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "John6665 commented on PR #7887:\nURL: https://github.com/apache/hadoop/pull/7887#issuecomment-3204892829\n\n   Good job \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T08:51:52.346+0000", "updated": "2025-08-20T08:51:52.346+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18015118", "id": "18015118", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail merged PR #7887:\nURL: https://github.com/apache/hadoop/pull/7887\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T10:09:33.291+0000", "updated": "2025-08-20T10:09:33.291+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626756/comment/18015119", "id": "18015119", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7887:\nURL: https://github.com/apache/hadoop/pull/7887#issuecomment-3205356855\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 38s |  |  https://github.com/apache/hadoop/pull/7887 does not apply to branch-3.4.2. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7887 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7887/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T10:11:21.067+0000", "updated": "2025-08-20T10:11:21.067+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "updated": "2025-08-21T01:39:59.000+0000", "created": "2025-08-19T13:16:06.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626749", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626749", "key": "HADOOP-19656", "fields": {"summary": "Fix hadoop-client-minicluster", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626749/comment/18015054", "id": "18015054", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayushtkn", "name": "ayushtkn", "key": "ayushtkn", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Saxena", "active": true, "timeZone": "Asia/Kolkata"}, "body": "can you please fill the description of the ticket, it isn't conclusive from the ticket, like what is broken which needs to be fixed", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayushtkn", "name": "ayushtkn", "key": "ayushtkn", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Saxena", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-08-20T05:01:23.791+0000", "updated": "2025-08-20T05:01:23.791+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626749/comment/18018331", "id": "18018331", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=chengpan", "name": "chengpan", "key": "chengpan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=chengpan&avatarId=52228", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengpan&avatarId=52228", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengpan&avatarId=52228", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengpan&avatarId=52228"}, "displayName": "Cheng Pan", "active": true, "timeZone": "Asia/Shanghai"}, "body": "I should close this ticket, the issue was fixed by HADOOP-19652", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=chengpan", "name": "chengpan", "key": "chengpan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=chengpan&avatarId=52228", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengpan&avatarId=52228", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengpan&avatarId=52228", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengpan&avatarId=52228"}, "displayName": "Cheng Pan", "active": true, "timeZone": "Asia/Shanghai"}, "created": "2025-09-05T09:18:09.041+0000", "updated": "2025-09-05T09:18:09.041+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-09-05T09:18:52.000+0000", "created": "2025-08-19T12:53:49.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626707", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626707", "key": "HADOOP-19655", "fields": {"summary": "Add RISC-V Zbc (CLMUL) hardware-accelerated CRC32/CRC32C implementation", "description": "This patch introduces hardware-accelerated CRC32 and CRC32C algorithms for RISC-V platforms supporting the Zbc extension (CLMUL instructions) in bulk_crc32_riscv.c.\r\nKey changes:\r\n * Implements optimized CRC32 and CRC32C routines using CLMUL instructions for zlib and Castagnoli polynomials.\r\n * Automatically switches to hardware acceleration when Zbc is available, otherwise falls back to generic table-based software implementation.\r\n * Maintains compatibility with platforms lacking Zbc support.\r\n\r\nThis optimization improves CRC performance on RISC-V CPUs with Zbc extension.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626707/comment/18016175", "id": "18016175", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "PeterPtroc opened a new pull request, #7896:\nURL: https://github.com/apache/hadoop/pull/7896\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   - Implements a CLMUL-based 16B fold + Barrett reduction algorithm, adapted from riscv-crc32-clmul.\r\n   - True interleaved (round-robin) multi-block pipeline (1\u20133 blocks) to increase ILP.\r\n   - Small buffers and tails fall back to the existing table-based software path.\r\n   - Runtime gating:\r\n     - Double-checked detection: \u201czbc\u201d in /proc/cpuinfo AND a SIGILL-safe CLMUL probe.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   - Build (native profile):\r\n     - mvn -pl hadoop-common-project/hadoop-common -am -Pnative -DskipTests clean install\r\n   - Run benchmark:\r\n     - mvn -Pnative -DskipTests -Dexec.classpathScope=test -Dexec.mainClass=org.apache.hadoop.util.Crc32PerformanceTest \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [x] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T03:04:09.606+0000", "updated": "2025-08-26T03:04:09.606+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626707/comment/18016204", "id": "18016204", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7896:\nURL: https://github.com/apache/hadoop/pull/7896#issuecomment-3222853817\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  27m 44s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  7s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 45s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/2/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  | 105m 59s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |  16m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |  16m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  16m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 47s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/2/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 12s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  24m 53s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 47s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 223m 28s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7896 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux 4727479d09e6 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 58baa6eb96c75dd288767f650918073c5c094a6f |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/2/testReport/ |\r\n   | Max. process+thread count | 3133 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/2/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T06:50:31.064+0000", "updated": "2025-08-26T06:50:31.064+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626707/comment/18016206", "id": "18016206", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7896:\nURL: https://github.com/apache/hadoop/pull/7896#issuecomment-3222859121\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  29m 24s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  46m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 41s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   1m 45s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/1/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  | 107m 55s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  cc  |  16m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  golang  |  16m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |  16m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   1m 43s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/1/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 59s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  24m 53s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 54s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 227m 14s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7896 |\r\n   | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang |\r\n   | uname | Linux 262a84b27cca 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 58baa6eb96c75dd288767f650918073c5c094a6f |\r\n   | Default Java | Red Hat, Inc.-1.8.0_312-b07 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/1/testReport/ |\r\n   | Max. process+thread count | 3133 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7896/1/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T06:52:36.656+0000", "updated": "2025-08-26T06:52:36.656+0000"}], "maxResults": 3, "total": 3, "startAt": 0}, "updated": "2025-10-17T16:49:52.000+0000", "created": "2025-08-19T02:52:30.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626670", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626670", "key": "HADOOP-19654", "fields": {"summary": "Upgrade AWS SDK to 2.35.4", "description": "Upgrade to a recent version of 2.33.x or later while off the critical path of things.\r\n\r\n\r\nHADOOP-19485 froze the sdk at a version which worked with third party stores. Apparently the new version works; early tests show that Bulk Delete calls with third party stores complain about lack of md5 headers, so some tuning is clearly going to be needed.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18014702", "id": "18014702", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #7882:\nURL: https://github.com/apache/hadoop/pull/7882\n\n   ### How was this patch tested?\r\n   \r\n   Testing in progress; still trying to get the ITests working.\r\n   \r\n   JUnit5 update complicates things here, as it highlights that minicluster tests aren't working.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [X] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T18:33:54.643+0000", "updated": "2025-08-18T18:33:54.643+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18014955", "id": "18014955", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3201364651\n\n   > JUnit5 update complicates things here, as it highlights that minicluster tests aren't working.\r\n   \r\n   I found `hadoop-client-runtime` and `hadoop-client-minicluster` broken during integration with Spark, HADOOP-19652 plus YARN-11824 recovers that, is it the same issue?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T16:09:58.714+0000", "updated": "2025-08-19T16:09:58.714+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18014976", "id": "18014976", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3201641390\n\n   @pan3793 maybe. \r\n   \r\n   what is unrelated is out the box the SDK doesn't do bulk delete with third party stores which support it (Dell ECS).\r\n   ```\r\n   org.apache.hadoop.fs.s3a.AWSBadRequestException: bulkDelete on job-00-fork-0001/test/org.apache.hadoop.fs.contract.s3a.ITestS3AContractBulkDelete: software.amazon.awssdk.services.s3.model.InvalidRequestException: Missing required header for this request: Content-MD5 (Service: S3, Status Code: 400, Request ID: 0c07c87d:196d43d824a:d5329:91d, Extended Request ID: 85e1d41b57b608d4e58222b552dea52902e93b05a12f63f54730ae77769df8d1) (SDK Attempt Count: 1):InvalidRequest: Missing required header for this request: Content-MD5 (Service: S3, Status Code: 400, Request ID: 0c07c87d:196d43d824a:d5329:91d, Extended Request ID: 85e1d41b57b608d4e58222b552dea52902e93b05a12f63f54730ae77769df8d1) (SDK Attempt Count: 1)\r\n   --\r\n   \r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T17:45:40.582+0000", "updated": "2025-08-19T17:45:40.582+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18014977", "id": "18014977", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3201646178\n\n   @pan3793 no, it's lifecycle related. Test needs to set up that minicluster before the test cases. and that's somehow not happening\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T17:47:23.055+0000", "updated": "2025-08-19T17:47:23.055+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18015336", "id": "18015336", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3209266234\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 49s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  34m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 32s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m 18s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 49s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  65m 42s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   1m 15s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 33s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 48s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  66m 27s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 368m 52s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/2/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 735m 38s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux cb65e960fd1f 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0d3f20b487ebe8cca5f4b91a3197d7e6cc639901 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/2/testReport/ |\r\n   | Max. process+thread count | 3658 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-21T07:00:51.417+0000", "updated": "2025-08-21T07:00:51.417+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18016122", "id": "18016122", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3221833528\n\n   regressions\r\n   \r\n   ## everywhere\r\n   \r\n   No logging. Instead we get\r\n   \r\n   ```\r\n   SLF4J: Failed to load class \"org.slf4j.impl.StaticMDCBinder\".\r\n   SLF4J: Defaulting to no-operation MDCAdapter implementation.\r\n   SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details.\r\n   ```\r\n   \r\n   `ITestS3AContractAnalyticsStreamVectoredRead` failures -stream closed.\r\n   \r\n   more on this once I've looked at it. If it is an SDK issue, major regression, though it may be something needing changes in the aal libary\r\n   \r\n   ## s3 express\r\n   ```\r\n   [ERROR]   ITestTreewalkProblems.testDistCp:319->lambda$testDistCp$3:320 [Exit code of distcp -useiterator -update -delete -direct s3a://stevel--usw2-az1--x-s3/job-00-fork-0005/test/testDistCp/src s3a://stevel--usw2-az1--x-s3/job-00-fork-0005/test/testDistCp/dest]    \r\n   ```\r\n   assumption: now that the store has lifecycle rules, you don't get prefix listings when there's an in-progress upload. \r\n   \r\n   Fix: change test but also path capability warning of inconsistency. this is good.\r\n   \r\n   Operation costs/auditing count an extra HTTP request, so cost tests fail. I suspect it is always calling CreateSession, but without logging can't be sure\r\n   \r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T21:42:37.666+0000", "updated": "2025-08-25T21:42:37.666+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18016191", "id": "18016191", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3222650336\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 10 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 57s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 39s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 50s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  65m 47s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   1m  3s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 22s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 52s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/3/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   4m 11s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/3/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 9 new + 42 unchanged - 5 fixed = 51 total (was 47)  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 53s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  65m 59s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 371m  3s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/3/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 17s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 733m 32s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.TestRollingUpgrade |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 880f3cb624ae 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5b9a7e32525c27e876698f49e88ab520eae2d8c4 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/3/testReport/ |\r\n   | Max. process+thread count | 3821 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T05:14:11.359+0000", "updated": "2025-08-26T05:14:11.359+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18020598", "id": "18020598", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3296808329\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 10 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 31s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  24m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   9m 23s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 50s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   2m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 17s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 11s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 37s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 40s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  23m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  3s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 24s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   7m 24s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/6/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   1m 54s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/6/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 9 new + 42 unchanged - 5 fixed = 51 total (was 47)  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 26s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  7s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 23s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 678m 20s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/6/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  8s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 913m 40s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.mapreduce.v2.TestUberAM |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 113d355d9ed2 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / cc31e5be98b54ee418f5ddad4696de2d40e099a0 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/6/testReport/ |\r\n   | Max. process+thread count | 4200 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T09:01:49.711+0000", "updated": "2025-09-16T09:01:49.711+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18020659", "id": "18020659", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3298415046\n\n   Thanks @steveloughran, PR looks good overall. \r\n   \r\n   Are then failures in `ITestS3AContractAnalyticsStreamVectoredRead` intermittent? I've not been able to reproduce, am running the test on this SDK upgrade branch. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T12:20:41.743+0000", "updated": "2025-09-16T12:20:41.743+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18020664", "id": "18020664", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on code in PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#discussion_r2352378026\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/ITestS3APutIfMatchAndIfNoneMatch.java:\n##########\n@@ -390,7 +416,7 @@ public void testIfNoneMatchOverwriteWithEmptyFile() throws Throwable {\n \n     // close the stream, should throw RemoteFileChangedException\n     RemoteFileChangedException exception = intercept(RemoteFileChangedException.class, stream::close);\n-    assertS3ExceptionStatusCode(SC_412_PRECONDITION_FAILED, exception);\n+    verifyS3ExceptionStatusCode(SC_412_PRECONDITION_FAILED, exception);\n\nReview Comment:\n   do you know what the difference is with the other tests here? \n   \n   As in, why with S3 express is it ok to assert that we'll get a 412, whereas the others tests will throw a 200?\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/ITestAssumeRole.java:\n##########\n@@ -203,7 +206,7 @@ protected Configuration createValidRoleConf() throws JsonProcessingException {\n     conf.set(ASSUMED_ROLE_SESSION_DURATION, \"45m\");\n     // disable create session so there's no need to\n     // add a role policy for it.\n-    disableCreateSession(conf);\n+    //disableCreateSession(conf);\n\nReview Comment:\n   nit: can just cut this instead of commenting it out, since we're skipping these tests if S3 Express is enabled\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-16T12:42:45.837+0000", "updated": "2025-09-16T12:42:45.837+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18020831", "id": "18020831", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3301096683\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 10 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 32s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  23m 50s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 32s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 30s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  14m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 33s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  5s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 32s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  23m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 15s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   7m 15s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/7/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   1m 58s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/7/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 9 new + 42 unchanged - 5 fixed = 51 total (was 47)  |\r\n   | +1 :green_heart: |  mvnsite  |  12m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 27s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  4s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 17s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 678m 56s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/7/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 11s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 905m  0s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.mapreduce.v2.TestUberAM |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 3b890eb50412 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3351e41830fbc9230ffe18bd88bfc0e2a60b20bd |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/7/testReport/ |\r\n   | Max. process+thread count | 4379 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T03:12:40.463+0000", "updated": "2025-09-17T03:12:40.463+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18020961", "id": "18020961", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3304013014\n\n   I've attached a log of a test run against an s3 express bucket where the test `ITestAWSStatisticCollection.testSDKMetricsCostOfGetFileStatusOnFile()` is failing because the AWS SDK stats report 2 http requests for the probe. I'd thought it was create-session related but it isn't: it looks like somehow the stream is broken. This happens reliably on every test runs.\r\n   \r\n   \r\n   The relevant stuff is at line 564 where a HEAD request fails because the stream is broken\r\n   \"end of stream\".\r\n   \r\n   ```\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"HEAD /test/testSDKMetricsCostOfGetFileStatusOnFile HTTP/1.1[\\r][\\n]\"\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"Host: stevel--usw2-az1--x-s3.s3express-usw2-az1.us-west-2.amazonaws.com[\\r][\\n]\"\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"amz-sdk-invocation-id: 1804bbcd-04de-cba8-8055-6a09917ca20d[\\r][\\n]\"\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"amz-sdk-request: attempt=1; max=3[\\r][\\n]\"\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"Authorization: AWS4-HMAC-SHA256 Credential=AKIA/20250917/us-west-2/s3express/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;host;referer;x-amz-content-sha256;x-amz-date, Signature=228a46bb1d008468d38afd0da0ed7b4c354ab12631a63bf4283cb23dc02527a3[\\r][\\n]\"\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"Referer: https://audit.example.org/hadoop/1/op_get_file_status/cf739331-1f2e-42dd-a5d9-f564d6023a23-00000008/?op=op_get_file_status&p1=test/testSDKMetricsCostOfGetFileStatusOnFile&pr=stevel&ps=282e3c5d-c1bd-4859-94b9-82e77ff225d1&id=cf739331-1f2e-42dd-a5d9-f564d6023a23-00000008&t0=1&fs=cf739331-1f2e-42dd-a5d9-f564d6023a23&t1=1&ts=1758131029311[\\r][\\n]\"\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"User-Agent: Hadoop 3.5.0-SNAPSHOT aws-sdk-java/2.33.8 md/io#sync md/http#Apache ua/2.1 api/S3#2.33.x os/Mac_OS_X#15.6.1 lang/java#17.0.8 md/OpenJDK_64-Bit_Server_VM#17.0.8+7-LTS md/vendor#Amazon.com_Inc. md/en_GB m/F,G hll/cross-region[\\r][\\n]\"\r\n   2025-09-17 18:43:49,313 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"x-amz-content-sha256: UNSIGNED-PAYLOAD[\\r][\\n]\"\r\n   2025-09-17 18:43:49,314 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"X-Amz-Date: 20250917T174349Z[\\r][\\n]\"\r\n   2025-09-17 18:43:49,314 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"Connection: Keep-Alive[\\r][\\n]\"\r\n   2025-09-17 18:43:49,314 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-1 >> \"[\\r][\\n]\"\r\n   2025-09-17 18:43:49,314 [setup] DEBUG http.wire (Wire.java:wire(87)) - http-outgoing-1 << \"end of stream\"\r\n   2025-09-17 18:43:49,314 [setup] DEBUG awssdk.request (LoggerAdapter.java:debug(125)) - Retryable error detected. Will retry in 51ms. Request attempt number 1\r\n   software.amazon.awssdk.core.exception.SdkClientException: Unable to execute HTTP request: The target server failed to respond\r\n   \tat software.amazon.awssdk.core.exception.SdkClientException$BuilderImpl.build(SdkClientException.java:130)\r\n   \tat software.amazon.awssdk.core.exception.SdkClientException.create(SdkClientException.java:47)\r\n   \r\n   ```\r\n   \r\n   The second request always works.\r\n   ```\r\n   2025-09-17 18:43:49,672 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"HEAD /test/testSDKMetricsCostOfGetFileStatusOnFile HTTP/1.1[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"Host: stevel--usw2-az1--x-s3.s3express-usw2-az1.us-west-2.amazonaws.com[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"amz-sdk-invocation-id: 1804bbcd-04de-cba8-8055-6a09917ca20d[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"amz-sdk-request: attempt=2; max=3[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"Authorization: AWS4-HMAC-SHA256 Credential=AKIA/20250917/us-west-2/s3express/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;host;referer;x-amz-content-sha256;x-amz-date, Signature=920d981fad319228c969f5df7f5c1a3c7e4d3c0e2f45ff53bba73e6cf47c5871[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"Referer: https://audit.example.org/hadoop/1/op_get_file_status/cf739331-1f2e-42dd-a5d9-f564d6023a23-00000008/?op=op_get_file_status&p1=test/testSDKMetricsCostOfGetFileStatusOnFile&pr=stevel&ps=282e3c5d-c1bd-4859-94b9-82e77ff225d1&id=cf739331-1f2e-42dd-a5d9-f564d6023a23-00000008&t0=1&fs=cf739331-1f2e-42dd-a5d9-f564d6023a23&t1=1&ts=1758131029311[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"User-Agent: Hadoop 3.5.0-SNAPSHOT aws-sdk-java/2.33.8 md/io#sync md/http#Apache ua/2.1 api/S3#2.33.x os/Mac_OS_X#15.6.1 lang/java#17.0.8 md/OpenJDK_64-Bit_Server_VM#17.0.8+7-LTS md/vendor#Amazon.com_Inc. md/en_GB m/F,G hll/cross-region[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"x-amz-content-sha256: UNSIGNED-PAYLOAD[\\r][\\n]\"\r\n   2025-09-17 18:43:49,673 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"X-Amz-Date: 20250917T174349Z[\\r][\\n]\"\r\n   2025-09-17 18:43:49,674 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"Connection: Keep-Alive[\\r][\\n]\"\r\n   2025-09-17 18:43:49,674 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 >> \"[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"HTTP/1.1 200 OK[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"server: AmazonS3[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"x-amz-request-id: 01869434dd00019958c6871b05090b3f875a3c90[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"x-amz-id-2: 9GqfbNyMyUs6[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"etag: \"6036aaaf62444466bf0a21cc7518f738\"[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"accept-ranges: bytes[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"last-modified: Wed, 17 Sep 2025 17:43:49 GMT[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"x-amz-storage-class: EXPRESS_ONEZONE[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"content-type: application/octet-stream[\\r][\\n]\"\r\n   2025-09-17 18:43:49,859 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"x-amz-server-side-encryption: AES256[\\r][\\n]\"\r\n   2025-09-17 18:43:49,860 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"content-length: 0[\\r][\\n]\"\r\n   2025-09-17 18:43:49,860 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"x-amz-expiration: NotImplemented[\\r][\\n]\"\r\n   2025-09-17 18:43:49,860 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"date: Wed, 17 Sep 2025 17:43:48 GMT[\\r][\\n]\"\r\n   2025-09-17 18:43:49,860 [setup] DEBUG http.wire (Wire.java:wire(73)) - http-outgoing-2 << \"[\\r][\\n]\"\r\n   2025-09-17 18:43:49,860 [setup] DEBUG awssdk.request (LoggerAdapter.java:debug(105)) - Received successful response: 200, Request ID: \r\n   ```\r\n   \r\n   Either the request is being rejected (why?) or the connection has gone stale. But why should it happen at exactly the same place on every single test run?\r\n   \r\n   \r\n   [org.apache.hadoop.fs.s3a.statistics.ITestAWSStatisticCollection-output.txt](https://github.com/user-attachments/files/22391405/org.apache.hadoop.fs.s3a.statistics.ITestAWSStatisticCollection-output.txt)\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T17:51:56.355+0000", "updated": "2025-09-17T17:51:56.355+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18020963", "id": "18020963", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#discussion_r2356314622\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/ITestS3APutIfMatchAndIfNoneMatch.java:\n##########\n@@ -390,7 +416,7 @@ public void testIfNoneMatchOverwriteWithEmptyFile() throws Throwable {\n \n     // close the stream, should throw RemoteFileChangedException\n     RemoteFileChangedException exception = intercept(RemoteFileChangedException.class, stream::close);\n-    assertS3ExceptionStatusCode(SC_412_PRECONDITION_FAILED, exception);\n+    verifyS3ExceptionStatusCode(SC_412_PRECONDITION_FAILED, exception);\n\nReview Comment:\n   Hey, it's your server code. Go see.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T17:59:23.011+0000", "updated": "2025-09-17T17:59:23.011+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021076", "id": "18021076", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3305933937\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  12m 12s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 48s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m  0s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   4m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  21m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 58s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  66m 25s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   1m  3s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 59s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 18s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 50s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 50s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  1s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/8/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   4m 10s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/8/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 7 new + 42 unchanged - 5 fixed = 49 total (was 47)  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 38s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 50s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +0 :ok: |  spotbugs  |   0m 21s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  66m 26s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 450m 14s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/8/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 21s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 832m 28s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 40fa101aa5ab 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 661dc6e3caa66f1218db70d8e6959c2ee3cb0a87 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/8/testReport/ |\r\n   | Max. process+thread count | 3559 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T07:51:09.155+0000", "updated": "2025-09-18T07:51:09.155+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021105", "id": "18021105", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3306500643\n\n   @steveloughran discovered completely by accident, but it's something to do with the checksumming code. \r\n   \r\n   If you comment out these lines: \r\n   \r\n   ```\r\n      //  builder.addPlugin(LegacyMd5Plugin.create());\r\n   \r\n       // do not do request checksums as this causes third-party store problems.\r\n     //  builder.requestChecksumCalculation(RequestChecksumCalculation.WHEN_REQUIRED);\r\n   \r\n       // response checksum validation. Slow, even with CRC32 checksums.\r\n   //    if (parameters.isChecksumValidationEnabled()) {\r\n   //      builder.responseChecksumValidation(ResponseChecksumValidation.WHEN_SUPPORTED);\r\n   //    }\r\n   \r\n   ```\r\n   \r\n   the test will pass. Could be something to do with s3Express not supporting md5, will look into it.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T09:38:36.643+0000", "updated": "2025-09-18T09:38:36.643+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021131", "id": "18021131", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3306741287\n\n   Specifically, it's this line: `builder.requestChecksumCalculation(RequestChecksumCalculation.WHEN_REQUIRED);` that causes this. \r\n   \r\n   Comment that out, or change it to `builder.requestChecksumCalculation(RequestChecksumCalculation.WHEN_SUPPORTED)`, it passes. \r\n   \r\n   My guess is it's something to do with S3 express not supporting MD5, but for operations where `RequestChecksumCalculation.WHEN_REQUIRED` is true, SDK calculates the m5 and then S3 express rejects it. \r\n   \r\n   Have asked the SDK team. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T10:37:54.521+0000", "updated": "2025-09-18T10:37:54.521+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021168", "id": "18021168", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3307416441\n\n   ok, so maybe for s3express stores we don't do legacy MD5 plugin stuff all is good?\r\n   \r\n   1. Does imply the far end is breaking the connection when it is unhappy -at least our unit tests found this stuff before the cost of every HEAD doubles.\r\n   2. maybe we should make the choice of checksums an enum with md5 the default, so it is something that can be turned off/changed in future.\r\n   \r\n   While on the topic of S3 Express, is it now the case that because there's lifecycle rules for cleanup, LIST calls don't return prefixes of paths with incomplete uploads? If so I will need to change production code and the test -with a separate JIRA for that for completeness\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T13:19:35.674+0000", "updated": "2025-09-18T13:19:35.674+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021368", "id": "18021368", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3311549488\n\n   > for s3express stores we don't do legacy MD5 plugin stuff all is good\r\n   \r\n   @steveloughran confirming with the SDK team, since the MD5 plugin is supposed to restore previous behaviour, the server rejecting the first request seems wrong. let's see what they have to say. \r\n   \r\n   >  LIST calls don't return prefixes of paths with incomplete uploads\r\n   \r\n   Will check with S3 express team on this\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T10:04:35.168+0000", "updated": "2025-09-19T10:04:35.168+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021414", "id": "18021414", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3312197290\n\n   thanks. I don't see it on tests against s3 with the 2.29.52 release, so something is changing with the requests made with new SDK + MD5 stuff.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T13:25:35.040+0000", "updated": "2025-09-19T13:25:35.040+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021849", "id": "18021849", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3318915081\n\n   @steveloughran not able to narrow this error down just yet, it looks like it's a combination of S3A's configuration of the S3 client + these new Md5 changes. \r\n   \r\n   ```\r\n     @Test\r\n     public void testHead() throws Throwable {\r\n      // S3Client s3Client = getFileSystem().getS3AInternals().getAmazonS3Client(\"test instance\");\r\n   \r\n       S3Client s3Client = S3Client.builder().region(Region.US_EAST_1)\r\n               .addPlugin(LegacyMd5Plugin.create())\r\n               .requestChecksumCalculation(RequestChecksumCalculation.WHEN_REQUIRED)\r\n               .responseChecksumValidation(ResponseChecksumValidation.WHEN_SUPPORTED)\r\n               .overrideConfiguration(o -> o.retryStrategy(b -> b.maxAttempts(1)))\r\n               .build();\r\n   \r\n   \r\n   \r\n       s3Client.headObject(HeadObjectRequest.builder().bucket(\"<>\")\r\n               .key(\"<>\").build());\r\n     }\r\n   ```\r\n   \r\n   I see the failure when the S3A client, and don't see it when I use a newly created client. So it's not just because of `requestChecksumCalculation(RequestChecksumCalculation.WHEN_REQUIRED)`\r\n   \r\n   Looking into it some more. \r\n   \r\n    S3 express team said there have been no changes in LIST behaviour. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-22T13:08:46.288+0000", "updated": "2025-09-22T13:08:46.288+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18021897", "id": "18021897", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3320014995\n\n   able to reproduce the issue outside of S3A. Basically did what would happen when you run a test in S3A:\r\n   \r\n   * a probe for the `test/` directory, and then create the `test/` directory, and then do the `headObject()` call. \r\n   \r\n   The head fails, but if you comment out `requestChecksumCalculation(RequestChecksumCalculation.WHEN_REQUIRED)` it works again. \r\n   \r\n   no idea what's going on. but have shared this local reproduction with SDK team. And rules out that it's something in the S3A code. \r\n   \r\n   \r\n   \r\n   ```\r\n   public class TestClass {\r\n   \r\n       S3Client s3Client;\r\n   \r\n       public TestClass() {\r\n           this.s3Client = S3Client.builder().region(Region.US_EAST_1)\r\n                   .addPlugin(LegacyMd5Plugin.create())\r\n                   .requestChecksumCalculation(RequestChecksumCalculation.WHEN_REQUIRED)\r\n                   .responseChecksumValidation(ResponseChecksumValidation.WHEN_SUPPORTED)\r\n                   .overrideConfiguration(o -> o.retryStrategy(b -> b.maxAttempts(1)))\r\n                   .build();\r\n       }\r\n   \r\n   \r\n       public void testS3Express(String bucket, String key) {\r\n           s3Client.listObjectsV2(ListObjectsV2Request.builder()\r\n                   .bucket(\"<>\")\r\n                   .maxKeys(2)\r\n                   .prefix(\"test/\")\r\n                   .build());\r\n   \r\n   \r\n           try {\r\n               s3Client.headObject(HeadObjectRequest.builder().bucket(\"<>\")\r\n                       .key(\"test\")\r\n                       .build());\r\n           } catch (Exception e) {\r\n               System.out.println(\"Exception thrown: \" + e.getMessage());\r\n           }\r\n   \r\n           s3Client.putObject(PutObjectRequest\r\n                   .builder()\r\n                   .bucket(\"<>\")\r\n                   .key(\"test/\").build(), RequestBody.empty());\r\n   \r\n           s3Client.headObject(HeadObjectRequest.builder().bucket(\"<>\")\r\n                   .key(\"<>\")\r\n                   .build());\r\n       }\r\n   \r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-22T16:22:45.459+0000", "updated": "2025-09-22T16:22:45.459+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18022235", "id": "18022235", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3325180154\n\n   well, nice and simple code snippet for the regression testing. Shows the value in having sdk metrics tied up...this is the only case which failed because it's the one asserting at the SDK level values.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T18:54:18.451+0000", "updated": "2025-09-23T18:54:18.451+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18023890", "id": "18023890", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3353451859\n\n   @ahmarsuhail is there a public sdk issue for this for me to link/track?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-30T19:06:46.002+0000", "updated": "2025-09-30T19:06:46.002+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18024006", "id": "18024006", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3355348352\n\n   Just created https://github.com/aws/aws-sdk-java-v2/issues/6459\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-01T08:46:42.642+0000", "updated": "2025-10-01T08:46:42.642+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18024870", "id": "18024870", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3370618249\n\n   FYI @steveloughran , SDK team was able to root cause the issue, details here: https://github.com/aws/aws-sdk-java-v2/issues/6459#issuecomment-3362570846\r\n   \r\n   Since it's a bit of an edge case, and the SDK retry means we recover from it anyway, you think we can go ahead with the upgrade or should we wait for the fix?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-06T09:07:35.668+0000", "updated": "2025-10-06T09:07:35.668+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030046", "id": "18030046", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3405709735\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  11m 32s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  27m  4s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 43s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 48s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   3m 13s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |  10m 26s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 10s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +0 :ok: |  spotbugs  |   0m 28s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |  31m  2s | [/branch-spotbugs-root-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/branch-spotbugs-root-warnings.html) |  root in trunk has 12 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  57m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 50s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  28m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m  6s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 39s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 39s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   3m 13s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 7 new + 42 unchanged - 5 fixed = 49 total (was 47)  |\r\n   | -1 :x: |  mvnsite  |   7m 15s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   9m  2s | [/results-javadoc-javadoc-root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 1 new + 43015 unchanged - 0 fixed = 43016 total (was 43015)  |\r\n   | +1 :green_heart: |  javadoc  |   8m 45s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +0 :ok: |  spotbugs  |   0m 24s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  57m  1s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 793m 21s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 44s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1110m 44s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.tools.TestDFSAdmin |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 503d715744fe 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e319765ca591fc2a0968f3b2e900586bb46ce7c1 |\r\n   | Default Java | Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/testReport/ |\r\n   | Max. process+thread count | 3551 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/10/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T10:27:10.615+0000", "updated": "2025-10-15T10:27:10.615+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030193", "id": "18030193", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3408678775\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 15 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  9s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  16m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 41s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   6m  5s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   5m  5s |  |  trunk passed  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   0m 28s | [/branch-spotbugs-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws.txt) |  hadoop-aws in trunk failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 16s | [/branch-spotbugs-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/branch-spotbugs-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m  2s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 30s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javac  |   8m 25s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   1m 32s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 11 new + 47 unchanged - 6 fixed = 58 total (was 53)  |\r\n   | -1 :x: |  mvnsite  |   3m 45s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   4m 54s | [/results-javadoc-javadoc-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/results-javadoc-javadoc-root.txt) |  root generated 4 new + 43015 unchanged - 0 fixed = 43019 total (was 43015)  |\r\n   | +0 :ok: |  spotbugs  |   0m 12s |  |  hadoop-project has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   0m 26s | [/patch-spotbugs-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/patch-spotbugs-hadoop-tools_hadoop-aws.txt) |  hadoop-aws in the patch failed.  |\r\n   | -1 :x: |  spotbugs  |   0m 17s | [/patch-spotbugs-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/patch-spotbugs-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 44s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 227m 31s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 343m 23s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.tools.TestDFSAdmin |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux f49b0547d834 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c2eb04aa497f8d4648a3b457a90843ce96abe7fe |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/testReport/ |\r\n   | Max. process+thread count | 5153 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/12/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T00:02:02.776+0000", "updated": "2025-10-16T00:02:02.776+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030429", "id": "18030429", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3412290514\n\n   @ahmarsuhail \r\n   \r\n   I'm handling the retries now by requiring the md5 plugin to be explicitly requested (i.e. third party stores); also making it easier to switch checksum generation from ALWAYS to WHEN_REQUESTED. So for AWS S3: stricter checksums, no md5. Other stores: configure it as needed. \r\n   \r\n   Still wondering if we should make this more automated, but not in a way which causes problems later.\r\n   \r\n   ---\r\n   \r\n   I am now seeing failings against s3 express\r\n   ```\r\n   org.opentest4j.AssertionFailedError: [Counter named audit_request_execution with expected value 4] \r\n   Expecting:\r\n    <11L>\r\n   to be equal to:\r\n    <4L>\r\n   but was not.\r\n   Expected :4\r\n   Actual   :11\r\n   <Click to see difference>\r\n   \r\n   \r\n   \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n   \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n   \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n   \tat org.apache.hadoop.fs.statistics.IOStatisticAssertions.verifyStatisticValue(IOStatisticAssertions.java:274)\r\n   \tat org.apache.hadoop.fs.statistics.IOStatisticAssertions.verifyStatisticCounterValue(IOStatisticAssertions.java:175)\r\n   \tat org.apache.hadoop.fs.s3a.ITestS3AAnalyticsAcceleratorStreamReading.testMultiRowGroupParquet(ITestS3AAnalyticsAcceleratorStreamReading.java:186)\r\n   \tat java.lang.reflect.Method.invoke(Method.java:498)\r\n   \tat java.util.ArrayList.forEach(ArrayList.java:1259)\r\n   \tat java.util.ArrayList.forEach(ArrayList.java:1259)\r\n   ```\r\n   \r\n   I'm changing this test to measure the # of audited requests before the file opening begins and then assert on the difference between them.\r\n   \r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T18:32:37.931+0000", "updated": "2025-10-16T18:32:37.931+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030433", "id": "18030433", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3412377933\n\n   Now that 3rd party is good, I'm getting S3 express happy, mainly by test tuning. But many, many errors with vectored reads\r\n   \r\n   ```\r\n   [ERROR] Errors: \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testAllRangesMergedIntoOne\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testAllRangesMergedIntoOne \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testAllRangesMergedIntoOne \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testBufferSlicing\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testBufferSlicing \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testBufferSlicing \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testConsecutiveRanges\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testConsecutiveRanges \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testConsecutiveRanges \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testMultipleVectoredReads\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testMultipleVectoredReads \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testMultipleVectoredReads \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testNormalReadAfterVectoredRead\r\n   [INFO]   Run 1: PASS\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testNormalReadAfterVectoredRead \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testReadVectoredWithAALStatsCollection\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testReadVectoredWithAALStatsCollection \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testReadVectoredWithAALStatsCollection \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testSomeRandomNonOverlappingRanges\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testSomeRandomNonOverlappingRanges \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testSomeRandomNonOverlappingRanges \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadAfterNormalRead\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadAfterNormalRead \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadAfterNormalRead \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadAndReadFully\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead>AbstractContractVectoredReadTest.testVectoredReadAndReadFully:220 \u00bb IO test/vectored_file.txt: Stream is closed!\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead>AbstractContractVectoredReadTest.testVectoredReadAndReadFully:220 \u00bb IO test/vectored_file.txt: Stream is closed!\r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadMultipleRanges\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead>AbstractContractVectoredReadTest.testVectoredReadMultipleRanges:206 \u00bb Execution java.io.IOException: Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt                                                                                                                                                               \r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead>AbstractContractVectoredReadTest.testVectoredReadMultipleRanges:206 \u00bb Execution java.io.IOException: Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt                                                                                                                                                               \r\n   [INFO] \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadWholeFile\r\n   [ERROR]   Run 1: ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadWholeFile \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [ERROR]   Run 2: ITestS3AContractAnalyticsStreamVectoredRead.testVectoredReadWholeFile \u00bb IO Server error accessing s3://stevel--usw2-az1--x-s3/test/vectored_file.txt\r\n   [INFO] \r\n   [INFO] \r\n   ```\r\n   \r\n   \r\n   ```\r\n   \r\n   [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead.testReadVectoredWithAALStatsCollection ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T18:48:35.658+0000", "updated": "2025-10-16T18:48:35.658+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030441", "id": "18030441", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3412492676\n\n   @steveloughran just ran with the old 2.29.x SDK, failures there too. will look into it and fix\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T19:12:49.318+0000", "updated": "2025-10-16T19:12:49.318+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030630", "id": "18030630", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3415388890\n\n    This is happening because those readVectored() tests create a new `vectored-read.txt` file on the setup() before each test. Since the tests are parameterized, they run twice, once for `direct-buffer` and then for `array-buffer`. \r\n    \r\n   On the first run for `direct-buffer`, a HEAD for the metadata is made and cached, and the data for `vectored-read.txt` is also cached. Then the stream is `closed()` and since the file ends in `.txt`, AAL clears the data cache. (since it's a sequential format, the chances there will be a backward seek and the same data will be accessed are low so it's better to clear the data cache). The metadata cache is not cleared here (it should be, and I will make that fix).\r\n   \r\n   On the second run for `array-buffer`, the `vectored-file` is written again. AAL will get the metadata from the metadata cache, and use that eTag when making the GETS for the block data. Since on S3 express, the eTag is no longer the md5 of the object content, even though the object content is the same, the eTag has changed. And hence the 412s on the GETS. \r\n   \r\n   On consistency with caching in general:\r\n   \r\n   * AAL provides a `metadatastore.ttl` config, set that to 0 and HEAD responses are never cached. This solves the caching issues we had when overwrite files before, as with that `ttl` 0 we will always get the latest version of the file. \r\n   \r\n   * Data blocks will be removed once memory usage is > defined memory threshold (2GB), and clean up happens every 5s by default. The edge case here is that what if data usage is always below 2GB, and data blocks never get evicted? This is why the   `metadatastore.ttl` was introduced. \r\n   \r\n   * Our `BlockKey` which is the key under which file data is stored is a combination of the S3URI + eTag. If the eTag changes, then we'll have a different BlockKey, which means we don't have any data stored for it. For example:\r\n   \r\n   ```\r\n   * Data is written to A.parquet, etag is \"1234\".\r\n   * A.parquet is read fully in to the cache, with key \"A.parquet + 1234\"\r\n   * A.parquet is overwritten, etag is \"6789\". \r\n   * A.parquet is opened for reading again:\r\n   \r\n   If metadata ttl has not yet expired, and  metadata cache has eTag as `1234`, so AAL will return data from the data cache using key \"A.parquet + 1234\". If the requested data is not in the data cache, we'll make a GET with the outdated eTag as `1234` and this will fail with a 412. \r\n   \r\n   If metadata TTL has expired, a new HEAD request is made, and we now have the eTag `6789`, this will now create a new BlockKey \"A.parquet + 6789\", and since there is no data stored here, will make GETS for the data. \r\n   ```\r\n   With this we ensure two things:\r\n   \r\n   1/ Once a stream opened it will always serve bytes from the same object version, or fail. \r\n   \r\n   2/ Data will be stale at maximum metadata.tll milliseconds, with the exception of stream's lifetime. \r\n   \r\n   Basically, if your data changes often, set the metadataTTL to 0, and AAL will always get the latest data. Otherwise we have eventually consistency. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-17T12:33:00.298+0000", "updated": "2025-10-17T12:33:00.298+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030632", "id": "18030632", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3415396379\n\n   The TLDR is: \r\n   \r\n   * I will make a small fix to clear the metadata cache on stream close for sequential formats (which fixes this issue)\r\n   * Setting the `metadata.ttl` also fixes this issue. \r\n   \r\n   I've tested with both, and all `ITestS3AContractAnalyticsStreamVectoredRead` test cases pass.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-17T12:34:40.704+0000", "updated": "2025-10-17T12:34:40.704+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030678", "id": "18030678", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3416145759\n\n   good explanation. Though I would have expected a bit broader test coverage of your own stores; something to look for on the next library update.\r\n   \r\n   Can I also get improvements in error translation too -we need the error string including request IDs. Relying on the stack entry below to print it isn't enough, as deep exception nesting (hive, spark) can lose that.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-17T15:56:22.837+0000", "updated": "2025-10-17T15:56:22.837+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18030679", "id": "18030679", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3416153341\n\n   one more thing here: make sure you can handle `null` as an etag in the cache.\r\n   Not all stores have it, which is why it can be turned off for classic input stream version checking.\r\n   \r\n   You won't be able to detect overwrites, but we can just document having a short TTL here.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-17T15:59:00.358+0000", "updated": "2025-10-17T15:59:00.358+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18031161", "id": "18031161", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3422219254\n\n   @steveloughran updated exception handling: https://github.com/awslabs/analytics-accelerator-s3/pull/361, next release will have include the requestIDs in the message, eg:\r\n   \r\n   ```\r\n   java.io.IOException: Server error accessing s3://xxx, request failed with: At least one of the pre-conditions you specified did not hold (Service: S3, Status Code: 412, Request ID: xxxx, Extended Request ID: xxxx)\r\n   ```\r\n   \r\n   The null as `eTag` will require more work, the only way to do that reliably is to disable the caching fully and provide a pass through stream. Do you know which stores don't support eTags?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-20T14:04:08.240+0000", "updated": "2025-10-20T14:04:08.240+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18031517", "id": "18031517", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3428848006\n\n   latest iteration works with third party stores without MPU (so no magic or use of memory for upload buffering), or bulk delete.\r\n   \r\n   tested google gcs, only underful buffers which can be ignored.\r\n   ```\r\n   [ERROR] Failures: \r\n   [ERROR]   ITestS3AContractUnbuffer>AbstractContractUnbufferTest.testMultipleUnbuffers:108->AbstractContractUnbufferTest.validateFullFileContents:141->AbstractContractUnbufferTest.validateFileContents:148 failed to read expected number of bytes from stream. This may be transient ==> expected: <1024> but was: <533>                                                          \r\n   [ERROR]   ITestS3AContractUnbuffer>AbstractContractUnbufferTest.testUnbufferAfterRead:61->AbstractContractUnbufferTest.validateFullFileContents:141->AbstractContractUnbufferTest.validateFileContents:148 failed to read expected number of bytes from stream. This may be transient ==> expected: <1024> but was: <533>                                                           \r\n   [ERROR]   ITestS3AContractUnbuffer>AbstractContractUnbufferTest.testUnbufferBeforeRead:71->AbstractContractUnbufferTest.validateFullFileContents:141->AbstractContractUnbufferTest.validateFileContents:148 failed to read expected number of bytes from stream. This may be transient ==> expected: <1024> but was: <539>                                                          \r\n   [ERROR]   ITestS3AContractUnbuffer>AbstractContractUnbufferTest.testUnbufferOnClosedFile:91->AbstractContractUnbufferTest.validateFullFileContents:141->AbstractContractUnbufferTest.validateFileContents:148 failed to read expected number of bytes from stream. This may be transient ==> expected: <1024> but was: <539>                                                        \r\n   [INFO] \r\n   [ERROR] Tests run: 1253, Failures: 4, Errors: 0, Skipped: 450\r\n   [INFO] \r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T18:51:58.062+0000", "updated": "2025-10-21T18:51:58.062+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18031519", "id": "18031519", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3428880917\n\n   @ahmarsuhail I think Apache Ozone is the one.\r\n   \r\n   I just added an `etag` command to cloudstore to print this stuff out and experimented with various stores: https://github.com/steveloughran/cloudstore/blob/main/src/main/site/etag.md\r\n   \r\n   dell ECS and Google both supply etags. We don't retrieve them for directory markers anyway, which isn't an issue\r\n   \r\n   * I've updated the third-party docs to cover etags in more detail, and say \"switch to classic and disable version checking\"\r\n   * I do think the cache needs to handle null/empty string tags, somehow. Certainly by not caching metadata.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-21T18:56:28.823+0000", "updated": "2025-10-21T18:56:28.823+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032075", "id": "18032075", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3432106892\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  15m  2s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 38 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 43s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  29m  3s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 53s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 41s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   3m 15s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |  10m 51s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 36s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 31s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +0 :ok: |  spotbugs  |   0m 28s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   1m 18s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | -1 :x: |  spotbugs  |  36m 27s | [/branch-spotbugs-root-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/branch-spotbugs-root-warnings.html) |  root in trunk has 9241 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  61m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 48s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  27m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 53s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  14m 53s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 24s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 24s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/blanks-eol.txt) |  The patch has 24 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   3m 15s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 14 new + 79 unchanged - 6 fixed = 93 total (was 85)  |\r\n   | -1 :x: |  mvnsite  |   7m  2s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   9m 37s | [/results-javadoc-javadoc-root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 4 new + 46184 unchanged - 0 fixed = 46188 total (was 46184)  |\r\n   | -1 :x: |  javadoc  |   8m 41s | [/results-javadoc-javadoc-root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 4 new + 43015 unchanged - 0 fixed = 43019 total (was 43015)  |\r\n   | +0 :ok: |  spotbugs  |   0m 22s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  62m 29s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 741m 49s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 44s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1085m  5s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.security.ssl.TestDelegatingSSLSocketFactory |\r\n   |   | hadoop.yarn.service.TestYarnNativeServices |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 8fbc6faf5962 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 1cd8a2820c4aadeca61f3a7449c7d98fd34bb9d8 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/testReport/ |\r\n   | Max. process+thread count | 3717 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/14/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-22T12:25:28.756+0000", "updated": "2025-10-22T12:25:28.756+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032296", "id": "18032296", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3434634222\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 27s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 39 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 18s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 18s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 18s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 25s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   6m 10s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 31s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 43s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   0m 41s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | -1 :x: |  spotbugs  |  18m 42s | [/branch-spotbugs-root-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/branch-spotbugs-root-warnings.html) |  root in trunk has 9241 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 22s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 52s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   7m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 17s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m 17s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/blanks-eol.txt) |  The patch has 24 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   1m 33s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 14 new + 79 unchanged - 6 fixed = 93 total (was 85)  |\r\n   | -1 :x: |  mvnsite  |   3m 43s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | -1 :x: |  javadoc  |   5m 23s | [/results-javadoc-javadoc-root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 4 new + 46184 unchanged - 0 fixed = 46188 total (was 46184)  |\r\n   | -1 :x: |  javadoc  |   4m 38s | [/results-javadoc-javadoc-root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 4 new + 43015 unchanged - 0 fixed = 43019 total (was 43015)  |\r\n   | +0 :ok: |  spotbugs  |   0m 12s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 15s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 594m 47s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 50s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 779m 27s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.yarn.server.resourcemanager.reservation.TestCapacityOverTimePolicy |\r\n   |   | hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes |\r\n   |   | hadoop.hdfs.server.federation.router.async.TestRouterAsyncRpcClient |\r\n   |   | hadoop.security.ssl.TestDelegatingSSLSocketFactory |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux c90f744f2220 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 96c3f38ea5e033636e1acdb8fe2ed4b398bedb08 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/testReport/ |\r\n   | Max. process+thread count | 4624 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/15/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T00:16:22.819+0000", "updated": "2025-10-23T00:16:22.819+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032517", "id": "18032517", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3437736945\n\n   fun test run today, against s3 london. Most of the multipart upload/commit tests were failing \"missing part\", from cli or IDE. Testing with S3 express was happy. (`-Dparallel-tests -DtestsThreadCount=8 -Panalytics -Dscale`)\r\n   \r\n   ```\r\n   [ERROR]   ITestS3AHugeMagicCommits.test_030_postCreationAssertions:192 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: JAEYPCZ4P3JYGMTD, Extended Request ID: O/135mw9Xd2aEuFUh0ICWYc8DLXSpBUWaVGkEgEFGf0xO8o+XlZXY0hI+mvennOGt+C/UI7mNrQ=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: JAEYPCZ4P3JYGMTD, Extended Request ID: O/135mw9Xd2aEuFUh0ICWYc8DLXSpBUWaVGkEgEFGf0xO8o+XlZXY0hI+mvennOGt+C/UI7mNrQ=) (SDK Attempt Count: 1)                                                                                                                                                                                   \r\n   [ERROR]   ITestS3AHugeMagicCommits>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin in s3a://stevel-london/job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit                                                                                                                                                      \r\n   [ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1)                                                                                                                     \r\n   [ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src                                                                                                                  \r\n   [ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src  \r\n   [ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src      \r\n   [ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src            \r\n   [ERROR]   ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src          \r\n   [ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/bytebuffer/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: K0K75V8AH7SVBHS3, Extended Request ID: kDosbp+Z2PLZn9tVtRF9QfOqh1MgLbIKYaYFn2JeIptXlBV4v1a/wFukoXnaF7fCp6zx3vR8feE0fScUJEw+WhNW9lzu9dBxssOA62UA2kg=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: K0K75V8AH7SVBHS3, Extended Request ID: kDosbp+Z2PLZn9tVtRF9QfOqh1MgLbIKYaYFn2JeIptXlBV4v1a/wFukoXnaF7fCp6zx3vR8feE0fScUJEw+WhNW9lzu9dBxssOA62UA2kg=) (SDK Attempt Count: 1)                                                                                                           \r\n   [ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                   \r\n   [ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                             \r\n   [ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                                 \r\n   [ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                                       \r\n   [ERROR]   ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src                                                                                                                                                                                     \r\n   [ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/disk/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 73T4YAYRWE63WAW5, Extended Request ID: 6ucEY2heh2NsxE8dBrlZp9AE4Tb+hbvnyxea1/yp5H85BEvkQdYsfNlRH5XZM1g4hHPDSoGMVtM=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 73T4YAYRWE63WAW5, Extended Request ID: 6ucEY2heh2NsxE8dBrlZp9AE4Tb+hbvnyxea1/yp5H85BEvkQdYsfNlRH5XZM1g4hHPDSoGMVtM=) (SDK Attempt Count: 1)                                                                                                                                                                                       \r\n   [ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src                                                                                                                     \r\n   [ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src     \r\n   [ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src         \r\n   [ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src               \r\n   [ERROR]   ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src             \r\n   [ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/disk/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: ZSY181YB49GQFR83, Extended Request ID: FrPEfsXO3Gbhxi3m4ZmyYSiyfscQ1QSm/1lKjRPLHEbLWH5vtGked+fHvZl281Dm6u013/5VP6pj42h4XISftk7p9uEIDGw31E7Ymcoviq4=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: ZSY181YB49GQFR83, Extended Request ID: FrPEfsXO3Gbhxi3m4ZmyYSiyfscQ1QSm/1lKjRPLHEbLWH5vtGked+fHvZl281Dm6u013/5VP6pj42h4XISftk7p9uEIDGw31E7Ymcoviq4=) (SDK Attempt Count: 1)                                                                                                                   \r\n   [ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src                                                                                                                 \r\n   [ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src \r\n   [ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src     \r\n   [ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src           \r\n   [ERROR]   ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src         \r\n   [ERROR]   ITestS3AHugeFilesStorageClass.test_010_CreateHugeFile:74->AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 \u00bb AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: APYCQNP1GY02DGDE, Extended Request ID: lE0hQJ67sSwCYSMmO7tDEAvEIOCcpwIbLdfqqrNTpWT0bHIaacaIEzZusajj79rnFQlWudxsMHBIUXdS9ELiKR0T923lcULZy4Essx1LoTs=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: APYCQNP1GY02DGDE, Extended Request ID: lE0hQJ67sSwCYSMmO7tDEAvEIOCcpwIbLdfqqrNTpWT0bHIaacaIEzZusajj79rnFQlWudxsMHBIUXdS9ELiKR0T923lcULZy4Essx1LoTs=) (SDK Attempt Count: 1)                                                                                        \r\n   [ERROR]   ITestS3AHugeFilesStorageClass.test_030_postCreationAssertions:81->AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 \u00bb FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src                                                                             \r\n   [ERROR]   ITestS3AHugeFilesStorageClass>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src     \r\n   [ERROR]   ITestS3AHugeFilesStorageClass.test_100_renameHugeFile:108->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 \u00bb FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src                                   \r\n   [INFO] \r\n   [ERROR] Tests run: 124, Failures: 1, Errors: 30, Skipped: 13\r\n   [INFO] \r\n   ```\r\n   \r\n   This has to be some transient issue with my s3 london bucket, as if in progress upload parts were not being retained. Never seen this before; the expiry time is set to 24h\r\n   \r\n   When these uploads fail we do leave incomplete uploads in progress:\r\n   ```\r\n   Listing uploads under path \"\"\r\n   job-00-fork-0005/test/testCommitOperations 141OKG11JHhWF1GOnunHUd9ZzBJ8cUG9z0LsW_4wUGgCXCvDMQM3kRi5IOCUV8FdCHtg_w8SlipfubRtzCQoT5yEpOLv.cWOiOwjEaBzUjnuJORppfXuKy1piHpLnu98\r\n   job-00-fork-0005/test/testIfMatchTwoMultipartUploadsRaceConditionOneClosesFirst yBJpm3zh4DjNQIDtyWgEmWVCk5sehVz5Vzn3QGr_tQT2iOonRp5ErXsQy24yIvnzRxBCZqVapy5VepLeu2udZBT5EXLnKRA3bchvzjtKDlipywSzYlL2N_xLUDCT359I\r\n   job-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads AnspJPHUoPJqg61t28OvLfAogi6G9ocyx1Dm6XY2C.a_H_onklM0Nr0LIXaPiYlQjZIiH0fTsQ1e2KhEjS9pGxvSKOXq_4YibiGZmFC6rBolmfACMqIRpoeaqYDgzYW4\r\n   job-00-fork-0005/test/testMagicWriteRecovery/file.txt KpvoTuVh85Wzm9XuU1EuxbATjb6D.Zv8vEj3z2S6AvJBHCBssy4iphxNhTkLDs7ceEwak4IPtdXED1vRf3geXT7MRMJn8d6feafvHVEgzbD31odpzTLmOaPrU_mFQXGV\r\n   job-00-fork-0005/test/testMagicWriteRecovery/file.txt CnrbWU3pzgEGvjRuDuaP43Xcv1eBF5aLknqYaZA1vwO3b1QUIu9QJSiZjuLMYKT9GKw1QXwqoKo4iuxTY1a18bARx4XMEiL98kZBv0TPMaAfXE.70Olh8Q2kTyDlUCSh\r\n   job-00-fork-0005/test/testMagicWriteRecovery/file.txt dEVGPBRsuOAzL5pGA02ve9qJhAlNK8lb8khF6laKjo9U0j_aG1xLkHEfPLrmcrcsLxC3R755Yv_uKbzY_Vnoc.nXCprvutM1TZmLLN_7LHrQ0tY0IjYSS6hVzDVlHbvC\r\n   job-00-fork-0006/test/restricted/testCommitEmptyFile/empty-commit.txt NOCjVJqycZhkalrvU26F5oIaJP51q055et2N6b74.2JVjiKL8KwrhOhdrtumOrZ2tZWNqaK4iKZ_iosqgehJOiPbWJwxvrfvA5V.dAUTLNqjtEf5tfWh0UXu.vahDy_S5SSgNLFXK.VB82i5MZtOcw--\r\n   job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin lsYNpdn_oiWLwEVvvM621hCvIwDVaL4y_bbwVpQouW1OBThA.P9cR8fZtxvBjGdMY41UH0dTjxGHtF3BXEY8WXqmcnO9QHs_Jy.os781pE3MGzqgzFyxmd0yN6LFcTbq\r\n   test/restricted/testCommitEmptyFile/empty-commit.txt T3W9V56Bv_FMhKpgcBgJ1H2wOBkPKk23T0JomesBzZyqiIAu3NiROibAgoZUhWSdoTKSJoOgcn3UWYGOvGBbsHteS_N_c1QoTEp0GE7PNlzDfs1GheJ5SOpUgaEY6MaYdNe0mn0gY48FDXpVB2nqiA--\r\n   test/restricted/testCommitEmptyFile/empty-commit.txt .cr4b3xkfze4N24Bj3PAm_ACIyIVuTU4DueDktU1abNu2LJWXH2HKnUu1oOjfnnQwnUXp4VmXBVbZ5aq8E8gVCxN.Oyb7hmGVtESmRjpqIXSW80JrB_0_dqXe.uAT.JH7kEWywAlb4NIqJ5Xz99tvA--\r\n   Total 10 uploads found.\r\n   ```\r\n   \r\n   Most interesting here is `testIfNoneMatchTwoConcurrentMultipartUploads`, because this initiates then completes an MPU, so as to create a zero byte file. It doesn't upload any parts. \r\n   \r\n   The attempt to complete failed.\r\n   ```\r\n   [ERROR]   ITestS3APutIfMatchAndIfNoneMatch.testIfNoneMatchTwoConcurrentMultipartUploads:380->createFileWithFlags:190 \u00bb AWSBadRequest Completing multipart upload on job-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found.  The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1)          \r\n   ```\r\n   \r\n   Yet the uploads list afterwards finds it\r\n   ```\r\n   job-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads AnspJPHUoPJqg61t28OvLfAogi6G9ocyx1Dm6XY2C.a_H_onklM0Nr0LIXaPiYlQjZIiH0fTsQ1e2KhEjS9pGxvSKOXq_4YibiGZmFC6rBolmfACMqIRpoeaqYDgzYW4\r\n   ```\r\n   \r\n   I have to conclude that the list of pending uploads was briefly offline/inconsistent.\r\n   \r\n   This is presumably so, so rare that there's almost no point retrying here. With no retries, every active write/job would have failed, even though the system had recovered within a minute.\r\n   \r\n   Maybe we should retry here? I remember a long long time ago the v1 sdk didn't retry on failures of the final POST to commit an upload, and how that sporadically caused problems. Retrying on MPU failures will allow for recovery in the presence of a transient failure here, and the cost of \"deletion of all pending uploads will take longer to fail all active uploads\". \r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T15:44:27.902+0000", "updated": "2025-10-23T15:44:27.902+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032666", "id": "18032666", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3441063874\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 19s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 39 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 42s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 10s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 15s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 36s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   6m 44s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 35s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 51s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   0m 41s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | -1 :x: |  spotbugs  |  19m  4s | [/branch-spotbugs-root-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/artifact/out/branch-spotbugs-root-warnings.html) |  root in trunk has 9241 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 44s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  16m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 49s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m 49s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   9m 26s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   9m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 41s |  |  root: The patch generated 0 new + 79 unchanged - 6 fixed = 79 total (was 85)  |\r\n   | -1 :x: |  mvnsite  |   4m 11s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 17s |  |  root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 0 new + 46182 unchanged - 2 fixed = 46182 total (was 46184)  |\r\n   | +1 :green_heart: |  javadoc  |   4m 44s |  |  root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 0 new + 43013 unchanged - 2 fixed = 43013 total (was 43015)  |\r\n   | +0 :ok: |  spotbugs  |   0m 11s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 53s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 591m 32s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 51s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 781m 38s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.hdfs.tools.TestDFSAdmin |\r\n   |   | hadoop.security.ssl.TestDelegatingSSLSocketFactory |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 54d25015775c 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / fa906dcf97ff8829f50184906bd7433bc2a0a73a |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/testReport/ |\r\n   | Max. process+thread count | 4675 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/17/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-24T04:55:19.546+0000", "updated": "2025-10-24T04:55:19.546+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032833", "id": "18032833", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3444243683\n\n   OK, this is all related to checksums on multipart puts.\r\n   \r\n   If you declare that checksums are always required on requests, you MUST define a checksum algorithm to use for multipart put, otherwise upload completions fail. I have no idea why, will file some SDK bug report to say \"this is wrong\" and simply change our settings to\r\n   - checksums NOT always required\r\n   - MD5 always enabled\r\n   - checksum algorithm is CRC32C (will test with third party store)\r\n   \r\n   checksums in MPUs breaks a couple of the multipart uploader tests; more worried that about a ITestS3AOpenCost test failing with checksum verification being enabled (slow, expensive). I need to make sure that this is not an SDK regression.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-24T17:46:39.828+0000", "updated": "2025-10-24T17:46:39.828+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032838", "id": "18032838", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3444263138\n\n   Its a change in the default value: downloads have checksums verified unless you say \"no\". we say no.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-24T17:53:50.702+0000", "updated": "2025-10-24T17:53:50.702+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032862", "id": "18032862", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "AWS SDK issue #6518 shows how checksum generation on uploaded data (fs.s3a.create.checksum) must be set if request checksum calculation is enabled (fs.s3a.checksum.generation)\r\n\r\nChecksum validation has also been enabled by default; {{ITestS3AOpenCost.testStreamIsNotChecksummed()}} caught that change.\r\n\r\nIt looks like the SDK has really embraced checksums, which first broke compatibility with other stores, but which has also surfaced problems within their own code.\r\n\r\nAll checksum logic will be off by default; MD5 headers will be attached now ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-10-24T20:01:02.429+0000", "updated": "2025-10-24T20:01:02.429+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626670/comment/18032926", "id": "18032926", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7882:\nURL: https://github.com/apache/hadoop/pull/7882#issuecomment-3446382053\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 23s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 44 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m  1s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m 50s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 12s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 23s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 36s |  |  trunk passed  |\r\n   | -1 :x: |  mvnsite  |   5m 54s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/branch-mvnsite-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 18s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 41s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +0 :ok: |  spotbugs  |   0m 16s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |   1m 27s | [/branch-spotbugs-hadoop-common-project_hadoop-common-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/branch-spotbugs-hadoop-common-project_hadoop-common-warnings.html) |  hadoop-common-project/hadoop-common in trunk has 448 extant spotbugs warnings.  |\r\n   | -1 :x: |  spotbugs  |   0m 39s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | -1 :x: |  spotbugs  |  18m 32s | [/branch-spotbugs-root-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/branch-spotbugs-root-warnings.html) |  root in trunk has 9241 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  32m  9s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 29s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  6s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m 20s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/blanks-eol.txt) |  The patch has 6 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   1m 30s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 6 new + 83 unchanged - 6 fixed = 89 total (was 89)  |\r\n   | -1 :x: |  mvnsite  |   3m 47s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 16s |  |  root-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 0 new + 46182 unchanged - 2 fixed = 46182 total (was 46184)  |\r\n   | +1 :green_heart: |  javadoc  |   4m 41s |  |  root-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 0 new + 43013 unchanged - 2 fixed = 43013 total (was 43015)  |\r\n   | +0 :ok: |  spotbugs  |   0m 11s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 34s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 587m  3s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 50s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 770m  3s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.service.TestYarnNativeServices |\r\n   |   | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   |   | hadoop.hdfs.tools.TestDFSAdmin |\r\n   |   | hadoop.security.ssl.TestDelegatingSSLSocketFactory |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7882 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets xmllint markdownlint shellcheck shelldocs |\r\n   | uname | Linux cc0336ad4f43 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 149e98291ada965d1dc2b85b4214f235bb4b5c5d |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/testReport/ |\r\n   | Max. process+thread count | 4586 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7882/20/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-25T09:26:53.461+0000", "updated": "2025-10-25T09:26:53.461+0000"}], "maxResults": 45, "total": 45, "startAt": 0}, "updated": "2025-10-25T09:26:53.000+0000", "created": "2025-08-18T16:47:04.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626577", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626577", "key": "HADOOP-19653", "fields": {"summary": "[JDK25] Bump ByteBuddy 1.17.6 and ASM 9.8 to support Java 25 bytecode", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014487", "id": "18014487", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7879:\nURL: https://github.com/apache/hadoop/pull/7879\n\n   \u2026tecode\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   ```\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T03:27:54.434+0000", "updated": "2025-08-18T03:27:54.434+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014496", "id": "18014496", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#discussion_r2281285636\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -146,7 +146,7 @@\n     <netty4.version>4.1.118.Final</netty4.version>\n     <snappy-java.version>1.1.10.4</snappy-java.version>\n     <lz4-java.version>1.7.1</lz4-java.version>\n-    <byte-buddy.version>1.15.11</byte-buddy.version>\n+    <byte-buddy.version>1.17.6</byte-buddy.version>\n\nReview Comment:\n   Should the LICENSE-binary be updated?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T04:45:12.333+0000", "updated": "2025-08-18T04:45:12.333+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014499", "id": "18014499", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#discussion_r2281290385\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -146,7 +146,7 @@\n     <netty4.version>4.1.118.Final</netty4.version>\n     <snappy-java.version>1.1.10.4</snappy-java.version>\n     <lz4-java.version>1.7.1</lz4-java.version>\n-    <byte-buddy.version>1.15.11</byte-buddy.version>\n+    <byte-buddy.version>1.17.6</byte-buddy.version>\n\nReview Comment:\n   they are test-only deps, not present in LICENSE/NOTICE files\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T04:50:22.822+0000", "updated": "2025-08-18T04:50:22.822+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014501", "id": "18014501", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#discussion_r2281293747\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -146,7 +146,7 @@\n     <netty4.version>4.1.118.Final</netty4.version>\n     <snappy-java.version>1.1.10.4</snappy-java.version>\n     <lz4-java.version>1.7.1</lz4-java.version>\n-    <byte-buddy.version>1.15.11</byte-buddy.version>\n+    <byte-buddy.version>1.17.6</byte-buddy.version>\n\nReview Comment:\n   LGTM.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T04:53:53.246+0000", "updated": "2025-08-18T04:53:53.246+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014505", "id": "18014505", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#issuecomment-3195141474\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  76m 14s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 15s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 45s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 19s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 117m  4s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7879/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7879 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 395fb749b4d0 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / fee75ef1efffd7f6da1fa67bdefd54b076f51df3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7879/1/testReport/ |\r\n   | Max. process+thread count | 549 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project U: hadoop-project |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7879/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T05:26:17.856+0000", "updated": "2025-08-18T05:26:17.856+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014574", "id": "18014574", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#issuecomment-3196190107\n\n   Have you tried building with Java 25 ?\r\n   Last time I updated ByteBuddy, I run into maven-shade-plugin incompatibilities.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T11:02:52.517+0000", "updated": "2025-08-18T11:02:52.517+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014580", "id": "18014580", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#issuecomment-3196229409\n\n   @stoty this PR indeed fixes the Java 25 building\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T11:16:53.555+0000", "updated": "2025-08-18T11:16:53.555+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014599", "id": "18014599", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#issuecomment-3196566191\n\n   Thanks.\r\n   \r\n   I can also successfully build with the patch.\r\n   \r\n   The shade plugin problem doesn't surface because we're actually compiling JDK17 bytecode.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T12:36:54.597+0000", "updated": "2025-08-18T12:36:54.597+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014602", "id": "18014602", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#issuecomment-3196591873\n\n   > The shade plugin problem doesn't surface because we're actually compiling JDK17 bytecode.\r\n   \r\n   @stoty This is actually addressed by upgrading ASM deps used by `maven-shade-plugin`, without this change, you will see error\r\n   \r\n   ```\r\n   [ERROR] Failed to execute goal org.apache.maven.plugins:maven-shade-plugin:3.6.0:shade (default) on project hadoop-client-minicluster: Error creating shaded jar: Problem shading JAR /home/chengpan/.m2/repository/net/bytebuddy/byte-buddy/1.17.6/byte-buddy-1.17.6.jar entry META-INF/versions/24/net/bytebuddy/jar/asmjdkbridge/JdkClassWriter$1.class: java.lang.IllegalArgumentException: Unsupported class file major version 68 -> [Help 1]\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T12:41:12.011+0000", "updated": "2025-08-18T12:41:12.011+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014609", "id": "18014609", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#issuecomment-3196844666\n\n   I've also tried to set the target version to 25, but some other plugin failed, the build didn't even get as far the shade plugin.\r\n   \r\n   But again, that is not a major issue, as we're building for Java 17 compatibility.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T13:20:48.376+0000", "updated": "2025-08-18T13:20:48.376+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014767", "id": "18014767", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T00:43:53.226+0000", "updated": "2025-08-19T00:43:53.226+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626577/comment/18014768", "id": "18014768", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7879:\nURL: https://github.com/apache/hadoop/pull/7879#issuecomment-3198832279\n\n   @pan3793 Thanks for the contribution! @stoty Thanks for the review!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T00:44:11.921+0000", "updated": "2025-08-19T00:44:11.921+0000"}], "maxResults": 12, "total": 12, "startAt": 0}, "updated": "2025-08-19T00:44:29.000+0000", "created": "2025-08-18T03:11:13.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626576", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626576", "key": "HADOOP-19652", "fields": {"summary": "Fix dependency exclusion list of hadoop-client-runtime.", "description": null, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014475", "id": "18014475", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 opened a new pull request, #7878:\nURL: https://github.com/apache/hadoop/pull/7878\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   When trying to use the Hadoop trunk version client with Spark 4.0.0, `NoClassDefFoundError` was raised.\r\n   \r\n   ```\r\n   Exception in thread \"main\" java.lang.NoClassDefFoundError: org/apache/hadoop/shaded/javax/ws/rs/WebApplicationException\r\n   \tat java.base/java.lang.ClassLoader.defineClass1(Native Method)\r\n   \tat java.base/java.lang.ClassLoader.defineClass(ClassLoader.java:962)\r\n   \tat java.base/java.security.SecureClassLoader.defineClass(SecureClassLoader.java:144)\r\n   \tat java.base/jdk.internal.loader.BuiltinClassLoader.defineClass(BuiltinClassLoader.java:776)\r\n   \tat java.base/jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(BuiltinClassLoader.java:691)\r\n   \tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(BuiltinClassLoader.java:620)\r\n   \tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:578)\r\n   \tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:490)\r\n   \tat org.apache.spark.deploy.yarn.YarnRMClient.getAmIpFilterParams(YarnRMClient.scala:109)\r\n   \tat org.apache.spark.deploy.yarn.ApplicationMaster.addAmIpFilter(ApplicationMaster.scala:698)\r\n   \tat org.apache.spark.deploy.yarn.ApplicationMaster.runExecutorLauncher(ApplicationMaster.scala:555)\r\n   \tat org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:265)\r\n   \tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:942)\r\n   \tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:941)\r\n   \tat java.base/jdk.internal.vm.ScopedValueContainer.callWithoutScope(ScopedValueContainer.java:162)\r\n   \tat java.base/jdk.internal.vm.ScopedValueContainer.call(ScopedValueContainer.java:147)\r\n   \tat java.base/java.lang.ScopedValue$Carrier.call(ScopedValue.java:419)\r\n   \tat java.base/javax.security.auth.Subject.callAs(Subject.java:331)\r\n   \tat org.apache.hadoop.util.SubjectUtil.callAs(SubjectUtil.java:134)\r\n   \tat org.apache.hadoop.util.SubjectUtil.doAs(SubjectUtil.java:166)\r\n   \tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:2039)\r\n   \tat org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:941)\r\n   \tat org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:973)\r\n   \tat org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)\r\n   Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.shaded.javax.ws.rs.WebApplicationException\r\n   \tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:580)\r\n   \tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:490)\r\n   \t... 24 more\r\n   ```\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Hadoop Client Runtime 3.4.2 RC2\r\n   <img width=\"407\" height=\"459\" alt=\"image\" src=\"https://github.com/user-attachments/assets/9ba6eb0c-2d52-4034-8f97-01c73195d795\" />\r\n   \r\n   Hadoop Client Runtime 3.5.0-SNAPSHOT trunk\r\n   <img width=\"516\" height=\"432\" alt=\"image\" src=\"https://github.com/user-attachments/assets/81115ab8-3f86-4336-9d95-fe61093b09d1\" />\r\n   \r\n   Hadoop Client Runtime 3.5.0-SNAPSHOT HADOOP-19652\r\n   <img width=\"509\" height=\"433\" alt=\"image\" src=\"https://github.com/user-attachments/assets/eb08a2d8-6b52-45f4-b56e-4ea3a92e950a\" />\r\n   \r\n   Tested by submitting a Spark application to a YARN cluster.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T02:44:26.934+0000", "updated": "2025-08-18T02:44:26.934+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014479", "id": "18014479", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3194939043\n\n   cc @slfan1989 @cnauroth, this is caused by Jersey upgrading.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T02:57:42.533+0000", "updated": "2025-08-18T02:57:42.533+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014480", "id": "18014480", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3194946944\n\n   AFAIK, there is no solid integration test for the Hadoop Shaded client, I will continue to test it with Spark and fix issues I encounter.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T03:04:03.509+0000", "updated": "2025-08-18T03:04:03.509+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014497", "id": "18014497", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3195086656\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  76m 30s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   5m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 16s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 16s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  35m 43s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 20s |  |  hadoop-client-runtime in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 121m 57s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7878 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 84d5837e24b5 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 16187caf9fa1ca13f0b60d9a5e2dabd40c2aba12 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/1/testReport/ |\r\n   | Max. process+thread count | 648 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-client-modules/hadoop-client-runtime U: hadoop-client-modules/hadoop-client-runtime |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T04:47:47.463+0000", "updated": "2025-08-18T04:47:47.463+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014500", "id": "18014500", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#discussion_r2281293084\n\n\n##########\nhadoop-client-modules/hadoop-client-runtime/pom.xml:\n##########\n@@ -176,14 +176,11 @@\n                       <exclude>org.glassfish.jersey.core:*</exclude>\n                       <exclude>org.glassfish.hk2.external:*</exclude>\n                       <exclude>org.glassfish.jaxb:*</exclude>\n-                      <exclude>jakarta.ws.rs:*</exclude>\n                       <exclude>jakarta.annotation:*</exclude>\n                       <exclude>jakarta.validation:*</exclude>\n-                      <exclude>jakarta.servlet:*</exclude>\n-                      <exclude>javax.annotation:*</exclude>\n                       <exclude>org.hamcrest:*</exclude>\n+                      <exclude>org.javassist:*</exclude>\n\nReview Comment:\n   Can this line remain unchanged?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T04:53:13.071+0000", "updated": "2025-08-18T04:53:13.071+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014503", "id": "18014503", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#discussion_r2281304950\n\n\n##########\nhadoop-client-modules/hadoop-client-runtime/pom.xml:\n##########\n@@ -176,14 +176,11 @@\n                       <exclude>org.glassfish.jersey.core:*</exclude>\n                       <exclude>org.glassfish.hk2.external:*</exclude>\n                       <exclude>org.glassfish.jaxb:*</exclude>\n-                      <exclude>jakarta.ws.rs:*</exclude>\n                       <exclude>jakarta.annotation:*</exclude>\n                       <exclude>jakarta.validation:*</exclude>\n-                      <exclude>jakarta.servlet:*</exclude>\n-                      <exclude>javax.annotation:*</exclude>\n                       <exclude>org.hamcrest:*</exclude>\n+                      <exclude>org.javassist:*</exclude>\n\nReview Comment:\n   this is the corrected version of\r\n   ```\r\n   <exclude>javassist:*</exclude>\r\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T05:04:59.544+0000", "updated": "2025-08-18T05:04:59.544+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014506", "id": "18014506", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3195164574\n\n   Not a real error, just caused by token expiration, push a new empty commit to retrigger CI.\r\n   \r\n   ```\r\n   12:47:42  ============================================================================\r\n   12:47:42  ============================================================================\r\n   12:47:42                           Adding comment to Github\r\n   12:47:42  ============================================================================\r\n   12:47:42  ============================================================================\r\n   12:47:42  \r\n   12:47:42  \r\n   12:47:46  ERROR: Failed to write github status. Token expired or missing repo:status write?\r\n   12:47:46  ERROR: Failed to write github status. Token expired or missing repo:status write?\r\n   ```\r\n   https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/1/console\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T05:38:57.900+0000", "updated": "2025-08-18T05:38:57.900+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014526", "id": "18014526", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3195503178\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  38m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  76m  3s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   5m 47s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 15s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  35m 29s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 20s |  |  hadoop-client-runtime in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 49s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 121m 21s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7878 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux f59cfeb748b8 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 830cdae5363f8db2dede0b6097accfce6a51f7b9 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/2/testReport/ |\r\n   | Max. process+thread count | 560 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-client-modules/hadoop-client-runtime U: hadoop-client-modules/hadoop-client-runtime |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T07:40:11.141+0000", "updated": "2025-08-18T07:40:11.141+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014562", "id": "18014562", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3196039890\n\n   @pan3793 https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/2/artifact/out/patch-shadedclient.txt\r\n   \r\n   ```\r\n   ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:3.5.0:enforce (enforce-banned-dependencies) on project hadoop-client-check-test-invariants: \r\n   [ERROR] Rule 1: org.apache.maven.plugins.enforcer.BanDuplicateClasses failed with message:\r\n   [ERROR] Duplicate classes found:\r\n   [ERROR] \r\n   [ERROR]   Found in:\r\n   [ERROR]     org.apache.hadoop:hadoop-client-minicluster:jar:3.5.0-SNAPSHOT:compile\r\n   [ERROR]     org.apache.hadoop:hadoop-client-runtime:jar:3.5.0-SNAPSHOT:compile\r\n   ......\r\n   [ERROR] After correcting the problems, you can resume the build with the command\r\n   [ERROR]   mvn <args> -rf :hadoop-client-check-test-invariants\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T10:12:07.495+0000", "updated": "2025-08-18T10:12:07.495+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014563", "id": "18014563", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3196049320\n\n   @slfan1989 I see, will fix soon\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T10:14:48.218+0000", "updated": "2025-08-18T10:14:48.218+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014645", "id": "18014645", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3197368091\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 31s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 54s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 53s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 50s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  79m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  22m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 37s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 20s |  |  hadoop-client-runtime in the patch passed.  |\r\n   | +1 :green_heart: |  unit  |   0m 21s |  |  hadoop-client-minicluster in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 143m 23s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7878 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux 5bff763e4c87 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0e4ad11e173fee8758c0267f4ee503448bfcdc97 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/3/testReport/ |\r\n   | Max. process+thread count | 546 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-client-modules/hadoop-client-runtime hadoop-client-modules/hadoop-client-minicluster U: hadoop-client-modules |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7878/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T15:20:26.357+0000", "updated": "2025-08-18T15:20:26.357+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18014766", "id": "18014766", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3198828530\n\n   > @slfan1989 I see, will fix soon\r\n   \r\n   @pan3793 Thank you for your contribution! I don\u2019t see any other issues. Let\u2019s wait for one more day, and if there are no further comments, I\u2019ll merge this PR.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T00:41:27.086+0000", "updated": "2025-08-19T00:41:27.086+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18015022", "id": "18015022", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T00:23:46.195+0000", "updated": "2025-08-20T00:23:46.195+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626576/comment/18015023", "id": "18015023", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7878:\nURL: https://github.com/apache/hadoop/pull/7878#issuecomment-3203410020\n\n   @pan3793 Thanks for the contribution! Merged into trunk.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T00:24:14.073+0000", "updated": "2025-08-20T00:24:14.073+0000"}], "maxResults": 14, "total": 14, "startAt": 0}, "updated": "2025-09-29T11:05:01.000+0000", "created": "2025-08-18T02:31:16.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626490", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626490", "key": "HADOOP-19651", "fields": {"summary": "Upgrade libopenssl to 3.5.2-1 needed for rsync", "description": "The currently used libopenssl-3.1.4-1 is no longer available on the msys repo - https://repo.msys2.org/msys/x86_64/libopenssl-3.1.4-1-x86_64.pkg.tar.zst\r\n\r\nThe Jenkins CI thus fails to download the same and thus it fails to build the docker image for Windows.\r\n\r\n{code}\r\n00:25:33 SUCCESS: Specified value was saved.\r\n00:25:46 Removing intermediate container 5ce7355571a1\r\n00:25:46 ---> a13a4bc69545\r\n00:25:46 Step 21/78 : RUN powershell Invoke-WebRequest -Uri https://repo.msys2.org/msys/x86_64/libopenssl-3.1.4-1-x86_64.pkg.tar.zst -OutFile $Env:TEMP\\libopenssl-3.1.4-1-x86_64.pkg.tar.zst\r\n00:25:46 ---> Running in d2dafad446f9\r\n00:25:54 \u001b[91mInvoke-WebRequest : The remote server returned an error: (404) Not Found.\r\n00:25:54 \u001b[0m\u001b[91mAt line:1 char:1\r\n00:25:54 \u001b[0m\u001b[91m+ Invoke-WebRequest -Uri https://repo.msys2.org/msys/x86_64/libopenssl- ...\r\n00:25:54 + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n00:25:54 \u001b[0m\u001b[91m + CategoryInfo : InvalidOperation: (System.Net.HttpWebRequest:Htt\r\n{code}\r\n\r\nThus, we need to upgrade to the latest version to address this.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626490/comment/18014189", "id": "18014189", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra opened a new pull request, #7875:\nURL: https://github.com/apache/hadoop/pull/7875\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   The currently used `libopenssl-3.1.4-1` is no longer available on the msys repo - https://repo.msys2.org/msys/x86_64/libopenssl-3.1.4-1-x86_64.pkg.tar.zst\r\n   \r\n   The Jenkins CI thus fails to download the same and thus it fails to build the docker image for Windows.\r\n   \r\n   ```\r\n   00:25:33 SUCCESS: Specified value was saved.\r\n   00:25:46 Removing intermediate container 5ce7355571a1\r\n   00:25:46 ---> a13a4bc69545\r\n   00:25:46 Step 21/78 : RUN powershell Invoke-WebRequest -Uri https://repo.msys2.org/msys/x86_64/libopenssl-3.1.4-1-x86_64.pkg.tar.zst -OutFile $Env:TEMP\\libopenssl-3.1.4-1-x86_64.pkg.tar.zst\r\n   00:25:46 ---> Running in d2dafad446f9\r\n   00:25:54 \u001b[91mInvoke-WebRequest : The remote server returned an error: (404) Not Found.\r\n   00:25:54 \u001b[0m\u001b[91mAt line:1 char:1\r\n   00:25:54 \u001b[0m\u001b[91m+ Invoke-WebRequest -Uri https://repo.msys2.org/msys/x86_64/libopenssl- ...\r\n   00:25:54 + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n   00:25:54 \u001b[0m\u001b[91m + CategoryInfo : InvalidOperation: (System.Net.HttpWebRequest:Htt\r\n   ```\r\n   \r\n   Thus, we need to upgrade to the latest available version to address this.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Jenkins CI - In progress.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-15T19:25:32.769+0000", "updated": "2025-08-15T19:25:32.769+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626490/comment/18014193", "id": "18014193", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7875:\nURL: https://github.com/apache/hadoop/pull/7875#issuecomment-3192521324\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7875/1/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-15T19:28:54.883+0000", "updated": "2025-08-15T19:28:54.883+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626490/comment/18014208", "id": "18014208", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7875:\nURL: https://github.com/apache/hadoop/pull/7875#issuecomment-3192810626\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  25m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 21s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  54m 29s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 17s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 40s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 123m 20s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7875/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7875 |\r\n   | Optional Tests | dupname asflicense |\r\n   | uname | Linux 7a9ce5519195 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 988bb50936dcb2b9808ed2ffaa95851a4c228fd6 |\r\n   | Max. process+thread count | 556 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7875/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-15T21:30:18.003+0000", "updated": "2025-08-15T21:30:18.003+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626490/comment/18014317", "id": "18014317", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra commented on PR #7875:\nURL: https://github.com/apache/hadoop/pull/7875#issuecomment-3193865491\n\n   Build is going through now - https://ci-hadoop.apache.org/view/Hadoop/job/hadoop-qbt-trunk-java8-win10-x86_64/1030/console.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-16T19:35:09.379+0000", "updated": "2025-08-16T19:35:09.379+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626490/comment/18014318", "id": "18014318", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra merged PR #7875:\nURL: https://github.com/apache/hadoop/pull/7875\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-16T19:36:17.051+0000", "updated": "2025-08-16T19:36:17.051+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626490/comment/18014319", "id": "18014319", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=gaurava", "name": "gaurava", "key": "gautham", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=gautham&avatarId=43091", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gautham&avatarId=43091", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gautham&avatarId=43091", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gautham&avatarId=43091"}, "displayName": "Gautham Banasandra", "active": true, "timeZone": "Asia/Kolkata"}, "body": "Merged PR to trunk - https://github.com/apache/hadoop/pull/7875.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=gaurava", "name": "gaurava", "key": "gautham", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=gautham&avatarId=43091", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gautham&avatarId=43091", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gautham&avatarId=43091", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gautham&avatarId=43091"}, "displayName": "Gautham Banasandra", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-08-16T19:37:06.702+0000", "updated": "2025-08-16T19:37:06.702+0000"}], "maxResults": 6, "total": 6, "startAt": 0}, "updated": "2025-08-16T19:37:06.000+0000", "created": "2025-08-15T19:19:04.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626478", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626478", "key": "HADOOP-19650", "fields": {"summary": "ABFS: NPE when close() called on uninitialized filesystem", "description": "code\r\n{code}\r\n  public void testABFSConstructor() throws Throwable {\r\n    new AzureBlobFileSystem().close();\r\n  }\r\n{code}\r\n\r\nstack\r\n{code}\r\n[ERROR] org.apache.hadoop.validator.TestRuntimeValid.testABFSConstructor -- Time elapsed: 0.003 s <<< ERROR!\r\njava.lang.NullPointerException: Cannot invoke \"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getClient()\" because \"this.abfsStore\" is null\r\n        at org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.close(AzureBlobFileSystem.java:800)\r\n        at org.apache.hadoop.validator.TestRuntimeValid.testABFSConstructor(TestRuntimeValid.java:49)\r\n{code}\r\n\r\n\r\n", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18014524", "id": "18014524", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "body": "Thanks for reporting this.\r\nWill work on the patch on priority.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-08-18T07:27:43.542+0000", "updated": "2025-08-18T07:27:43.542+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18014649", "id": "18014649", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3197386039\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  9s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 42s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 11s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 141m 38s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7880 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 160d07de834c 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / fd85bee514d271d663f801bf3498b3145ec08fec |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/2/testReport/ |\r\n   | Max. process+thread count | 530 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T15:24:49.838+0000", "updated": "2025-08-18T15:24:49.838+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18014673", "id": "18014673", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2282920640\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -148,7 +150,7 @@ public class AzureBlobFileSystem extends FileSystem\n   private URI uri;\n   private Path workingDir;\n   private AzureBlobFileSystemStore abfsStore;\n-  private boolean isClosed;\n+  private boolean isClosed = true;\n\nReview Comment:\n   so this really means inited and closed. Mention that in javadocs.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T16:42:43.777+0000", "updated": "2025-08-18T16:42:43.777+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18014675", "id": "18014675", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3197699593\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  15m 15s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 14s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 33s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/3/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 1 unchanged - 0 fixed = 3 total (was 1)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 42s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 140m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7880 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 741539520d55 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 18fa0f27d00c849b858b19383a3c213a71a9aacb |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/3/testReport/ |\r\n   | Max. process+thread count | 564 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T16:51:58.148+0000", "updated": "2025-08-18T16:51:58.148+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18014963", "id": "18014963", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3201478753\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 34s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/4/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 1 unchanged - 0 fixed = 3 total (was 1)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 45s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 38s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7880 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 4b13a9c47991 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 62141e105067253aaf4a3fc516b5c06f84f8da9f |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/4/testReport/ |\r\n   | Max. process+thread count | 558 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T16:47:12.260+0000", "updated": "2025-08-19T16:47:12.260+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015050", "id": "18015050", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3204164409\n\n   ------------------------------\r\n   :::: AGGREGATED TEST RESULT ::::\r\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 862, Failures: 0, Errors: 0, Skipped: 209\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 865, Failures: 0, Errors: 0, Skipped: 161\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 704, Failures: 0, Errors: 0, Skipped: 240\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 862, Failures: 0, Errors: 0, Skipped: 220\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 709, Failures: 0, Errors: 0, Skipped: 135\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 701, Failures: 0, Errors: 0, Skipped: 242\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 706, Failures: 0, Errors: 0, Skipped: 147\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 703, Failures: 0, Errors: 0, Skipped: 189\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 6\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 736, Failures: 0, Errors: 0, Skipped: 216\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 701, Failures: 0, Errors: 0, Skipped: 239\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   Time taken: 199 mins 4 secs.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T04:40:00.477+0000", "updated": "2025-08-20T04:40:00.477+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015053", "id": "18015053", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2286986125\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -148,7 +150,7 @@ public class AzureBlobFileSystem extends FileSystem\n   private URI uri;\n   private Path workingDir;\n   private AzureBlobFileSystemStore abfsStore;\n-  private boolean isClosed;\n+  private boolean isClosed = true;\n\nReview Comment:\n   Yes, added the javadcoc.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T05:01:13.956+0000", "updated": "2025-08-20T05:01:13.956+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015056", "id": "18015056", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2287000680\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -795,10 +801,10 @@ public boolean mkdirs(final Path f, final FsPermission permission) throws IOExce\n \n   @Override\n   public synchronized void close() throws IOException {\n-    if (isClosed) {\n+    if (isClosed()) {\n\nReview Comment:\n   Should we throw an exception in case someone is trying to close non initialized or already closed file system?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T05:13:44.148+0000", "updated": "2025-08-20T05:13:44.148+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015057", "id": "18015057", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2287009604\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestFileSystemInitialization.java:\n##########\n@@ -81,21 +89,123 @@ public void testFileSystemCapabilities() throws Throwable {\n \n     final Path p = new Path(\"}\");\n     // etags always present\n-    Assertions.assertThat(fs.hasPathCapability(p, ETAGS_AVAILABLE))\n+    assertThat(fs.hasPathCapability(p, ETAGS_AVAILABLE))\n         .describedAs(\"path capability %s in %s\", ETAGS_AVAILABLE, fs)\n         .isTrue();\n     // readahead always correct\n-    Assertions.assertThat(fs.hasPathCapability(p, CAPABILITY_SAFE_READAHEAD))\n+    assertThat(fs.hasPathCapability(p, CAPABILITY_SAFE_READAHEAD))\n         .describedAs(\"path capability %s in %s\", CAPABILITY_SAFE_READAHEAD, fs)\n         .isTrue();\n \n     // etags-over-rename and ACLs are either both true or both false.\n     final boolean etagsAcrossRename = fs.hasPathCapability(p, ETAGS_PRESERVED_IN_RENAME);\n     final boolean acls = fs.hasPathCapability(p, FS_ACLS);\n-    Assertions.assertThat(etagsAcrossRename)\n+    assertThat(etagsAcrossRename)\n         .describedAs(\"capabilities %s=%s and %s=%s in %s\",\n             ETAGS_PRESERVED_IN_RENAME, etagsAcrossRename,\n             FS_ACLS, acls, fs)\n         .isEqualTo(acls);\n   }\n+\n+  /**\n+   * Test that the AzureBlobFileSystem close without init works\n+   * @throws Exception if an error occurs\n+   */\n+  @Test\n+  public void testABFSCloseWithoutInit() throws Exception {\n+    AzureBlobFileSystem fs = new AzureBlobFileSystem();\n+    assertThat(fs.isClosed()).isTrue();\n+    fs.close();\n+    fs.initialize(this.getFileSystem().getUri(), getRawConfiguration());\n+    assertThat(fs.isClosed()).isFalse();\n+    fs.close();\n+    assertThat(fs.isClosed()).isTrue();\n+  }\n+\n+  /**\n+   * Test that the AzureBlobFileSystem throws an exception\n+   * when trying to perform an operation without initialization.\n+   * @throws Exception if an error occurs\n+   */\n+  @Test\n+  public void testABFSUninitializedFileSystem() throws Exception {\n+    AzureBlobFileSystem fs = new AzureBlobFileSystem();\n+    assertThat(fs.isClosed()).isTrue();\n+    Path testPath = new Path(\"testPath\");\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        fs::toString);\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.open(testPath, ONE_MB));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.create(testPath, FsPermission.getDefault(), false, ONE_MB,\n+            fs.getDefaultReplication(testPath), ONE_MB, null));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.createNonRecursive(testPath, FsPermission.getDefault(), false, ONE_MB,\n+            fs.getDefaultReplication(testPath), ONE_MB, null));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.append(testPath, ONE_MB, null));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.rename(testPath, testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.delete(testPath, true));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.listStatus(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.mkdirs(testPath, FsPermission.getDefault()));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.getFileStatus(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.breakLease(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.makeQualified(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.setOwner(testPath, \"\", \"\"));\n\nReview Comment:\n   EMPTY_STRING can be used here\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T05:20:25.509+0000", "updated": "2025-08-20T05:20:25.509+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015060", "id": "18015060", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3204282967\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 41s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |  30m 22s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   0m 31s | [/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 30s | [/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -0 :warning: |  checkstyle  |   0m 29s | [/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   0m 30s | [/branch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/branch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 30s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 30s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 30s | [/branch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   3m 51s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 24s | [/patch-mvninstall-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-mvninstall-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 23s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 23s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   0m 42s | [/patch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 23s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 24s | [/patch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   5m  1s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 24s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 24s |  |  ASF License check generated no output?  |\r\n   |  |   |  45m 10s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7880 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 4535df39a5aa 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 579d0674d77eb78689c28a0df8aa4b49aac222c8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/testReport/ |\r\n   | Max. process+thread count | 65 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T05:49:08.763+0000", "updated": "2025-08-20T05:49:08.763+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015073", "id": "18015073", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3204495167\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 54s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 48s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  9s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 24s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7880 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 84fe5e904fca 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 77e3546d9fc5ff4a180abe2300956dbbd003e079 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/5/testReport/ |\r\n   | Max. process+thread count | 576 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T07:10:59.327+0000", "updated": "2025-08-20T07:10:59.327+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015084", "id": "18015084", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2287442313\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -795,10 +801,10 @@ public boolean mkdirs(final Path f, final FsPermission permission) throws IOExce\n \n   @Override\n   public synchronized void close() throws IOException {\n-    if (isClosed) {\n+    if (isClosed()) {\n\nReview Comment:\n   fs.close() is supposed to be idempotent IMO\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T08:44:32.160+0000", "updated": "2025-08-20T08:44:32.160+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015085", "id": "18015085", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2287443157\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestFileSystemInitialization.java:\n##########\n@@ -81,21 +89,123 @@ public void testFileSystemCapabilities() throws Throwable {\n \n     final Path p = new Path(\"}\");\n     // etags always present\n-    Assertions.assertThat(fs.hasPathCapability(p, ETAGS_AVAILABLE))\n+    assertThat(fs.hasPathCapability(p, ETAGS_AVAILABLE))\n         .describedAs(\"path capability %s in %s\", ETAGS_AVAILABLE, fs)\n         .isTrue();\n     // readahead always correct\n-    Assertions.assertThat(fs.hasPathCapability(p, CAPABILITY_SAFE_READAHEAD))\n+    assertThat(fs.hasPathCapability(p, CAPABILITY_SAFE_READAHEAD))\n         .describedAs(\"path capability %s in %s\", CAPABILITY_SAFE_READAHEAD, fs)\n         .isTrue();\n \n     // etags-over-rename and ACLs are either both true or both false.\n     final boolean etagsAcrossRename = fs.hasPathCapability(p, ETAGS_PRESERVED_IN_RENAME);\n     final boolean acls = fs.hasPathCapability(p, FS_ACLS);\n-    Assertions.assertThat(etagsAcrossRename)\n+    assertThat(etagsAcrossRename)\n         .describedAs(\"capabilities %s=%s and %s=%s in %s\",\n             ETAGS_PRESERVED_IN_RENAME, etagsAcrossRename,\n             FS_ACLS, acls, fs)\n         .isEqualTo(acls);\n   }\n+\n+  /**\n+   * Test that the AzureBlobFileSystem close without init works\n+   * @throws Exception if an error occurs\n+   */\n+  @Test\n+  public void testABFSCloseWithoutInit() throws Exception {\n+    AzureBlobFileSystem fs = new AzureBlobFileSystem();\n+    assertThat(fs.isClosed()).isTrue();\n+    fs.close();\n+    fs.initialize(this.getFileSystem().getUri(), getRawConfiguration());\n+    assertThat(fs.isClosed()).isFalse();\n+    fs.close();\n+    assertThat(fs.isClosed()).isTrue();\n+  }\n+\n+  /**\n+   * Test that the AzureBlobFileSystem throws an exception\n+   * when trying to perform an operation without initialization.\n+   * @throws Exception if an error occurs\n+   */\n+  @Test\n+  public void testABFSUninitializedFileSystem() throws Exception {\n+    AzureBlobFileSystem fs = new AzureBlobFileSystem();\n+    assertThat(fs.isClosed()).isTrue();\n+    Path testPath = new Path(\"testPath\");\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        fs::toString);\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.open(testPath, ONE_MB));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.create(testPath, FsPermission.getDefault(), false, ONE_MB,\n+            fs.getDefaultReplication(testPath), ONE_MB, null));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.createNonRecursive(testPath, FsPermission.getDefault(), false, ONE_MB,\n+            fs.getDefaultReplication(testPath), ONE_MB, null));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.append(testPath, ONE_MB, null));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.rename(testPath, testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.delete(testPath, true));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.listStatus(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.mkdirs(testPath, FsPermission.getDefault()));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.getFileStatus(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.breakLease(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.makeQualified(testPath));\n+\n+    intercept(IllegalStateException.class, ERR_INVALID_ABFS_STATE,\n+        () -> fs.setOwner(testPath, \"\", \"\"));\n\nReview Comment:\n   Will take up this.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T08:44:50.585+0000", "updated": "2025-08-20T08:44:50.585+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015125", "id": "18015125", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2287814760\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -795,10 +801,10 @@ public boolean mkdirs(final Path f, final FsPermission permission) throws IOExce\n \n   @Override\n   public synchronized void close() throws IOException {\n-    if (isClosed) {\n+    if (isClosed()) {\n\nReview Comment:\n   There is chance that more two threads can attempt to close store and client twice. \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T11:06:13.020+0000", "updated": "2025-08-20T11:06:13.020+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015138", "id": "18015138", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2287814760\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -795,10 +801,10 @@ public boolean mkdirs(final Path f, final FsPermission permission) throws IOExce\n \n   @Override\n   public synchronized void close() throws IOException {\n-    if (isClosed) {\n+    if (isClosed()) {\n\nReview Comment:\n   There is chance that more two threads can attempt to close store and client which can cause similar issue what we got now. \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T11:31:09.669+0000", "updated": "2025-08-20T11:31:09.669+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015166", "id": "18015166", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2288107530\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -795,10 +801,10 @@ public boolean mkdirs(final Path f, final FsPermission permission) throws IOExce\n \n   @Override\n   public synchronized void close() throws IOException {\n-    if (isClosed) {\n+    if (isClosed()) {\n\nReview Comment:\n   @bhattmanish98 I don't see concurrency issues because close() is synchronized, and once closed it can't be closed again. Of course, once one thread has closed it, nobody else can use the instance. fix: don't do that. \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T13:06:27.991+0000", "updated": "2025-08-20T13:06:27.991+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015172", "id": "18015172", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3206294039\n\n   > +1\r\n   > \r\n   > ready to merge.\r\n   \r\n   Sure, just did a commit to rerun yetus, will merge as soon as green.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T13:13:41.415+0000", "updated": "2025-08-20T13:13:41.415+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015174", "id": "18015174", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#discussion_r2288137399\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java:\n##########\n@@ -795,10 +801,10 @@ public boolean mkdirs(final Path f, final FsPermission permission) throws IOExce\n \n   @Override\n   public synchronized void close() throws IOException {\n-    if (isClosed) {\n+    if (isClosed()) {\n\nReview Comment:\n   @steveloughran Make sense, I overlooked synchronized in the method definition. PR Looks good. Approved the changes.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T13:14:29.362+0000", "updated": "2025-08-20T13:14:29.362+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015213", "id": "18015213", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3206925500\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 52s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 39s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 26s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 145m 34s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7880 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux a9e8d7a37f31 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5a51d6a271f282878677fdab891549d77dac2e6d |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/7/testReport/ |\r\n   | Max. process+thread count | 536 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7880/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T15:39:41.252+0000", "updated": "2025-08-20T15:39:41.252+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015216", "id": "18015216", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T15:51:05.179+0000", "updated": "2025-08-20T15:51:05.179+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015223", "id": "18015223", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 opened a new pull request, #7888:\nURL: https://github.com/apache/hadoop/pull/7888\n\n   ### Description of PR\r\n   PR on trunk: https://github.com/apache/hadoop/pull/7880\r\n   JIRA: https://issues.apache.org/jira/browse/HADOOP-19650\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T16:18:52.965+0000", "updated": "2025-08-20T16:18:52.965+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015224", "id": "18015224", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 opened a new pull request, #7889:\nURL: https://github.com/apache/hadoop/pull/7889\n\n   ### Description of PR\r\n   PR on trunk: https://github.com/apache/hadoop/pull/7880\r\n   JIRA: https://issues.apache.org/jira/browse/HADOOP-19650\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T16:20:34.495+0000", "updated": "2025-08-20T16:20:34.495+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015233", "id": "18015233", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7880:\nURL: https://github.com/apache/hadoop/pull/7880#issuecomment-3207359625\n\n   Will do backport for 3.4 and 3.4.2\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T17:19:07.068+0000", "updated": "2025-08-20T17:19:07.068+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015241", "id": "18015241", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7889:\nURL: https://github.com/apache/hadoop/pull/7889#issuecomment-3207450187\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   6m 54s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 26s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 18s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 24s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 41s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 39s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 21s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 15s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 12s |  |  hadoop-tools/hadoop-azure: The patch generated 0 new + 1 unchanged - 1 fixed = 1 total (was 2)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 33s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m  3s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  81m 35s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7889/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7889 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 6822d049569c 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / cc5116580b5f7b89333cf0c606432b50e29a543b |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7889/1/testReport/ |\r\n   | Max. process+thread count | 559 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7889/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T17:44:16.107+0000", "updated": "2025-08-20T17:44:16.107+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015248", "id": "18015248", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7888:\nURL: https://github.com/apache/hadoop/pull/7888#issuecomment-3207584935\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  11m 45s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ branch-3.4.2 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  37m 15s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  branch-3.4.2 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  branch-3.4.2 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  branch-3.4.2 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  branch-3.4.2 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  33m 16s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  hadoop-tools/hadoop-azure: The patch generated 0 new + 1 unchanged - 1 fixed = 1 total (was 2)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 23s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 26s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 128m 43s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7888/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7888 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 5e18fda5c880 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4.2 / eb7913ebe57cf38ee41eba62cdba53d5d9a25bff |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7888/1/testReport/ |\r\n   | Max. process+thread count | 699 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7888/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T18:30:02.404+0000", "updated": "2025-08-20T18:30:02.404+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015261", "id": "18015261", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7888:\nURL: https://github.com/apache/hadoop/pull/7888#issuecomment-3207755446\n\n   FYI, @steveloughran @ahmarsuhail \r\n   Thanks\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T19:22:25.125+0000", "updated": "2025-08-20T19:22:25.125+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015262", "id": "18015262", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7889:\nURL: https://github.com/apache/hadoop/pull/7889#issuecomment-3207761504\n\n   @steveloughran @ahmarsuhail \r\n   Let me know if this is good to merge.\r\n   Thanks\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T19:23:15.208+0000", "updated": "2025-08-20T19:23:15.208+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015373", "id": "18015373", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail merged PR #7888:\nURL: https://github.com/apache/hadoop/pull/7888\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-21T09:50:05.831+0000", "updated": "2025-08-21T09:50:05.831+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18015374", "id": "18015374", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail merged PR #7889:\nURL: https://github.com/apache/hadoop/pull/7889\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-21T09:50:50.170+0000", "updated": "2025-08-21T09:50:50.170+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18016982", "id": "18016982", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail opened a new pull request, #7920:\nURL: https://github.com/apache/hadoop/pull/7920\n\n   Reverts apache/hadoop#7888\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T09:34:59.148+0000", "updated": "2025-08-29T09:34:59.148+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18016983", "id": "18016983", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail closed pull request #7920: Revert \"HADOOP-19650. [ABFS][Backport-3.4.2] Fixing NPE when close() called on uninitialized AzureBlobFileSystem\"\nURL: https://github.com/apache/hadoop/pull/7920\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T09:35:31.990+0000", "updated": "2025-08-29T09:35:31.990+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626478/comment/18017001", "id": "18017001", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7920:\nURL: https://github.com/apache/hadoop/pull/7920#issuecomment-3236755969\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 40s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ branch-3.4.2 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  37m 27s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  branch-3.4.2 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  branch-3.4.2 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  branch-3.4.2 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  branch-3.4.2 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  branch-3.4.2 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 57s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7920/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 1 unchanged - 0 fixed = 2 total (was 1)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 44s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 28s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 128m  0s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7920/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7920 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 15ea4ce1ec3b 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4.2 / 88dcaa58e8f0ca5850444ce56867884b3149f101 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7920/1/testReport/ |\r\n   | Max. process+thread count | 742 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7920/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T11:44:15.556+0000", "updated": "2025-08-29T11:44:15.556+0000"}], "maxResults": 32, "total": 32, "startAt": 0}, "updated": "2025-08-29T11:44:15.000+0000", "created": "2025-08-15T17:27:57.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626235", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626235", "key": "HADOOP-19649", "fields": {"summary": "ABFS: Fixing Test Failures and Wrong assumptions after Junit Upgrade", "description": "After https://issues.apache.org/jira/browse/HADOOP-19425\r\n\r\nmost of the integration tests are getting skipped. All tests need to be fixed with this PR\u00a0", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18013631", "id": "18013631", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 opened a new pull request, #7868:\nURL: https://github.com/apache/hadoop/pull/7868\n\n   ### Description of PR\r\n   After https://issues.apache.org/jira/browse/HADOOP-19425\r\n   most of the integration tests are getting skipped. All tests need to be fixed with this PR \r\n   \r\n   ### How was this patch tested?\r\n   Test Suite ran.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-13T09:10:00.470+0000", "updated": "2025-08-13T09:10:00.470+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18013650", "id": "18013650", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Copilot commented on code in PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#discussion_r2272827582\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemAppend.java:\n##########\n@@ -608,12 +608,12 @@ public void testCreateExplicitDirectoryOverDfsAppendOverBlob()\n    **/\n   @Test\n   public void testRecreateAppendAndFlush() throws IOException {\n+      assumeThat(isAppendBlobEnabled()).as(\"Not valid for APPEND BLOB\").isFalse();\n+      assumeThat(getIngressServiceType()).isEqualTo(AbfsServiceType.BLOB);\n\nReview Comment:\n   This assumption is placed after the assertThrows() call begins, but should be before it. The assumption should be checked before setting up the exception assertion to ensure the test conditions are met first.\n   ```suggestion\n         assumeThat(getIngressServiceType()).isEqualTo(AbfsServiceType.BLOB);\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-13T10:12:52.758+0000", "updated": "2025-08-13T10:12:52.758+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18013664", "id": "18013664", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3183429913\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m  4s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 9 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 21s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 51s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 16s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 140m 11s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7868/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7868 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 51d70a663e18 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 64f15bfbb96b28d201067683e6e619496d0683da |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7868/1/testReport/ |\r\n   | Max. process+thread count | 719 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7868/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-13T11:31:30.362+0000", "updated": "2025-08-13T11:31:30.362+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18013808", "id": "18013808", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3186336426\n\n   @anujmodi2021 Thank you for your contribution! LGTM.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-14T01:05:51.262+0000", "updated": "2025-08-14T01:05:51.262+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18013839", "id": "18013839", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3187064274\n\n   ------------------------------\r\n   :::: AGGREGATED TEST RESULT ::::\r\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 209\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 863, Failures: 0, Errors: 0, Skipped: 161\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 702, Failures: 0, Errors: 0, Skipped: 240\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 220\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 707, Failures: 0, Errors: 0, Skipped: 135\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 699, Failures: 0, Errors: 0, Skipped: 242\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 704, Failures: 0, Errors: 0, Skipped: 147\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 701, Failures: 0, Errors: 0, Skipped: 189\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 6\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 734, Failures: 0, Errors: 0, Skipped: 216\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 699, Failures: 0, Errors: 0, Skipped: 239\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-14T05:57:55.104+0000", "updated": "2025-08-14T05:57:55.104+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014026", "id": "18014026", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3190296832\n\n   @anujmodi2021 Thank you for your contribution! I noticed a small improvement we could make in this PR: removing the junit-vintage-engine dependency. This dependency is used for running mixed JUnit 4 and JUnit 5 tests, but since this module has been fully migrated to JUnit 5, I believe we can safely remove it.\r\n   \r\n   https://github.com/apache/hadoop/blob/1abdf72dca0c530c265859362b2a2d574d8c9d72/hadoop-tools/hadoop-azure/pom.xml#L363-L367\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-15T00:43:22.789+0000", "updated": "2025-08-15T00:43:22.789+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014510", "id": "18014510", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#discussion_r2281356462\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFilesystemAcl.java:\n##########\n@@ -56,33 +56,55 @@\n  * Test acl operations.\n  */\n public class ITestAzureBlobFilesystemAcl extends AbstractAbfsIntegrationTest {\n+\n\nReview Comment:\n   revert changes with extra spaces\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T05:51:58.762+0000", "updated": "2025-08-18T05:51:58.762+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014511", "id": "18014511", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#discussion_r2281359848\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFilesystemAcl.java:\n##########\n@@ -238,41 +276,46 @@ public void testModifyAclEntriesStickyBit() throws Exception {\n     fs.modifyAclEntries(path, aclSpec);\n     AclStatus s = fs.getAclStatus(path);\n     AclEntry[] returned = s.getEntries().toArray(new AclEntry[0]);\n-    assertArrayEquals(new AclEntry[]{aclEntry(ACCESS, USER, FOO, READ_EXECUTE),\n-        aclEntry(ACCESS, GROUP, READ_EXECUTE), aclEntry(DEFAULT, USER, ALL),\n-        aclEntry(DEFAULT, USER, FOO, READ_EXECUTE), aclEntry(DEFAULT, GROUP, READ_EXECUTE),\n-        aclEntry(DEFAULT, MASK, READ_EXECUTE), aclEntry(DEFAULT, OTHER, NONE)},\n+    assertArrayEquals(new AclEntry[]{\n+            aclEntry(ACCESS, USER, FOO, READ_EXECUTE),\n+            aclEntry(ACCESS, GROUP, READ_EXECUTE),\n+            aclEntry(DEFAULT, USER, ALL),\n+            aclEntry(DEFAULT, USER, FOO, READ_EXECUTE),\n+            aclEntry(DEFAULT, GROUP, READ_EXECUTE),\n+            aclEntry(DEFAULT, MASK, READ_EXECUTE),\n+            aclEntry(DEFAULT, OTHER, NONE)\n+        },\n         returned);\n     assertPermission(fs, (short) 01750);\n   }\n \n   @Test\n   public void testModifyAclEntriesPathNotFound() throws Exception {\n-      Assertions.assertThrows(FileNotFoundException.class, () -> {\n-          final AzureBlobFileSystem fs = this.getFileSystem();\n-          assumeTrue(getIsNamespaceEnabled(fs));\n-          path = new Path(testRoot, UUID.randomUUID().toString());\n-          List<AclEntry> aclSpec = Lists.newArrayList(\n-        aclEntry(ACCESS, USER, ALL),\n-        aclEntry(ACCESS, USER, FOO, ALL),\n-        aclEntry(ACCESS, GROUP, READ_EXECUTE),\n-        aclEntry(ACCESS, OTHER, NONE));\n-          fs.modifyAclEntries(path, aclSpec);\n-      });\n+    assumeTrue(getIsNamespaceEnabled(getFileSystem()));\n+    Assertions.assertThrows(FileNotFoundException.class, () -> {\n+      final AzureBlobFileSystem fs = this.getFileSystem();\n+      path = new Path(testRoot, UUID.randomUUID().toString());\n+      List<AclEntry> aclSpec = Lists.newArrayList(\n+          aclEntry(ACCESS, USER, ALL),\n+          aclEntry(ACCESS, USER, FOO, ALL),\n+          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n+          aclEntry(ACCESS, OTHER, NONE));\n+      fs.modifyAclEntries(path, aclSpec);\n+    });\n   }\n \n   @Test\n   public void testModifyAclEntriesDefaultOnFile() throws Exception {\n-      Assertions.assertThrows(Exception.class, () -> {\n-          final AzureBlobFileSystem fs = this.getFileSystem();\n-          assumeTrue(getIsNamespaceEnabled(fs));\n-          path = new Path(testRoot, UUID.randomUUID().toString());\n-          fs.create(path).close();\n-          fs.setPermission(path, FsPermission.createImmutable((short) RW_R));\n-          List<AclEntry> aclSpec = Lists.newArrayList(\n-        aclEntry(DEFAULT, USER, FOO, ALL));\n-          fs.modifyAclEntries(path, aclSpec);\n-      });\n+    Assertions.assertThrows(Exception.class, () -> {\n+      final AzureBlobFileSystem fs = this.getFileSystem();\n\nReview Comment:\n   same as above,  only space changes can be reverted \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T05:54:26.566+0000", "updated": "2025-08-18T05:54:26.566+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014523", "id": "18014523", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3195393896\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 9 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  25m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 26s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 14s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 23s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 26s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  78m  3s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7868/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7868 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 14573deebbd7 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bf4b108ed612d69707da0fd5a95294a2734b3986 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7868/2/testReport/ |\r\n   | Max. process+thread count | 700 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7868/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T07:07:32.957+0000", "updated": "2025-08-18T07:07:32.957+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014567", "id": "18014567", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#discussion_r2282011563\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFilesystemAcl.java:\n##########\n@@ -56,33 +56,55 @@\n  * Test acl operations.\n  */\n public class ITestAzureBlobFilesystemAcl extends AbstractAbfsIntegrationTest {\n+\n\nReview Comment:\n   So when the last time these changes were made the proper code-style was not set by whoever made these changes.\r\n   In this PR these changes came in automatically due to importing the recommended code-style.\r\n   \r\n   Since this is the right thing to do, I feel like it might be okay to retain these changes. Anyways this is a small PR.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFilesystemAcl.java:\n##########\n@@ -238,41 +276,46 @@ public void testModifyAclEntriesStickyBit() throws Exception {\n     fs.modifyAclEntries(path, aclSpec);\n     AclStatus s = fs.getAclStatus(path);\n     AclEntry[] returned = s.getEntries().toArray(new AclEntry[0]);\n-    assertArrayEquals(new AclEntry[]{aclEntry(ACCESS, USER, FOO, READ_EXECUTE),\n-        aclEntry(ACCESS, GROUP, READ_EXECUTE), aclEntry(DEFAULT, USER, ALL),\n-        aclEntry(DEFAULT, USER, FOO, READ_EXECUTE), aclEntry(DEFAULT, GROUP, READ_EXECUTE),\n-        aclEntry(DEFAULT, MASK, READ_EXECUTE), aclEntry(DEFAULT, OTHER, NONE)},\n+    assertArrayEquals(new AclEntry[]{\n+            aclEntry(ACCESS, USER, FOO, READ_EXECUTE),\n+            aclEntry(ACCESS, GROUP, READ_EXECUTE),\n+            aclEntry(DEFAULT, USER, ALL),\n+            aclEntry(DEFAULT, USER, FOO, READ_EXECUTE),\n+            aclEntry(DEFAULT, GROUP, READ_EXECUTE),\n+            aclEntry(DEFAULT, MASK, READ_EXECUTE),\n+            aclEntry(DEFAULT, OTHER, NONE)\n+        },\n         returned);\n     assertPermission(fs, (short) 01750);\n   }\n \n   @Test\n   public void testModifyAclEntriesPathNotFound() throws Exception {\n-      Assertions.assertThrows(FileNotFoundException.class, () -> {\n-          final AzureBlobFileSystem fs = this.getFileSystem();\n-          assumeTrue(getIsNamespaceEnabled(fs));\n-          path = new Path(testRoot, UUID.randomUUID().toString());\n-          List<AclEntry> aclSpec = Lists.newArrayList(\n-        aclEntry(ACCESS, USER, ALL),\n-        aclEntry(ACCESS, USER, FOO, ALL),\n-        aclEntry(ACCESS, GROUP, READ_EXECUTE),\n-        aclEntry(ACCESS, OTHER, NONE));\n-          fs.modifyAclEntries(path, aclSpec);\n-      });\n+    assumeTrue(getIsNamespaceEnabled(getFileSystem()));\n+    Assertions.assertThrows(FileNotFoundException.class, () -> {\n+      final AzureBlobFileSystem fs = this.getFileSystem();\n+      path = new Path(testRoot, UUID.randomUUID().toString());\n+      List<AclEntry> aclSpec = Lists.newArrayList(\n+          aclEntry(ACCESS, USER, ALL),\n+          aclEntry(ACCESS, USER, FOO, ALL),\n+          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n+          aclEntry(ACCESS, OTHER, NONE));\n+      fs.modifyAclEntries(path, aclSpec);\n+    });\n   }\n \n   @Test\n   public void testModifyAclEntriesDefaultOnFile() throws Exception {\n-      Assertions.assertThrows(Exception.class, () -> {\n-          final AzureBlobFileSystem fs = this.getFileSystem();\n-          assumeTrue(getIsNamespaceEnabled(fs));\n-          path = new Path(testRoot, UUID.randomUUID().toString());\n-          fs.create(path).close();\n-          fs.setPermission(path, FsPermission.createImmutable((short) RW_R));\n-          List<AclEntry> aclSpec = Lists.newArrayList(\n-        aclEntry(DEFAULT, USER, FOO, ALL));\n-          fs.modifyAclEntries(path, aclSpec);\n-      });\n+    Assertions.assertThrows(Exception.class, () -> {\n+      final AzureBlobFileSystem fs = this.getFileSystem();\n\nReview Comment:\n   Same as above\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T10:36:03.559+0000", "updated": "2025-08-18T10:36:03.559+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014571", "id": "18014571", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3196145863\n\n   ------------------------------\r\n   :::: AGGREGATED TEST RESULT ::::\r\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 209\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 863, Failures: 0, Errors: 0, Skipped: 161\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 702, Failures: 0, Errors: 0, Skipped: 240\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 220\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 707, Failures: 0, Errors: 0, Skipped: 135\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 699, Failures: 0, Errors: 0, Skipped: 242\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 704, Failures: 0, Errors: 0, Skipped: 147\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 701, Failures: 0, Errors: 0, Skipped: 189\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 6\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 734, Failures: 0, Errors: 0, Skipped: 216\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 699, Failures: 0, Errors: 0, Skipped: 239\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 271, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   Time taken: 198 mins 45 secs.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T10:48:08.026+0000", "updated": "2025-08-18T10:48:08.026+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014771", "id": "18014771", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3198853166\n\n   Thanks everyone for pushing this PR forward and for the review.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T00:59:50.471+0000", "updated": "2025-08-19T00:59:50.471+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014792", "id": "18014792", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T05:09:16.837+0000", "updated": "2025-08-19T05:09:16.837+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014793", "id": "18014793", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3199223431\n\n   > Thanks everyone for pushing this PR forward and for the review.\r\n   \r\n   Thanks for review. Have merged the PR.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T05:09:34.271+0000", "updated": "2025-08-19T05:09:34.271+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014794", "id": "18014794", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3199224446\n\n   @slfan1989 are we pursuing this upgrade for upcoming 3.4.2 release as well? Or is it targetted for 3.5.0 only?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T05:10:16.226+0000", "updated": "2025-08-19T05:10:16.226+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626235/comment/18014801", "id": "18014801", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7868:\nURL: https://github.com/apache/hadoop/pull/7868#issuecomment-3199287275\n\n   > @slfan1989 are we pursuing this upgrade for upcoming 3.4.2 release as well? Or is it targetted for 3.5.0 only?\r\n   \r\n   Personally, I think it\u2019s needed, but it hasn\u2019t gone through community discussion yet. For now, we should apply it to version 3.5 first.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T05:46:14.604+0000", "updated": "2025-08-19T05:46:14.604+0000"}], "maxResults": 16, "total": 16, "startAt": 0}, "updated": "2025-08-26T03:57:39.000+0000", "created": "2025-08-13T06:11:03.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13626015", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13626015", "key": "HADOOP-19648", "fields": {"summary": "cos use token credential will lost token field", "description": "Hi,\r\n\r\nI've discovered a bug when accessing COSN using temporary credentials (access key, secret key, and session token).\r\n\r\nIn the org.apache.hadoop.fs.cosn.CosNativeFileSystemStore#initCOSClient method, when the client is initialized, it only passes the access key and secret key, completely ignoring the session token. This causes all subsequent operations that rely on these temporary credentials to fail.\r\n\r\nFurthermore, this re-initialization step seems unnecessary. Instead of creating a new client with incomplete credentials, the existing credential provider (which already contains the AK, SK, and token) should be passed down directly.\r\n!image-2025-08-11-10-37-12-451.png|width=1048,height=540! \r\n!image-2025-08-11-10-42-36-375.png!", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18013144", "id": "18013144", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing opened a new pull request, #7866:\nURL: https://github.com/apache/hadoop/pull/7866\n\n   \r\n   ### Description of PR\r\n   In the org.apache.hadoop.fs.cosn.CosNativeFileSystemStore#initCOSClient method, when the client is initialized, it only passes the access key and secret key, completely ignoring the session token. This causes all subsequent operations that rely on these temporary credentials to fail.\r\n   Furthermore, this re-initialization step seems unnecessary. Instead of creating a new client with incomplete credentials, the existing credential provider (which already contains the AK, SK, and token) should be passed down directly.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [\u2714] Does the title or this PR starts with the corresponding JIRA issue id \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-11T03:01:34.057+0000", "updated": "2025-08-11T03:01:34.057+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18013145", "id": "18013145", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing closed pull request #7866: HADOOP-19648. [hotfix] Cos use token credential will lose token field\nURL: https://github.com/apache/hadoop/pull/7866\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-11T03:01:52.708+0000", "updated": "2025-08-11T03:01:52.708+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18013146", "id": "18013146", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing opened a new pull request, #7867:\nURL: https://github.com/apache/hadoop/pull/7867\n\n   \r\n   ### Description of PR\r\n   \r\n   In the org.apache.hadoop.fs.cosn.CosNativeFileSystemStore#initCOSClient method, when the client is initialized, it only passes the access key and secret key, completely ignoring the session token. This causes all subsequent operations that rely on these temporary credentials to fail.\r\n   Furthermore, this re-initialization step seems unnecessary. Instead of creating a new client with incomplete credentials, the existing credential provider (which already contains the AK, SK, and token) should be passed down directly.\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [\u2714] Does the title or this PR starts with the corresponding JIRA issue id \r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-11T03:07:58.155+0000", "updated": "2025-08-11T03:07:58.155+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18013156", "id": "18013156", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3173339571\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 11s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 31s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 35s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 22s |  |  hadoop-cos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 156m 39s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7867 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 0a4e3db4c896 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / a2fb2f41505dd147136a842dc66395632cee38f8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/1/testReport/ |\r\n   | Max. process+thread count | 540 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-cos U: hadoop-cloud-storage-project/hadoop-cos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-11T05:46:03.393+0000", "updated": "2025-08-11T05:46:03.393+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18013236", "id": "18013236", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3175078496\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 21s |  |  hadoop-cos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 138m 35s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7867 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets xmllint |\r\n   | uname | Linux 3d08225597f2 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4d939984a47fcbbb4e3ca1cd5ffa32a0cc953838 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/2/testReport/ |\r\n   | Max. process+thread count | 535 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-cos U: hadoop-cloud-storage-project/hadoop-cos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-11T14:23:01.512+0000", "updated": "2025-08-11T14:23:01.512+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18013915", "id": "18013915", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3188421349\n\n   @slfan1989 @cnauroth hi guys\uff0ccould you help me review this pr\uff1fthx   : )\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-14T13:16:08.866+0000", "updated": "2025-08-14T13:16:08.866+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014207", "id": "18014207", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on code in PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#discussion_r2279916489\n\n\n##########\nhadoop-cloud-storage-project/hadoop-cos/src/test/java/org/apache/hadoop/fs/cosn/TestCosCredentials.java:\n##########\n@@ -131,4 +134,44 @@ private void validateCredentials(URI uri, Configuration configuration)\n       }\n     }\n   }\n+\n+  @Test\n+  public void testTmpTokenCredentialsProvider() throws Throwable {\n+    Configuration configuration = new Configuration();\n+    // Set DynamicTemporaryCosnCredentialsProvider as the CosCredentials\n+    // Provider.\n+    configuration.set(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER,\n+        \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\");\n+    validateTmpTokenCredentials(this.fsUri, configuration);\n+  }\n+\n+  private void validateTmpTokenCredentials(URI uri, Configuration configuration)\n+      throws IOException {\n+    if (null != configuration) {\n+      COSCredentialsProvider credentialsProvider =\n+          CosNUtils.createCosCredentialsProviderSet(uri, configuration);\n+      COSCredentials cosCredentials = credentialsProvider.getCredentials();\n+      assertNotNull(cosCredentials, \"The cos credentials obtained is null.\");\n+      assertTrue(\n+          StringUtils.equalsIgnoreCase(configuration.get(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER),\n+              \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\"),\n+          \"CredentialsProvider must be DynamicTemporaryCosnCredentialsProvider\");\n+\n+      if (!(cosCredentials instanceof BasicSessionCredentials)) {\n\nReview Comment:\n   This could be simplified to:\r\n   \r\n   ```\r\n   assertTrue(cosCredentials instanceof BasicSessionCredentials, \"...\");\r\n   ```\r\n   \n\n\n\n##########\nhadoop-cloud-storage-project/hadoop-cos/src/test/java/org/apache/hadoop/fs/cosn/TestCosCredentials.java:\n##########\n@@ -131,4 +134,44 @@ private void validateCredentials(URI uri, Configuration configuration)\n       }\n     }\n   }\n+\n+  @Test\n+  public void testTmpTokenCredentialsProvider() throws Throwable {\n+    Configuration configuration = new Configuration();\n+    // Set DynamicTemporaryCosnCredentialsProvider as the CosCredentials\n+    // Provider.\n+    configuration.set(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER,\n+        \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\");\n+    validateTmpTokenCredentials(this.fsUri, configuration);\n+  }\n+\n+  private void validateTmpTokenCredentials(URI uri, Configuration configuration)\n+      throws IOException {\n+    if (null != configuration) {\n\nReview Comment:\n   Is this null check required? It seems like `configuration` will always be non-null.\n\n\n\n##########\nhadoop-cloud-storage-project/hadoop-cos/src/test/java/org/apache/hadoop/fs/cosn/TestCosCredentials.java:\n##########\n@@ -131,4 +134,44 @@ private void validateCredentials(URI uri, Configuration configuration)\n       }\n     }\n   }\n+\n+  @Test\n+  public void testTmpTokenCredentialsProvider() throws Throwable {\n+    Configuration configuration = new Configuration();\n+    // Set DynamicTemporaryCosnCredentialsProvider as the CosCredentials\n+    // Provider.\n+    configuration.set(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER,\n+        \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\");\n+    validateTmpTokenCredentials(this.fsUri, configuration);\n+  }\n+\n+  private void validateTmpTokenCredentials(URI uri, Configuration configuration)\n+      throws IOException {\n+    if (null != configuration) {\n+      COSCredentialsProvider credentialsProvider =\n+          CosNUtils.createCosCredentialsProviderSet(uri, configuration);\n+      COSCredentials cosCredentials = credentialsProvider.getCredentials();\n+      assertNotNull(cosCredentials, \"The cos credentials obtained is null.\");\n+      assertTrue(\n+          StringUtils.equalsIgnoreCase(configuration.get(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER),\n+              \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\"),\n+          \"CredentialsProvider must be DynamicTemporaryCosnCredentialsProvider\");\n+\n+      if (!(cosCredentials instanceof BasicSessionCredentials)) {\n+        fail(\"cosCredentials must be instanceof BasicSessionCredentials\");\n+      }\n+\n+      if (!StringUtils.equals(cosCredentials.getCOSAccessKeyId(), \"ak\") || !StringUtils.equals(\n\nReview Comment:\n   Instead of conditional logic around `fail`, I suggest that this should be 3 separate `assertEquals` for access key, secret key and session token.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-15T21:28:44.127+0000", "updated": "2025-08-15T21:28:44.127+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014828", "id": "18014828", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on code in PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#discussion_r2284575792\n\n\n##########\nhadoop-cloud-storage-project/hadoop-cos/src/test/java/org/apache/hadoop/fs/cosn/TestCosCredentials.java:\n##########\n@@ -131,4 +134,44 @@ private void validateCredentials(URI uri, Configuration configuration)\n       }\n     }\n   }\n+\n+  @Test\n+  public void testTmpTokenCredentialsProvider() throws Throwable {\n+    Configuration configuration = new Configuration();\n+    // Set DynamicTemporaryCosnCredentialsProvider as the CosCredentials\n+    // Provider.\n+    configuration.set(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER,\n+        \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\");\n+    validateTmpTokenCredentials(this.fsUri, configuration);\n+  }\n+\n+  private void validateTmpTokenCredentials(URI uri, Configuration configuration)\n+      throws IOException {\n+    if (null != configuration) {\n\nReview Comment:\n   yep, you'r right.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T08:47:11.759+0000", "updated": "2025-08-19T08:47:11.759+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014831", "id": "18014831", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on code in PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#discussion_r2284603156\n\n\n##########\nhadoop-cloud-storage-project/hadoop-cos/src/test/java/org/apache/hadoop/fs/cosn/TestCosCredentials.java:\n##########\n@@ -131,4 +134,44 @@ private void validateCredentials(URI uri, Configuration configuration)\n       }\n     }\n   }\n+\n+  @Test\n+  public void testTmpTokenCredentialsProvider() throws Throwable {\n+    Configuration configuration = new Configuration();\n+    // Set DynamicTemporaryCosnCredentialsProvider as the CosCredentials\n+    // Provider.\n+    configuration.set(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER,\n+        \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\");\n+    validateTmpTokenCredentials(this.fsUri, configuration);\n+  }\n+\n+  private void validateTmpTokenCredentials(URI uri, Configuration configuration)\n+      throws IOException {\n+    if (null != configuration) {\n+      COSCredentialsProvider credentialsProvider =\n+          CosNUtils.createCosCredentialsProviderSet(uri, configuration);\n+      COSCredentials cosCredentials = credentialsProvider.getCredentials();\n+      assertNotNull(cosCredentials, \"The cos credentials obtained is null.\");\n+      assertTrue(\n+          StringUtils.equalsIgnoreCase(configuration.get(CosNConfigKeys.COSN_CREDENTIALS_PROVIDER),\n+              \"org.apache.hadoop.fs.cosn.auth.DynamicTemporaryCosnCredentialsProvider\"),\n+          \"CredentialsProvider must be DynamicTemporaryCosnCredentialsProvider\");\n+\n+      if (!(cosCredentials instanceof BasicSessionCredentials)) {\n\nReview Comment:\n   : ).  Thx for your suggestion. I've also found a more standardized way to write the code.   \r\n   \r\n   `assertInstanceOf(BasicSessionCredentials.class, cosCredentials,\r\n           \"cosCredentials must be instanceof BasicSessionCredentials\");`\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T08:57:54.081+0000", "updated": "2025-08-19T08:57:54.081+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014835", "id": "18014835", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3199934458\n\n   > @leosanqing , thank you for the patch. I commented with a few suggestions.\r\n   > \r\n   > Can you or someone else make sure the integration tests are passing? I don't have the means to run those myself.\r\n   \r\n   Thx bro. \r\n   \r\n   Sure, I'v added a new ITest, and pass the test on my local env.(the failed tests are Junit method not found, I've looked up each failed tests)\r\n   <img width=\"2510\" height=\"481\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f3f6b152-6dc5-471f-8dbb-f21e4d55c33c\" />\r\n   \r\n   \r\n   When I'm not change code. This ITest will throw exception like this.\r\n   <img width=\"2419\" height=\"1374\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f381bc6d-0ab7-4a1e-920d-0fae8e6eb3e5\" />\r\n   \r\n   \r\n   and this is the new code for testing.\r\n   <img width=\"2509\" height=\"475\" alt=\"image\" src=\"https://github.com/user-attachments/assets/69ad045e-449b-47ca-b13c-6d606767c099\" />\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T09:17:28.040+0000", "updated": "2025-08-19T09:17:28.040+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014846", "id": "18014846", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3200102193\n\n   > @leosanqing , thank you for the patch. I commented with a few suggestions.\r\n   > \r\n   > Can you or someone else make sure the integration tests are passing? I don't have the means to run those myself.\r\n   \r\n   For newest, I add the test dependence, all tests are passed.\r\n   <img width=\"2278\" height=\"1151\" alt=\"image\" src=\"https://github.com/user-attachments/assets/2ab96a2e-c789-4c11-b1c3-7a2d825a3f7a\" />\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T10:08:03.281+0000", "updated": "2025-08-19T10:08:03.281+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014861", "id": "18014861", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3200299993\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 37s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 14s | [/buildtool-patch-checkstyle-hadoop-cloud-storage-project_hadoop-cos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/3/artifact/out/buildtool-patch-checkstyle-hadoop-cloud-storage-project_hadoop-cos.txt) |  The patch fails to run checkstyle in hadoop-cos  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 27s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 21s |  |  hadoop-cos in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   0m 38s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/3/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 129m 59s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7867 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux d39db1ea78c7 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 23868390c030e1b63dce02867f5d5baf816a45c5 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/3/testReport/ |\r\n   | Max. process+thread count | 556 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-cos U: hadoop-cloud-storage-project/hadoop-cos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T11:08:41.757+0000", "updated": "2025-08-19T11:08:41.757+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014877", "id": "18014877", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3200543127\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m  6s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 35s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 24s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 13s | [/buildtool-patch-checkstyle-hadoop-cloud-storage-project_hadoop-cos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/4/artifact/out/buildtool-patch-checkstyle-hadoop-cloud-storage-project_hadoop-cos.txt) |  The patch fails to run checkstyle in hadoop-cos  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 27s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 22s |  |  hadoop-cos in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   0m 38s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/4/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 136m 47s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7867 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 4e15f55ee773 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0a56214a7af88643a157e0c743258af4fceb4f2d |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/4/testReport/ |\r\n   | Max. process+thread count | 531 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-cos U: hadoop-cloud-storage-project/hadoop-cos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T12:23:21.429+0000", "updated": "2025-08-19T12:23:21.429+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014892", "id": "18014892", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3200678324\n\n   Sorry for committing so many times, I'm not used for hadoop code style. Pls forgive me. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T13:04:16.678+0000", "updated": "2025-08-19T13:04:16.678+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014917", "id": "18014917", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3200958862\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 19s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 15s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 36s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 11s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 14s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 14s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 15s |  |  hadoop-cos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  76m 13s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7867 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 6c557ebeaf9a 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0bab4e6ecff4636cbb8fe5af133af5652cef157e |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/6/testReport/ |\r\n   | Max. process+thread count | 553 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-cos U: hadoop-cloud-storage-project/hadoop-cos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T14:16:25.097+0000", "updated": "2025-08-19T14:16:25.097+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18014928", "id": "18014928", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3201095625\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  1s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 39s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 13s | [/buildtool-patch-checkstyle-hadoop-cloud-storage-project_hadoop-cos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/5/artifact/out/buildtool-patch-checkstyle-hadoop-cloud-storage-project_hadoop-cos.txt) |  The patch fails to run checkstyle in hadoop-cos  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 41s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 21s |  |  hadoop-cos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 136m 39s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7867 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 1b78dd2042d8 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f2dbd3e7e6603a5ceccf86d2c17acbc9ab06ee62 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/5/testReport/ |\r\n   | Max. process+thread count | 587 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-cos U: hadoop-cloud-storage-project/hadoop-cos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7867/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T14:54:13.064+0000", "updated": "2025-08-19T14:54:13.064+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18015043", "id": "18015043", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3204031971\n\n   > Sorry for committing so many times, I'm not used for hadoop code style. Pls forgive me.\r\n   \r\n   No worries! We appreciate the contribution!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-20T03:15:09.957+0000", "updated": "2025-08-20T03:15:09.957+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18015836", "id": "18015836", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3218110763\n\n   @cnauroth Hey, bro, sorry to ping you on a weekend. Just a friendly reminder about this PR, looks like it hasn't been merged yet. \r\n   \r\n   Happy weekend!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-24T13:38:10.387+0000", "updated": "2025-08-24T13:38:10.387+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18016066", "id": "18016066", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth closed pull request #7867: HADOOP-19648. [hotfix] Cos use token credential will lose token field\nURL: https://github.com/apache/hadoop/pull/7867\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T19:17:46.399+0000", "updated": "2025-08-25T19:17:46.399+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18016067", "id": "18016067", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on PR #7867:\nURL: https://github.com/apache/hadoop/pull/7867#issuecomment-3221459343\n\n   @leosanqing , thank you for the reminder. I have committed this to trunk. This would ship the fix in Hadoop 3.5.0. I looked at backporting to branch-3.4, but there were conflicts. If you need the patch in earlier versions, please send up a separate pull request targeting branch-3.4. Thank you for the contribution!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T19:19:18.430+0000", "updated": "2025-08-25T19:19:18.430+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18016665", "id": "18016665", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing opened a new pull request, #7911:\nURL: https://github.com/apache/hadoop/pull/7911\n\n   \r\n   \r\n   ### Description of PR\r\n   In the org.apache.hadoop.fs.cosn.CosNativeFileSystemStore#initCOSClient method, when the client is initialized, it only passes the access key and secret key, completely ignoring the session token. This causes all subsequent operations that rely on these temporary credentials to fail.\r\n   Furthermore, this re-initialization step seems unnecessary. Instead of creating a new client with incomplete credentials, the existing credential provider (which already contains the AK, SK, and token) should be passed down directly.\r\n   \r\n   This is same as https://github.com/apache/hadoop/pull/7867,but there were some conflicts. so I send up a separate pull request targeting branch-3.4.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n    ITests  are passed on my local env.\r\n   \r\n   <img width=\"2528\" height=\"576\" alt=\"image\" src=\"https://github.com/user-attachments/assets/fff41a10-f423-46ee-a8f9-5a806175c97f\" />\r\n   \r\n   ### For code changes:\r\n   \r\n   - [\u2714] Does the title or this PR starts with the corresponding JIRA issue id (yes)?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T02:19:42.947+0000", "updated": "2025-08-28T02:19:42.947+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18016692", "id": "18016692", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7911:\nURL: https://github.com/apache/hadoop/pull/7911#issuecomment-3231866522\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  19m 31s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 58s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 26s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 26s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 54s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 24s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 21s |  |  hadoop-cos in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 145m 34s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7911/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7911 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 5b677ee4dfa6 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / 7cf257320847af9fc5a7075abe7ffda257bee4ee |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7911/1/testReport/ |\r\n   | Max. process+thread count | 527 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-cloud-storage-project/hadoop-cos U: hadoop-cloud-storage-project/hadoop-cos |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7911/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T04:46:40.772+0000", "updated": "2025-08-28T04:46:40.772+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18016694", "id": "18016694", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on PR #7911:\nURL: https://github.com/apache/hadoop/pull/7911#issuecomment-3231885127\n\n   @cnauroth hi, bro, I send a new pr to merge targeting brach-3.4. Previous conflicts are test dependencies.  ITest's results are here. Cloud you help me  to review this pr?\r\n   <img width=\"2528\" height=\"576\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5098c1c2-7dd4-4b4f-afed-3de28355d47d\" />\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-28T04:56:48.358+0000", "updated": "2025-08-28T04:56:48.358+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18017123", "id": "18017123", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth closed pull request #7911: HADOOP-19648. Cos use token credential will lose token field\nURL: https://github.com/apache/hadoop/pull/7911\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T20:58:18.870+0000", "updated": "2025-08-29T20:58:18.870+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18017124", "id": "18017124", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on PR #7911:\nURL: https://github.com/apache/hadoop/pull/7911#issuecomment-3238260120\n\n   Thank you again @leosanqing . I committed this to branch-3.4.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T20:58:19.762+0000", "updated": "2025-08-29T20:58:19.762+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18017142", "id": "18017142", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "leosanqing commented on PR #7911:\nURL: https://github.com/apache/hadoop/pull/7911#issuecomment-3238639566\n\n   > Thank you again @leosanqing . I committed this to branch-3.4.\r\n   Hey\uff0cthank you for your merging.\r\n   \r\n   I'm not sure if branch-3.3 is still being maintained, but I have tested this PR against branch-3.3 in my local environment, and it passed. If you are still releasing new versions for 3.3, this could be merged into branch-3.3 as well, since it was the original branch where this COS feature was first introduced.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T23:08:50.172+0000", "updated": "2025-08-29T23:08:50.172+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13626015/comment/18017703", "id": "18017703", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on PR #7911:\nURL: https://github.com/apache/hadoop/pull/7911#issuecomment-3245771396\n\n   > > Thank you again @leosanqing . I committed this to branch-3.4.\r\n   > > Hey\uff0cthank you for your merging.\r\n   > \r\n   > I'm not sure if branch-3.3 is still being maintained, but I have tested this PR against branch-3.3 in my local environment, and it passed. If you are still releasing new versions for 3.3, this could be merged into branch-3.3 as well, since it was the original branch where this COS feature was first introduced.\r\n   \r\n   I'm not aware of any specific schedule for another 3.3 release, but there are still a few patches going in there. I merged this to branch-3.3. Thanks again, @leosanqing .\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-02T15:14:00.154+0000", "updated": "2025-09-02T15:14:00.154+0000"}], "maxResults": 27, "total": 27, "startAt": 0}, "updated": "2025-09-02T15:14:00.000+0000", "created": "2025-08-11T02:44:05.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13625746", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13625746", "key": "HADOOP-19647", "fields": {"summary": "ABFS: Read Policy set in openFileOptions should be considered for enabling various optimizations", "description": "AbfsInputStream should take in account the Read Policy set by user with Open File Options. Based on the read policy set, appropriate optimizations should be enabled and kicked in.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13625746/comment/18012895", "id": "18012895", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "key ones are random, whole file and sequential, with recognising avro, parquet, a bonus\r\n\r\n* parquet does now open files with \"parquet\" as first entry\r\n* distcp always uses whole-file where a few large 64MB+  blocks deliver great performance", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-08-08T16:09:59.560+0000", "updated": "2025-08-08T16:09:59.560+0000"}], "maxResults": 1, "total": 1, "startAt": 0}, "updated": "2025-08-08T16:09:59.000+0000", "created": "2025-08-07T07:54:02.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13625597", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13625597", "key": "HADOOP-19646", "fields": {"summary": "S3A: Migrate hadoop-aws module from JUnit4 Assume to JUnit5 Assumptions", "description": "This task aims to migrate the test code in the {{hadoop-aws}} module from JUnit4's {{org.junit.Assume}} API to JUnit5's {{org.junit.jupiter.api.Assumptions}} API in order to unify the testing framework and improve maintainability.\r\nh4. Scope of changes:\r\n * Replace usages of {{{}Assume.assumeTrue(...){}}}, {{{}Assume.assumeFalse(...){}}}, etc., with the corresponding methods from JUnit5, such as {{{}Assumptions.assumeTrue(...){}}};\r\n\r\n * Ensure the assertion logic remains consistent with the original behavior;\r\n\r\n * Update any outdated import statements referencing JUnit4's {{{}Assume{}}};\r\n\r\n * Verify that all affected unit tests pass correctly under JUnit5.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18012279", "id": "18012279", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #7858:\nURL: https://github.com/apache/hadoop/pull/7858\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   JIRA: HADOOP-19646. [JDK17] Migrate hadoop-aws module from JUnit4 Assume to JUnit5 Assumptions.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-06T05:15:08.377+0000", "updated": "2025-08-06T05:15:08.377+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18012300", "id": "18012300", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858#issuecomment-3157797389\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 47s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 16s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 23s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 143m  0s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7858/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7858 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 5abd35351f22 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 6ca49d5da145efa997723827e84e0d9b047683a3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7858/1/testReport/ |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7858/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-06T07:39:30.616+0000", "updated": "2025-08-06T07:39:30.616+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18012307", "id": "18012307", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858#issuecomment-3158154572\n\n   @steveloughran @anujmodi2021 Could you please review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-06T08:23:24.835+0000", "updated": "2025-08-06T08:23:24.835+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18012418", "id": "18012418", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858#issuecomment-3161012685\n\n   Can we move to AssertJ here?\r\n   1. it's a better syntax, and nicely extensible\r\n   1. it lets us cherrypick into java4 branches without any problems\r\n   1. everyone who has already used it knows the syntax\r\n   \r\n   I don't want to invest any time learning JUnit5's assert syntax, not given AssertJ is good and I'm still learning the nuances in what is a very powerful assertion language\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-06T17:36:57.102+0000", "updated": "2025-08-06T17:36:57.102+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18012461", "id": "18012461", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858#issuecomment-3162122354\n\n   > Can we move to AssertJ here?\r\n   > \r\n   > 1. it's a better syntax, and nicely extensible\r\n   > 2. it lets us cherrypick into java4 branches without any problems\r\n   > 3. everyone who has already used it knows the syntax\r\n   > \r\n   > I don't want to invest any time learning JUnit5's assert syntax, not given AssertJ is good and I'm still learning the nuances in what is a very powerful assertion language\r\n   \r\n   Thank you very much for your feedback! I completely agree with your suggestions. I will make improvements in this PR accordingly. Once the upgrade to JUnit 5 is fully completed, I will create a separate JIRA ticket to batch-convert JUnit 5 assertions to AssertJ.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-07T01:28:40.506+0000", "updated": "2025-08-07T01:28:40.506+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18012948", "id": "18012948", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858#issuecomment-3169619857\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m  7s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 5 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 56s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 37s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 45s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 59s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m  3s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 27s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 39s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 139m 48s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7858/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7858 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 9af81ee0d453 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 21b0dfe8a802763f56d63b29a99ee3e2281a3fa1 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7858/2/testReport/ |\r\n   | Max. process+thread count | 549 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7858/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-09T01:30:00.366+0000", "updated": "2025-08-09T01:30:00.366+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18013186", "id": "18013186", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858#issuecomment-3173954615\n\n   @steveloughran Could you please help review this PR? Thank you very much! I\u2019ve updated it to use AssertJ.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-11T09:35:44.136+0000", "updated": "2025-08-11T09:35:44.136+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18013336", "id": "18013336", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-12T01:38:32.088+0000", "updated": "2025-08-12T01:38:32.088+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18013337", "id": "18013337", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7858:\nURL: https://github.com/apache/hadoop/pull/7858#issuecomment-3177411353\n\n   > LGTM\r\n   > +1\r\n   \r\n   @steveloughran Thank you very much for the review!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-12T01:40:24.425+0000", "updated": "2025-08-12T01:40:24.425+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019574", "id": "18019574", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "zhtttylz opened a new pull request, #7951:\nURL: https://github.com/apache/hadoop/pull/7951\n\n   ### Description of PR\r\n   JIRA:HADOOP-19646. [Addendum] [JDK17] Migrate hadoop-aws module from JUnit4 Assume to JUnit5 Assumptions.\r\n   \r\n   ### How was this patch tested?\r\n   Junit Test.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T11:51:47.541+0000", "updated": "2025-09-11T11:51:47.541+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019595", "id": "18019595", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951#discussion_r2340668453\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/ITestTreewalkProblems.java:\n##########\n@@ -316,7 +316,7 @@ public void testDistCp() throws Throwable {\n           options, getConfiguration());\n     } else {\n       // distcp fails if uploads are visible\n-      intercept(org.junit.ComparisonFailure.class, () -> {\n+      intercept(org.opentest4j.AssertionFailedError.class, () -> {\n\nReview Comment:\n   why not import it at the beginning?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T12:43:45.888+0000", "updated": "2025-09-11T12:43:45.888+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019599", "id": "18019599", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "zhtttylz commented on code in PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951#discussion_r2340699995\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/ITestTreewalkProblems.java:\n##########\n@@ -316,7 +316,7 @@ public void testDistCp() throws Throwable {\n           options, getConfiguration());\n     } else {\n       // distcp fails if uploads are visible\n-      intercept(org.junit.ComparisonFailure.class, () -> {\n+      intercept(org.opentest4j.AssertionFailedError.class, () -> {\n\nReview Comment:\n   Thanks for the feedback\u2014I\u2019ll make the updates right away!\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T12:50:46.491+0000", "updated": "2025-09-11T12:50:46.491+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019624", "id": "18019624", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951#issuecomment-3280996134\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 47s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 22s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 50s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m 26s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 142m 35s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7951/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7951 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 2780b877b219 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 775a0d2508eb5c067af32f20f99a59c3e6ec9748 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7951/1/testReport/ |\r\n   | Max. process+thread count | 526 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7951/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T14:15:38.866+0000", "updated": "2025-09-11T14:15:38.866+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019638", "id": "18019638", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951#issuecomment-3281110579\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  28m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  22m 24s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 16s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  22m 15s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 35s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 27s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  82m 40s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7951/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7951 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 05afa27f9842 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 75dad0ad76f5d20b28f9cd4db43206bbee1b3e03 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7951/2/testReport/ |\r\n   | Max. process+thread count | 703 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7951/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T14:34:23.944+0000", "updated": "2025-09-11T14:34:23.944+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019711", "id": "18019711", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951#issuecomment-3282915596\n\n   @ahmarsuhail Could you help review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-11T23:07:12.051+0000", "updated": "2025-09-11T23:07:12.051+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019890", "id": "18019890", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951#issuecomment-3285924530\n\n   Thanks @zhtttylz! +1, LGTM.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T16:19:06.737+0000", "updated": "2025-09-12T16:19:06.737+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019900", "id": "18019900", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T16:49:06.661+0000", "updated": "2025-09-12T16:49:06.661+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13625597/comment/18019901", "id": "18019901", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7951:\nURL: https://github.com/apache/hadoop/pull/7951#issuecomment-3286046276\n\n   @zhtttylz Thanks for the contriburion! @pan3793 @ahmarsuhail Thanks for the review!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-12T16:49:49.507+0000", "updated": "2025-09-12T16:49:49.507+0000"}], "maxResults": 18, "total": 18, "startAt": 0}, "updated": "2025-09-12T16:49:49.000+0000", "created": "2025-08-06T05:12:27.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624892", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624892", "key": "HADOOP-19645", "fields": {"summary": "ABFS: [ReadAheadV2] Improve Metrics for Read Calls to identify type of read done.", "description": "There are a number of ways in which ABFS driver can trigger a network call to read data. We need a way to identify what type of read call was made from client. Plan is to add an indication for this in already present ClientRequestId header.\r\n\r\nFollowing are types of read we want to identify:\r\n # Direct Read: Read from a given position in remote file. This will be synchronous read\r\n # Normal Read: Read from current seeked position where read ahead was bypassed. This will be synchronous read.\r\n # Prefetch Read: Read triggered from background threads filling up in memory cache. This will be asynchronous read.\r\n # Missed Cache Read: Read triggered after nothing was received from read ahead. This will be synchronous read.\r\n # Footer Read: Read triggered as part of footer read optimization. This will be synchronous.\r\n # Small File Read: Read triggered as a part of small file read. This will be synchronous read.\r\n\r\nWe will add another field in the Tracing Header (Client Request Id) for each request. We can call this field \"Operation Specific Header\" very similar to how we have \"Retry Header\" today. As part of this we will only use it for read operations keeping it empty for other operations. Moving ahead f we need to publish any operation specific info, same header can be used.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18010847", "id": "18010847", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3135193019\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  47m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 14 new + 1 unchanged - 0 fixed = 15 total (was 1)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 29s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/1/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 26s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/1/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   2m 59s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/1/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 146m 51s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.fs.azurebfs.services.TestApacheHttpClientFallback |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux c64bcd4ab2e9 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ea1572a40346a9ddfa4e80f4f1a4925308205175 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/1/testReport/ |\r\n   | Max. process+thread count | 533 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T07:39:37.419+0000", "updated": "2025-07-30T07:39:37.419+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18010848", "id": "18010848", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3135296997\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 47s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  47m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 11s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 17 new + 1 unchanged - 0 fixed = 18 total (was 1)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 30s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/2/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 28s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/2/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 28s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   2m 59s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/2/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 146m 30s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.fs.azurebfs.services.TestApacheHttpClientFallback |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 7be945cb4d05 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 42ecdd05eb6954bdfd26d5022bf4c8a517c607ba |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/2/testReport/ |\r\n   | Max. process+thread count | 540 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T08:16:17.523+0000", "updated": "2025-07-30T08:16:17.523+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18010878", "id": "18010878", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3135629353\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m 28s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  2s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  2s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 58s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/3/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 18 new + 1 unchanged - 0 fixed = 19 total (was 1)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 29s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/3/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 26s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/3/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  46m 42s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 42s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 148m 56s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 5f43a0e97825 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 224f712fee069bd839f8c27a979367e61cec8c17 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/3/testReport/ |\r\n   | Max. process+thread count | 596 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T09:59:11.370+0000", "updated": "2025-07-30T09:59:11.370+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18010886", "id": "18010886", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3135851673\n\n   -----------------------------\r\n   :::: AGGREGATED TEST RESULT ::::\r\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 874, Failures: 0, Errors: 0, Skipped: 223\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 34\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 874, Failures: 0, Errors: 0, Skipped: 172\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 34\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 858, Failures: 0, Errors: 0, Skipped: 395\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 35\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 874, Failures: 0, Errors: 0, Skipped: 234\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 58\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 858, Failures: 0, Errors: 0, Skipped: 285\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 29\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 858, Failures: 0, Errors: 0, Skipped: 400\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 35\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 858, Failures: 0, Errors: 0, Skipped: 301\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 29\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 858, Failures: 0, Errors: 0, Skipped: 346\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 53\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 874, Failures: 0, Errors: 0, Skipped: 356\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 34\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 858, Failures: 0, Errors: 0, Skipped: 397\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 35\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T11:15:47.177+0000", "updated": "2025-07-30T11:15:47.177+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011079", "id": "18011079", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Copilot commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2244303281\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -265,6 +289,34 @@ private String addFailureReasons(final String header,\n     return String.format(\"%s_%s\", header, previousFailure);\n   }\n \n+  private String getRetryHeader(final String previousFailure, String retryPolicyAbbreviation) {\n+    String retryHeader = String.format(\"%d\", retryCount);\n+    if (previousFailure == null) {\n+      return retryHeader;\n+    }\n+    if (CONNECTION_TIMEOUT_ABBREVIATION.equals(previousFailure) && retryPolicyAbbreviation != null) {\n+      return String.format(\"%s_%s_%s\", retryHeader, previousFailure, retryPolicyAbbreviation);\n+    }\n+    return String.format(\"%s_%s\", retryHeader, previousFailure);\n+  }\n+\n+  private String getOperationSpecificHeader(FSOperationType opType) {\n+    // Similar header can be added for other operations in the future.\n+    switch (opType) {\n+      case READ:\n+        return readSpecificHeader();\n+      default:\n+        return EMPTY_STRING; // no operation specific header\n+    }\n+  }\n+\n+  private String readSpecificHeader() {\n+    // More information on read can be added to this header in the future.\n+    // As underscore separated values.\n+    String readHeader = String.format(\"%s\", readType.toString());\n\nReview Comment:\n   The String.format with \"%s\" is unnecessary here. Use readType.toString() directly for better readability and performance.\n   ```suggestion\n       String readHeader = readType.toString();\n   ```\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,31 +213,35 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n+    case ALL_ID_FORMAT:\n       header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n+          AbfsHttpConstants.TracingHeaderVersion.V1 + \":\" +\n+          clientCorrelationID + \":\" +\n+          clientRequestId + \":\" +\n+          fileSystemID + \":\" +\n+          getPrimaryRequestIdForHeader(retryCount > 0) + \":\" +\n+          streamID + \":\" +\n+          opType + \":\" +\n+          getRetryHeader(previousFailure, retryPolicyAbbreviation) + \":\" +\n+          ingressHandler + \":\" +\n+          position + \":\" +\n+          operatedBlobCount + \":\" +\n+          httpOperation.getTracingContextSuffix() + \":\" +\n+          getOperationSpecificHeader(opType);\n+\n       metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n       break;\n     case TWO_ID_FORMAT:\n-      header = clientCorrelationID + \":\" + clientRequestId;\n+      header =\n+          AbfsHttpConstants.TracingHeaderVersion.V1 + \":\" +\n+          clientCorrelationID + \":\" + clientRequestId;\n       metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n       break;\n     default:\n       //case SINGLE_ID_FORMAT\n-      header = clientRequestId;\n+      header =\n+          AbfsHttpConstants.TracingHeaderVersion.V1 + \":\" +\n\nReview Comment:\n   The hardcoded V1 version is used in multiple places. Consider using TracingHeaderVersion.getCurrentVersion() consistently to centralize version management.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,31 +213,35 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n+    case ALL_ID_FORMAT:\n       header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n+          AbfsHttpConstants.TracingHeaderVersion.V1 + \":\" +\n\nReview Comment:\n   The hardcoded V1 version is used in multiple places. Consider using TracingHeaderVersion.getCurrentVersion() consistently to centralize version management.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,31 +213,35 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n+    case ALL_ID_FORMAT:\n       header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n+          AbfsHttpConstants.TracingHeaderVersion.V1 + \":\" +\n+          clientCorrelationID + \":\" +\n+          clientRequestId + \":\" +\n+          fileSystemID + \":\" +\n+          getPrimaryRequestIdForHeader(retryCount > 0) + \":\" +\n+          streamID + \":\" +\n+          opType + \":\" +\n+          getRetryHeader(previousFailure, retryPolicyAbbreviation) + \":\" +\n+          ingressHandler + \":\" +\n+          position + \":\" +\n+          operatedBlobCount + \":\" +\n+          httpOperation.getTracingContextSuffix() + \":\" +\n+          getOperationSpecificHeader(opType);\n+\n       metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n       break;\n     case TWO_ID_FORMAT:\n-      header = clientCorrelationID + \":\" + clientRequestId;\n+      header =\n+          AbfsHttpConstants.TracingHeaderVersion.V1 + \":\" +\n+          clientCorrelationID + \":\" + clientRequestId;\n       metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n       break;\n     default:\n       //case SINGLE_ID_FORMAT\n-      header = clientRequestId;\n+      header =\n+          AbfsHttpConstants.TracingHeaderVersion.V1 + \":\" +\n\nReview Comment:\n   The hardcoded V1 version is used in multiple places. Consider using TracingHeaderVersion.getCurrentVersion() consistently to centralize version management.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderValidator.java:\n##########\n@@ -81,82 +85,93 @@ public TracingHeaderValidator(String clientCorrelationId, String fileSystemId,\n   }\n \n   private void validateTracingHeader(String tracingContextHeader) {\n-    String[] idList = tracingContextHeader.split(\":\");\n+    String[] idList = tracingContextHeader.split(\":\", -1);\n\nReview Comment:\n   [nitpick] Consider defining the split limit (-1) as a named constant to improve code readability and maintainability.\n   ```suggestion\n       String[] idList = tracingContextHeader.split(\":\", SPLIT_NO_LIMIT);\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T04:10:40.693+0000", "updated": "2025-07-31T04:10:40.693+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011105", "id": "18011105", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3138813312\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 26s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m  9s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 13s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/4/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 6 new + 5 unchanged - 0 fixed = 11 total (was 5)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 23s |  |  hadoop-azure in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   0m 27s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/4/artifact/out/results-asflicense.txt) |  The patch generated 1 ASF License warnings.  |\r\n   |  |   |  79m 44s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux ba7a35768638 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0d926b14ba007e88c0099c5880f78176988d2442 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/4/testReport/ |\r\n   | Max. process+thread count | 555 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T07:13:19.664+0000", "updated": "2025-07-31T07:13:19.664+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011190", "id": "18011190", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2245426192\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -265,6 +289,34 @@ private String addFailureReasons(final String header,\n     return String.format(\"%s_%s\", header, previousFailure);\n   }\n \n+  private String getRetryHeader(final String previousFailure, String retryPolicyAbbreviation) {\n+    String retryHeader = String.format(\"%d\", retryCount);\n+    if (previousFailure == null) {\n+      return retryHeader;\n+    }\n+    if (CONNECTION_TIMEOUT_ABBREVIATION.equals(previousFailure) && retryPolicyAbbreviation != null) {\n+      return String.format(\"%s_%s_%s\", retryHeader, previousFailure, retryPolicyAbbreviation);\n+    }\n+    return String.format(\"%s_%s\", retryHeader, previousFailure);\n+  }\n+\n+  private String getOperationSpecificHeader(FSOperationType opType) {\n+    // Similar header can be added for other operations in the future.\n+    switch (opType) {\n+      case READ:\n+        return readSpecificHeader();\n+      default:\n+        return EMPTY_STRING; // no operation specific header\n+    }\n+  }\n+\n+  private String readSpecificHeader() {\n+    // More information on read can be added to this header in the future.\n+    // As underscore separated values.\n+    String readHeader = String.format(\"%s\", readType.toString());\n\nReview Comment:\n   Rataining it as in future we might add more info to the same field\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T13:36:31.313+0000", "updated": "2025-07-31T13:36:31.313+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011196", "id": "18011196", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2245456486\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/AbfsHttpConstants.java:\n##########\n@@ -128,6 +128,7 @@ public final class AbfsHttpConstants {\n   public static final String STAR = \"*\";\n   public static final String COMMA = \",\";\n   public static final String COLON = \":\";\n+  public static final String HYPHEN = \"-\";\n\nReview Comment:\n   We already have CHAR_HYPHEN defined for this.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n+  }\n+\n+  public int getFieldCount() {\n+    return V1.fieldCount;\n+  }\n+\n+  public String getVersion() {\n+    return V1.version;\n\nReview Comment:\n   Same as above, it should be `return this.version`?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -265,6 +286,34 @@ private String addFailureReasons(final String header,\n     return String.format(\"%s_%s\", header, previousFailure);\n   }\n \n+  private String getRetryHeader(final String previousFailure, String retryPolicyAbbreviation) {\n\nReview Comment:\n   Please add javadoc to all newly added methods\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n+  }\n+\n+  public int getFieldCount() {\n+    return V1.fieldCount;\n\nReview Comment:\n   Shouldn't it be just `return this.fieldCount`?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n\nReview Comment:\n   Java Doc missing\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T14:00:13.187+0000", "updated": "2025-07-31T14:00:13.187+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011212", "id": "18011212", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3140309047\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 24s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 26s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 46s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 21s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 44s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 25s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  78m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux b44a21d0bd2d 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 9bb6cdbeda33155f0957108cfdf87b63dcefe53a |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/5/testReport/ |\r\n   | Max. process+thread count | 676 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T14:58:54.479+0000", "updated": "2025-07-31T14:58:54.479+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011345", "id": "18011345", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2246885435\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java:\n##########\n@@ -544,7 +555,9 @@ private int readInternal(final long position, final byte[] b, final int offset,\n       }\n \n       // got nothing from read-ahead, do our own read now\n-      receivedBytes = readRemote(position, b, offset, length, new TracingContext(tracingContext));\n+      TracingContext tc = new TracingContext(tracingContext);\n+      tc.setReadType(ReadType.MISSEDCACHE_READ);\n+      receivedBytes = readRemote(position, b, offset, length, tc);\n       return receivedBytes;\n     } else {\n       LOG.debug(\"read ahead disabled, reading remote\");\n\nReview Comment:\n   Should we add readtype as normal read for this TC as well?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T04:46:21.813+0000", "updated": "2025-08-01T04:46:21.813+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011349", "id": "18011349", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2246929766\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java:\n##########\n@@ -442,6 +451,7 @@ private int optimisedRead(final byte[] b, final int off, final int len,\n     //  bCursor that means the user requested data has not been read.\n     if (fCursor < contentLength && bCursor > limit) {\n       restorePointerState();\n+      tracingContext.setReadType(ReadType.NORMAL_READ);\n\nReview Comment:\n   Before readOneBlock we're setting TC as normal read both here and line 439. In readOneBlock method- we're setting TC again to normal read- do we need it twice?\r\n   We can keep it once in the method only otherwise\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T05:18:14.198+0000", "updated": "2025-08-01T05:18:14.198+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011351", "id": "18011351", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2246993787\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n+          + clientCorrelationID + COLON\n+          + clientRequestId + COLON\n+          + fileSystemID + COLON\n+          + getPrimaryRequestIdForHeader(retryCount > 0) + COLON\n+          + streamID + COLON\n+          + opType + COLON\n+          + getRetryHeader(previousFailure, retryPolicyAbbreviation) + COLON\n+          + ingressHandler + COLON\n+          + position + COLON\n+          + operatedBlobCount + COLON\n+          + httpOperation.getTracingContextSuffix() + COLON\n+          + getOperationSpecificHeader(opType);\n\nReview Comment:\n   should we keep the op specific header before adding the HTTP client? It would get all req related info together and then network client. \r\n   Eg- .....:RE:1_EGR:NR:JDK\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T05:52:06.955+0000", "updated": "2025-08-01T05:52:06.955+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011354", "id": "18011354", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247014906\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -265,6 +286,34 @@ private String addFailureReasons(final String header,\n     return String.format(\"%s_%s\", header, previousFailure);\n   }\n \n+  private String getRetryHeader(final String previousFailure, String retryPolicyAbbreviation) {\n\nReview Comment:\n   we can remove the addFailureReasons method- it has no usage now\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T06:01:46.957+0000", "updated": "2025-08-01T06:01:46.957+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011362", "id": "18011362", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247066421\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n\nReview Comment:\n   Since the next versions would be V1.1/V1.2- so should we consider starting with V1.0/V1.1?\r\n   And with the version updates- would we update the version field in V1 only or new V1.1 enum?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T06:24:44.962+0000", "updated": "2025-08-01T06:24:44.962+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011381", "id": "18011381", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247336266\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Missed Cache Read Type.\n+     * Setting read ahead depth to 0 ensure that nothing can be got from prefetch.\n+     * In such a case Input Stream will do a sequential read with missed cache read type.\n+     */\n+    fileSize = ONE_MB; // To make sure only one block is read.\n+    numOfReadCalls += 1; // 1 block of 1MB.\n+    Mockito.doReturn(0).when(spiedConfig).getReadAheadQueueDepth();\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, MISSEDCACHE_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Prefetch Read Type.\n+     * Setting read ahead depth to 2 with prefetch enabled ensures that prefetch is done.\n+     * First read here might be Normal or Missed Cache but the rest 2 should be Prefetched Read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3;\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    Mockito.doReturn(3).when(spiedConfig).getReadAheadQueueDepth();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, PREFETCH_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Footer Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(false).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(true).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, FOOTER_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Small File Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(true).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(false).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, SMALLFILE_READ, numOfReadCalls);\n+  }\n+\n+  private void testReadTypeInTracingContextHeaderInternal(AzureBlobFileSystem fs, int fileSize, ReadType readType, int numOfReadCalls) throws Exception {\n+    Path testPath = new Path(\"testFile\");\n+    byte[] fileContent = getRandomBytesArray(fileSize);\n+    try (FSDataOutputStream oStream = fs.create(testPath)) {\n+      oStream.write(fileContent);\n+      oStream.flush();\n+    }\n+    try (FSDataInputStream iStream = fs.open(testPath)) {\n+      int bytesRead = iStream.read(new byte[fileSize], 0,\n+          fileSize);\n+      Assertions.assertThat(fileSize)\n+          .describedAs(\"Read size should match file size\")\n+          .isEqualTo(bytesRead);\n+    }\n+\n+    ArgumentCaptor<String> captor1 = ArgumentCaptor.forClass(String.class);\n+    ArgumentCaptor<Long> captor2 = ArgumentCaptor.forClass(Long.class);\n+    ArgumentCaptor<byte[]> captor3 = ArgumentCaptor.forClass(byte[].class);\n+    ArgumentCaptor<Integer> captor4 = ArgumentCaptor.forClass(Integer.class);\n+    ArgumentCaptor<Integer> captor5 = ArgumentCaptor.forClass(Integer.class);\n+    ArgumentCaptor<String> captor6 = ArgumentCaptor.forClass(String.class);\n+    ArgumentCaptor<String> captor7 = ArgumentCaptor.forClass(String.class);\n+    ArgumentCaptor<ContextEncryptionAdapter> captor8 = ArgumentCaptor.forClass(ContextEncryptionAdapter.class);\n+    ArgumentCaptor<TracingContext> captor9 = ArgumentCaptor.forClass(TracingContext.class);\n+\n+    verify(fs.getAbfsStore().getClient(), times(numOfReadCalls)).read(\n+        captor1.capture(), captor2.capture(), captor3.capture(),\n+        captor4.capture(), captor5.capture(), captor6.capture(),\n+        captor7.capture(), captor8.capture(), captor9.capture());\n+    TracingContext tracingContext = captor9.getAllValues().get(numOfReadCalls - 1);\n+    verifyHeaderForReadTypeInTracingContextHeader(tracingContext, readType);\n+  }\n+\n+  private void verifyHeaderForReadTypeInTracingContextHeader(TracingContext tracingContext, ReadType readType) {\n+    AbfsHttpOperation mockOp = Mockito.mock(AbfsHttpOperation.class);\n+    doReturn(EMPTY_STRING).when(mockOp).getTracingContextSuffix();\n+    tracingContext.constructHeader(mockOp, null, null);\n+    String[] idList = tracingContext.getHeader().split(COLON, SPLIT_NO_LIMIT);\n+    Assertions.assertThat(idList).describedAs(\"Client Request Id should have all fields\").hasSize(\n+        TracingHeaderVersion.getCurrentVersion().getFieldCount());\n+    Assertions.assertThat(tracingContext.getHeader()).describedAs(\"Operation Type Should Be Read\")\n+        .contains(FSOperationType.READ.toString());\n+    Assertions.assertThat(tracingContext.getHeader()).describedAs(\"Read type in tracing context header should match\")\n+        .contains(readType.toString());\n+  }\n+\n+//  private testReadTypeInTracingContextHeaderInternal(ReadType readType) throws Exception {\n\nReview Comment:\n   Nit- we can remove this\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T08:39:08.330+0000", "updated": "2025-08-01T08:39:08.330+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011388", "id": "18011388", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247415571\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -77,8 +81,7 @@ public class TracingContext {\n    * this field shall not be set.\n    */\n   private String primaryRequestIdForRetry;\n-\n-  private Integer operatedBlobCount = null;\n+  private Integer operatedBlobCount = 1; // Only relevant for rename-delete over blob endpoint where it will be explicitly set.\n\nReview Comment:\n   why is it changed from null to 1 ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:15:09.074+0000", "updated": "2025-08-01T09:15:09.074+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011389", "id": "18011389", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247428588\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n\nReview Comment:\n   So every time we add a new header, we need to add a new version ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:21:15.085+0000", "updated": "2025-08-01T09:21:15.085+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011390", "id": "18011390", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247438249\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n+  }\n+\n+  public int getFieldCount() {\n+    return V1.fieldCount;\n\nReview Comment:\n   +1\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:25:37.946+0000", "updated": "2025-08-01T09:25:37.946+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011391", "id": "18011391", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247441472\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n\nReview Comment:\n   will this need to be updated everytime a new version is introduced ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:27:14.393+0000", "updated": "2025-08-01T09:27:14.393+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011392", "id": "18011392", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247441472\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n\nReview Comment:\n   this needs to be updated everytime a new version is introduced, can it be dynamically fetched ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:27:40.350+0000", "updated": "2025-08-01T09:27:40.350+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011393", "id": "18011393", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247447664\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n\nReview Comment:\n   should we use getCurrentVersion here ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:29:30.416+0000", "updated": "2025-08-01T09:29:30.416+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011394", "id": "18011394", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247451122\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n+          + clientCorrelationID + COLON\n+          + clientRequestId + COLON\n+          + fileSystemID + COLON\n+          + getPrimaryRequestIdForHeader(retryCount > 0) + COLON\n+          + streamID + COLON\n+          + opType + COLON\n+          + getRetryHeader(previousFailure, retryPolicyAbbreviation) + COLON\n+          + ingressHandler + COLON\n\nReview Comment:\n   these empty string checks are needed \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:30:49.644+0000", "updated": "2025-08-01T09:30:49.644+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011395", "id": "18011395", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247460310\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n+          + clientCorrelationID + COLON\n+          + clientRequestId + COLON\n+          + fileSystemID + COLON\n+          + getPrimaryRequestIdForHeader(retryCount > 0) + COLON\n+          + streamID + COLON\n+          + opType + COLON\n+          + getRetryHeader(previousFailure, retryPolicyAbbreviation) + COLON\n+          + ingressHandler + COLON\n+          + position + COLON\n+          + operatedBlobCount + COLON\n+          + httpOperation.getTracingContextSuffix() + COLON\n+          + getOperationSpecificHeader(opType);\n+\n+      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : EMPTY_STRING;\n       break;\n     case TWO_ID_FORMAT:\n-      header = clientCorrelationID + \":\" + clientRequestId;\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n\nReview Comment:\n   same as above getCurrentVersion ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:35:15.314+0000", "updated": "2025-08-01T09:35:15.314+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011396", "id": "18011396", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247472876\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestTracingContext.java:\n##########\n@@ -326,8 +329,8 @@ fileSystemId, FSOperationType.CREATE_FILESYSTEM, tracingHeaderFormat, new Tracin\n   }\n \n   private void checkHeaderForRetryPolicyAbbreviation(String header, String expectedFailureReason, String expectedRetryPolicyAbbreviation) {\n-    String[] headerContents = header.split(\":\");\n-    String previousReqContext = headerContents[6];\n+    String[] headerContents = header.split(\":\", SPLIT_NO_LIMIT);\n\nReview Comment:\n   colon constant here as well since we are changing at other places\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:41:25.750+0000", "updated": "2025-08-01T09:41:25.750+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011398", "id": "18011398", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247491342\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n\nReview Comment:\n   should we also verify that it is normal_read for all the three calls made ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:47:30.975+0000", "updated": "2025-08-01T09:47:30.975+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011399", "id": "18011399", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247493079\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Missed Cache Read Type.\n+     * Setting read ahead depth to 0 ensure that nothing can be got from prefetch.\n+     * In such a case Input Stream will do a sequential read with missed cache read type.\n+     */\n+    fileSize = ONE_MB; // To make sure only one block is read.\n+    numOfReadCalls += 1; // 1 block of 1MB.\n+    Mockito.doReturn(0).when(spiedConfig).getReadAheadQueueDepth();\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, MISSEDCACHE_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Prefetch Read Type.\n+     * Setting read ahead depth to 2 with prefetch enabled ensures that prefetch is done.\n+     * First read here might be Normal or Missed Cache but the rest 2 should be Prefetched Read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3;\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    Mockito.doReturn(3).when(spiedConfig).getReadAheadQueueDepth();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, PREFETCH_READ, numOfReadCalls);\n\nReview Comment:\n   same here verify that 2 calls have prefetch_read\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:47:55.997+0000", "updated": "2025-08-01T09:47:55.997+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011401", "id": "18011401", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247491342\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n\nReview Comment:\n   should we also verify that it is normal_read for all the three calls made, currently it verifies for contains \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:49:26.061+0000", "updated": "2025-08-01T09:49:26.061+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011402", "id": "18011402", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2247501549\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Missed Cache Read Type.\n+     * Setting read ahead depth to 0 ensure that nothing can be got from prefetch.\n+     * In such a case Input Stream will do a sequential read with missed cache read type.\n+     */\n+    fileSize = ONE_MB; // To make sure only one block is read.\n+    numOfReadCalls += 1; // 1 block of 1MB.\n+    Mockito.doReturn(0).when(spiedConfig).getReadAheadQueueDepth();\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, MISSEDCACHE_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Prefetch Read Type.\n+     * Setting read ahead depth to 2 with prefetch enabled ensures that prefetch is done.\n+     * First read here might be Normal or Missed Cache but the rest 2 should be Prefetched Read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3;\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    Mockito.doReturn(3).when(spiedConfig).getReadAheadQueueDepth();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, PREFETCH_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Footer Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(false).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(true).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, FOOTER_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Small File Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(true).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(false).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, SMALLFILE_READ, numOfReadCalls);\n+  }\n\nReview Comment:\n   One test for direct read as well ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T09:50:01.077+0000", "updated": "2025-08-01T09:50:01.077+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011559", "id": "18011559", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "violetnspct commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2249151187\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java:\n##########\n@@ -578,6 +591,7 @@ int readRemote(long position, byte[] b, int offset, int length, TracingContext t\n         streamStatistics.remoteReadOperation();\n       }\n       LOG.trace(\"Trigger client.read for path={} position={} offset={} length={}\", path, position, offset, length);\n+      tracingContext.setPosition(String.valueOf(position));\n\nReview Comment:\n   Is there a test to verify position is correctly added to tracing context? Position is a key identifier for read operations.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T07:07:30.970+0000", "updated": "2025-08-02T07:07:30.970+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011697", "id": "18011697", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250024646\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java:\n##########\n@@ -544,7 +555,9 @@ private int readInternal(final long position, final byte[] b, final int offset,\n       }\n \n       // got nothing from read-ahead, do our own read now\n-      receivedBytes = readRemote(position, b, offset, length, new TracingContext(tracingContext));\n+      TracingContext tc = new TracingContext(tracingContext);\n+      tc.setReadType(ReadType.MISSEDCACHE_READ);\n+      receivedBytes = readRemote(position, b, offset, length, tc);\n       return receivedBytes;\n     } else {\n       LOG.debug(\"read ahead disabled, reading remote\");\n\nReview Comment:\n   This is coming directly from readOneBlock() so will always be normal\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-03T15:41:45.557+0000", "updated": "2025-08-03T15:41:45.557+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011710", "id": "18011710", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3148617353\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  25m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 21s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 56s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 21s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 47s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 25s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  77m 23s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 5948820d65fb 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 132893fcbf3d7eb4b31ca01dbaef26c186560dd3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/6/testReport/ |\r\n   | Max. process+thread count | 555 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-03T18:26:50.065+0000", "updated": "2025-08-03T18:26:50.065+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011758", "id": "18011758", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250346945\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/AbfsHttpConstants.java:\n##########\n@@ -128,6 +128,7 @@ public final class AbfsHttpConstants {\n   public static final String STAR = \"*\";\n   public static final String COMMA = \",\";\n   public static final String COLON = \":\";\n+  public static final String HYPHEN = \"-\";\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -265,6 +286,34 @@ private String addFailureReasons(final String header,\n     return String.format(\"%s_%s\", header, previousFailure);\n   }\n \n+  private String getRetryHeader(final String previousFailure, String retryPolicyAbbreviation) {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:02:31.698+0000", "updated": "2025-08-04T04:02:31.698+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011759", "id": "18011759", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250347466\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n+  }\n+\n+  public int getFieldCount() {\n+    return V1.fieldCount;\n\nReview Comment:\n   Fixed, Thanks for pointing out\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n+  }\n+\n+  public int getFieldCount() {\n+    return V1.fieldCount;\n+  }\n+\n+  public String getVersion() {\n+    return V1.version;\n\nReview Comment:\n   Fixed\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:02:56.709+0000", "updated": "2025-08-04T04:02:56.709+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011760", "id": "18011760", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250348114\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java:\n##########\n@@ -442,6 +451,7 @@ private int optimisedRead(final byte[] b, final int off, final int len,\n     //  bCursor that means the user requested data has not been read.\n     if (fCursor < contentLength && bCursor > limit) {\n       restorePointerState();\n+      tracingContext.setReadType(ReadType.NORMAL_READ);\n\nReview Comment:\n   Nice Catch, that seemed redundant, hence removed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:03:40.747+0000", "updated": "2025-08-04T04:03:40.747+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011761", "id": "18011761", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250348323\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n+          + clientCorrelationID + COLON\n+          + clientRequestId + COLON\n+          + fileSystemID + COLON\n+          + getPrimaryRequestIdForHeader(retryCount > 0) + COLON\n+          + streamID + COLON\n+          + opType + COLON\n+          + getRetryHeader(previousFailure, retryPolicyAbbreviation) + COLON\n+          + ingressHandler + COLON\n+          + position + COLON\n+          + operatedBlobCount + COLON\n+          + httpOperation.getTracingContextSuffix() + COLON\n+          + getOperationSpecificHeader(opType);\n\nReview Comment:\n   Sounds Better, Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -265,6 +286,34 @@ private String addFailureReasons(final String header,\n     return String.format(\"%s_%s\", header, previousFailure);\n   }\n \n+  private String getRetryHeader(final String previousFailure, String retryPolicyAbbreviation) {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:03:55.075+0000", "updated": "2025-08-04T04:03:55.075+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011762", "id": "18011762", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250349750\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n\nReview Comment:\n   We will have simple version strings like v0, v1, v2 and so on. This will help reduce char count in clientReqId.\r\n   \r\n   With any new changes in the schema of Tracing Header (add/delete/rearrange) we need to bump up version and update the schema and getCurrentVersion method to return the latest version.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Missed Cache Read Type.\n+     * Setting read ahead depth to 0 ensure that nothing can be got from prefetch.\n+     * In such a case Input Stream will do a sequential read with missed cache read type.\n+     */\n+    fileSize = ONE_MB; // To make sure only one block is read.\n+    numOfReadCalls += 1; // 1 block of 1MB.\n+    Mockito.doReturn(0).when(spiedConfig).getReadAheadQueueDepth();\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, MISSEDCACHE_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Prefetch Read Type.\n+     * Setting read ahead depth to 2 with prefetch enabled ensures that prefetch is done.\n+     * First read here might be Normal or Missed Cache but the rest 2 should be Prefetched Read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3;\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    Mockito.doReturn(3).when(spiedConfig).getReadAheadQueueDepth();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, PREFETCH_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Footer Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(false).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(true).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, FOOTER_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Small File Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(true).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(false).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, SMALLFILE_READ, numOfReadCalls);\n+  }\n+\n+  private void testReadTypeInTracingContextHeaderInternal(AzureBlobFileSystem fs, int fileSize, ReadType readType, int numOfReadCalls) throws Exception {\n+    Path testPath = new Path(\"testFile\");\n+    byte[] fileContent = getRandomBytesArray(fileSize);\n+    try (FSDataOutputStream oStream = fs.create(testPath)) {\n+      oStream.write(fileContent);\n+      oStream.flush();\n+    }\n+    try (FSDataInputStream iStream = fs.open(testPath)) {\n+      int bytesRead = iStream.read(new byte[fileSize], 0,\n+          fileSize);\n+      Assertions.assertThat(fileSize)\n+          .describedAs(\"Read size should match file size\")\n+          .isEqualTo(bytesRead);\n+    }\n+\n+    ArgumentCaptor<String> captor1 = ArgumentCaptor.forClass(String.class);\n+    ArgumentCaptor<Long> captor2 = ArgumentCaptor.forClass(Long.class);\n+    ArgumentCaptor<byte[]> captor3 = ArgumentCaptor.forClass(byte[].class);\n+    ArgumentCaptor<Integer> captor4 = ArgumentCaptor.forClass(Integer.class);\n+    ArgumentCaptor<Integer> captor5 = ArgumentCaptor.forClass(Integer.class);\n+    ArgumentCaptor<String> captor6 = ArgumentCaptor.forClass(String.class);\n+    ArgumentCaptor<String> captor7 = ArgumentCaptor.forClass(String.class);\n+    ArgumentCaptor<ContextEncryptionAdapter> captor8 = ArgumentCaptor.forClass(ContextEncryptionAdapter.class);\n+    ArgumentCaptor<TracingContext> captor9 = ArgumentCaptor.forClass(TracingContext.class);\n+\n+    verify(fs.getAbfsStore().getClient(), times(numOfReadCalls)).read(\n+        captor1.capture(), captor2.capture(), captor3.capture(),\n+        captor4.capture(), captor5.capture(), captor6.capture(),\n+        captor7.capture(), captor8.capture(), captor9.capture());\n+    TracingContext tracingContext = captor9.getAllValues().get(numOfReadCalls - 1);\n+    verifyHeaderForReadTypeInTracingContextHeader(tracingContext, readType);\n+  }\n+\n+  private void verifyHeaderForReadTypeInTracingContextHeader(TracingContext tracingContext, ReadType readType) {\n+    AbfsHttpOperation mockOp = Mockito.mock(AbfsHttpOperation.class);\n+    doReturn(EMPTY_STRING).when(mockOp).getTracingContextSuffix();\n+    tracingContext.constructHeader(mockOp, null, null);\n+    String[] idList = tracingContext.getHeader().split(COLON, SPLIT_NO_LIMIT);\n+    Assertions.assertThat(idList).describedAs(\"Client Request Id should have all fields\").hasSize(\n+        TracingHeaderVersion.getCurrentVersion().getFieldCount());\n+    Assertions.assertThat(tracingContext.getHeader()).describedAs(\"Operation Type Should Be Read\")\n+        .contains(FSOperationType.READ.toString());\n+    Assertions.assertThat(tracingContext.getHeader()).describedAs(\"Read type in tracing context header should match\")\n+        .contains(readType.toString());\n+  }\n+\n+//  private testReadTypeInTracingContextHeaderInternal(ReadType readType) throws Exception {\n\nReview Comment:\n   Removed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:05:56.730+0000", "updated": "2025-08-04T04:05:56.730+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011763", "id": "18011763", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250351378\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -77,8 +81,7 @@ public class TracingContext {\n    * this field shall not be set.\n    */\n   private String primaryRequestIdForRetry;\n-\n-  private Integer operatedBlobCount = null;\n+  private Integer operatedBlobCount = 1; // Only relevant for rename-delete over blob endpoint where it will be explicitly set.\n\nReview Comment:\n   Because it was coming out as null in ClientReqId. Having a null value does not looks good and can be prone to NPE if someone used this value anywhere.\r\n   Since this is set only in rename/delete other ops are prone to NPE.\r\n   \r\n   As to why set to 1, I thought for every operation this has to be 1. I am open to suggestions for a better default value but strongly feel null should be avoided.\r\n   \r\n   Thoughts?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:08:11.838+0000", "updated": "2025-08-04T04:08:11.838+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011764", "id": "18011764", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250351858\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderVersion.java:\n##########\n@@ -0,0 +1,50 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.utils;\n+\n+public enum TracingHeaderVersion {\n+\n+  V0(\"\", 8),\n+  V1(\"v1\", 13);\n+\n+  private final String version;\n+  private final int fieldCount;\n+\n+  TracingHeaderVersion(String version, int fieldCount) {\n+    this.version = version;\n+    this.fieldCount = fieldCount;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return version;\n+  }\n+\n+  public static TracingHeaderVersion getCurrentVersion() {\n+    return V1;\n\nReview Comment:\n   We need to update it to the latest version every time we do a version upgrade.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n\nReview Comment:\n   Fixed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:08:51.850+0000", "updated": "2025-08-04T04:08:51.850+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011765", "id": "18011765", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250353075\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n+          + clientCorrelationID + COLON\n+          + clientRequestId + COLON\n+          + fileSystemID + COLON\n+          + getPrimaryRequestIdForHeader(retryCount > 0) + COLON\n+          + streamID + COLON\n+          + opType + COLON\n+          + getRetryHeader(previousFailure, retryPolicyAbbreviation) + COLON\n+          + ingressHandler + COLON\n\nReview Comment:\n   With empty checks we cannot have a fixed schema. We need the proper defined schema where each position after split is fixed for all the headers and analysis can be done easily without worrying about the position of info we need to analyse.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -193,32 +213,33 @@ public void setListener(Listener listener) {\n   public void constructHeader(AbfsHttpOperation httpOperation, String previousFailure, String retryPolicyAbbreviation) {\n     clientRequestId = UUID.randomUUID().toString();\n     switch (format) {\n-    case ALL_ID_FORMAT: // Optional IDs (e.g. streamId) may be empty\n-      header =\n-          clientCorrelationID + \":\" + clientRequestId + \":\" + fileSystemID + \":\"\n-              + getPrimaryRequestIdForHeader(retryCount > 0) + \":\" + streamID\n-              + \":\" + opType + \":\" + retryCount;\n-      header = addFailureReasons(header, previousFailure, retryPolicyAbbreviation);\n-      if (!(ingressHandler.equals(EMPTY_STRING))) {\n-        header += \":\" + ingressHandler;\n-      }\n-      if (!(position.equals(EMPTY_STRING))) {\n-        header += \":\" + position;\n-      }\n-      if (operatedBlobCount != null) {\n-        header += (\":\" + operatedBlobCount);\n-      }\n-      header += (\":\" + httpOperation.getTracingContextSuffix());\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+    case ALL_ID_FORMAT:\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n+          + clientCorrelationID + COLON\n+          + clientRequestId + COLON\n+          + fileSystemID + COLON\n+          + getPrimaryRequestIdForHeader(retryCount > 0) + COLON\n+          + streamID + COLON\n+          + opType + COLON\n+          + getRetryHeader(previousFailure, retryPolicyAbbreviation) + COLON\n+          + ingressHandler + COLON\n+          + position + COLON\n+          + operatedBlobCount + COLON\n+          + httpOperation.getTracingContextSuffix() + COLON\n+          + getOperationSpecificHeader(opType);\n+\n+      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : EMPTY_STRING;\n       break;\n     case TWO_ID_FORMAT:\n-      header = clientCorrelationID + \":\" + clientRequestId;\n-      metricHeader += !(metricResults.trim().isEmpty()) ? metricResults  : \"\";\n+      header = TracingHeaderVersion.V1.getVersion() + COLON\n\nReview Comment:\n   Fixed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:10:26.878+0000", "updated": "2025-08-04T04:10:26.878+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011766", "id": "18011766", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250353287\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestTracingContext.java:\n##########\n@@ -326,8 +329,8 @@ fileSystemId, FSOperationType.CREATE_FILESYSTEM, tracingHeaderFormat, new Tracin\n   }\n \n   private void checkHeaderForRetryPolicyAbbreviation(String header, String expectedFailureReason, String expectedRetryPolicyAbbreviation) {\n-    String[] headerContents = header.split(\":\");\n-    String previousReqContext = headerContents[6];\n+    String[] headerContents = header.split(\":\", SPLIT_NO_LIMIT);\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:10:41.885+0000", "updated": "2025-08-04T04:10:41.885+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011767", "id": "18011767", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250353532\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Missed Cache Read Type.\n+     * Setting read ahead depth to 0 ensure that nothing can be got from prefetch.\n+     * In such a case Input Stream will do a sequential read with missed cache read type.\n+     */\n+    fileSize = ONE_MB; // To make sure only one block is read.\n+    numOfReadCalls += 1; // 1 block of 1MB.\n+    Mockito.doReturn(0).when(spiedConfig).getReadAheadQueueDepth();\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, MISSEDCACHE_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Prefetch Read Type.\n+     * Setting read ahead depth to 2 with prefetch enabled ensures that prefetch is done.\n+     * First read here might be Normal or Missed Cache but the rest 2 should be Prefetched Read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3;\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    Mockito.doReturn(3).when(spiedConfig).getReadAheadQueueDepth();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, PREFETCH_READ, numOfReadCalls);\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -781,6 +794,132 @@ public void testDefaultReadaheadQueueDepth() throws Exception {\n     in.close();\n   }\n \n+  @Test\n+  public void testReadTypeInTracingContextHeader() throws Exception {\n+    AzureBlobFileSystem spiedFs = Mockito.spy(getFileSystem());\n+    AzureBlobFileSystemStore spiedStore = Mockito.spy(spiedFs.getAbfsStore());\n+    AbfsConfiguration spiedConfig = Mockito.spy(spiedStore.getAbfsConfiguration());\n+    AbfsClient spiedClient = Mockito.spy(spiedStore.getClient());\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadBufferSize();\n+    Mockito.doReturn(ONE_MB).when(spiedConfig).getReadAheadBlockSize();\n+    Mockito.doReturn(spiedClient).when(spiedStore).getClient();\n+    Mockito.doReturn(spiedStore).when(spiedFs).getAbfsStore();\n+    Mockito.doReturn(spiedConfig).when(spiedStore).getAbfsConfiguration();\n+    int numOfReadCalls = 0;\n+    int fileSize = 0;\n+\n+    /*\n+     * Test to verify Normal Read Type.\n+     * Disabling read ahead ensures that read type is normal read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3; // 3 blocks of 1MB each.\n+    doReturn(false).when(spiedConfig).isReadAheadV2Enabled();\n+    doReturn(false).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, NORMAL_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Missed Cache Read Type.\n+     * Setting read ahead depth to 0 ensure that nothing can be got from prefetch.\n+     * In such a case Input Stream will do a sequential read with missed cache read type.\n+     */\n+    fileSize = ONE_MB; // To make sure only one block is read.\n+    numOfReadCalls += 1; // 1 block of 1MB.\n+    Mockito.doReturn(0).when(spiedConfig).getReadAheadQueueDepth();\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, MISSEDCACHE_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Prefetch Read Type.\n+     * Setting read ahead depth to 2 with prefetch enabled ensures that prefetch is done.\n+     * First read here might be Normal or Missed Cache but the rest 2 should be Prefetched Read.\n+     */\n+    fileSize = 3 * ONE_MB; // To make sure multiple blocks are read.\n+    numOfReadCalls += 3;\n+    doReturn(true).when(spiedConfig).isReadAheadEnabled();\n+    Mockito.doReturn(3).when(spiedConfig).getReadAheadQueueDepth();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, PREFETCH_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Footer Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(false).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(true).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, FOOTER_READ, numOfReadCalls);\n+\n+    /*\n+     * Test to verify Small File Read Type.\n+     * Having file size less than footer read size and disabling small file opt\n+     */\n+    fileSize = 8 * ONE_KB;\n+    numOfReadCalls += 1; // Full file will be read along with footer.\n+    doReturn(true).when(spiedConfig).readSmallFilesCompletely();\n+    doReturn(false).when(spiedConfig).optimizeFooterRead();\n+    testReadTypeInTracingContextHeaderInternal(spiedFs, fileSize, SMALLFILE_READ, numOfReadCalls);\n+  }\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:10:56.890+0000", "updated": "2025-08-04T04:10:56.890+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011768", "id": "18011768", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250353998\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java:\n##########\n@@ -578,6 +591,7 @@ int readRemote(long position, byte[] b, int offset, int length, TracingContext t\n         streamStatistics.remoteReadOperation();\n       }\n       LOG.trace(\"Trigger client.read for path={} position={} offset={} length={}\", path, position, offset, length);\n+      tracingContext.setPosition(String.valueOf(position));\n\nReview Comment:\n   Thanks for the suggestion. I updated the current test to assert on position as well.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T04:11:26.906+0000", "updated": "2025-08-04T04:11:26.906+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011777", "id": "18011777", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3149195033\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 26s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m  6s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 52s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 25s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 26s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  79m  1s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 5a4dce188fdc 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 6345ec99eeb23cd09b5d7197e777b1dec23a35e0 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/7/testReport/ |\r\n   | Max. process+thread count | 559 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T05:40:57.724+0000", "updated": "2025-08-04T05:40:57.724+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011811", "id": "18011811", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250858558\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -77,8 +81,7 @@ public class TracingContext {\n    * this field shall not be set.\n    */\n   private String primaryRequestIdForRetry;\n-\n-  private Integer operatedBlobCount = null;\n+  private Integer operatedBlobCount = 1; // Only relevant for rename-delete over blob endpoint where it will be explicitly set.\n\nReview Comment:\n   But there was a null check before it was added to the header which would avoid the NPE\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T08:59:29.953+0000", "updated": "2025-08-04T08:59:29.953+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011813", "id": "18011813", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250885278\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -886,40 +928,54 @@ private void testReadTypeInTracingContextHeaderInternal(AzureBlobFileSystem fs,\n     ArgumentCaptor<ContextEncryptionAdapter> captor8 = ArgumentCaptor.forClass(ContextEncryptionAdapter.class);\n     ArgumentCaptor<TracingContext> captor9 = ArgumentCaptor.forClass(TracingContext.class);\n \n-    verify(fs.getAbfsStore().getClient(), times(numOfReadCalls)).read(\n+    verify(fs.getAbfsStore().getClient(), times(totalReadCalls)).read(\n         captor1.capture(), captor2.capture(), captor3.capture(),\n         captor4.capture(), captor5.capture(), captor6.capture(),\n         captor7.capture(), captor8.capture(), captor9.capture());\n-    TracingContext tracingContext = captor9.getAllValues().get(numOfReadCalls - 1);\n-    verifyHeaderForReadTypeInTracingContextHeader(tracingContext, readType);\n+    List<TracingContext> tracingContextList = captor9.getAllValues();\n+    if (readType == PREFETCH_READ) {\n+      /*\n+       * For Prefetch Enabled, first read can be Normal or Missed Cache Read.\n+       * Sow e will assert only for last 2 calls which should be Prefetched Read.\n\nReview Comment:\n   nit typo: so\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T09:10:44.693+0000", "updated": "2025-08-04T09:10:44.693+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011828", "id": "18011828", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2250972747\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/utils/TracingHeaderValidator.java:\n##########\n@@ -206,7 +207,7 @@ public void updateReadType(ReadType readType) {\n   }\n \n   /**\n-   * Sets the value of the number of blobs operated on\n+   * Sets the value of the number of blobs operated on976345\n\nReview Comment:\n   typo issue\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -886,40 +928,54 @@ private void testReadTypeInTracingContextHeaderInternal(AzureBlobFileSystem fs,\n     ArgumentCaptor<ContextEncryptionAdapter> captor8 = ArgumentCaptor.forClass(ContextEncryptionAdapter.class);\n     ArgumentCaptor<TracingContext> captor9 = ArgumentCaptor.forClass(TracingContext.class);\n \n-    verify(fs.getAbfsStore().getClient(), times(numOfReadCalls)).read(\n+    verify(fs.getAbfsStore().getClient(), times(totalReadCalls)).read(\n         captor1.capture(), captor2.capture(), captor3.capture(),\n         captor4.capture(), captor5.capture(), captor6.capture(),\n         captor7.capture(), captor8.capture(), captor9.capture());\n-    TracingContext tracingContext = captor9.getAllValues().get(numOfReadCalls - 1);\n-    verifyHeaderForReadTypeInTracingContextHeader(tracingContext, readType);\n+    List<TracingContext> tracingContextList = captor9.getAllValues();\n+    if (readType == PREFETCH_READ) {\n+      /*\n+       * For Prefetch Enabled, first read can be Normal or Missed Cache Read.\n+       * Sow e will assert only for last 2 calls which should be Prefetched Read.\n+       * Since calls are asynchronous, we can not guarantee the order of calls.\n+       * Therefore, we cannot assert on exact position here.\n+       */\n+      for (int i = tracingContextList.size() - (numOfReadCalls - 1); i < tracingContextList.size(); i++) {\n+        verifyHeaderForReadTypeInTracingContextHeader(tracingContextList.get(i), readType, -1);\n+      }\n+    } else if (readType == DIRECT_READ) {\n+      int expectedReadPos = ONE_MB/3;\n\nReview Comment:\n   comment for why are we starting with this position will help in clarity\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestApacheHttpClientFallback.java:\n##########\n@@ -61,15 +61,15 @@ private TracingContext getSampleTracingContext(int[] jdkCallsRegister,\n           answer.callRealMethod();\n           AbfsHttpOperation op = answer.getArgument(0);\n           if (op instanceof AbfsAHCHttpOperation) {\n-            Assertions.assertThat(tc.getHeader()).contains(APACHE_IMPL);\n+            Assertions.assertThat(tc.getHeader()).endsWith(APACHE_IMPL);\n             apacheCallsRegister[0]++;\n           }\n           if (op instanceof AbfsJdkHttpOperation) {\n             jdkCallsRegister[0]++;\n             if (AbfsApacheHttpClient.usable()) {\n-              Assertions.assertThat(tc.getHeader()).contains(JDK_IMPL);\n+              Assertions.assertThat(tc.getHeader()).endsWith(JDK_IMPL);\n\nReview Comment:\n   this might fail if we add new header where the network library is not maintained as the last header, so contains looks better to me\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T09:52:41.909+0000", "updated": "2025-08-04T09:52:41.909+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011844", "id": "18011844", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2251145110\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -64,9 +67,10 @@ public class TracingContext {\n   //final concatenated ID list set into x-ms-client-request-id header\n   private String header = EMPTY_STRING;\n   private String ingressHandler = EMPTY_STRING;\n-  private String position = EMPTY_STRING;\n+  private String position = String.valueOf(0); // position of read/write in remote file\n\nReview Comment:\n   Any reason we are changing this default value?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T11:07:17.366+0000", "updated": "2025-08-04T11:07:17.366+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011874", "id": "18011874", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2251498573\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -77,8 +81,7 @@ public class TracingContext {\n    * this field shall not be set.\n    */\n   private String primaryRequestIdForRetry;\n-\n-  private Integer operatedBlobCount = null;\n+  private Integer operatedBlobCount = 1; // Only relevant for rename-delete over blob endpoint where it will be explicitly set.\n\nReview Comment:\n   Yes but we decided to keep the header schema fix and publishing this value as null does not look good in Client Request Id as it can be exposed to user.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T13:28:58.399+0000", "updated": "2025-08-04T13:28:58.399+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011875", "id": "18011875", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2251499536\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TracingContext.java:\n##########\n@@ -64,9 +67,10 @@ public class TracingContext {\n   //final concatenated ID list set into x-ms-client-request-id header\n   private String header = EMPTY_STRING;\n   private String ingressHandler = EMPTY_STRING;\n-  private String position = EMPTY_STRING;\n+  private String position = String.valueOf(0); // position of read/write in remote file\n\nReview Comment:\n   No reason, will revert.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T13:29:18.399+0000", "updated": "2025-08-04T13:29:18.399+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011877", "id": "18011877", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#discussion_r2251505718\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java:\n##########\n@@ -886,40 +928,54 @@ private void testReadTypeInTracingContextHeaderInternal(AzureBlobFileSystem fs,\n     ArgumentCaptor<ContextEncryptionAdapter> captor8 = ArgumentCaptor.forClass(ContextEncryptionAdapter.class);\n     ArgumentCaptor<TracingContext> captor9 = ArgumentCaptor.forClass(TracingContext.class);\n \n-    verify(fs.getAbfsStore().getClient(), times(numOfReadCalls)).read(\n+    verify(fs.getAbfsStore().getClient(), times(totalReadCalls)).read(\n         captor1.capture(), captor2.capture(), captor3.capture(),\n         captor4.capture(), captor5.capture(), captor6.capture(),\n         captor7.capture(), captor8.capture(), captor9.capture());\n-    TracingContext tracingContext = captor9.getAllValues().get(numOfReadCalls - 1);\n-    verifyHeaderForReadTypeInTracingContextHeader(tracingContext, readType);\n+    List<TracingContext> tracingContextList = captor9.getAllValues();\n+    if (readType == PREFETCH_READ) {\n+      /*\n+       * For Prefetch Enabled, first read can be Normal or Missed Cache Read.\n+       * Sow e will assert only for last 2 calls which should be Prefetched Read.\n+       * Since calls are asynchronous, we can not guarantee the order of calls.\n+       * Therefore, we cannot assert on exact position here.\n+       */\n+      for (int i = tracingContextList.size() - (numOfReadCalls - 1); i < tracingContextList.size(); i++) {\n+        verifyHeaderForReadTypeInTracingContextHeader(tracingContextList.get(i), readType, -1);\n+      }\n+    } else if (readType == DIRECT_READ) {\n+      int expectedReadPos = ONE_MB/3;\n\nReview Comment:\n   Already added in comment above.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T13:30:48.542+0000", "updated": "2025-08-04T13:30:48.542+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011903", "id": "18011903", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3151118542\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  27m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 24s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 15s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m 36s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 25s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 25s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  79m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 2f9b7814e558 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 9059784765d6d3519f9649968b07fd94ef9798e8 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/8/testReport/ |\r\n   | Max. process+thread count | 554 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T14:53:23.296+0000", "updated": "2025-08-04T14:53:23.296+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18011950", "id": "18011950", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837#issuecomment-3152193026\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 38s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 51s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 56s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 142m  5s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/9/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7837 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 3280cde505cb 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c787d3b39af6bacd3d9a003fe3b6f81ccc10e194 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/9/testReport/ |\r\n   | Max. process+thread count | 536 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7837/9/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T20:09:47.921+0000", "updated": "2025-08-04T20:09:47.921+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18012062", "id": "18012062", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7837:\nURL: https://github.com/apache/hadoop/pull/7837\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-05T07:54:08.465+0000", "updated": "2025-08-05T07:54:08.465+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18014684", "id": "18014684", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 opened a new pull request, #7881:\nURL: https://github.com/apache/hadoop/pull/7881\n\n   ### Description of PR\r\n   Backport for 3.4\r\n   Jira: https://issues.apache.org/jira/browse/HADOOP-19645\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T17:44:36.905+0000", "updated": "2025-08-18T17:44:36.905+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18014685", "id": "18014685", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7881:\nURL: https://github.com/apache/hadoop/pull/7881#issuecomment-3197856944\n\n   ------------------------------\r\n   :::: AGGREGATED TEST RESULT ::::\r\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 876, Failures: 0, Errors: 0, Skipped: 223\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 32\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 876, Failures: 0, Errors: 0, Skipped: 172\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 32\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 395\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 33\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 876, Failures: 0, Errors: 0, Skipped: 234\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 56\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 285\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 400\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 33\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 301\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 346\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 51\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 876, Failures: 0, Errors: 0, Skipped: 356\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 32\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 397\r\n   [WARNING] Tests run: 182, Failures: 0, Errors: 0, Skipped: 33\r\n   [WARNING] Tests run: 274, Failures: 0, Errors: 0, Skipped: 24\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T17:45:06.942+0000", "updated": "2025-08-18T17:45:06.942+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18014720", "id": "18014720", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7881:\nURL: https://github.com/apache/hadoop/pull/7881#issuecomment-3198211215\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  12m 11s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  36m 33s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 36s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 30s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 27s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 127m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7881/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7881 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux da6887b03eda 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / dc1821731086534899f15dc2abcc2d9bf2c61ae4 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7881/1/testReport/ |\r\n   | Max. process+thread count | 728 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7881/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-18T19:53:28.610+0000", "updated": "2025-08-18T19:53:28.610+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624892/comment/18014790", "id": "18014790", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7881:\nURL: https://github.com/apache/hadoop/pull/7881\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-19T04:58:38.454+0000", "updated": "2025-08-19T04:58:38.454+0000"}], "maxResults": 57, "total": 57, "startAt": 0}, "updated": "2025-08-26T03:58:21.000+0000", "created": "2025-07-29T12:45:56.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624880", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624880", "key": "HADOOP-19644", "fields": {"summary": "ABFS: [ReadAheadV2] Negative tests for Read Buffer Manager V2 and dynamic scaling", "description": null, "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-07-29T10:53:52.000+0000", "created": "2025-07-29T10:52:56.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624878", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624878", "key": "HADOOP-19643", "fields": {"summary": "upgrade gson due to security fixes", "description": "not sure why https://github.com/google/gson/pull/2588 didn't attract a CVE\r\n\r\nlinked to https://issues.apache.org/jira/browse/HADOOP-19632 - nimbus-jose-jwt uses gson", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624878/comment/18010625", "id": "18010625", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #7833:\nURL: https://github.com/apache/hadoop/pull/7833\n\n   Update LICENSE-binary\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   https://issues.apache.org/jira/browse/HADOOP-19643\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T10:21:04.694+0000", "updated": "2025-07-29T10:21:04.694+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624878/comment/18010738", "id": "18010738", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7833:\nURL: https://github.com/apache/hadoop/pull/7833#issuecomment-3134038336\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 23s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  33m  2s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m 49s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 49s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  51m 52s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |  30m 48s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7833/1/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  compile  |  15m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 22s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  56m  3s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 339m 51s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7833/1/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 16s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 629m  8s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.federation.policies.amrmproxy.TestLocalityMulticastAMRMProxyPolicy |\r\n   |   | hadoop.crypto.key.kms.server.TestKMSAudit |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7833/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7833 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 3d08bdf50c29 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 04292f85b2cde016fe4e4c12bfe4c8cd1c040dd4 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7833/1/testReport/ |\r\n   | Max. process+thread count | 3066 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7833/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T20:51:33.892+0000", "updated": "2025-07-29T20:51:33.892+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-07-29T20:51:34.000+0000", "created": "2025-07-29T10:11:17.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624874", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624874", "key": "HADOOP-19642", "fields": {"summary": "upgrade nimbus-jose-jwt due to CVE-2025-53864", "description": "https://www.cve.org/CVERecord?id=CVE-2025-53864", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624874/comment/18010622", "id": "18010622", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ananysin", "name": "ananysin", "key": "ananysin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34049", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34049", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34049", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34049"}, "displayName": "Ananya Singh", "active": true, "timeZone": "Etc/UTC"}, "body": "Hi [~fanningpj] , working on a patch for this. I had raised Jira for the same https://issues.apache.org/jira/browse/HADOOP-19632.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ananysin", "name": "ananysin", "key": "ananysin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34049", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34049", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34049", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34049"}, "displayName": "Ananya Singh", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T09:45:00.153+0000", "updated": "2025-07-29T09:45:00.153+0000"}], "maxResults": 1, "total": 1, "startAt": 0}, "updated": "2025-07-29T09:54:35.000+0000", "created": "2025-07-29T09:37:38.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624851", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624851", "key": "HADOOP-19641", "fields": {"summary": "ABFS: [ReadAheadV2] First Read should bypass ReadBufferManager", "description": "We have observed this across multiple workload runs that when we start reading data from input stream. The first read which came to input stream has to be read synchronously even if we trigger prefetch request for that particular offset. Most of the times we end up doing extra work of checking if the prefetch is trigerred, removing prefetch from the pending queue and go ahead to do a direct remote read in workload thread itself.\r\n\r\nTo avoid all this overhead, we will always bypass read ahead for the very first read of each input stream and trigger read aheads for second read onwards.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624851/comment/18012186", "id": "18012186", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "are you using the openFile seek policy as suggested? parquet will tell you when its a parquet file and its read policy is common: 8 byte footer, reall footer, rowgroups. ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-08-05T18:03:00.195+0000", "updated": "2025-08-05T18:03:00.195+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624851/comment/18012494", "id": "18012494", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "body": "Thanks for the feedback steve. We will definitely incorporate that.\r\nI will hold onto this PR and will make this change with the Read Policy suggested by user taken into consideration.\r\n\r\nWill work diligently on all the read policies and have reads happening in way optimal for each one of them.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-08-07T07:47:32.353+0000", "updated": "2025-08-07T07:47:32.353+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-08-07T07:55:08.000+0000", "created": "2025-07-29T07:01:30.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624477", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624477", "key": "HADOOP-19640", "fields": {"summary": "Resource leak in AssumedRoleCredentialProvider", "description": "When `org.apache.hadoop.fs.s3a.auth.AssumedRoleCredentialProvider` is used in a Hadoop Configuration object, it will attempt to `resolveCredentials()` inside the constructor.\r\n\r\n(lines 165-167)\r\n{code:java}\r\n// and force in a fail-fast check just to keep the stack traces less\r\n// convoluted\r\nresolveCredentials();{code}\r\n\r\nIf this method fails, because the current identity is not able to assume role, the constructor will throw an exception, and fail to close the `stsClient`, `stsProvider` and any other resources that are created in the constructor, leaking threads and other resources.\r\n\u00a0\r\nIn a long running application, that handles Hadoop S3 file systems, where the user can dynamically change to configured role to assume, and external id, this will lead to eventually the system running out of resources due to the leaked threads created by the AWS SDK clients that are not closed when a wrong role or external id is used.\r\n\u00a0\r\n\r\nThere are two potential fixes for this problem:\r\n\r\n\u00a0- Don't attempt to `resolveCredentials()` inside the constructor\r\n\r\n\u00a0- Wrap the `resolveCredentials()` in the constructor in a try/catch block, that cleans the resources and rethrows the exception in the catch block.", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-07-24T08:02:55.000+0000", "created": "2025-07-24T08:01:58.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624415", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624415", "key": "HADOOP-19639", "fields": {"summary": "SecretManager configuration at runtime", "description": "In case of TEZ *DAGAppMaster* the Hadoop *SecretManager* code can not read yarn config xml file, therefore the SELECTED_ALGORITHM and SELECTED_LENGTH variables in SecretManager can not be set at runtime.\r\nThis can results with the following exception in FIPS environment:\r\n\r\n{code:java}\r\njava.security.InvalidParameterException: Key size for HMAC must be at least 112 bits in approved mode: SHA-1/HMAC\r\n\tat com.safelogic.cryptocomply.fips.core/com.safelogic.cryptocomply.jcajce.provider.BaseKeyGenerator.engineInit(Unknown Source)\r\n\tat java.base/javax.crypto.KeyGenerator.init(KeyGenerator.java:540)\r\n\tat java.base/javax.crypto.KeyGenerator.init(KeyGenerator.java:517)\r\n\tat org.apache.hadoop.security.token.SecretManager.<init>(SecretManager.java:157)\r\n\tat org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager.<init>(BaseClientToAMTokenSecretManager.java:38)\r\n\tat org.apache.hadoop.yarn.security.client.ClientToAMTokenSecretManager.<init>(ClientToAMTokenSecretManager.java:46)\r\n\tat org.apache.tez.common.security.TezClientToAMTokenSecretManager.<init>(TezClientToAMTokenSecretManager.java:33)\r\n\tat org.apache.tez.dag.app.DAGAppMaster.serviceInit(DAGAppMaster.java:493)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.tez.dag.app.DAGAppMaster$9.run(DAGAppMaster.java:2649)\r\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.base/javax.security.auth.Subject.doAs(Subject.java:423)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1910)\r\n\tat org.apache.tez.dag.app.DAGAppMaster.initAndStartAppMaster(DAGAppMaster.java:2646)\r\n\tat org.apache.tez.dag.app.DAGAppMaster.main(DAGAppMaster.java:2440)\r\n{code}\r\n\r\nTo mitigate the problem we should provide some ability for the component to be able to modify the configuration without corresponding config files on class path.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009514", "id": "18009514", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K opened a new pull request, #7827:\nURL: https://github.com/apache/hadoop/pull/7827\n\n   ### Description of PR\r\n   \r\n   - static configuration of SecretManager is required because it has some static method what use the selected algorithm\r\n   - in case if class path not contains the config values (for example TEZ DAGAppMaster run) the default values will be loaded at runtime\r\n   - the default values can cause failers in modern environments (they are not FIPS compliant)\r\n   - new SecretManagerConfig created to be able to modify the SecretManager config without core-site.xml present on class path\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   - Unit tests were run\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T10:08:44.862+0000", "updated": "2025-07-24T10:08:44.862+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009531", "id": "18009531", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=abstractdog", "name": "abstractdog", "key": "abstractdog", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=abstractdog&avatarId=40415", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=abstractdog&avatarId=40415", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=abstractdog&avatarId=40415", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=abstractdog&avatarId=40415"}, "displayName": "L\u00e1szl\u00f3 Bodor", "active": true, "timeZone": "Etc/UTC"}, "body": "let me add the motivation from Tez side as a context, so as [~bkosztolnik] mentioned we faced a problem after YARN-11738,\r\nbecause Tez is supposed to work by runtime payloads (containing all the hadoop config), but in the hadoop layer, the options are initialized in the static initializer, so tez cannot help with that exception, because new Configuration() depends on the core-site.xml config which is *maybe* on the classpath, otherwise, everything turns to default\r\nfirst I tried to make the TezClientToAMTokenSecretManager extend a custom Tez implementation of SecretManager, but it led to compilation issues, as Hadoop layers expect a Hadoop SecretManager (see RPC), so eventually we cannot pass a Tez SecretManager that doesn\u2019t inherit Hadoop\u2019s SecretManager, but as long as we extend the Hadoop one, the static initializer and then the field initializer of keyGen keyGen.init(SELECTED_LENGTH) will kick in immediately\r\n\r\nso this cannot be fixed from Tez, we have 2 options:\r\n1. rework YARN-11738 (as this problem was also implied in this comment upstream)\r\n2. make the core-site.xml localized to tez containers to have it picked up <- this is against tez design, so I would prefer 1)\r\n\r\noptimal way would be completely eliminate static fields from SecretManager, but I'm afraid they are there for a reason, so basically, anything could work for us which makes Tez able to intercept, and configure the SecretManager from a Configuration object, which is different than the default one (which is instantiated by new Configuration())\r\n\r\nso this cannot be fixed from Tez, we have 2 options:\r\n1. rework YARN-11738 (as this problem was also implied in this comment upstream)\r\n2. make the core-site.xml localized to tez containers to have it picked up\r\n\r\nI\u2019m a bit against 2), because it\u2019s also a design decision to make file config resources available to tez containers instead of payload, so I would definitely be in favor of 1), here is where I need the opinion of Hadoop folks", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=abstractdog", "name": "abstractdog", "key": "abstractdog", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=abstractdog&avatarId=40415", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=abstractdog&avatarId=40415", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=abstractdog&avatarId=40415", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=abstractdog&avatarId=40415"}, "displayName": "L\u00e1szl\u00f3 Bodor", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:13:38.984+0000", "updated": "2025-07-24T11:14:23.657+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009532", "id": "18009532", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2228219825\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,123 @@\n+\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import javax.crypto.SecretKey;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator} and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+public class SecretManagerConfig {\n+    private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+    private static String SELECTED_ALGORITHM;\n+    private static int SELECTED_LENGTH;\n+\n+    static {\n+        update(new Configuration());\n+    }\n+\n+    /**\n+     * Updates the selected cryptographic algorithm and key length using the provided\n+     * Hadoop {@link Configuration}. This method reads the values for\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+     *\n+     * @param conf the configuration object containing cryptographic settings\n+     */\n+    public static void update(Configuration conf) {\n+        SELECTED_ALGORITHM = conf.get(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_DEFAULT);\n+        LOG.debug(\"Selected hash algorithm: {}\", SELECTED_ALGORITHM);\n+        SELECTED_LENGTH = conf.getInt(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_DEFAULT);\n+        LOG.debug(\"Selected hash key length: {}\", SELECTED_LENGTH);\n+    }\n+\n+    /**\n+     * Returns the currently selected cryptographic algorithm.\n+     *\n+     * @return the name of the selected algorithm\n+     */\n+    public static String getSelectedAlgorithm() {\n+        return SELECTED_ALGORITHM;\n+    }\n+\n+    /**\n+     * Returns the currently selected key length in bits.\n+     *\n+     * @return the selected key length\n+     */\n+    public static int getSelectedLength() {\n+        return SELECTED_LENGTH;\n+    }\n+\n+    /**\n+     * Sets the cryptographic algorithm to use.\n+     *\n+     * @param algorithm the algorithm name (e.g., \"HmacSHA256\", \"AES\")\n+     */\n+    public static void setSelectedAlgorithm(String algorithm) {\n+        SELECTED_ALGORITHM = algorithm;\n+        LOG.debug(\"Selected hash algorithm set to {}\", algorithm);\n+    }\n+\n+    /**\n+     * Sets the cryptographic key length to use (in bits).\n+     *\n+     * @param length the key length\n+     */\n+    public static void setSelectedLength(int length) {\n+        SELECTED_LENGTH = length;\n+        LOG.debug(\"Selected hash key length set to{}\", length);\n\nReview Comment:\n   nit: 1 space before the length\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:15:47.414+0000", "updated": "2025-07-24T11:15:47.414+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009533", "id": "18009533", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2228222651\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,123 @@\n+\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import javax.crypto.SecretKey;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator} and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+public class SecretManagerConfig {\n+    private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+    private static String SELECTED_ALGORITHM;\n+    private static int SELECTED_LENGTH;\n+\n+    static {\n+        update(new Configuration());\n+    }\n+\n+    /**\n+     * Updates the selected cryptographic algorithm and key length using the provided\n+     * Hadoop {@link Configuration}. This method reads the values for\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+     *\n+     * @param conf the configuration object containing cryptographic settings\n+     */\n+    public static void update(Configuration conf) {\n+        SELECTED_ALGORITHM = conf.get(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_DEFAULT);\n+        LOG.debug(\"Selected hash algorithm: {}\", SELECTED_ALGORITHM);\n+        SELECTED_LENGTH = conf.getInt(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_DEFAULT);\n+        LOG.debug(\"Selected hash key length: {}\", SELECTED_LENGTH);\n+    }\n+\n+    /**\n+     * Returns the currently selected cryptographic algorithm.\n+     *\n+     * @return the name of the selected algorithm\n+     */\n+    public static String getSelectedAlgorithm() {\n+        return SELECTED_ALGORITHM;\n+    }\n+\n+    /**\n+     * Returns the currently selected key length in bits.\n+     *\n+     * @return the selected key length\n+     */\n+    public static int getSelectedLength() {\n+        return SELECTED_LENGTH;\n+    }\n+\n+    /**\n+     * Sets the cryptographic algorithm to use.\n+     *\n+     * @param algorithm the algorithm name (e.g., \"HmacSHA256\", \"AES\")\n+     */\n+    public static void setSelectedAlgorithm(String algorithm) {\n\nReview Comment:\n   we need to decide what other components will use, which is I guess update(conf), in which case this should rather become package protected with @VisibleForTesting\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:17:13.393+0000", "updated": "2025-07-24T11:17:13.393+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009534", "id": "18009534", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2228223190\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,123 @@\n+\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import javax.crypto.SecretKey;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator} and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+public class SecretManagerConfig {\n+    private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+    private static String SELECTED_ALGORITHM;\n+    private static int SELECTED_LENGTH;\n+\n+    static {\n+        update(new Configuration());\n+    }\n+\n+    /**\n+     * Updates the selected cryptographic algorithm and key length using the provided\n+     * Hadoop {@link Configuration}. This method reads the values for\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+     *\n+     * @param conf the configuration object containing cryptographic settings\n+     */\n+    public static void update(Configuration conf) {\n+        SELECTED_ALGORITHM = conf.get(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_DEFAULT);\n+        LOG.debug(\"Selected hash algorithm: {}\", SELECTED_ALGORITHM);\n+        SELECTED_LENGTH = conf.getInt(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_DEFAULT);\n+        LOG.debug(\"Selected hash key length: {}\", SELECTED_LENGTH);\n+    }\n+\n+    /**\n+     * Returns the currently selected cryptographic algorithm.\n+     *\n+     * @return the name of the selected algorithm\n+     */\n+    public static String getSelectedAlgorithm() {\n+        return SELECTED_ALGORITHM;\n+    }\n+\n+    /**\n+     * Returns the currently selected key length in bits.\n+     *\n+     * @return the selected key length\n+     */\n+    public static int getSelectedLength() {\n+        return SELECTED_LENGTH;\n+    }\n+\n+    /**\n+     * Sets the cryptographic algorithm to use.\n+     *\n+     * @param algorithm the algorithm name (e.g., \"HmacSHA256\", \"AES\")\n+     */\n+    public static void setSelectedAlgorithm(String algorithm) {\n+        SELECTED_ALGORITHM = algorithm;\n+        LOG.debug(\"Selected hash algorithm set to {}\", algorithm);\n+    }\n+\n+    /**\n+     * Sets the cryptographic key length to use (in bits).\n+     *\n+     * @param length the key length\n+     */\n+    public static void setSelectedLength(int length) {\n\nReview Comment:\n   @VisibleForTesting for the same reason as setSelectedAlgorithm\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:17:31.895+0000", "updated": "2025-07-24T11:17:31.895+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009536", "id": "18009536", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2228235542\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,123 @@\n+\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import javax.crypto.SecretKey;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator} and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+public class SecretManagerConfig {\n+    private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+    private static String SELECTED_ALGORITHM;\n+    private static int SELECTED_LENGTH;\n+\n+    static {\n+        update(new Configuration());\n+    }\n+\n+    /**\n+     * Updates the selected cryptographic algorithm and key length using the provided\n+     * Hadoop {@link Configuration}. This method reads the values for\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+     *\n+     * @param conf the configuration object containing cryptographic settings\n+     */\n+    public static void update(Configuration conf) {\n+        SELECTED_ALGORITHM = conf.get(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_DEFAULT);\n+        LOG.debug(\"Selected hash algorithm: {}\", SELECTED_ALGORITHM);\n+        SELECTED_LENGTH = conf.getInt(\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY,\n+                CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_DEFAULT);\n+        LOG.debug(\"Selected hash key length: {}\", SELECTED_LENGTH);\n+    }\n+\n+    /**\n+     * Returns the currently selected cryptographic algorithm.\n+     *\n+     * @return the name of the selected algorithm\n+     */\n+    public static String getSelectedAlgorithm() {\n+        return SELECTED_ALGORITHM;\n+    }\n+\n+    /**\n+     * Returns the currently selected key length in bits.\n+     *\n+     * @return the selected key length\n+     */\n+    public static int getSelectedLength() {\n+        return SELECTED_LENGTH;\n+    }\n+\n+    /**\n+     * Sets the cryptographic algorithm to use.\n+     *\n+     * @param algorithm the algorithm name (e.g., \"HmacSHA256\", \"AES\")\n+     */\n+    public static void setSelectedAlgorithm(String algorithm) {\n\nReview Comment:\n   Hi @abstractdog !\r\n   \r\n   Thanks for the review. I was thinking we can provide 2 method and components can decide what they prefer, but maybe you right and that will over complicate the things. I will delete these setters.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:23:37.756+0000", "updated": "2025-07-24T11:23:37.756+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009541", "id": "18009541", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2228243815\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,123 @@\n+\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import javax.crypto.SecretKey;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator} and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+public class SecretManagerConfig {\n+    private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+    private static String SELECTED_ALGORITHM;\n+    private static int SELECTED_LENGTH;\n+\n+    static {\n+        update(new Configuration());\n+    }\n+\n+    /**\n+     * Updates the selected cryptographic algorithm and key length using the provided\n+     * Hadoop {@link Configuration}. This method reads the values for\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+     *\n+     * @param conf the configuration object containing cryptographic settings\n+     */\n+    public static void update(Configuration conf) {\n\nReview Comment:\n   while this method is crucial for Tez as explain on [HADOOP-19639](https://issues.apache.org/jira/browse/HADOOP-19639), it might also bring confusion, which is due to the fact that we try to lazy init static things, so scenario I'm worried about a wrong usage:\r\n   1. keyGen is initialized by createKeyGenerator\r\n   2. update is called\r\n   3. update is not effective as the keyGen is already initialized\r\n   \r\n   need to make this more robust by giving a warning or even throwing an exception if the update(Configuration) is called after initialization, making the user aware that the settings won't be applied\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:27:40.478+0000", "updated": "2025-07-24T11:27:40.478+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009542", "id": "18009542", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2228243815\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,123 @@\n+\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import javax.crypto.SecretKey;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator} and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+public class SecretManagerConfig {\n+    private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+    private static String SELECTED_ALGORITHM;\n+    private static int SELECTED_LENGTH;\n+\n+    static {\n+        update(new Configuration());\n+    }\n+\n+    /**\n+     * Updates the selected cryptographic algorithm and key length using the provided\n+     * Hadoop {@link Configuration}. This method reads the values for\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+     *\n+     * @param conf the configuration object containing cryptographic settings\n+     */\n+    public static void update(Configuration conf) {\n\nReview Comment:\n   while this method is crucial for Tez as explained on [HADOOP-19639](https://issues.apache.org/jira/browse/HADOOP-19639), it might also bring confusion, which is due to the fact that we try to lazy init static things, so scenario I'm worried about a wrong usage:\r\n   1. keyGen is initialized by createKeyGenerator\r\n   2. update is called\r\n   3. update is not effective as the keyGen is already initialized\r\n   \r\n   need to make this more robust by giving a warning or even throwing an exception if the update(Configuration) is called after initialization, making the user aware that the settings won't be applied\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:27:53.047+0000", "updated": "2025-07-24T11:27:53.047+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009543", "id": "18009543", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2228243815\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,123 @@\n+\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import javax.crypto.SecretKey;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator} and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+public class SecretManagerConfig {\n+    private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+    private static String SELECTED_ALGORITHM;\n+    private static int SELECTED_LENGTH;\n+\n+    static {\n+        update(new Configuration());\n+    }\n+\n+    /**\n+     * Updates the selected cryptographic algorithm and key length using the provided\n+     * Hadoop {@link Configuration}. This method reads the values for\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+     * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+     *\n+     * @param conf the configuration object containing cryptographic settings\n+     */\n+    public static void update(Configuration conf) {\n\nReview Comment:\n   while this method is crucial for Tez as explained on [HADOOP-19639](https://issues.apache.org/jira/browse/HADOOP-19639), it might also bring confusion, which is due to the fact that we try to lazy init static things, so a possible scenario I'm worried about is this below:\r\n   1. keyGen is initialized by createKeyGenerator\r\n   2. update is called\r\n   3. update is not effective as the keyGen is already initialized\r\n   \r\n   need to make this more robust by giving a warning or even throwing an exception if the update(Configuration) is called after initialization, making the user aware that the settings won't be applied\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T11:28:17.814+0000", "updated": "2025-07-24T11:28:17.814+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009588", "id": "18009588", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3113583720\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  38m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m 30s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 14s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 22s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 36s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m  0s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  14m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m  9s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/1/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 105 new + 3 unchanged - 5 fixed = 108 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 48s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 47s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   1m  1s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/1/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 227m 13s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 8cb7def7bf45 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 917e1a914ed3e869376961a0ff2a2678b3d851db |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/1/testReport/ |\r\n   | Max. process+thread count | 3151 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T13:57:39.985+0000", "updated": "2025-07-24T13:57:39.985+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009589", "id": "18009589", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3113584468\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  28m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 35s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 29s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  22m 31s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   7m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 42s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/6/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 99 new + 3 unchanged - 5 fixed = 102 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 37s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 49s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  18m 47s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   0m 42s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/6/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 134m  7s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 15839c6479be 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f9f28d6d5d32f97017b839cd542001e5abfd01a6 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/6/testReport/ |\r\n   | Max. process+thread count | 1290 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T13:57:52.854+0000", "updated": "2025-07-24T13:57:52.854+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009591", "id": "18009591", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3113598769\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  34m  6s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  10m 21s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 48s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 52s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  27m 57s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   9m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   9m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m 11s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   8m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 38s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/5/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 85 new + 3 unchanged - 5 fixed = 88 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  23m 32s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  18m 18s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   0m 34s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/5/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 151m 13s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux a6c2fd546b0d 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c12d388317dbaa35f3a7ccdeb195a863defa7cea |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/5/testReport/ |\r\n   | Max. process+thread count | 3151 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T14:02:08.176+0000", "updated": "2025-07-24T14:02:08.176+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009595", "id": "18009595", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3113633207\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  0s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m 35s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 55s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 37s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 11s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 37s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m  1s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 59s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m  7s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m  5s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  14m  5s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m  8s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/2/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 101 new + 3 unchanged - 5 fixed = 104 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  5s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 48s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 16s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 57s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   1m  1s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/2/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 225m 26s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d930993a819a 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / fecb7de4f374c95b0e0597b513b5417c77f57429 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/2/testReport/ |\r\n   | Max. process+thread count | 1267 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T14:12:00.732+0000", "updated": "2025-07-24T14:12:00.732+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009601", "id": "18009601", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3113695501\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m 23s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 50s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m 44s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 38s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 28s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m  9s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/3/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 101 new + 3 unchanged - 5 fixed = 104 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 10s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 48s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 40s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 50s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   1m  2s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/3/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 239m  6s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 8277f4c6fcb7 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / fecb7de4f374c95b0e0597b513b5417c77f57429 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/3/testReport/ |\r\n   | Max. process+thread count | 1378 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T14:28:53.193+0000", "updated": "2025-07-24T14:28:53.193+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009607", "id": "18009607", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3113751006\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  31m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   9m 37s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   8m 15s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m  1s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  23m 23s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  10m  3s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  10m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   9m 12s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   9m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 39s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/8/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 99 new + 3 unchanged - 5 fixed = 102 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 53s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  18m 25s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   0m 40s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/8/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 143m 35s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 137a54bc5cde 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / dc8b28237db668b0b3f7ccbaf43f3f023e679158 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/8/testReport/ |\r\n   | Max. process+thread count | 3151 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T14:44:04.621+0000", "updated": "2025-07-24T14:44:04.621+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009608", "id": "18009608", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3113778631\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m  4s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m 59s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  9s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 47s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 13s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m  3s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m 11s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  14m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m  9s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/4/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 101 new + 3 unchanged - 5 fixed = 104 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  7s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 49s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 43s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 41s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   1m  6s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/4/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 223m  5s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux cb505e4e8d20 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 43d1e7af3a8259b87e1b9c3bc11f888ebec47e8a |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/4/testReport/ |\r\n   | Max. process+thread count | 1378 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T14:51:40.989+0000", "updated": "2025-07-24T14:51:40.989+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009642", "id": "18009642", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3114088366\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  25m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  43m  6s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  20m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  18m 20s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 20s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 55s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m  6s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m  4s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  18m  0s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  18m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 41s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  16m 41s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m 11s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/7/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 99 new + 3 unchanged - 5 fixed = 102 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 47s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 58s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 49s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 24s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m  7s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   1m  7s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/7/artifact/out/results-asflicense.txt) |  The patch generated 2 ASF License warnings.  |\r\n   |  |   | 267m 40s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 573d4710b3df 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / dc8b28237db668b0b3f7ccbaf43f3f023e679158 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/7/testReport/ |\r\n   | Max. process+thread count | 1254 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T16:22:47.206+0000", "updated": "2025-07-24T16:22:47.206+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009650", "id": "18009650", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3114142782\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  28m 15s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 23s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 31s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 48s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  22m 15s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 59s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   7m 59s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 25s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   7m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 32s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/10/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 99 new + 3 unchanged - 5 fixed = 102 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  21m 51s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  18m 25s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 42s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 133m 45s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/10/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 35bc6361dd7d 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b4c125bf4bf93c83bab494febd0a631651ae8236 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/10/testReport/ |\r\n   | Max. process+thread count | 3151 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/10/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T16:42:47.397+0000", "updated": "2025-07-24T16:42:47.397+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009664", "id": "18009664", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3114376961\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 38s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 55s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 49s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 20s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 55s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 22s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 56s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 19s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 43s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m 11s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/9/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 99 new + 3 unchanged - 5 fixed = 102 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 49s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 55s |  |  hadoop-common in the patch passed.  |\r\n   | -1 :x: |  asflicense  |   1m  2s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/9/artifact/out/results-asflicense.txt) |  The patch generated 1 ASF License warnings.  |\r\n   |  |   | 222m 47s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/9/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 04f8fbe20f81 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / d7b4811a130b9a0e5df41c71b0b57e0439dcffe6 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/9/testReport/ |\r\n   | Max. process+thread count | 1288 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/9/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T18:06:23.686+0000", "updated": "2025-07-24T18:06:23.686+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009699", "id": "18009699", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3114850985\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 59s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m  7s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 18s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 56s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 38s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 22s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 10s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 58s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m 13s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/11/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 7 new + 3 unchanged - 5 fixed = 10 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 12s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 23s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 50s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  7s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 221m 25s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/11/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 9029f853de3e 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 62cb8b55bf58188f56016b180713ab7a2acd498c |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/11/testReport/ |\r\n   | Max. process+thread count | 3152 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/11/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T20:37:05.457+0000", "updated": "2025-07-24T20:37:05.457+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009889", "id": "18009889", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3116949549\n\n   @K0K0V0K LGTM +1.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T08:50:32.872+0000", "updated": "2025-07-25T08:50:32.872+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009891", "id": "18009891", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230571393\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+  private static boolean initialized;\n+\n+  static {\n+    update(new Configuration());\n+  }\n+\n+  private SecretManagerConfig() {\n+  }\n+\n+  /**\n+   * Updates the selected cryptographic algorithm and key length using the provided\n+   * Hadoop {@link Configuration}. This method reads the values for\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+   *\n+   * @param conf the configuration object containing cryptographic settings\n+   */\n+  public static synchronized void update(Configuration conf) {\n+    if (initialized) {\n+      LOG.warn(\n+        \"Keygen or Mac was already initialized with older config, those will not be updated\");\n\nReview Comment:\n   I'm afraid this message in its current form is confusing:\r\n   1. we don't know if keygen or mac\r\n   2. mac is threadlocal, so it can also further complicate this situation\r\n   \r\n    what about including Keygen and Mac instance here (their initialization was on debug level, so we don't know what's happening here), something like:\r\n   ```\r\n           \"Keygen ({}) or Mac ({}, thread: {}) was already initialized with older config, those will not be updated\", keyGen, macForThisThread, threadId);\r\n   ```\r\n   I know this complicates the code because there are not necessarily available here, we can also consider moving this class as a static inner class to SecretManager, as it's already tightly coupled, we won't won anything by having it a separate class\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T09:01:52.359+0000", "updated": "2025-07-25T09:01:52.359+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009892", "id": "18009892", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230573481\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+  private static boolean initialized;\n+\n+  static {\n+    update(new Configuration());\n+  }\n+\n+  private SecretManagerConfig() {\n+  }\n+\n+  /**\n+   * Updates the selected cryptographic algorithm and key length using the provided\n+   * Hadoop {@link Configuration}. This method reads the values for\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+   *\n+   * @param conf the configuration object containing cryptographic settings\n+   */\n+  public static synchronized void update(Configuration conf) {\n+    if (initialized) {\n+      LOG.warn(\n+        \"Keygen or Mac was already initialized with older config, those will not be updated\");\n+    }\n+    selectedAlgorithm = conf.get(\n+      CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY,\n+      CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_DEFAULT);\n+    LOG.debug(\"Selected hash algorithm: {}\", selectedAlgorithm);\n+    selectedLength = conf.getInt(\n+      CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY,\n+      CommonConfigurationKeysPublic.HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_DEFAULT);\n+    LOG.debug(\"Selected hash key length: {}\", selectedLength);\n+  }\n+\n+  /**\n+   * Returns the currently selected cryptographic algorithm.\n+   *\n+   * @return the name of the selected algorithm\n+   */\n+  public static synchronized String getSelectedAlgorithm() {\n+    return selectedAlgorithm;\n+  }\n+\n+  /**\n+   * Returns the currently selected key length in bits.\n+   *\n+   * @return the selected key length\n+   */\n+  public static synchronized int getSelectedLength() {\n+    return selectedLength;\n+  }\n+\n+  /**\n+   * Creates a new {@link KeyGenerator} instance configured with the currently selected\n+   * algorithm and key length.\n+   *\n+   * @return a new {@code KeyGenerator} instance\n+   * @throws IllegalArgumentException if the specified algorithm is not available\n+   */\n+  public static synchronized KeyGenerator createKeyGenerator() {\n+    LOG.debug(\"Creating key generator instance {}, {}\", selectedAlgorithm, selectedLength);\n+    initialized = true;\n+    try {\n+      KeyGenerator keyGen = KeyGenerator.getInstance(selectedAlgorithm);\n+      keyGen.init(selectedLength);\n+      return keyGen;\n+    } catch (NoSuchAlgorithmException nsa) {\n+      throw new IllegalArgumentException(\"Can't find \" + selectedAlgorithm, nsa);\n+    }\n+  }\n+\n+  /**\n+   * Creates a new {@link Mac} instance using the currently selected algorithm.\n+   *\n+   * @return a new {@code Mac} instance\n+   * @throws IllegalArgumentException if the specified algorithm is not available\n+   */\n+  public static synchronized Mac createMac() {\n+    LOG.debug(\"Creating mac instance {}\", selectedAlgorithm);\n\nReview Comment:\n   include thread id in this message (regardless of what the logging library does, we might want to have this information)\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T09:02:57.435+0000", "updated": "2025-07-25T09:02:57.435+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009893", "id": "18009893", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3116992779\n\n   @K0K0V0K thanks for the patch so far! please consider the 2 comments I left before proceeding, I believe it would make this patch cleaner and more user-friendly\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T09:03:46.488+0000", "updated": "2025-07-25T09:03:46.488+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009895", "id": "18009895", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230571393\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+  private static boolean initialized;\n+\n+  static {\n+    update(new Configuration());\n+  }\n+\n+  private SecretManagerConfig() {\n+  }\n+\n+  /**\n+   * Updates the selected cryptographic algorithm and key length using the provided\n+   * Hadoop {@link Configuration}. This method reads the values for\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+   *\n+   * @param conf the configuration object containing cryptographic settings\n+   */\n+  public static synchronized void update(Configuration conf) {\n+    if (initialized) {\n+      LOG.warn(\n+        \"Keygen or Mac was already initialized with older config, those will not be updated\");\n\nReview Comment:\n   I'm afraid this message in its current form is confusing:\r\n   1. we don't know if keygen or mac\r\n   2. mac is threadlocal, so it can also further complicate this situation\r\n   \r\n    what about including Keygen and Mac instance here (their initialization was on debug level, so we don't know what's happening here), something like:\r\n   ```\r\n           \"Keygen ({}) or Mac ({}, thread: {}) was already initialized with older config, those will not be updated\", keyGen, macForThisThread, threadId);\r\n   ```\r\n   I know this complicates the code because those variables are not necessarily available here, we can also consider moving this class as a static inner class to SecretManager, as it's already tightly coupled, we won't won anything by having it a separate class\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T09:04:47.541+0000", "updated": "2025-07-25T09:04:47.541+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009902", "id": "18009902", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3117058957\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m 14s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 43s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 14s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 53s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m  6s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m  7s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 51s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m 13s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/12/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 2 new + 3 unchanged - 5 fixed = 5 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 56s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 43s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 219m 35s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/12/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 8468afa4e21a 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b02c20254ed02b0802bb849fda7299e25ef3eb88 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/12/testReport/ |\r\n   | Max. process+thread count | 1288 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/12/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T09:26:43.784+0000", "updated": "2025-07-25T09:26:43.784+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009911", "id": "18009911", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230728221\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+  private static boolean initialized;\n+\n+  static {\n+    update(new Configuration());\n+  }\n+\n+  private SecretManagerConfig() {\n+  }\n+\n+  /**\n+   * Updates the selected cryptographic algorithm and key length using the provided\n+   * Hadoop {@link Configuration}. This method reads the values for\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+   *\n+   * @param conf the configuration object containing cryptographic settings\n+   */\n+  public static synchronized void update(Configuration conf) {\n+    if (initialized) {\n+      LOG.warn(\n+        \"Keygen or Mac was already initialized with older config, those will not be updated\");\n\nReview Comment:\n   Thanks @abstractdog for the hints!\r\n   \r\n   I am a bit troubled with the macs ...\r\n   As you mentioned these are thread locals, so not just one can be present of them in the java process.\r\n   If I keep reference for them i believe the GC will never clean them (not sure). Maybe i can try with some WeakReference if you think that can be acceptable.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T10:18:31.030+0000", "updated": "2025-07-25T10:18:31.030+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009914", "id": "18009914", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230768478\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+  private static boolean initialized;\n+\n+  static {\n+    update(new Configuration());\n+  }\n+\n+  private SecretManagerConfig() {\n+  }\n+\n+  /**\n+   * Updates the selected cryptographic algorithm and key length using the provided\n+   * Hadoop {@link Configuration}. This method reads the values for\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+   *\n+   * @param conf the configuration object containing cryptographic settings\n+   */\n+  public static synchronized void update(Configuration conf) {\n+    if (initialized) {\n+      LOG.warn(\n+        \"Keygen or Mac was already initialized with older config, those will not be updated\");\n\nReview Comment:\n   The current solution seems not leaking\r\n   ```\r\n     @Test\r\n     public void tmpTest() throws InterruptedException {\r\n       new Thread(\"tmpTest-1\") {\r\n         @Override\r\n         public void run() {\r\n           Mac mac = SecretManagerConfig.createMac();\r\n           try {\r\n             Thread.sleep(2000);\r\n           } catch (InterruptedException e) {\r\n             throw new RuntimeException(e);\r\n           }      }\r\n       }.start();\r\n       new Thread(\"tmpTest-2\") {\r\n         @Override\r\n         public void run() {\r\n           Mac mac = SecretManagerConfig.createMac();\r\n           try {\r\n             Thread.sleep(2000);\r\n           } catch (InterruptedException e) {\r\n             throw new RuntimeException(e);\r\n           }      }\r\n       }.start();\r\n       Thread.sleep(500);\r\n       System.err.println(\"MACS:\" + SecretManagerConfig.MACS);\r\n       Thread.sleep(2000);\r\n       System.gc();\r\n       Thread.sleep(500);\r\n       System.err.println(\"MACS:\" + SecretManagerConfig.MACS);\r\n     }\r\n   ```\r\n   OUTPUT:\r\n   ```\r\n   MACS:{Thread[tmpTest-1,5,main]=javax.crypto.Mac@52aa2946, Thread[tmpTest-2,5,main]=javax.crypto.Mac@4de5031f}\r\n   MACS:{}\r\n   ```\r\n   \r\n   Feel free to ask modification\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T10:41:32.176+0000", "updated": "2025-07-25T10:41:32.176+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009915", "id": "18009915", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230777430\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,143 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+import java.util.Map;\n+import java.util.WeakHashMap;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public final class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+\n+  private static final Map<Thread, KeyGenerator> KEYGENS = new WeakHashMap<>();\n\nReview Comment:\n   KeyGenerator is not threadlocal, there will be a single global instance, right?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T10:46:47.559+0000", "updated": "2025-07-25T10:46:47.559+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009916", "id": "18009916", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230781641\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,143 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+import java.util.Map;\n+import java.util.WeakHashMap;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public final class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+\n+  private static final Map<Thread, KeyGenerator> KEYGENS = new WeakHashMap<>();\n\nReview Comment:\n   If everything works as expected yes, but no there is not granted some one will not call this method again ...\r\n   you right this should be in SecretManager not in an other class \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T10:49:17.644+0000", "updated": "2025-07-25T10:49:17.644+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009917", "id": "18009917", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2230784229\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,143 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+import java.util.Map;\n+import java.util.WeakHashMap;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public final class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+\n+  private static final Map<Thread, KeyGenerator> KEYGENS = new WeakHashMap<>();\n+  public static final Map<Thread, Mac> MACS = new WeakHashMap<>();\n+\n+  static {\n+    update(new Configuration());\n+  }\n+\n+  private SecretManagerConfig() {\n+  }\n+\n+  /**\n+   * Updates the selected cryptographic algorithm and key length using the provided\n+   * Hadoop {@link Configuration}. This method reads the values for\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_GENERATOR_ALGORITHM_KEY} and\n+   * {@code HADOOP_SECURITY_SECRET_MANAGER_KEY_LENGTH_KEY}, or uses default values if not set.\n+   *\n+   * @param conf the configuration object containing cryptographic settings\n+   */\n+  public static synchronized void update(Configuration conf) {\n+    if (!KEYGENS.isEmpty()) {\n+      LOG.warn(\"Keygen was already initialized with older config, those will not be updated.\" +\n+          \"Hint: If you turn on debug log you can see when it happened. Keygens: {}\", KEYGENS);\n+    }\n+    if (!MACS.isEmpty()) {\n+      LOG.warn(\"Mac was already initialized with older config, those will not be updated.\" +\n\nReview Comment:\n   I don't think we need to store and log all the macs, I would be satisfied with logging if there is any in the current thread, acquired by:\r\n   ```\r\n   threadLocalMac.get()\r\n   ```\r\n   assuming that the update() happens on the same thread as the usage, this can be a useful logging message (without logging a whole MACS collection)\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T10:50:47.711+0000", "updated": "2025-07-25T10:50:47.711+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009964", "id": "18009964", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3118018889\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  0s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  38m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 57s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 49s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 38s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 20s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 56s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 37s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 39s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 38s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 14s |  |  hadoop-common-project/hadoop-common: The patch generated 0 new + 3 unchanged - 5 fixed = 3 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 39s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 56s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 38s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 43s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  7s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 215m 10s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/14/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux a551e66581bc 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ef05d1708c289152368751b72c6d237812c5a84c |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/14/testReport/ |\r\n   | Max. process+thread count | 3152 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/14/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T14:22:39.081+0000", "updated": "2025-07-25T14:22:39.081+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18009966", "id": "18009966", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3118085178\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m 30s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 15s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 35s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 41s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m 41s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 55s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m  8s |  |  hadoop-common-project/hadoop-common: The patch generated 0 new + 3 unchanged - 5 fixed = 3 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m  9s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  44m  2s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  23m 30s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  2s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 229m 12s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/13/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux f6ec6f660895 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e56c0213ef2d44f90b6cd6a570878ca3ba78c4ae |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/13/testReport/ |\r\n   | Max. process+thread count | 3152 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/13/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T14:30:09.103+0000", "updated": "2025-07-25T14:30:09.103+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18010273", "id": "18010273", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on code in PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#discussion_r2234948795\n\n\n##########\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/SecretManagerConfig.java:\n##########\n@@ -0,0 +1,143 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.security.token;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.Mac;\n+import java.security.NoSuchAlgorithmException;\n+import java.util.Map;\n+import java.util.WeakHashMap;\n+\n+/**\n+ * Provides configuration and utility methods for managing cryptographic key generation\n+ * and message authentication code (MAC) generation using specified algorithms and key lengths.\n+ * <p>\n+ * This class supports static access to the selected cryptographic algorithm and key length,\n+ * and provides methods to create configured {@link javax.crypto.KeyGenerator}\n+ * and {@link javax.crypto.Mac} instances.\n+ * The configuration is initialized statically from a provided {@link Configuration} object.\n+ * <p>\n+ * The {@link SecretManager} has some static method, so static configuration is required\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Evolving\n+public final class SecretManagerConfig {\n+  private static final Logger LOG = LoggerFactory.getLogger(SecretManagerConfig.class);\n+  private static String selectedAlgorithm;\n+  private static int selectedLength;\n+\n+  private static final Map<Thread, KeyGenerator> KEYGENS = new WeakHashMap<>();\n\nReview Comment:\n   I just rechecked the code, seems like Keygenerator is a local variable for every SecretManager instance.\r\n   Maybe this could be thread local, and maybe could improve the performance, but i would rather not touch this for sake of the stability.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T06:56:46.529+0000", "updated": "2025-07-28T06:56:46.529+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18010297", "id": "18010297", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3126108509\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  2s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |  13m 19s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   0m 16s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 31s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -0 :warning: |  checkstyle  |   0m 28s | [/buildtool-branch-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/buildtool-branch-checkstyle-hadoop-common-project_hadoop-common.txt) |  The patch fails to run checkstyle in hadoop-common  |\r\n   | -1 :x: |  mvnsite  |   0m 27s | [/branch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/branch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/branch-javadoc-hadoop-common-project_hadoop-common-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/branch-javadoc-hadoop-common-project_hadoop-common-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-common in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 21s | [/branch-javadoc-hadoop-common-project_hadoop-common-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/branch-javadoc-hadoop-common-project_hadoop-common-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-common in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 50s |  |  trunk passed  |\r\n   | -1 :x: |  shadedclient  |   8m 38s |  |  branch has errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |   9m  2s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   1m 17s |  |  the patch passed  |\r\n   | -1 :x: |  compile  |   5m 27s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   5m 27s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 25s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 25s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 23s | [/buildtool-patch-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/buildtool-patch-checkstyle-hadoop-common-project_hadoop-common.txt) |  The patch fails to run checkstyle in hadoop-common  |\r\n   | -1 :x: |  mvnsite  |   0m 26s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 26s | [/patch-javadoc-hadoop-common-project_hadoop-common-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-javadoc-hadoop-common-project_hadoop-common-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-common in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 26s | [/patch-javadoc-hadoop-common-project_hadoop-common-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-javadoc-hadoop-common-project_hadoop-common-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-common in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 25s | [/patch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-spotbugs-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | -1 :x: |  shadedclient  |   5m  7s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 25s | [/patch-unit-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt) |  hadoop-common in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 25s |  |  ASF License check generated no output?  |\r\n   |  |   |  40m 51s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d2b0f5829ad5 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / dc7eb8ae892c32c9080f2e9333ee611ac326c794 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/testReport/ |\r\n   | Max. process+thread count | 152 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/15/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T08:26:10.875+0000", "updated": "2025-07-28T08:26:10.875+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18010368", "id": "18010368", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3126847633\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m 24s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 51s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 58s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 37s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 17s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 55s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 30s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  37m 57s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 56s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m  4s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m  4s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 57s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 57s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m 12s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/16/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) |  hadoop-common-project/hadoop-common: The patch generated 1 new + 3 unchanged - 5 fixed = 4 total (was 8)  |\r\n   | +1 :green_heart: |  mvnsite  |   1m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   1m 15s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 53s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 51s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |  22m 42s |  |  hadoop-common in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  8s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 229m 10s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/16/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7827 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d37cb15a00f9 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / abbb7a3ee3423fdb67688a63b3ffc2e9c4ac31d5 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/16/testReport/ |\r\n   | Max. process+thread count | 2152 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7827/16/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T11:45:05.641+0000", "updated": "2025-07-28T11:45:05.641+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18010391", "id": "18010391", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "K0K0V0K commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3127087300\n\n   Hi @abstractdog @slfan1989,\r\n   \r\n   I ended up deleting the SecretManagerConfig file and moved the relevant code into SecretManager. This ensures that only SecretManager has access to key generation and MAC creation, reducing the risk of other components using that logic unintentionally.\r\n   \r\n   Thank you for your previous reviews and suggestions\u2014they were very helpful in improving this PR. When you have a moment, could you kindly take another look?\r\n   \r\n   Thanks again!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T12:50:05.226+0000", "updated": "2025-07-28T12:50:05.226+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18010874", "id": "18010874", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "abstractdog commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3135574684\n\n   > Hi @abstractdog @slfan1989,\r\n   > \r\n   > I ended up deleting the SecretManagerConfig file and moved the relevant code into SecretManager. This ensures that only SecretManager has access to key generation and MAC creation, reducing the risk of other components using that logic unintentionally.\r\n   > \r\n   > Thank you for your previous reviews and suggestions\u2014they were very helpful in improving this PR. When you have a moment, could you kindly take another look?\r\n   > \r\n   > Thanks again!\r\n   \r\n   thanks a lot @K0K0V0K for taking care of this, looks good to me!\r\n   \r\n   I know not everything you\u2019ve had to do here has been the most exciting\u2014it is what it is, especially as long as we\u2019re dealing with static stuff around SecretManager\r\n   \r\n   let me defer the final decision to hadoop folks\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T09:46:26.038+0000", "updated": "2025-07-30T09:46:26.038+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18011084", "id": "18011084", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3138597566\n\n   @K0K0V0K  Thank you for your contribution, LGTM +1. We will wait for 1-2 days to see if there are any other comments. If not, we will merge this PR.\r\n   cc: @abstractdog\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T05:22:36.802+0000", "updated": "2025-07-31T05:22:36.802+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18011524", "id": "18011524", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T02:38:07.226+0000", "updated": "2025-08-02T02:38:07.226+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624415/comment/18011525", "id": "18011525", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7827:\nURL: https://github.com/apache/hadoop/pull/7827#issuecomment-3146149735\n\n   @K0K0V0K Thanks for the contribution! Merged into trunk. @abstractdog @Hean-Chhinling Thanks for the review!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T02:38:39.261+0000", "updated": "2025-08-02T02:38:39.261+0000"}], "maxResults": 41, "total": 41, "startAt": 0}, "updated": "2025-08-02T02:39:45.000+0000", "created": "2025-07-23T16:17:56.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624403", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624403", "key": "HADOOP-19638", "fields": {"summary": "[JDK17] Set Up CI Support JDK17 & JDK21", "description": "Plan to establish a new build pipeline using JDK 17 for Apache Hadoop, as part of the ongoing effort to upgrade the project\u2019s Java compatibility. This pipeline will serve as the foundation for testing and validating future JDK 17 support and ensuring smooth integration with existing CI/CD processes.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010076", "id": "18010076", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #7831:\nURL: https://github.com/apache/hadoop/pull/7831\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   JIRA: HADOOP-19638. [JDK17] Set Up CI Support JDK17.\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-26T02:10:38.048+0000", "updated": "2025-07-26T02:10:38.048+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010077", "id": "18010077", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3121008019\n\n   @GauthamBanasandra I\u2019m working on adding a new pipeline in Trunk to support JDK17. While reviewing the history, I noticed you've done in-depth work on this area, particularly around the upgrade to `jenkins.sh`\r\n   \r\n   As part of this change, I reviewed the implementation in HADOOP-16888(#2012) to better understand how JDK11 support was introduced. From what I can tell, it seems that enabling JDK17 unit test support only requires configuring the appropriate JDK17-related variables in `jenkins.sh`, similar to how JDK11 was handled. Could you please confirm if that's sufficient? Let me know if there are any additional compatibility steps or considerations I should be aware of.\r\n   \r\n   Thank you very much!\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-26T02:20:13.780+0000", "updated": "2025-07-26T02:20:13.780+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010078", "id": "18010078", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3121011939\n\n   @ayushtkn @aajisaka Could you kindly provide some help and guidance? I would really appreciate it.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-26T02:22:11.995+0000", "updated": "2025-07-26T02:22:11.995+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010083", "id": "18010083", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3121183709\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  0s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 46s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  30m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  30m 37s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 29s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  30m 30s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 33s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 105m 45s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7831 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux b2225bbcc657 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 0024f51e6ba35cbe31db45afab54cb9a1521708d |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/1/testReport/ |\r\n   | Max. process+thread count | 548 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-26T03:57:51.871+0000", "updated": "2025-07-26T03:57:51.871+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010161", "id": "18010161", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3122378936\n\n   @slfan1989 yes, what you've done in this PR should be sufficient to get the multi-JDK tests running. The multi-JDK unit tests are only run as part of the nightly CI and not for PRs. Could you please trigger on nightly CI run on ci-hadoop.apache.org?\r\n   \r\n   Let me know if you need me to do this.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-26T18:48:46.606+0000", "updated": "2025-07-26T18:48:46.606+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010168", "id": "18010168", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3123880810\n\n   > @slfan1989 yes, what you've done in this PR should be sufficient to get the multi-JDK tests running. The multi-JDK unit tests are only run as part of the nightly CI and not for PRs. Could you please trigger on nightly CI run on ci-hadoop.apache.org?\r\n   > \r\n   > Let me know if you need me to do this.\r\n   \r\n   \r\n   \r\n   > @slfan1989 yes, what you've done in this PR should be sufficient to get the multi-JDK tests running. The multi-JDK unit tests are only run as part of the nightly CI and not for PRs. Could you please trigger on nightly CI run on ci-hadoop.apache.org?\r\n   > \r\n   > Let me know if you need me to do this.\r\n   \r\n   Thank you very much for your reply! I'm not very familiar with how to trigger a JDK17 build. If you happen to know how, would you mind helping trigger a JDK17 build for this PR? Also, if we want the PR builds to run under the JDK17 environment as well, do you know how we can configure that?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-27T04:25:19.923+0000", "updated": "2025-07-27T04:25:19.923+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010169", "id": "18010169", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3123896957\n\n   @steveloughran @ayushtkn @Hexiaoqiao Is it possible to remove JDK 8 compilation support from the trunk? We\u2019d appreciate your input.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-27T04:35:36.862+0000", "updated": "2025-07-27T04:35:36.862+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010439", "id": "18010439", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3127566790\n\n   @slfan1989 I just checked the nightly pipeline for Linux and it looks like it's isn't using `jenkins.sh` anymore. The `jenkins.sh` is currently used by the nightly pipeline for Windows and the pre-commit pipeline for Linux.\r\n   \r\n   Anyway, I just created a new pipeline that runs on JDK 17 - https://ci-hadoop.apache.org/view/Hadoop/job/hadoop-qbt-trunk-java17-linux-x86_64/.\r\n   \r\n   You should be having the permission to trigger the builds. I've currently configured it to checkout your repo (I've mentioned the same in the pipeline's description page). I'll reconfigure it to github.com/apache/hadoop once you're done with the testing.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T14:43:44.604+0000", "updated": "2025-07-28T14:43:44.604+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010445", "id": "18010445", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3127664208\n\n   I've started a run with JDK 17 on that pipeline - https://ci-hadoop.apache.org/view/Hadoop/job/hadoop-qbt-trunk-java17-linux-x86_64/1/console.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T15:05:34.721+0000", "updated": "2025-07-28T15:05:34.721+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010537", "id": "18010537", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3130322461\n\n   @GauthamBanasandra Thank you very much for your kind help in configuring this pipeline!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T02:07:13.039+0000", "updated": "2025-07-29T02:07:13.039+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010631", "id": "18010631", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3131923151\n\n   Looks like the Jenkins CI had some trouble with the docker container when it was running the unit tests -\r\n   ```\r\n   cd /home/jenkins/jenkins-home/workspace/hadoop-qbt-trunk-java17-linux-x86_64/sourcedir/hadoop-common-project/hadoop-auth\r\n   /usr/bin/mvn --batch-mode -Dmaven.repo.local=/home/jenkins/jenkins-home/workspace/hadoop-qbt-trunk-java17-linux-x86_64/yetus-m2/hadoop-HADOOP-19638-full-2 -DskipTests test-compile spotbugs:spotbugs -DskipTests=true > /home/jenkins/jenkins-home/workspace/hadoop-qbt-trunk-java17-linux-x86_64/out/branch-spotbugs-hadoop-common-project_hadoop-auth.txt 2>&1\r\n   \r\n   \r\n   Cleaning up docker image used for testing.\r\n   Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\r\n   \r\n   \r\n   ============================================================================\r\n   ============================================================================\r\n                                 Finished build.\r\n   ============================================================================\r\n   ============================================================================\r\n   ```\r\n   \r\n   I've started another run - https://ci-hadoop.apache.org/view/Hadoop/job/hadoop-qbt-trunk-java17-linux-x86_64/2/console\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T10:59:28.458+0000", "updated": "2025-07-29T10:59:28.458+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010726", "id": "18010726", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3133728324\n\n   > @steveloughran @ayushtkn @Hexiaoqiao @GauthamBanasandra Is it possible to remove JDK 8 compilation support from the trunk? We\u2019d appreciate your input.\r\n   \r\n   @slfan1989 I don't think we should remove JDK 8 support yet.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T19:13:09.848+0000", "updated": "2025-07-29T19:13:09.848+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010884", "id": "18010884", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ayushtkn commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3135759641\n\n   I don't think we can maintain so many JDK versions. There would be some thirdparty dependencies which we might upgrade to & they would be compiled on higher JDK versions. So, the moment that happens, JDK-8 compilation will break. & Not upgrading to those dependencies or not using higher JDK features doesn't make sense. \r\n   \r\n   Hadoop in branch-3 dropped JDK-7 support as well, branch-2 only has JDK-7 IIRC. We haven't marked the lower branches which are JDK-8 compliant as EOL, so, it isn't a deal breaker for someone who wants to stick to JDK-8, Moreover we can't run tests & all on all JDK versions, We need to pick one only.\r\n   \r\n   I think most of the projects are dropping the JDK-8 support and chasing for higher versions. I know in Hive it is like 4.0 line -JDK-8, 4.1.0 line - JDK-17 & now master branch min JDK-21 compile time, same with Tez the master is on JDK-21 compile time support.\r\n   \r\n   I don't think sticking to any legacy stuff is worth it if it adds any technical debt for us, Should chase for a higher version. Just my opinion, other might feel differently \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T10:41:37.713+0000", "updated": "2025-07-30T10:41:37.713+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010993", "id": "18010993", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3137400811\n\n   @GauthamBanasandra 3.5 is java17+ only. \r\n   \r\n   there are things we depend on which are java11; there are places where we can't make use of the JDK features, let alone language changes.\r\n   \r\n   we have stayed on java8 for longer than we've ever been on any older java version. Time to move on.\r\n   \r\n   If you want to keep java8 support alive, then backport new features to branch-3.4. Me? I'm looking at bug fixes only there. \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T18:24:14.531+0000", "updated": "2025-07-30T18:24:14.531+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18010995", "id": "18010995", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3137407351\n\n   ...assuming we switch now to java17 on trunk, all backports to branch-3.4 must be retested on that branch in case something in the JDK itself changed. With the JUnit move that's needed anyway, IMO\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T18:26:29.242+0000", "updated": "2025-07-30T18:26:29.242+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18011080", "id": "18011080", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3138524338\n\n   @GauthamBanasandra @ayushtkn @steveloughran Thank you all for the feedback! From my perspective, it makes sense to drop support for JDK 8, and I also agree with using JDK 17 for the trunk branch. However, there are still some issues with the JDK 17 pipeline compilation, and I will work on fixing the related unit tests.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T04:28:44.124+0000", "updated": "2025-07-31T04:28:44.124+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18011526", "id": "18011526", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3146156723\n\n   I have adjusted the trunk branch's build to default to JDK 17 support. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T02:51:17.464+0000", "updated": "2025-08-02T02:51:17.464+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18011533", "id": "18011533", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3146204334\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 53s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  11m 29s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  29m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  30m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 27s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  30m 14s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 34s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 105m 11s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7831 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux 459b670a40fa 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 577479ba84422a763054b1f4684b0a8fa23b3362 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/2/testReport/ |\r\n   | Max. process+thread count | 547 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T04:29:33.423+0000", "updated": "2025-08-02T04:29:33.423+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18014192", "id": "18014192", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "GauthamBanasandra commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3192520796\n\n   @slfan1989 could you please let us know at what point does the compilation with JDK 8 breaks?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-15T19:28:36.371+0000", "updated": "2025-08-15T19:28:36.371+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18016988", "id": "18016988", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3236498588\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 44s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   7m 58s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  29m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  29m 41s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 28s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  29m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 122m 28s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7831 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux 97acd1950f16 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f8e749693777c3816e6262928a717ccbf70921c4 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/3/testReport/ |\r\n   | Max. process+thread count | 611 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-29T10:10:25.350+0000", "updated": "2025-08-29T10:10:25.350+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18017504", "id": "18017504", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#discussion_r2314272985\n\n\n##########\ndev-support/jenkins.sh:\n##########\n@@ -124,9 +124,8 @@ function run_ci() {\n     YETUS_ARGS+=(\"--mvn-custom-repos\")\n     YETUS_ARGS+=(\"--dockermemlimit=22g\")\n \n-    # test with Java 8 and 11\n-    YETUS_ARGS+=(\"--java-home=/usr/lib/jvm/java-8-openjdk-amd64\")\n-    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-11-openjdk-amd64\")\n+    # test with Java 17\n+    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-17-openjdk-amd64\")\n\nReview Comment:\n   now, all platforms on the trunk branch have `java-17-openjdk-amd64` installed in the docker image, it's time to move forward\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-01T15:53:31.259+0000", "updated": "2025-09-01T15:53:31.259+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18023248", "id": "18023248", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3340964462\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 59s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 51s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  35m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  30m 33s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  30m  5s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 34s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 109m 37s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7831 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux 8e7dd49e956b 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / db6a4cb61b785de00ed82cd3e9957acab0746cc4 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/5/testReport/ |\r\n   | Max. process+thread count | 546 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/5/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-27T01:26:52.273+0000", "updated": "2025-09-27T01:26:52.273+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029164", "id": "18029164", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3393051785\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 59s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 20s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  35m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  29m 56s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 29s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  29m 35s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 129m 16s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7831 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux aefc94cb1d97 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3b2a01d785cffcf73c9ecca6a48caa45f9a101ae |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/6/testReport/ |\r\n   | Max. process+thread count | 585 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7831/6/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-11T08:11:58.594+0000", "updated": "2025-10-11T08:11:58.594+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029267", "id": "18029267", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-12T00:55:03.019+0000", "updated": "2025-10-12T00:55:03.019+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029268", "id": "18029268", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7831:\nURL: https://github.com/apache/hadoop/pull/7831#issuecomment-3393790285\n\n   @ayushtkn @steveloughran @GauthamBanasandra @cnauroth @pan3793 Merge this PR into the trunk branch to support pipeline compilation with JDK 17. \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-12T00:58:42.839+0000", "updated": "2025-10-12T00:58:42.839+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029376", "id": "18029376", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #8030:\nURL: https://github.com/apache/hadoop/pull/8030\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   JIRA: HADOOP-19638. [Addendum] [JDK17] Set Up CI Support JDK17.\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T01:56:45.031+0000", "updated": "2025-10-13T01:56:45.031+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029389", "id": "18029389", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#issuecomment-3395710867\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   9m 10s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 52s |  |  Maven dependency ordering for branch  |\r\n   | -1 :x: |  mvninstall  |  15m 51s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/2/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 23s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 19s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 34s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  62m 58s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8030 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux 8828e8951baa 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ac73fe197ca9f8418c9af6397d08903a130f4465 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/2/testReport/ |\r\n   | Max. process+thread count | 573 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T03:06:11.094+0000", "updated": "2025-10-13T03:06:11.094+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029392", "id": "18029392", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#issuecomment-3395798651\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m  5s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 52s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  37m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 23s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  32m 35s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 136m 57s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8030 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux d7c4c36f06f4 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ac73fe197ca9f8418c9af6397d08903a130f4465 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/1/testReport/ |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T04:15:02.274+0000", "updated": "2025-10-13T04:15:02.274+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029395", "id": "18029395", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#issuecomment-3395810701\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 38s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  15m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 38s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 19s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 20s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 21s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  54m 52s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8030 |\r\n   | Optional Tests | dupname asflicense mvnsite unit codespell detsecrets shellcheck shelldocs |\r\n   | uname | Linux 0bd5ffd3e04f 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2c677aca06d2cab666b3cdc4fc5031e5c794f12c |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/3/testReport/ |\r\n   | Max. process+thread count | 729 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8030/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T04:23:13.889+0000", "updated": "2025-10-13T04:23:13.889+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029533", "id": "18029533", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#issuecomment-3397990368\n\n   @cnauroth @szetszwo Could you please help review this PR? Thank you very much! We have confirmed that the current Hadoop version can be successfully compiled with both JDK 17 and JDK 21. I plan to add support for these two JDK versions.  \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-13T15:27:41.697+0000", "updated": "2025-10-13T15:27:41.697+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18029747", "id": "18029747", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#issuecomment-3401292933\n\n   @steveloughran Could you please review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-14T11:14:22.562+0000", "updated": "2025-10-14T11:14:22.562+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18030023", "id": "18030023", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#issuecomment-3405488556\n\n   @Hexiaoqiao Could you please review this PR? Thank you very much!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T09:36:30.655+0000", "updated": "2025-10-15T09:36:30.655+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18030120", "id": "18030120", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on code in PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#discussion_r2433036912\n\n\n##########\ndev-support/jenkins.sh:\n##########\n@@ -124,8 +124,9 @@ function run_ci() {\n     YETUS_ARGS+=(\"--mvn-custom-repos\")\n     YETUS_ARGS+=(\"--dockermemlimit=22g\")\n \n-    # test with Java 17\n-    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-17-openjdk-amd64\")\n+    # test with Java 17 & Java 21\n+    YETUS_ARGS+=(\"--java-home=/usr/lib/jvm/java-17-openjdk-amd64\")\n+    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-21-openjdk-amd64\")\n\nReview Comment:\n   Do we need two jdk dirs?\n   ```\n   --multijdkdirs=/usr/lib/jvm/java-21-openjdk-amd64,/usr/lib/jvm/java-17-openjdk-amd64\n   ```\n   https://yetus.apache.org/documentation/0.15.1/precommit/usage-intro/#multijdk\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T15:31:39.561+0000", "updated": "2025-10-15T15:31:39.561+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18030122", "id": "18030122", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#discussion_r2433097240\n\n\n##########\ndev-support/jenkins.sh:\n##########\n@@ -124,8 +124,9 @@ function run_ci() {\n     YETUS_ARGS+=(\"--mvn-custom-repos\")\n     YETUS_ARGS+=(\"--dockermemlimit=22g\")\n \n-    # test with Java 17\n-    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-17-openjdk-amd64\")\n+    # test with Java 17 & Java 21\n+    YETUS_ARGS+=(\"--java-home=/usr/lib/jvm/java-17-openjdk-amd64\")\n+    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-21-openjdk-amd64\")\n\nReview Comment:\n   Thank you very much for helping with the review! Since I\u2019m not yet very familiar with Yetus, the current configuration was created by referring to and simulating the original JDK 8 and JDK 11 configurations.  \r\n   \r\n   ```\r\n   # test with Java 8 and 11\r\n   YETUS_ARGS+=(\"--java-home=/usr/lib/jvm/java-8-openjdk-amd64\")\r\n   YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-11-openjdk-amd64\")\r\n   YETUS_ARGS+=(\"--multijdktests=compile\")\r\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T15:46:13.633+0000", "updated": "2025-10-15T15:46:13.633+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18030128", "id": "18030128", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "szetszwo commented on code in PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#discussion_r2433168273\n\n\n##########\ndev-support/jenkins.sh:\n##########\n@@ -124,8 +124,9 @@ function run_ci() {\n     YETUS_ARGS+=(\"--mvn-custom-repos\")\n     YETUS_ARGS+=(\"--dockermemlimit=22g\")\n \n-    # test with Java 17\n-    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-17-openjdk-amd64\")\n+    # test with Java 17 & Java 21\n+    YETUS_ARGS+=(\"--java-home=/usr/lib/jvm/java-17-openjdk-amd64\")\n+    YETUS_ARGS+=(\"--multijdkdirs=/usr/lib/jvm/java-21-openjdk-amd64\")\n\nReview Comment:\n   I see. Let's keep using it then.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-15T16:03:23.975+0000", "updated": "2025-10-15T16:03:23.975+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18030379", "id": "18030379", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T14:09:04.163+0000", "updated": "2025-10-16T14:09:04.163+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624403/comment/18030380", "id": "18030380", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #8030:\nURL: https://github.com/apache/hadoop/pull/8030#issuecomment-3411088399\n\n   @szetszwo @Hexiaoqiao @zhtttylz Thank you very much for reviewing the code!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-16T14:09:24.496+0000", "updated": "2025-10-16T14:09:24.496+0000"}], "maxResults": 37, "total": 37, "startAt": 0}, "updated": "2025-10-23T00:11:53.000+0000", "created": "2025-07-23T13:49:51.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624401", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624401", "key": "HADOOP-19637", "fields": {"summary": "[JDK17] Attempted to build on CentOS Stream 9.", "description": "We aim to successfully compile Apache Hadoop on CentOS Stream 9 to verify the feasibility of using this platform in future development and deployment environments.\r\n\r\nThis task may involve addressing potential compatibility issues related to GCC and libc versions. Initial attempts will focus on resolving compilation challenges and ensuring the platform meets the necessary requirements for Hadoop builds.", "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-07-23T13:38:21.000+0000", "created": "2025-07-23T13:37:59.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624396", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624396", "key": "HADOOP-19636", "fields": {"summary": "[JDK17] Remove CentOS 7 Support and Clean Up Dockerfile. ", "description": "Removed build support for the following EOL (End-of-Life) operating system versions (e.g., CentOS 7, Debian 9, etc.).\r\n\r\nCleaned up redundant code and dependency configurations in the Dockerfile related to these operating systems.\r\n\r\nOptimized the build logic to ensure that currently supported OS versions build successfully.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009275", "id": "18009275", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 opened a new pull request, #7822:\nURL: https://github.com/apache/hadoop/pull/7822\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   JIRA: HADOOP-19636. [JDK17] Remove EOL OS Support and Clean Up Dockerfile.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   test.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-23T14:05:29.744+0000", "updated": "2025-07-23T14:05:29.744+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009276", "id": "18009276", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3108826927\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/1/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-23T14:08:44.923+0000", "updated": "2025-07-23T14:08:44.923+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009308", "id": "18009308", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3109175364\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   2m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  1s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 42s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 51s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  hadolint  |   0m  2s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  95m 21s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint |\r\n   | uname | Linux 6fb52aab7b2a 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / d4650c0d79570cf96fd5c62db6e8a00157b647d5 |\r\n   | Max. process+thread count | 564 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-23T15:42:02.175+0000", "updated": "2025-07-23T15:42:02.175+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009412", "id": "18009412", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3111531611\n\n   @ayushtkn @GauthamBanasandra Could you please help review this PR? Thank you very much!\r\n   \r\n   cc: @pan3793 \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T00:09:23.533+0000", "updated": "2025-07-24T00:09:23.533+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009430", "id": "18009430", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2227179274\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   I don't think we should remove centos8, instead, we should migrate it Rocky Linux 8 (or other RHEL-like OS) in place, then 9 or 10\n\n\n\n##########\ndev-support/Jenkinsfile:\n##########\n@@ -113,144 +113,6 @@ pipeline {\n             }\n         }\n \n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 7.\n-        stage ('precommit-run Centos 7') {\n\nReview Comment:\n   there's leftover ceontos 7 stuff at line 86\n\n\n\n##########\ndev-support/docker/Dockerfile_debian_10:\n##########\n@@ -1,102 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM debian:10\n\nReview Comment:\n   same here, we should upgrade it to debian 12 or 13 in place\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T02:35:03.581+0000", "updated": "2025-07-24T02:35:03.581+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009431", "id": "18009431", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2227178384\n\n\n##########\ndev-support/Jenkinsfile:\n##########\n@@ -113,144 +113,6 @@ pipeline {\n             }\n         }\n \n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 7.\n-        stage ('precommit-run Centos 7') {\n\nReview Comment:\n   there's leftover centos 7 stuff at line 86\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T02:35:24.168+0000", "updated": "2025-07-24T02:35:24.168+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009450", "id": "18009450", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2227281222\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   From a personal perspective, I don't agree with your suggestion. I believe we should completely remove operating systems that have reached their End of Life (EOL). If we need to support CentOS 9 or Debian 12 in the future, it should be done by submitting a new PR for a thorough evaluation. Rather than maintaining multiple Dockerfiles, I prefer a more lightweight approach, such as providing support through documentation. As the number of supported operating systems increases, if we have to maintain Dockerfiles for each one, we could end up managing dozens, which is neither cost-effective nor sustainable.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T04:07:35.159+0000", "updated": "2025-07-24T04:07:35.159+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009455", "id": "18009455", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2227342002\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   > I believe we should completely remove operating systems that have reached their End of Life (EOL). If we need to support CentOS 9 or Debian 12 in the future, it should be done by submitting a new PR for a thorough evaluation.\r\n   \r\n   I don't see much benefit in your proposal, I suppose upgrading in place is straightforward, and can leave clear diff in the commit history to guide users to understand what they should change for planning Hadoop cluster OS upgrading.\r\n   \r\n   > Rather than maintaining multiple Dockerfiles, I prefer a more lightweight approach, such as providing support through documentation.\r\n   \r\n   The documentation can easily become outdated (you can try `Building on macOS (without Docker)` in `BUILDING.txt`). As I replied here, I think the `Dockerfile` itself is the best documentation for setup the building env.\r\n   \r\n   https://lists.apache.org/thread/2ypqcrnsth3jk21rpjvjv53tntz21ht8\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T04:58:22.377+0000", "updated": "2025-07-24T04:58:22.377+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009461", "id": "18009461", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2227448044\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   The choice of operating system should be made by the user, and therefore, the resolution of compilation issues should also be handled by the user.\r\n   \r\n   Take CentOS 7 as an example, which has multiple versions (such as 7.2, 7.3, 7.9, etc.). Different versions may have configuration or dependency differences (e.g., glibc, gcc versions), which can lead to compilation issues, such as with protobuf or native package compilation. For these issues, we should not add extra workarounds, as that would make the project redundant. \r\n   \r\n   If we were to upgrade to `CentOS 9`, we would change the Dockerfile name from `Dockerfile_centos_8` to `Dockerfile_centos_9`. Users comparing the diff would see that `Dockerfile_centos_8` has been deleted and replaced with `Dockerfile_centos_9`, which contains entirely new content.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T05:54:37.444+0000", "updated": "2025-07-24T05:54:37.444+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009482", "id": "18009482", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2227687926\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   I understand that we can not enumerate all Linux distributions and versions. I believe most enterprises use Debian/RHEL family of Linux distributions to run Hadoop. Given the limitation of developer resources in the Hadoop community, how about keeping only 2 OS Dockerfiles and CI pipelines - the latest(or sub-latest) version of Ubuntu(the default env for building, testing, releasing) and Rocky Linux(only verify the compilation)? They will serve as reference for users who want to set up a building environment based on their preferred Linux distribution.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T07:37:29.032+0000", "updated": "2025-07-24T07:37:29.032+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18009884", "id": "18009884", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Hexiaoqiao commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2230528916\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   My point is that we should remove some dependencies which are EOL, just like some other module. Back to here , CentOS 8 has reached its EOL and the packages re no longer available on mirror.centos.org site.(https://www.centos.org/centos-linux-eol/), So +1 to Shilun's comments from my side. cc @pan3793 What do you think about. Thanks.\n\n\n\n##########\ndev-support/Jenkinsfile:\n##########\n@@ -113,144 +113,6 @@ pipeline {\n             }\n         }\n \n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 7.\n-        stage ('precommit-run Centos 7') {\n\nReview Comment:\n   +1\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-25T08:43:26.194+0000", "updated": "2025-07-25T08:43:26.194+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18010080", "id": "18010080", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2232440829\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   @Hexiaoqiao If you agree to retain at least one RHEL-family OS Dockerfile for Hadoop building, I suggest keeping CentOS 8, because CentOS 8 works well(the `mirror.centos.org` site was replaced by `vault.centos.org`, see `dev-support/docker/pkg-resolver/set-vault-as-baseurl-centos.sh`) for the Hadoop project build as of today, I plan to migrate it to Rocky Linux 8 soon.\r\n   https://endoflife.date/rocky-linux\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-26T03:23:15.157+0000", "updated": "2025-07-26T03:23:15.157+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18010268", "id": "18010268", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2234892718\n\n\n##########\ndev-support/Jenkinsfile:\n##########\n@@ -113,144 +113,6 @@ pipeline {\n             }\n         }\n \n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 7.\n-        stage ('precommit-run Centos 7') {\n-            environment {\n-                SOURCEDIR = \"${WORKSPACE}/centos-7/src\"\n-                PATCHDIR = \"${WORKSPACE}/centos-7/out\"\n-                DOCKERFILE = \"${SOURCEDIR}/dev-support/docker/Dockerfile_centos_7\"\n-                IS_OPTIONAL = 1\n-            }\n-\n-            steps {\n-                withCredentials(getGithubCreds()) {\n-                    sh '''#!/usr/bin/env bash\n-\n-                    chmod u+x \"${SOURCEDIR}/dev-support/jenkins.sh\"\n-                    \"${SOURCEDIR}/dev-support/jenkins.sh\" run_ci\n-                    '''\n-                }\n-            }\n-\n-            post {\n-                // Since this is an optional platform, we want to copy the artifacts\n-                // and archive it only if the build fails, to help with debugging.\n-                failure {\n-                    sh '''#!/usr/bin/env bash\n-\n-                    cp -Rp \"${WORKSPACE}/centos-7/out\" \"${WORKSPACE}\"\n-                    '''\n-                    archiveArtifacts \"out/**\"\n-                }\n-\n-                cleanup() {\n-                    script {\n-                        sh '''#!/usr/bin/env bash\n-\n-                        chmod u+x \"${SOURCEDIR}/dev-support/jenkins.sh\"\n-                        \"${SOURCEDIR}/dev-support/jenkins.sh\" cleanup_ci_proc\n-                        '''\n-                    }\n-                }\n-            }\n-        }\n-\n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 8.\n-        stage ('precommit-run Centos 8') {\n\nReview Comment:\n   Instead of removing CentOS 8, I would suggest replacing it with another supported RHEL8 clone, like Rocky Linux.\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T06:42:16.907+0000", "updated": "2025-07-28T06:42:16.907+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18010271", "id": "18010271", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3125789130\n\n   > I think we should replace CentOs 8 instead of dropping it outright.\r\n   \r\n   Thank you for your feedback. Feel free to continue sharing your thoughts in this email thread. So far, I\u2019ve received comments from @ayushtkn , @Hexiaoqiao , @cnauroth, @pan3793. We are still in the discussion phase, and a final decision will be made based on the collective input.\r\n   \r\n   https://lists.apache.org/thread/2ypqcrnsth3jk21rpjvjv53tntz21ht8\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T06:53:21.858+0000", "updated": "2025-07-28T06:53:21.858+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18010274", "id": "18010274", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3125804239\n\n   @GauthamBanasandra Thank you, and I look forward to hearing your thoughts on this issue.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T06:57:06.042+0000", "updated": "2025-07-28T06:57:06.042+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18010276", "id": "18010276", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3125812503\n\n   Can you please forward the last email to stoty@apache.org @slfan1989 so that I can reply?\r\n   I am not subscribed to commons-dev yet.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T07:00:01.040+0000", "updated": "2025-07-28T07:00:01.040+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18010280", "id": "18010280", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3125839533\n\n   > Can you please forward the last email to [stoty@apache.org](mailto:stoty@apache.org) @slfan1989 so that I can reply?\r\n   > I am not subscribed to commons-dev yet.\r\n   \r\n   I\u2019ve cc\u2019d you on the email\u2014please have a look when it\u2019s convenient for you.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T07:08:09.213+0000", "updated": "2025-07-28T07:08:09.213+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18010483", "id": "18010483", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2237553419\n\n\n##########\ndev-support/docker/Dockerfile_centos_8:\n##########\n@@ -1,118 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# Dockerfile for installing the necessary dependencies for building Hadoop.\n-# See BUILDING.txt.\n-\n-FROM centos:8\n\nReview Comment:\n   I'm supportive of a RHEL variant. There's also the option of an amazon linux container image, which uses yum.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T18:45:33.943+0000", "updated": "2025-07-28T18:45:33.943+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011541", "id": "18011541", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146234748\n\n   @Hexiaoqiao @steveloughran @stoty @pan3793 Thank you all for your participation and valuable feedback! After careful consideration, I have decided to adopt your suggestions in the upcoming JDK 17 upgrade. Regarding the removal of support for EOL operating systems, I plan to discontinue the Docker and Jenkins build commands on CentOS 7, while continuing to support image builds on CentOS 8 and Debian 10. Moving forward, we will also focus on upgrading to CentOS 9 and higher versions of Debian.\r\n   \r\n   cc: @GauthamBanasandra @ayushtkn @cnauroth \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T05:19:41.458+0000", "updated": "2025-08-02T05:19:41.458+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011543", "id": "18011543", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146238349\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/2/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T05:28:29.208+0000", "updated": "2025-08-02T05:28:29.208+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011544", "id": "18011544", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146239802\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   3m 15s |  |  Docker failed to build run-specific yetus/hadoop:tp-32546}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T05:31:45.951+0000", "updated": "2025-08-02T05:31:45.951+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011549", "id": "18011549", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146256846\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/3/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T06:09:54.987+0000", "updated": "2025-08-02T06:09:54.987+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011550", "id": "18011550", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146256976\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   0m 17s |  |  Docker failed to build run-specific yetus/hadoop:tp-288}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/3/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T06:10:13.513+0000", "updated": "2025-08-02T06:10:13.513+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011647", "id": "18011647", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146852693\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/4/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T23:32:38.388+0000", "updated": "2025-08-02T23:32:38.388+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011648", "id": "18011648", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146853778\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   3m 16s |  |  Docker failed to build run-specific yetus/hadoop:tp-11920}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/4/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-02T23:35:54.509+0000", "updated": "2025-08-02T23:35:54.509+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011653", "id": "18011653", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146940448\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  28m 19s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  6s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  49m 10s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 45s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 53s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 121m  4s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux 6d7f8de11c86 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4d2cd528c8c45ef0ad654fbf841e3d21d49519e9 |\r\n   | Max. process+thread count | 604 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/5/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-03T03:09:50.715+0000", "updated": "2025-08-03T03:09:50.715+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011659", "id": "18011659", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146975557\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m 10s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 44s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 48s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 44s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 16s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 51s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  85m 41s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux 3163bdea0f05 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4d2cd528c8c45ef0ad654fbf841e3d21d49519e9 |\r\n   | Max. process+thread count | 590 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/5/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-03T04:35:43.173+0000", "updated": "2025-08-03T04:35:43.173+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011660", "id": "18011660", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146976128\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/5/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-03T04:37:18.880+0000", "updated": "2025-08-03T04:37:18.880+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011661", "id": "18011661", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3146976620\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   1m 18s |  |  Docker failed to build run-specific yetus/hadoop:tp-25352}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/5/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-03T04:38:38.350+0000", "updated": "2025-08-03T04:38:38.350+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18011774", "id": "18011774", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3149167804\n\n   This looks good to me, but this no longer matches the JIRA/commit description, as only Centos7 is removed now, but ubuntu 10 and Centos 8 is kept.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T05:25:38.856+0000", "updated": "2025-08-04T05:25:38.856+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18014371", "id": "18014371", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3194118724\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  29m  3s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  3s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  49m 37s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 56s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 121m 50s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux 59705cfced91 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / a789f690dfe0df422d093f743e65fe648ad8d048 |\r\n   | Max. process+thread count | 533 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/6/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-17T04:25:45.993+0000", "updated": "2025-08-17T04:25:45.993+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18014375", "id": "18014375", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3194151066\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m 12s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 45s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 19s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 47s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 23s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 56s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  84m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux b38d1747439b 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / a789f690dfe0df422d093f743e65fe648ad8d048 |\r\n   | Max. process+thread count | 583 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/6/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-17T05:50:29.117+0000", "updated": "2025-08-17T05:50:29.117+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18014378", "id": "18014378", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3194151639\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/6/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-17T05:52:06.741+0000", "updated": "2025-08-17T05:52:06.741+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18014379", "id": "18014379", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3194152152\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   1m 21s |  |  Docker failed to build run-specific yetus/hadoop:tp-21562}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/6/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-17T05:53:29.156+0000", "updated": "2025-08-17T05:53:29.156+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015783", "id": "18015783", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3217036390\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  28m 59s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 50s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  50m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 24s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 57s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 122m 26s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux 1f22f16ee8ab 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 8925c4af7dc0ad369ecf37361333c5f2375fe54a |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/7/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-23T14:14:07.958+0000", "updated": "2025-08-23T14:14:07.958+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015784", "id": "18015784", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3217123391\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m 15s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 29s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 44s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 37s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 55s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  85m 52s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux ea126888a24e 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 8925c4af7dc0ad369ecf37361333c5f2375fe54a |\r\n   | Max. process+thread count | 534 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/7/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-23T15:40:11.646+0000", "updated": "2025-08-23T15:40:11.646+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015785", "id": "18015785", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3217125222\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/7/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-23T15:41:57.488+0000", "updated": "2025-08-23T15:41:57.488+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015786", "id": "18015786", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3217126419\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  docker  |   1m  6s |  |  Docker failed to build run-specific yetus/hadoop:tp-13190}.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/7/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-23T15:43:04.971+0000", "updated": "2025-08-23T15:43:04.971+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015802", "id": "18015802", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2296430883\n\n\n##########\ndev-support/docker/pkg-resolver/packages.json:\n##########\n@@ -35,7 +30,6 @@\n     \"ubuntu:focal\": \"build-essential\",\n     \"ubuntu:noble\": \"build-essential\",\n     \"ubuntu:focal::arch64\": \"build-essential\",\n\nReview Comment:\n   \r\n   ```suggestion\r\n       \"ubuntu:focal::arch64\": \"build-essential\"\r\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-24T01:47:09.321+0000", "updated": "2025-08-24T01:47:09.321+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015817", "id": "18015817", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3217977054\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 53s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 30s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  48m 35s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 44s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 30s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 58s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  94m 37s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux 08cb2ba2ac54 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 793b2b17e1235a80af4553c8d5a804dcc5bc63d0 |\r\n   | Max. process+thread count | 524 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/8/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-24T09:42:00.358+0000", "updated": "2025-08-24T09:42:00.358+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015823", "id": "18015823", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3218022287\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m 11s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shellcheck  |   0m  0s |  |  Shellcheck was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  hadolint  |   0m  0s |  |  hadolint was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  0s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 46s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  40m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 45s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 39s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 55s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  83m 36s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs hadolint jsonlint |\r\n   | uname | Linux 6b761ad73cbb 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 793b2b17e1235a80af4553c8d5a804dcc5bc63d0 |\r\n   | Max. process+thread count | 580 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/8/console |\r\n   | versions | git=2.27.0 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-24T11:05:50.440+0000", "updated": "2025-08-24T11:05:50.440+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015824", "id": "18015824", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3218023225\n\n   (!) A patch to the testing environment has been detected. \r\n   Re-executing against the patched versions to perform further tests. \r\n   The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/8/console in case of problems.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-24T11:07:22.471+0000", "updated": "2025-08-24T11:07:22.471+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015831", "id": "18015831", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3218085442\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  21m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +0 :ok: |  jsonlint  |   0m  1s |  |  jsonlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 32s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 53s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  hadolint  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  40m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 105m 34s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7822 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint |\r\n   | uname | Linux fa4a74a316d6 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 793b2b17e1235a80af4553c8d5a804dcc5bc63d0 |\r\n   | Max. process+thread count | 568 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7822/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-24T12:51:30.922+0000", "updated": "2025-08-24T12:51:30.922+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015889", "id": "18015889", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3218962358\n\n   @steveloughran @Hexiaoqiao Could you please take another look at this PR? I've updated the description. If everything looks good, I\u2019ll go ahead and merge it. The co-authors are Stoty and Pan.\r\n   \r\n   cc: @stoty @pan3793\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T06:12:35.053+0000", "updated": "2025-08-25T06:12:35.053+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015890", "id": "18015890", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pan3793 commented on PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#issuecomment-3218968914\n\n   LGTM. I can submit PRs to 1) upgrade Debian from 10 to 11, and 2) migrate CentOS 8 to Rocky Linux 8 after this gets in.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T06:15:43.166+0000", "updated": "2025-08-25T06:15:43.166+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015894", "id": "18015894", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "stoty commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2297232121\n\n\n##########\ndev-support/Jenkinsfile:\n##########\n@@ -113,144 +113,6 @@ pipeline {\n             }\n         }\n \n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 7.\n-        stage ('precommit-run Centos 7') {\n-            environment {\n-                SOURCEDIR = \"${WORKSPACE}/centos-7/src\"\n-                PATCHDIR = \"${WORKSPACE}/centos-7/out\"\n-                DOCKERFILE = \"${SOURCEDIR}/dev-support/docker/Dockerfile_centos_7\"\n-                IS_OPTIONAL = 1\n-            }\n-\n-            steps {\n-                withCredentials(getGithubCreds()) {\n-                    sh '''#!/usr/bin/env bash\n-\n-                    chmod u+x \"${SOURCEDIR}/dev-support/jenkins.sh\"\n-                    \"${SOURCEDIR}/dev-support/jenkins.sh\" run_ci\n-                    '''\n-                }\n-            }\n-\n-            post {\n-                // Since this is an optional platform, we want to copy the artifacts\n-                // and archive it only if the build fails, to help with debugging.\n-                failure {\n-                    sh '''#!/usr/bin/env bash\n-\n-                    cp -Rp \"${WORKSPACE}/centos-7/out\" \"${WORKSPACE}\"\n-                    '''\n-                    archiveArtifacts \"out/**\"\n-                }\n-\n-                cleanup() {\n-                    script {\n-                        sh '''#!/usr/bin/env bash\n-\n-                        chmod u+x \"${SOURCEDIR}/dev-support/jenkins.sh\"\n-                        \"${SOURCEDIR}/dev-support/jenkins.sh\" cleanup_ci_proc\n-                        '''\n-                    }\n-                }\n-            }\n-        }\n-\n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 8.\n-        stage ('precommit-run Centos 8') {\n\nReview Comment:\n   (This was already suggested earlier...)\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T06:30:06.803+0000", "updated": "2025-08-25T06:30:06.803+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18015895", "id": "18015895", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on code in PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822#discussion_r2297261130\n\n\n##########\ndev-support/Jenkinsfile:\n##########\n@@ -113,144 +113,6 @@ pipeline {\n             }\n         }\n \n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 7.\n-        stage ('precommit-run Centos 7') {\n-            environment {\n-                SOURCEDIR = \"${WORKSPACE}/centos-7/src\"\n-                PATCHDIR = \"${WORKSPACE}/centos-7/out\"\n-                DOCKERFILE = \"${SOURCEDIR}/dev-support/docker/Dockerfile_centos_7\"\n-                IS_OPTIONAL = 1\n-            }\n-\n-            steps {\n-                withCredentials(getGithubCreds()) {\n-                    sh '''#!/usr/bin/env bash\n-\n-                    chmod u+x \"${SOURCEDIR}/dev-support/jenkins.sh\"\n-                    \"${SOURCEDIR}/dev-support/jenkins.sh\" run_ci\n-                    '''\n-                }\n-            }\n-\n-            post {\n-                // Since this is an optional platform, we want to copy the artifacts\n-                // and archive it only if the build fails, to help with debugging.\n-                failure {\n-                    sh '''#!/usr/bin/env bash\n-\n-                    cp -Rp \"${WORKSPACE}/centos-7/out\" \"${WORKSPACE}\"\n-                    '''\n-                    archiveArtifacts \"out/**\"\n-                }\n-\n-                cleanup() {\n-                    script {\n-                        sh '''#!/usr/bin/env bash\n-\n-                        chmod u+x \"${SOURCEDIR}/dev-support/jenkins.sh\"\n-                        \"${SOURCEDIR}/dev-support/jenkins.sh\" cleanup_ci_proc\n-                        '''\n-                    }\n-                }\n-            }\n-        }\n-\n-        // This is an optional stage which runs only when there's a change in\n-        // C++/C++ build/platform.\n-        // This stage serves as a means of cross platform validation, which is\n-        // really needed to ensure that any C++ related/platform change doesn't\n-        // break the Hadoop build on Centos 8.\n-        stage ('precommit-run Centos 8') {\n\nReview Comment:\n   Thank you for your suggestion! We will continue to retain CentOS 8 and plan to upgrade to Rocky Linux 8 in the future.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T06:47:33.122+0000", "updated": "2025-08-25T06:47:33.122+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624396/comment/18016165", "id": "18016165", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7822:\nURL: https://github.com/apache/hadoop/pull/7822\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T02:28:22.241+0000", "updated": "2025-08-26T02:28:22.241+0000"}], "maxResults": 48, "total": 48, "startAt": 0}, "updated": "2025-09-18T06:26:42.000+0000", "created": "2025-07-23T13:31:22.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624383", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624383", "key": "HADOOP-19635", "fields": {"summary": "ABFS: [FNS Over Blob] Marker creation fail exception should not be propagated", "description": "Marker creation is attempted during certain operations such as {*}create{*}, {*}getPathStatus{*}, {*}setPathProperties{*}, and {*}rename{*}, in order to add a 0-byte file that signifies the existence of a folder at that path. However, if marker creation fails, the failure should not be propagated to the user.", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18009351", "id": "18009351", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 opened a new pull request, #7825:\nURL: https://github.com/apache/hadoop/pull/7825\n\n   Marker creation is a best-effort operation performed during folder-related actions such as create, getPathStatus, setPathProperties, and rename. It involves writing a 0-byte file to indicate the presence of a folder. However, marker creation is not critical to the success of the primary operation. This change ensures that failures encountered during marker creation (e.g., due to transient issues or permission errors) are not propagated back to the user, preserving expected behavior and preventing unnecessary operation failures.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-23T18:20:40.324+0000", "updated": "2025-07-23T18:20:40.324+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18009381", "id": "18009381", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3110072912\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 59s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 39s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 27s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 32s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 40s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 129m 46s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7825 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux ecc3a3683189 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e7f2bc3c1192045d0e6d24f754f7bbee8f9bea9f |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/1/testReport/ |\r\n   | Max. process+thread count | 632 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-23T20:31:41.818+0000", "updated": "2025-07-23T20:31:41.818+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18009658", "id": "18009658", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3114250873\n\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 209\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 23\r\n    \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 863, Failures: 0, Errors: 0, Skipped: 161\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 10\r\n    \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 702, Failures: 0, Errors: 0, Skipped: 242\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 11\r\n    \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 860, Failures: 0, Errors: 0, Skipped: 220\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 23\r\n    \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 12\r\n   [WARNING] Tests run: 707, Failures: 0, Errors: 0, Skipped: 159\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 8\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 11\r\n    \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 699, Failures: 0, Errors: 0, Skipped: 244\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\r\n    \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 12\r\n   [WARNING] Tests run: 704, Failures: 0, Errors: 0, Skipped: 171\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 8\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\r\n    \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 12\r\n   [WARNING] Tests run: 701, Failures: 0, Errors: 0, Skipped: 212\r\n   [WARNING] Tests run: 135, Failures: 0, Errors: 0, Skipped: 9\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\r\n    \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 734, Failures: 0, Errors: 0, Skipped: 216\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 23\r\n    \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 177, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 699, Failures: 0, Errors: 0, Skipped: 241\r\n   [WARNING] Tests run: 158, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 269, Failures: 0, Errors: 0, Skipped: 24\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-24T17:19:39.069+0000", "updated": "2025-07-24T17:19:39.069+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010282", "id": "18010282", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "Copilot commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235023374\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1160,8 +1160,12 @@ public AbfsRestOperation setPathProperties(final String path,\n       // This path could be present as an implicit directory in FNS.\n       if (op.getResult().getStatusCode() == HTTP_NOT_FOUND && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found, create a marker blob at this path and set properties.\n-        this.createPathRestOp(path, false, false, false, null,\n-            contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createPathRestOp(path, false, false, false, null,\n+              contextEncryptionAdapter, tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n+          LOG.debug(\"Marker creation failed for path {} during setPathProperties\", path);\n\nReview Comment:\n   Consider including the exception details in the debug log message to aid in troubleshooting. For example: `LOG.debug(\"Marker creation failed for path {} during setPathProperties: {}\", path, exception.getMessage());`\n   ```suggestion\n             LOG.debug(\"Marker creation failed for path {} during setPathProperties: {}\", path, exception.getMessage());\n   ```\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1242,7 +1246,12 @@ public AbfsRestOperation getPathStatus(final String path,\n           && isImplicitCheckRequired && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found.\n         // Create a marker blob at this path.\n-        this.createMarkerAtPath(path, null, contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createMarkerAtPath(path, null, contextEncryptionAdapter,\n+              tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n+          LOG.debug(\"Marker creation failed for path {} during getPathStatus \", path);\n\nReview Comment:\n   Consider including the exception details in the debug log message to aid in troubleshooting. For example: `LOG.debug(\"Marker creation failed for path {} during getPathStatus: {}\", path, exception.getMessage());`\n   ```suggestion\n             LOG.debug(\"Marker creation failed for path {} during getPathStatus: {}\", path, exception.getMessage());\n   ```\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java:\n##########\n@@ -167,6 +168,30 @@ public void testBlobDataReader() throws Exception {\n \n   }\n \n+  /*\n+   * BLOB DATA READER should have only READ access to the container and blobs in the container.\n+   * */\n+  @Test\n+  public void testGetPathStatusWithReader() throws Exception {\n+    String clientId = this.getConfiguration().get(TestConfigurationKeys.FS_AZURE_BLOB_DATA_READER_CLIENT_ID);\n+    Assume.assumeTrue(\"Reader client id not provided\", clientId != null);\n+    String secret = this.getConfiguration().get(TestConfigurationKeys.FS_AZURE_BLOB_DATA_READER_CLIENT_SECRET);\n+    Assume.assumeTrue(\"Reader client secret not provided\", secret != null);\n+\n+    Path existedFolderPath = path(EXISTED_FOLDER_PATH);\n+    createAzCopyFolder(existedFolderPath);\n+    final AzureBlobFileSystem fs = getBlobReader();\n+\n+    // Use abfsStore in this test to verify the  ERROR code in AbfsRestOperationException\n+    AzureBlobFileSystemStore abfsStore = fs.getAbfsStore();\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+\n+   // GETPATHSTATUS marker creation fail should not be propagated to the caller.\n\nReview Comment:\n   There's an extra space at the beginning of this comment line. Remove the leading space for consistent formatting.\n   ```suggestion\n       // GETPATHSTATUS marker creation fail should not be propagated to the caller.\n   ```\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T07:15:57.279+0000", "updated": "2025-07-28T07:15:57.279+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010288", "id": "18010288", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235073847\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1160,8 +1160,12 @@ public AbfsRestOperation setPathProperties(final String path,\n       // This path could be present as an implicit directory in FNS.\n       if (op.getResult().getStatusCode() == HTTP_NOT_FOUND && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found, create a marker blob at this path and set properties.\n-        this.createPathRestOp(path, false, false, false, null,\n-            contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createPathRestOp(path, false, false, false, null,\n+              contextEncryptionAdapter, tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n+          LOG.debug(\"Marker creation failed for path {} during setPathProperties\", path);\n\nReview Comment:\n   It would be better we can log exception status code as well or some details of exception just to know what the exact reason of the failure is\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1242,7 +1246,12 @@ public AbfsRestOperation getPathStatus(final String path,\n           && isImplicitCheckRequired && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found.\n         // Create a marker blob at this path.\n-        this.createMarkerAtPath(path, null, contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createMarkerAtPath(path, null, contextEncryptionAdapter,\n+              tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n+          LOG.debug(\"Marker creation failed for path {} during getPathStatus \", path);\n\nReview Comment:\n   Same as above.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1160,8 +1160,12 @@ public AbfsRestOperation setPathProperties(final String path,\n       // This path could be present as an implicit directory in FNS.\n       if (op.getResult().getStatusCode() == HTTP_NOT_FOUND && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found, create a marker blob at this path and set properties.\n-        this.createPathRestOp(path, false, false, false, null,\n-            contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createPathRestOp(path, false, false, false, null,\n\nReview Comment:\n   Test case to check this change is not added, should we add that?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T07:44:23.726+0000", "updated": "2025-07-28T07:44:23.726+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010313", "id": "18010313", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235533414\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1160,8 +1160,12 @@ public AbfsRestOperation setPathProperties(final String path,\n       // This path could be present as an implicit directory in FNS.\n       if (op.getResult().getStatusCode() == HTTP_NOT_FOUND && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found, create a marker blob at this path and set properties.\n-        this.createPathRestOp(path, false, false, false, null,\n-            contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createPathRestOp(path, false, false, false, null,\n+              contextEncryptionAdapter, tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n+          LOG.debug(\"Marker creation failed for path {} during setPathProperties\", path);\n\nReview Comment:\n   +1 on this.\r\n   At least status code and storage error code (Enum like PATHNOTFOUND) we should print in debug log.\r\n   \r\n   Also a comment here on why we are swallowing the error for future reference will be better.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1242,7 +1246,12 @@ public AbfsRestOperation getPathStatus(final String path,\n           && isImplicitCheckRequired && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found.\n         // Create a marker blob at this path.\n-        this.createMarkerAtPath(path, null, contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createMarkerAtPath(path, null, contextEncryptionAdapter,\n+              tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n\nReview Comment:\n   Was keeping this behind a config not part of the plan?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T09:24:44.307+0000", "updated": "2025-07-28T09:24:44.307+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010316", "id": "18010316", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235546667\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1242,7 +1246,12 @@ public AbfsRestOperation getPathStatus(final String path,\n           && isImplicitCheckRequired && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found.\n         // Create a marker blob at this path.\n-        this.createMarkerAtPath(path, null, contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createMarkerAtPath(path, null, contextEncryptionAdapter,\n+              tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n\nReview Comment:\n   No we planned to just swallow exceptions instead of config changes\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T09:26:50.269+0000", "updated": "2025-07-28T09:26:50.269+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010328", "id": "18010328", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235613773\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1242,7 +1246,12 @@ public AbfsRestOperation getPathStatus(final String path,\n           && isImplicitCheckRequired && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found.\n         // Create a marker blob at this path.\n-        this.createMarkerAtPath(path, null, contextEncryptionAdapter, tracingContext);\n+        try {\n\nReview Comment:\n   For confirmation- we want to swallow exceptions only for metadata related operations and allow permission exceptions for all write ones (createDirectory, createFile)?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T09:44:20.187+0000", "updated": "2025-07-28T09:44:20.187+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010329", "id": "18010329", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235613773\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1242,7 +1246,12 @@ public AbfsRestOperation getPathStatus(final String path,\n           && isImplicitCheckRequired && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found.\n         // Create a marker blob at this path.\n-        this.createMarkerAtPath(path, null, contextEncryptionAdapter, tracingContext);\n+        try {\n\nReview Comment:\n   For confirmation- we want to swallow exceptions only for metadata related operations and allow permission exceptions for all write ones (createDirectory, createFile), correct?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T09:44:59.800+0000", "updated": "2025-07-28T09:44:59.800+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010340", "id": "18010340", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235721787\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1242,7 +1246,12 @@ public AbfsRestOperation getPathStatus(final String path,\n           && isImplicitCheckRequired && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found.\n         // Create a marker blob at this path.\n-        this.createMarkerAtPath(path, null, contextEncryptionAdapter, tracingContext);\n+        try {\n\nReview Comment:\n   marker creation is best effort for us, we don't want to fail the actual operation called if marker creation fails, so only for marker creation we are swallowing exception and not blocking the actual call\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T10:15:25.416+0000", "updated": "2025-07-28T10:15:25.416+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010362", "id": "18010362", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235940559\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1160,8 +1160,12 @@ public AbfsRestOperation setPathProperties(final String path,\n       // This path could be present as an implicit directory in FNS.\n       if (op.getResult().getStatusCode() == HTTP_NOT_FOUND && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found, create a marker blob at this path and set properties.\n-        this.createPathRestOp(path, false, false, false, null,\n-            contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createPathRestOp(path, false, false, false, null,\n\nReview Comment:\n   This change is no longer needed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T11:17:06.945+0000", "updated": "2025-07-28T11:17:06.945+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010363", "id": "18010363", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2235958717\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1160,8 +1160,12 @@ public AbfsRestOperation setPathProperties(final String path,\n       // This path could be present as an implicit directory in FNS.\n       if (op.getResult().getStatusCode() == HTTP_NOT_FOUND && isNonEmptyDirectory(path, tracingContext)) {\n         // Implicit path found, create a marker blob at this path and set properties.\n-        this.createPathRestOp(path, false, false, false, null,\n-            contextEncryptionAdapter, tracingContext);\n+        try {\n+          this.createPathRestOp(path, false, false, false, null,\n+              contextEncryptionAdapter, tracingContext);\n+        } catch (AbfsRestOperationException exception) {\n+          LOG.debug(\"Marker creation failed for path {} during setPathProperties\", path);\n\nReview Comment:\n   taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T11:22:27.340+0000", "updated": "2025-07-28T11:22:27.340+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010373", "id": "18010373", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3126864078\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m 29s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   2m 55s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   0m 25s | [/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -0 :warning: |  checkstyle  |   0m 23s | [/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   0m 25s | [/branch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/branch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 26s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 25s | [/branch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   2m 59s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 25s | [/patch-mvninstall-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-mvninstall-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   1m 27s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   1m 27s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 22s | [/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   0m 23s | [/patch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 18s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 23s | [/patch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   4m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   1m 55s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  asflicense  |   0m 39s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/results-asflicense.txt) |  The patch generated 1 ASF License warnings.  |\r\n   |  |   |  19m 45s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7825 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux dc108aee355c 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f28f92259789882b7b2455500a3d1765de294bd5 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/testReport/ |\r\n   | Max. process+thread count | 129 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T11:49:16.278+0000", "updated": "2025-07-28T11:49:16.278+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010385", "id": "18010385", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3127003915\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  3s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 25s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   0m 26s | [/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 26s | [/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -0 :warning: |  checkstyle  |   0m 22s | [/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   0m 28s | [/branch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/branch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 12s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   2m 47s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 28s | [/branch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   5m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 26s | [/patch-mvninstall-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-mvninstall-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 26s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 26s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 26s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 26s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 25s | [/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   0m 26s | [/patch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 27s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 51s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  spotbugs  |   2m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |   3m  8s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 24s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 10s |  |  ASF License check generated no output?  |\r\n   |  |   |  19m 43s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7825 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 39f7d777211b 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e8472eb4cee9abd4ebe5e349175bb90082c06c61 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/testReport/ |\r\n   | Max. process+thread count | 78 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T12:27:48.358+0000", "updated": "2025-07-28T12:27:48.358+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010410", "id": "18010410", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3127345361\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m  4s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 18s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 52s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 58s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7825 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 1446327a7baa 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f28f92259789882b7b2455500a3d1765de294bd5 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/2/testReport/ |\r\n   | Max. process+thread count | 547 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T13:51:56.753+0000", "updated": "2025-07-28T13:51:56.753+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010544", "id": "18010544", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2238281684\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java:\n##########\n@@ -167,6 +168,30 @@ public void testBlobDataReader() throws Exception {\n \n   }\n \n+  /*\n+   * GetPathStatus with Blob Data Reader role should not throw an exception when marker creation fails due to permission issues.\n+   * */\n+  @Test\n+  public void testGetPathStatusWithReader() throws Exception {\n+    String clientId = this.getConfiguration().get(TestConfigurationKeys.FS_AZURE_BLOB_DATA_READER_CLIENT_ID);\n\nReview Comment:\n   Nit: since we have already imported TestConfigurationKeys constants we can use FS_AZURE_BLOB_DATA_READER_CLIENT_ID and FS_AZURE_BLOB_DATA_READER_CLIENT_SECRET directly\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T03:00:25.900+0000", "updated": "2025-07-29T03:00:25.900+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010547", "id": "18010547", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#discussion_r2238320094\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java:\n##########\n@@ -167,6 +168,30 @@ public void testBlobDataReader() throws Exception {\n \n   }\n \n+  /*\n+   * GetPathStatus with Blob Data Reader role should not throw an exception when marker creation fails due to permission issues.\n+   * */\n+  @Test\n+  public void testGetPathStatusWithReader() throws Exception {\n+    String clientId = this.getConfiguration().get(TestConfigurationKeys.FS_AZURE_BLOB_DATA_READER_CLIENT_ID);\n\nReview Comment:\n   taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T03:21:11.161+0000", "updated": "2025-07-29T03:21:11.161+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010550", "id": "18010550", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3130529507\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  8s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 31s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |\r\n   | -1 :x: |  compile  |   0m 25s | [/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 25s | [/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/branch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -0 :warning: |  checkstyle  |   0m 23s | [/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/buildtool-branch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   3m  6s | [/branch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/branch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/branch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 25s | [/branch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in trunk failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   5m 41s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | -1 :x: |  mvninstall  |   0m 24s | [/patch-mvninstall-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-mvninstall-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   0m 24s | [/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m  8s | [/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/buildtool-patch-checkstyle-hadoop-tools_hadoop-azure.txt) |  The patch fails to run checkstyle in hadoop-azure  |\r\n   | -1 :x: |  mvnsite  |   0m 24s | [/patch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-mvnsite-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | -1 :x: |  javadoc  |   0m 24s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  hadoop-azure in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  hadoop-azure in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  spotbugs  |   0m 25s | [/patch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-spotbugs-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +1 :green_heart: |  shadedclient  |   4m  6s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   0m 25s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) |  hadoop-azure in the patch failed.  |\r\n   | +0 :ok: |  asflicense  |   0m 24s |  |  ASF License check generated no output?  |\r\n   |  |   |  16m 12s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7825 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux f2985c2e055a 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4640893a4e42f4ea3249fb4974e3142b72e80e12 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/testReport/ |\r\n   | Max. process+thread count | 41 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T03:38:35.225+0000", "updated": "2025-07-29T03:38:35.225+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010892", "id": "18010892", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3135939508\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  1s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  42m 37s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/7/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 43s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 57s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 28s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7825 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 25cf764a5bf9 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 8dc9cdc11db577814800d19f5dce3a6ed3d2a5d9 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/7/testReport/ |\r\n   | Max. process+thread count | 530 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T11:48:38.042+0000", "updated": "2025-07-30T11:48:38.042+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18010947", "id": "18010947", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825#issuecomment-3136596005\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 32s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 30s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 30s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 57s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 37s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 144m 48s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7825 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux ef313b1a3b7c 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bef0a6c2b1e17cbdaa7612bb823f500c193d8a2c |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/8/testReport/ |\r\n   | Max. process+thread count | 533 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7825/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T14:24:26.585+0000", "updated": "2025-07-30T14:24:26.585+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624383/comment/18011145", "id": "18011145", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7825:\nURL: https://github.com/apache/hadoop/pull/7825\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-31T11:02:52.115+0000", "updated": "2025-07-31T11:02:52.115+0000"}], "maxResults": 21, "total": 21, "startAt": 0}, "updated": "2025-09-30T10:09:13.000+0000", "created": "2025-07-23T12:14:47.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624380", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624380", "key": "HADOOP-19634", "fields": {"summary": "acknowledge Guava license on LimitInputStream", "description": "When ASF projects copy 3rd party code into their code bases, they are meant to:\r\n* check the orginal license is Category A - https://www.apache.org/legal/resolved.html\r\n* keep the original source code headers\r\n* add something to their LICENSE that mentions the source file and what license is on it\r\n* if the 3rd party project is Apache licensed but has a NOTICE file, we need to copy its contents to our NOTICE\r\n* these requirements are only negated if the original code is submitted to the ASF project by the code's copyright holder (the individual or company that wrote the original code).\r\n\r\n* Hadoop copy https://github.com/apache/hadoop/blob/c357e435fd691b4c184b82325bef6d7c65e5f32b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java#L39\r\n* Original code has a Guava copyright that we probably need to keep https://github.com/google/guava/blob/master/guava/src/com/google/common/io/ByteStreams.java", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624380/comment/18009245", "id": "18009245", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #7821:\nURL: https://github.com/apache/hadoop/pull/7821\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   See https://issues.apache.org/jira/browse/HADOOP-19634\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-23T12:08:24.188+0000", "updated": "2025-07-23T12:08:24.188+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624380/comment/18009322", "id": "18009322", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7821:\nURL: https://github.com/apache/hadoop/pull/7821\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-23T16:38:18.863+0000", "updated": "2025-07-23T16:38:18.863+0000"}], "maxResults": 2, "total": 2, "startAt": 0}, "updated": "2025-07-23T16:42:06.000+0000", "created": "2025-07-23T11:57:14.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624358", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624358", "key": "HADOOP-19633", "fields": {"summary": "upgrade commons-beanutils to 1.11.0", "description": null, "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "updated": "2025-07-23T09:01:52.000+0000", "created": "2025-07-23T09:01:52.000+0000"}}
{"expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields", "id": "13624357", "self": "https://issues.apache.org/jira/rest/api/latest/issue/13624357", "key": "HADOOP-19632", "fields": {"summary": "Upgrade nimbusds to 10.0.2", "description": "Includes fix for CVE-2025-53864", "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18010623", "id": "18010623", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=fanningpj", "name": "fanningpj", "key": "fanningpj", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "PJ Fanning", "active": true, "timeZone": "Europe/Madrid"}, "body": "[~ananysin] the version is wrong - we need at least 10.0.2 to fix https://www.cve.org/CVERecord?id=CVE-2025-53864\r\n\r\nI would suggest using the latest - 10.4", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=fanningpj", "name": "fanningpj", "key": "fanningpj", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "PJ Fanning", "active": true, "timeZone": "Europe/Madrid"}, "created": "2025-07-29T09:53:33.529+0000", "updated": "2025-07-29T09:53:33.529+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18010795", "id": "18010795", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ananysin", "name": "ananysin", "key": "ananysin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34049", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34049", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34049", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34049"}, "displayName": "Ananya Singh", "active": true, "timeZone": "Etc/UTC"}, "body": "Sure [~fanningpj]\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ananysin", "name": "ananysin", "key": "ananysin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34049", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34049", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34049", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34049"}, "displayName": "Ananya Singh", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T04:04:00.549+0000", "updated": "2025-07-30T04:04:00.549+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18010798", "id": "18010798", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "AnanyaSingh2121 opened a new pull request, #7836:\nURL: https://github.com/apache/hadoop/pull/7836\n\n   (no comment)\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T04:46:00.375+0000", "updated": "2025-07-30T04:46:00.375+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18010827", "id": "18010827", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3135017183\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  44m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 21s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  88m 13s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 13s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 13s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 12s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  10m 27s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   0m 15s |  |  hadoop-project in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 34s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 102m 53s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7836 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint |\r\n   | uname | Linux a9ee212ce67e 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ebe2cfe49dfcbd6d3d42732a2a0f11cb476d7556 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/1/testReport/ |\r\n   | Max. process+thread count | 525 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project U: hadoop-project |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T06:30:14.959+0000", "updated": "2025-07-30T06:30:14.959+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18013795", "id": "18013795", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning opened a new pull request, #7870:\nURL: https://github.com/apache/hadoop/pull/7870\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   CVE-2025-53864 fix has now appeared in 9.37.4\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-13T23:30:04.379+0000", "updated": "2025-08-13T23:30:04.379+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18013887", "id": "18013887", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7870:\nURL: https://github.com/apache/hadoop/pull/7870#issuecomment-3187924858\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 31s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 45s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  16m 48s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 47s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 14s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 46s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 10s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 34s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  31m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 20s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  14m  4s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  14m  4s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 47s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 36s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 359m 25s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/1/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 13s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 648m 35s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7870 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 78fd5943d0a3 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5428389323ee3d1a20cc1bca948d55556634be91 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/1/testReport/ |\r\n   | Max. process+thread count | 3329 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-14T10:19:57.316+0000", "updated": "2025-08-14T10:19:57.316+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18014241", "id": "18014241", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7870:\nURL: https://github.com/apache/hadoop/pull/7870#issuecomment-3193392751\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 47s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  32m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 53s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 49s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 43s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 51s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  52m  1s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  31m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 30s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 50s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 38s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 44s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 357m 15s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/2/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 10s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 643m 11s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7870 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux e1aa30c14bc2 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b71c33b81f0ddc3c6b5380c9c38b01b9fcef73f4 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/2/testReport/ |\r\n   | Max. process+thread count | 2991 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-16T05:04:30.655+0000", "updated": "2025-08-16T05:04:30.655+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18016085", "id": "18016085", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ayushtkn commented on code in PR #7870:\nURL: https://github.com/apache/hadoop/pull/7870#discussion_r2299062286\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -244,7 +244,7 @@\n     <openssl-wildfly.version>2.1.4.Final</openssl-wildfly.version>\n     <jsonschema2pojo.version>1.0.2</jsonschema2pojo.version>\n     <woodstox.version>5.4.0</woodstox.version>\n-    <nimbus-jose-jwt.version>9.37.2</nimbus-jose-jwt.version>\n+    <nimbus-jose-jwt.version>9.37.4</nimbus-jose-jwt.version>\n\nReview Comment:\n   why don't we move to 9.48?\r\n   https://mvnrepository.com/artifact/com.nimbusds/nimbus-jose-jwt/9.48\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T20:30:00.488+0000", "updated": "2025-08-25T20:30:00.488+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18016097", "id": "18016097", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on code in PR #7870:\nURL: https://github.com/apache/hadoop/pull/7870#discussion_r2299121430\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -244,7 +244,7 @@\n     <openssl-wildfly.version>2.1.4.Final</openssl-wildfly.version>\n     <jsonschema2pojo.version>1.0.2</jsonschema2pojo.version>\n     <woodstox.version>5.4.0</woodstox.version>\n-    <nimbus-jose-jwt.version>9.37.2</nimbus-jose-jwt.version>\n+    <nimbus-jose-jwt.version>9.37.4</nimbus-jose-jwt.version>\n\nReview Comment:\n   @ayushtkn 9.48 is affected by CVE-2025-8916 while 9.37.4 was specifically patched with the fix.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T20:56:53.399+0000", "updated": "2025-08-25T20:56:53.399+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18016098", "id": "18016098", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on code in PR #7870:\nURL: https://github.com/apache/hadoop/pull/7870#discussion_r2299121430\n\n\n##########\nhadoop-project/pom.xml:\n##########\n@@ -244,7 +244,7 @@\n     <openssl-wildfly.version>2.1.4.Final</openssl-wildfly.version>\n     <jsonschema2pojo.version>1.0.2</jsonschema2pojo.version>\n     <woodstox.version>5.4.0</woodstox.version>\n-    <nimbus-jose-jwt.version>9.37.2</nimbus-jose-jwt.version>\n+    <nimbus-jose-jwt.version>9.37.4</nimbus-jose-jwt.version>\n\nReview Comment:\n   @ayushtkn 9.48 is affected by CVE-2025-53864 while 9.37.4 was specifically patched with the fix.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-25T20:58:58.736+0000", "updated": "2025-08-25T20:58:58.736+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18016190", "id": "18016190", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "AnanyaSingh2121 commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3222609894\n\n   Added the changes for License-binary\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T04:50:56.060+0000", "updated": "2025-08-26T04:50:56.060+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18016257", "id": "18016257", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3223593915\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 10s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   8m 45s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  20m  3s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 23s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 26s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  15m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 36s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 45s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  30m 53s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   6m 44s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |   2m 32s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  compile  |   3m 56s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   3m 56s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   3m 45s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   3m 45s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   9m 26s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 14s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 49s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  15m 57s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 199m 10s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 43s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 342m 58s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7836 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux ab7be46c111d 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bf57741c9f666feb5859857cc65d3ee40545044f |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/testReport/ |\r\n   | Max. process+thread count | 3926 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-26T10:33:04.986+0000", "updated": "2025-08-26T10:33:04.986+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18019419", "id": "18019419", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7870:\nURL: https://github.com/apache/hadoop/pull/7870#issuecomment-3275915284\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 33s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m  7s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  33m  2s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 46s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 37s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  21m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m  7s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 50s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  52m 20s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  31m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 10s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 44s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 13s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 37s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 51s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 29s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 803m 41s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/4/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 49s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1087m 43s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.mapreduce.v2.TestUberAM |\r\n   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n   |   | hadoop.yarn.server.router.webapp.TestFederationWebApp |\r\n   |   | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler |\r\n   |   | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7870 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux f41a9b0d025f 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / d15e31597255bf5bb43434b3c493900f315096fa |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/4/testReport/ |\r\n   | Max. process+thread count | 3705 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7870/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-10T17:38:37.102+0000", "updated": "2025-09-10T17:38:37.102+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18020421", "id": "18020421", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3293226585\n\n   build failed.\r\n   @AnanyaSingh2121 can you rebase and force push to see what happens against trunk now. thanks\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:33:10.605+0000", "updated": "2025-09-15T17:33:10.605+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18020425", "id": "18020425", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3293253190\n\n   @steveloughran https://github.com/apache/hadoop/pull/7965 seems to be a more accurate attempt at this.\r\n   \r\n   I also have https://github.com/apache/hadoop/pull/7870 which also fixes the CVE by upgrading a 9.x patch that was specially released with the CVE fix.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-15T17:39:41.106+0000", "updated": "2025-09-15T17:39:41.106+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18020890", "id": "18020890", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3302359120\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 42s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  24m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 33s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 34s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  14m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 31s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 53s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  31m  4s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 25s |  |  Maven dependency ordering for patch  |\r\n   | -1 :x: |  mvninstall  |   7m 31s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/patch-mvninstall-root.txt) |  root in the patch failed.  |\r\n   | -1 :x: |  compile  |   4m  1s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  javac  |   4m  1s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) |  root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.  |\r\n   | -1 :x: |  compile  |   3m 43s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | -1 :x: |  javac  |   3m 43s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) |  root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -1 :x: |  mvnsite  |   9m 30s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/patch-mvnsite-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 23s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 53s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | -1 :x: |  shadedclient  |  16m  5s |  |  patch has errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 265m 23s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 41s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 406m 50s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.server.balancer.TestBalancerLongRunningTasks |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7836 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 8e30f3250d87 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c7db3f77b8f6ed3c5f30e632a247d93af2ebbac0 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/testReport/ |\r\n   | Max. process+thread count | 4186 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7836/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T10:29:59.029+0000", "updated": "2025-09-17T10:29:59.029+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18020997", "id": "18020997", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3304801731\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 51s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 52s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 57s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 49s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  21m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 44s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  53m  6s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 44s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 21s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 42s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 38s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 47s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 12s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 450m 48s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/3/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 14s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 754m 15s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7965 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux e199fa50a2f0 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b51e3a0ed589cdad9206e767d8ff6344ce088c3d |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/3/testReport/ |\r\n   | Max. process+thread count | 3299 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router hadoop-tools/hadoop-sls . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-17T23:05:57.402+0000", "updated": "2025-09-17T23:05:57.402+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021024", "id": "18021024", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3304976023\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 53s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 34s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 59s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 33s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 22s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 55s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  59m 12s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  49m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 52s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m 26s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  16m 26s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |  10m 51s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m 10s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  62m 23s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 503m 12s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/2/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 848m 20s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7965 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 903ae8a8a984 5.15.0-151-generic #161-Ubuntu SMP Tue Jul 22 14:25:40 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 03d76d18b073b38de6c01c1d2c724f9feba7d793 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/2/testReport/ |\r\n   | Max. process+thread count | 3484 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router hadoop-tools/hadoop-sls . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T00:32:40.312+0000", "updated": "2025-09-18T00:32:40.312+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021140", "id": "18021140", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3306891395\n\n   @pjfanning could you please take a look at this again whenever you have time? Thanks\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T11:15:51.265+0000", "updated": "2025-09-18T11:15:51.265+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021145", "id": "18021145", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3306924014\n\n   the test build crashed\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T11:23:50.266+0000", "updated": "2025-09-18T11:23:50.266+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021149", "id": "18021149", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3307020292\n\n   Could you please help understand how the test build crashed as I am a bit confused about the CI process here? \r\n   \r\n   As per this execution: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/2/testReport/history/ \r\n   The attempt #3 has no test failures with 19K+ passes and 300+ skips. Thanks\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-18T11:47:07.968+0000", "updated": "2025-09-18T11:47:07.968+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021381", "id": "18021381", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3311743722\n\n   I'll let one of the Hadoop committers review this. The CI jobs can be flaky and when I want to rerun them, I rebase the PR to cause a new run.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T10:56:38.671+0000", "updated": "2025-09-19T10:56:38.671+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021435", "id": "18021435", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3312539483\n\n   @rohit-kb do a rebase and a force push to trigger a new yetus build. thanks\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-19T14:58:26.219+0000", "updated": "2025-09-19T14:58:26.219+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021539", "id": "18021539", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3314493477\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 34s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  11m 40s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  15m 59s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  13m 42s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   9m 44s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 56s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  52m  7s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 37s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  40m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  13m 36s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  13m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   9m 39s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 52s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  53m 51s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 460m 19s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/4/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 17s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 765m 28s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7965 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 4dc676b6b738 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 13d0d0419323bc818420a9321e593f886eeda4c0 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/4/testReport/ |\r\n   | Max. process+thread count | 3396 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router hadoop-tools/hadoop-sls . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-20T03:51:12.608+0000", "updated": "2025-09-20T03:51:12.608+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021945", "id": "18021945", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3321392221\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  22m 11s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  10m 27s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  18m  8s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  16m 52s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   8m  5s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  57m 45s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  47m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  17m 35s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  17m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 46s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |  10m 17s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 58s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  61m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 505m 36s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/5/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 22s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 869m 23s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7965 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 7a0cad96adcb 5.15.0-151-generic #161-Ubuntu SMP Tue Jul 22 14:25:40 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4aee820e7dff92a6b86afde61f29d1391e284302 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/5/testReport/ |\r\n   | Max. process+thread count | 3598 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router hadoop-tools/hadoop-sls . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-22T20:31:37.678+0000", "updated": "2025-09-22T20:31:37.678+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18021992", "id": "18021992", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3322038031\n\n   I am able to run the crashed tests locally:\r\n   `[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMHAForAsyncScheduler\r\n   [INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.61 s ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T01:08:40.608+0000", "updated": "2025-09-23T01:08:40.608+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022199", "id": "18022199", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T15:35:47.074+0000", "updated": "2025-09-23T15:35:47.074+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022200", "id": "18022200", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3324549237\n\n   @rohit-kb - merged. will take a backport to branch-3.4\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T15:36:10.203+0000", "updated": "2025-09-23T15:36:10.203+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022201", "id": "18022201", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3324573362\n\n   Thanks @slfan1989, @steveloughran for the review and the merge!  Will upload to branch-3.4 soon\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T15:42:26.389+0000", "updated": "2025-09-23T15:42:26.389+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022202", "id": "18022202", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7965:\nURL: https://github.com/apache/hadoop/pull/7965#issuecomment-3324609056\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |  12m 33s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  46m 52s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |  17m 56s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 13s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  23m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |  10m 24s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 47s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  59m  0s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 35s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  49m 48s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  18m 12s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  18m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 58s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 58s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  19m 47s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |  11m 15s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   9m 17s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  65m 15s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 529m 32s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/6/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 33s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 880m 49s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7965 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 073c181e5730 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 54195011a5d3bdb01704484607b66a24d854a2b3 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/6/testReport/ |\r\n   | Max. process+thread count | 2509 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router hadoop-tools/hadoop-sls . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7965/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T15:52:26.557+0000", "updated": "2025-09-23T15:52:26.557+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022216", "id": "18022216", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb opened a new pull request, #7993:\nURL: https://github.com/apache/hadoop/pull/7993\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T16:56:25.352+0000", "updated": "2025-09-23T16:56:25.352+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022264", "id": "18022264", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3325673729\n\n   #7965 was merged making this obsolete?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T21:56:13.067+0000", "updated": "2025-09-23T21:56:13.067+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022265", "id": "18022265", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning closed pull request #7870: HADOOP-19632. Upgrade to nimbus-jose-jwt 9.37.4 due to CVE-2025-53864\nURL: https://github.com/apache/hadoop/pull/7870\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T21:56:36.763+0000", "updated": "2025-09-23T21:56:36.763+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022266", "id": "18022266", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "pjfanning commented on PR #7870:\nURL: https://github.com/apache/hadoop/pull/7870#issuecomment-3325674481\n\n   https://github.com/apache/hadoop/pull/7965 was merged making this obsolete\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-23T21:56:37.658+0000", "updated": "2025-09-23T21:56:37.658+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022356", "id": "18022356", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7993:\nURL: https://github.com/apache/hadoop/pull/7993#issuecomment-3327115927\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  12m  8s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   3m  1s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  34m 38s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |  16m 54s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  15m 56s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  mvnsite  |  22m  6s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   8m 24s |  |  branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 36s |  |  branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  48m  5s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  30m  2s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  16m  6s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  16m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |  15m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |  18m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   8m 16s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 39s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  shadedclient  |  49m  6s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 622m 40s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7993/1/artifact/out/patch-unit-root.txt) |  root in the patch failed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  9s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 909m 22s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Unreaped Processes | root:2 |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7993/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7993 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |\r\n   | uname | Linux 56e26a8a857e 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / b0c85b602202ff0f371a6ead734a230805a248a0 |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Unreaped Processes Log | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7993/1/artifact/out/patch-unit-root-reaper.txt |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7993/1/testReport/ |\r\n   | Max. process+thread count | 4564 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router hadoop-tools/hadoop-sls . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7993/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T08:07:06.104+0000", "updated": "2025-09-24T08:07:06.104+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022369", "id": "18022369", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 merged PR #7993:\nURL: https://github.com/apache/hadoop/pull/7993\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T08:54:55.073+0000", "updated": "2025-09-24T08:54:55.073+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022370", "id": "18022370", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "slfan1989 commented on PR #7993:\nURL: https://github.com/apache/hadoop/pull/7993#issuecomment-3327295427\n\n   @rohit-kb Thanks for the contribution! Merged into branch-3.4.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T08:56:40.565+0000", "updated": "2025-09-24T08:56:40.565+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022374", "id": "18022374", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "rohit-kb commented on PR #7993:\nURL: https://github.com/apache/hadoop/pull/7993#issuecomment-3327346430\n\n   Thanks @slfan1989 for the review and the merge\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T09:10:17.658+0000", "updated": "2025-09-24T09:10:17.658+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022458", "id": "18022458", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran closed pull request #7836: HADOOP-19632 : Upgrade nimbusds to 10.4\nURL: https://github.com/apache/hadoop/pull/7836\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T15:17:02.016+0000", "updated": "2025-09-24T15:17:02.016+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13624357/comment/18022459", "id": "18022459", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7836:\nURL: https://github.com/apache/hadoop/pull/7836#issuecomment-3329278859\n\n   yes it does; closing this\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-09-24T15:17:02.888+0000", "updated": "2025-09-24T15:17:02.888+0000"}], "maxResults": 40, "total": 40, "startAt": 0}, "updated": "2025-09-24T15:17:03.000+0000", "created": "2025-07-23T09:00:38.000+0000"}}
